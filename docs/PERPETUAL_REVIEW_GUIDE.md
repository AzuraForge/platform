# 📜 AzuraForge: Sürekli İnceleme ve İterasyon Rehberi

**AzuraForge projesinin her bir iterasyon başlangıcında, ana geliştirme toplantılarında veya kritik bir stratejik karar noktasında başvurulacak "Anayasası"dır.** Bu rehber, projemizi farklı uzmanlık perspektiflerinden sistematik bir şekilde değerlendirmemizi sağlar. Amacımız, **"The AzuraForge Way"** felsefesine bağlı kalarak, her adımı bilinçli, sağlam, yenilikçi ve ileriye dönük atmaktır.

**Bu Belge Neden Var?**
*   **Kör Noktaları Giderme:** Her bir uzmanın kendi alanındaki kör noktalarını aşmasını ve farklı bakış açılarını entegre etmesini sağlar.
*   **Riskleri Erken Tespit Etme:** Potansiyel teknik, operasyonel, pazar veya kullanıcı deneyimi risklerini proaktif olarak belirler.
*   **İnovasyonu Teşvik Etme:** Her perspektiften yeni fikirlerin ve iyileştirme alanlarının ortaya çıkmasını sağlar.
*   **Vizyon ve Misyon Hizalaması:** Tüm çalışmaların "The AzuraForge Way" felsefesi ve uzun vadeli yol haritası ile uyumlu kalmasını garanti eder.
*   **Bilinçli Karar Alma:** Önemli kararların çok yönlü değerlendirilmesine dayalı olmasını sağlar.

---

### **Nasıl Kullanılır:**

1.  **Toplantı Zamanlaması:** Her iterasyon planlama toplantısının başında, ana ürün stratejisi incelemelerinde veya önemli bir mimari/teknik karar toplantısında bu rehber açılır.
2.  **Sorumluluk Dağılımı:** Toplantıya katılan ilgili ekip üyeleri (veya belirlenen bir lider), kendi sorumluluklarındaki perspektifleri incelemek ve bu bölümdeki soruları temel alarak bulgularını sunmakla görevlendirilir.
3.  **Perspektif Odaklı Değerlendirme:** Her uzman, kendi bölümündeki soruları dikkate alarak, planlanan yeni özellikler, mevcut durum ve potansiyel sorunlar hakkında bulgularını ve görüşlerini paylaşır. Bu bir beyin fırtınası oturumu şeklinde ilerleyebilir.
4.  **Bulguları ve Kararları Belgele:** Her perspektiften çıkan önemli güçlü yönler, geliştirme alanları, yeni fikirler ve toplantıda alınan kararlar, toplantı notlarına, ürün backlog'una veya ilgili proje yönetim araçlarındaki (Jira, Trello vb.) kartlara işlenir.
5.  **Geri Bildirim ve Entegrasyon:** Toplanan bilgiler, iterasyonun backlog'una dönüştürülerek önceliklendirilir, risk listesine eklenir, teknik borç envanterine işlenir veya araştırma maddeleri olarak belirlenir.
6.  **Dinamik Belge:** Bu rehber, projenin büyümesi, teknolojik değişimler veya yeni zorluklar ortaya çıktıkça sürekli olarak gözden geçirilmeli ve güncellenmelidir.

---

### **1. Ürün Yöneticisi Perspektifi**

*   **Sorumlu Kişi/Roller:** Ürün Yöneticisi, Proje Yöneticisi (stratejik danışmanlık), UX Tasarımcısı (kullanıcı ihtiyaçları).
*   **Odak:** Pazara uygunluk, kullanıcı değeri, ürün vizyonu ve yol haritası hizalaması, rekabet analizi, anahtar performans göstergeleri (KPI'lar), kullanıcı geri bildirimleri, ürün önceliklendirmesi ve kapsam yönetimi.
*   **Sorulacak Sorular:**
    *   Bu iterasyonda ele alacağımız özellik(ler) veya düzeltme(ler), **hangi spesifik kullanıcı sorununu çözüyor** veya **hangi pazar ihtiyacını karşılıyor**? Bu, kullanıcının hayatında somut olarak neyi değiştirecek?
    *   Bu işler, AzuraForge'un genel **ürün vizyonu** ve uzun vadeli **yol haritası** (Faz 0, Faz 1, Faz 2, Faz 3) ile ne kadar uyumlu? Bu bize "Uzay Gemisi Şasisi" hedefimize ne kadar yaklaştırıyor? Gerekirse yol haritasını revize etmeli miyiz?
    *   Bu iterasyonun veya özelliğin başarısını ölçecek **anahtar performans göstergeleri (KPI'lar)** nelerdir? (Örn: Deney başlatma sayısı, aktif kullanıcı sayısı, model eğitim başarı oranı, rapor görüntüleme sıklığı). Bu metrikleri nasıl takip edip analiz edeceğiz?
    *   **Rakiplerimiz** AzuraForge'a benzer hangi çözümleri sunuyor? Bu değişiklik bizi onlardan nasıl ayırıyor veya onlara karşı nasıl bir **rekabet avantajı** sağlıyor?
    *   Kullanıcılardan gelen **geri bildirimleri** (destek talepleri, anketler, sosyal medya, canlı gözlem) yeterince topluyor ve değerlendiriyor muyuz? Bu geri bildirimler mevcut veya planlanan işlerimizi nasıl etkiliyor?
    *   Minimum Viable Product (MVP) kapsamını koruyabiliyor muyuz, yoksa "nice-to-have" (olsa iyi olur) özelliklerle **kapsam genişlemesi (scope creep)** yaşıyor muyuz? Önceliklendirme ne kadar net?
    *   Bu özelliğin veya değişikliğin **iş etkisi/değeri** nedir? Bu değer, geliştirme maliyetini haklı çıkarıyor mu?
*   **Actionable Çıktılar (İterasyon Planı için):**
    *   Güncellenmiş ürün backlog'u ve önceliklendirme kararları.
    *   Net ve ölçülebilir başarı metrikleri ile tanımlanmış özellikler (user story'ler).
    *   Kullanıcı araştırması veya anket planları.
    *   Rekabet analizi raporları ve ürün konumlandırma stratejileri.

---

### **2. Proje Yöneticisi Perspektifi**

*   **Sorumlu Kişi/Roller:** Proje Yöneticisi, Takım Liderleri, Geliştiriciler.
*   **Odak:** Operasyonel kapsam, kaynak tahsisi, zaman çizelgesi, bütçe, ekip koordinasyonu, proje içi ve dışı bağımlılıklar, proje riskleri, iç ve dış paydaşlara ilerleme raporlama.
*   **Sorulacak Sorular:**
    *   Bu iterasyonda ele alacağımız işlerin **kapsamı net ve tanımlı** mı? Kapsam kayması riski var mı ve bunu nasıl yöneteceğiz?
    *   Ekip üyelerinin **iş yükü dengeli** mi? Teknik kaynaklar (örn. GPU erişimi, Redis/Postgres kapasitesi, depolama alanı) mevcut backlog'u karşılamak için yeterli tahsis edildi mi? Potansiyel darboğazlar veya kapasite sınırlamaları var mı?
    *   Planlanan işler için **tahmini zaman çizelgesi** gerçekçi mi? Geçmiş performans verilerimize göre ayarlamalar yapmalı mıyız?
    *   Repolar arası bağımlılıklar (özellikle `pyproject.toml` veya `package.json` güncellemeleri) için **süreç net mi ve yönetilebilir durumda mı**? Yeni bir kütüphane yayını, bağımlı repolarda beklenmedik sorunlar yaratır mı? **Otomatik bağımlılık senkronizasyonu için bir plan var mıydı, ne aşamada?**
    *   Planlanan işlerde veya mevcut sistemde **potansiyel riskler** (teknik borç birikimi, performans düşüşü, güvenlik açığı, insan kaynağı riski) nelerdir? Bu riskleri nasıl önceliklendirip nasıl yöneteceğiz veya azaltacağız?
    *   İç paydaşlara (ekip liderleri, üst yönetim) **ilerleme durumu raporlaması** yeterince şeffaf ve düzenli mi? Bilgi akışı sağlıklı mı?
    *   Proje **bütçesi** kontrol altında mı? Yeni araçlar, servisler veya altyapı için ek maliyetler öngörülüyor mu? Maliyet optimizasyonu fırsatları var mı?
*   **Actionable Çıktılar (İterasyon Planı için):**
    *   Sprint backlog'unun detaylı planı ve görev dağılımı.
    *   Kaynak tahsis raporları ve olası takviye/dengesiz dağılım planları.
    *   Proje risk kayıt defteri ve azaltma stratejileri.
    *   İletişim planları ve ilerleme raporlama şablonları.

---

### **3. Ürün Tasarımcısı (Sistem & UX) Perspektifi**

*   **Sorumlu Kişi/Roller:** UX/UI Tasarımcısı, Ürün Yöneticisi, Ön Yüz Geliştiricisi.
*   **Odak:** Kullanıcı deneyimi, kullanılabilirlik, arayüz tutarlılığı, etkileşim tasarımı, görsel tasarım, erişilebilirlik, hata geri bildirimleri, kullanıcı akışları.
*   **Sorulacak Sorular:**
    *   Planlanan yeni özellikler, kullanıcıların AzuraForge ile olan genel **etkileşim akışına sorunsuz bir şekilde entegre oluyor mu**? Kullanım karmaşıklığını artırıyor mu?
    *   Kullanıcı arayüzü genelinde (Dashboard, paneller, formlar, raporlar) **görsel tutarlılık ve marka kimliği** korunuyor mu? CSS değişkenleri, component kütüphanesi ve tipografi standartlara uyuyor mu?
    *   **Hata mesajları** kullanıcı için açıklayıcı ve yol gösterici mi, yoksa teknik detaylarla dolu mu? Kullanıcılar bir eylemin sonucunu veya bir hatanın nedenini kolayca anlayabiliyor mu?
    *   Formlar, canlı takip panelleri ve interaktif raporlar gibi **kritik etkileşim noktalarında kullanıcı deneyimi** ne kadar sezgisel ve akıcı? Özellikle "batch" deneyleri veya liste girişi gibi karmaşık girdiler yeterince anlaşılır mı?
    *   Uygulama genelinde **erişilebilirlik standartlarına** (klavye navigasyonu, ekran okuyucu uyumu, renk kontrastları) ne kadar uyumluyuz? Bu iterasyonda geliştirme yaparken bunları göz önünde bulunduruyor muyuz?
    *   Kullanıcı geribildirimlerini almak için **dahili bir mekanizma** (feedback formu, anket pop-up'ı) entegre edebilir miyiz?
*   **Actionable Çıktılar (İterasyon Planı için):**
    *   Detaylı kullanıcı akış şemaları ve senaryoları.
    *   Güncellenmiş UI/UX prototipleri, wireframe'ler veya mock-up'lar.
    *   Kullanılabilirlik testleri (A/B testi, kullanıcı görüşmeleri) planları ve bulguları.
    *   Hata mesajı ve geri bildirim mekanizması iyileştirme görevleri.
    *   Erişilebilirlik denetimi ve düzeltme görevleri.

---

### **4. Arka Uç Geliştirici Perspektifi**

*   **Sorumlu Kişi/Roller:** Backend Geliştiricileri, AI Mimarı (altyapı ve API bağımlılıkları), Run Yöneticisi (altyapı entegrasyonu).
*   **Odak:** API tasarımı ve tutarlılığı, veri modelleri, iş mantığı implementasyonu, performans, güvenlik, ölçeklenebilirlik, veritabanı işlemleri, servisler arası iletişim güvenilirliği.
*   **Sorulacak Sorular:**
    *   Planlanan yeni API endpoint'leri veya mevcutların değişiklikleri, genel **API tasarımı ve RESTful prensiplerine** uygun mu? Geriye dönük uyumluluk nasıl sağlanacak? Versiyonlama stratejisi net mi?
    *   Veritabanı şeması değişiklikleri için bir **veri geçiş (migration) stratejisi** belirlendi mi? Canlı ortamda potansiyel performans veya kilitlenme riskleri var mı?
    *   API'nin Worker'ın dahili yapısına olan **bağımlılığı (örn. pipeline keşfi)** hala mevcut mu? Bu bağımlılığı nasıl azaltabilir veya tamamen ortadan kaldırabiliriz? Servisleri daha bağımsız hale getirmek için ne gibi refactoring'ler yapılabilir?
    *   Celery görev kuyruğu performansı ve hata toleransı ne durumda? Redis üzerindeki **yük ve Celery worker yoğunluğu** izleniyor mu? Aşırı yüklenme durumunda ne oluyor?
    *   Sistem genelinde **veri güvenliği** (hassas API anahtarları, veritabanı şifreleri, kimlik doğrulama tokenları) için mevcut en iyi pratikler uygulanıyor mu? Sır yönetimi stratejisi ne durumda?
    *   Yeni özellikler, mevcut arka uç servislerinin **performansını veya ölçeklenebilirliğini** nasıl etkileyecek? Gerekli yük testleri veya kapasite planlaması yapıldı mı?
    *   Servisler arası iletişim için **standartlar ve protokoller** (örn. HTTP, WebSocket, Redis Pub/Sub) tutarlı bir şekilde kullanılıyor mu?
*   **Actionable Çıktılar (İterasyon Planı için):**
    *   API spesifikasyonu (OpenAPI/Swagger) güncellemeleri.
    *   Veritabanı migration scriptleri ve testleri.
    *   Servisler arası bağımlılıkları azaltmaya yönelik refactoring görevleri.
    *   Backend performans ve güvenlik testi görevleri.
    *   Celery kuyruk ve worker izleme entegrasyonları.

---

### **5. Ön Yüz Geliştirici Perspektifi**

*   **Sorumlu Kişi/Roller:** Frontend Geliştiricileri, UX/UI Tasarımcısı (implementasyon onayı), Ürün Yöneticisi (kullanıcı değeri).
*   **Odak:** UI implementasyonu, responsive tasarım, frontend performansı, komponent yeniden kullanılabilirliği, state yönetimi, build süreçleri, tarayıcı uyumluluğu ve geliştirici deneyimi.
*   **Sorulacak Sorular:**
    *   Planlanan UI değişiklikleri için mevcut React component'lerimiz yeterli mi, yoksa yeni component'lere ihtiyaç var mı? Bu yeni component'ler **yeniden kullanılabilir, test edilebilir ve mantıksal olarak ayrılmış** durumda mı?
    *   Dashboard'un mobil ve tablet dahil olmak üzere **farklı ekran boyutlarında tamamen uyumlu ve kullanılabilir** olduğundan emin miyiz? Responsive tasarım prensiplerine uyuluyor mu?
    *   Sayfa yükleme süreleri, etkileşim gecikmeleri ve animasyon akıcılığı açısından **frontend performansı optimize edilmiş mi**? `React.memo`, `useCallback`, `useMemo` gibi hook'lar doğru ve yerinde kullanılıyor mu?
    *   CSS yönetimi (`App.css`'in büyüklüğü, global kapsamı) gelecekte stil çakışmaları veya bakım zorlukları yaratacak mı? CSS modülleri, Tailwind CSS veya Styled Components gibi alternatiflere geçiş düşünüldü mü?
    *   Frontend **state yönetimi** (`useState` bağımlılığı) karmaşıklaşıyor mu? Daha organize ve ölçeklenebilir bir state yönetim kütüphanesine (örn. Redux, Zustand) ihtiyaç duyuluyor mu?
    *   Build süreci (Vite, Dockerfile) hızlı ve verimli mi? Üretim imajları boyut ve performans açısından optimize edilmiş mi? `npm cache clean`, `rm -f package-lock.json` gibi kritik adımlar sorunsuz çalışıyor mu?
    *   Uygulama, **popüler tarayıcılarda sorunsuz çalışacak mı**? Potansiyel uyumluluk sorunları var mı?
*   **Actionable Çıktılar (İterasyon Planı için):**
    *   Yeni/güncellenmiş React component'lerinin geliştirme görevleri.
    *   Performans iyileştirme görevleri (code splitting, lazy loading, image optimization, ağ isteklerini azaltma).
    *   CSS refactoring planları veya stil kütüphanesi entegrasyonu araştırması.
    *   Frontend state yönetim çözümü araştırması/implementasyonu.
    *   Tarayıcı uyumluluğu testleri ve düzeltmeleri.

---

### **6. AI Mimarı Perspektifi**

*   **Sorumlu Kişi/Roller:** AI Mimarı, Backend Geliştiricileri (entegrasyon), Run Yöneticisi (donanım).
*   **Odak:** Model tasarımı, algoritma verimliliği, veri işleme boru hatları (pipeline'lar), model değerlendirme metrikleri, açıklanabilirlik (XAI), çekirdek AI altyapısı (Tensor, LSTM, optimizatörler), model kayıt ve sunum, "Sıfırdan İnşa" prensibi hizalaması.
*   **Sorulacak Sorular:**
    *   `azuraforge-core` ve `azuraforge-learner` katmanlarımız, planlanan yeni AI modelleri veya algoritmaları için yeterli soyutlamayı ve yeteneği sunuyor mu? Yeni katmanlara (örn. `Conv2D`, `Attention`), veri yapılarına veya optimizasyonlara (örn. `batch_norm`, `dropout`) ihtiyaç var mı? Bu eklemeler "sıfırdan inşa" felsefemize nasıl uyacak?
    *   Model eğitiminin **performansı** (eğitim süresi, bellek/GPU kullanımı) nasıl daha da optimize edilebilir? `AZURAFORGE_DEVICE=gpu` ve CuPy entegrasyonu beklenen faydayı sağlıyor mu? Daha fazla donanım optimizasyonu (örn. karma hassasiyet) düşünülebilir mi?
    *   Veri ön işleme adımları (`TimeSeriesPipeline`'daki log dönüşümü, ölçeklendirme) genel ve esnek mi? Farklı veri tiplerini (görüntü, metin) desteklemek için ne gibi değişiklikler veya yeni pipeline sınıfları gerekli?
    *   Model değerlendirme metrikleri (R², MAE) amaca uygun ve kapsamlı mı? Yeni görev türleri (sınıflandırma gibi) için ek metrikler, görselleştirmeler ve raporlama şablonları gerekiyor mu?
    *   Modelin "neden" belirli bir tahmin yaptığını açıklayabilme yeteneğimizi (XAI) nasıl artırabiliriz? Platforma SHAP, LIME gibi **açıklanabilirlik araçları** entegre edilebilir mi? Bu iterasyonda bunun için bir prototip planlandı mı?
    *   **Model versiyonlama, model kayıt defteri ve model sunum (serving) için mimari ve teknik adımlar** yeterli mi? Bu adımlar kritik yol haritası hedeflerimizle uyumlu mu?
    *   "Sıfırdan inşa" ettiğimiz çekirdek motor, endüstri standartlarındaki kütüphanelerle (PyTorch, TensorFlow) kıyaslandığında hangi alanlarda yetersiz kalıyor ve bu bir **kritik bir risk** mi? Uzun vadede bu boşlukları nasıl kapatmayı planlıyoruz?
*   **Actionable Çıktılar (İterasyon Planı için):**
    *   Yeni AI katmanları, aktivasyon fonksiyonları veya algoritmaları için araştırma/geliştirme görevleri.
    *   Model performans testleri ve optimizasyon görevleri.
    *   Veri ön işleme veya özellik mühendisliği modülü geliştirmeleri.
    *   Model doğrulama, metrik ve raporlama iyileştirme görevleri.
    *   XAI entegrasyonu için prototipleme veya tasarım.
    *   Model sürümleme ve sunum sistemi için detaylı tasarım belgeleri.

---

### **7. Run Yöneticisi (DevOps / Operasyon) Perspektifi**

*   **Sorumlu Kişi/Roller:** DevOps Mühendisleri, Sistem Yöneticileri, Backend Geliştiricileri (altyapı entegrasyonu).
*   **Odak:** Dağıtım stratejileri, altyapı yönetimi, izleme (monitoring), loglama, hata yönetimi, güvenlik, güvenilirlik (reliability), maliyet optimizasyonu, felaket kurtarma ve otomatikleştirme.
*   **Sorulacak Sorular:**
    *   Mevcut Docker Compose tabanlı dağıtım modeli, **üretim ortamı gereksinimlerini** (yüksek erişilebilirlik, otomatik ölçeklendirme, Kubernetes entegrasyonu) karşılıyor mu? Bir sonraki adıma geçiş için yol haritası ne?
    *   Tüm servislerden gelen loglar (API, Worker, Redis, Postgres) **merkezi bir sistemde (örn. ELK Stack, Grafana Loki)** toplanıyor ve kolayca aranıp analiz ediliyor mu? Log seviyeleri doğru ayarlanmış mı?
    *   Platformun genel sistem metrikleri (CPU, RAM, disk, ağ, GPU kullanımı) ve Celery kuyruk metrikleri (bekleyen görevler, çalışan worker sayısı) **izleniyor mu**? Anormalliklerde otomatik uyarılar tetikleniyor mu?
    *   Hassas yapılandırma bilgileri (veritabanı kimlik bilgileri gibi) `.env` dosyasında açıkça tutulmak yerine **güvenli bir sır yönetimi çözümüyle (örn. Docker Secrets, HashiCorp Vault)** yönetiliyor mu?
    *   CI/CD pipeline'ları (GitHub Actions) stabil mi ve tüm otomasyon adımlarını (testler, versiyonlama, imaj oluşturma, dağıtım) sorunsuz çalıştırıyor mu? **"Gelecek Hedefi" olarak belirtilen otomatik bağımlılık güncellemesi ne aşamada?**
    *   Docker imajlarımız boyut ve güvenlik (zayıflık taramaları) açısından **optimize edilmiş mi**? Sürekli güvenlik taramaları yapılıyor mu?
    *   **Felaket kurtarma ve iş sürekliliği** için yedekleme ve geri yükleme stratejileri belirlendi mi? Yüksek erişilebilirlik için ne gibi adımlar atıldı/planlandı?
    *   Yeni özellikler veya artan kullanım, **altyapı maliyetlerini** (özellikle GPU kullanımı) nasıl etkileyecek? Maliyet optimizasyonu için ne gibi fırsatlar var (spot instance'lar, kaynak limitleri)?
*   **Actionable Çıktılar (İterasyon Planı için):**
    *   Merkezi loglama ve izleme çözümleri için araştırma/entegrasyon görevleri.
    *   Sır yönetimi çözümleri implementasyonu.
    *   Altyapı otomasyonu (IaC) geliştirmeleri (Terraform, Helm).
    *   CI/CD pipeline iyileştirme ve güvenlik tarama görevleri.
    *   Maliyet analizleri ve optimizasyon önerileri.

---

### **8. İnovasyon ve Gelecek Vizyoneri Perspektifi**

*   **Sorumlu Kişi/Roller:** AI Mimarı (teknik fizibilite), Ürün Yöneticisi (pazar uygunluğu), Proje Yöneticisi (kaynak), Ekip Liderleri (yaratıcı katkı).
*   **Odak:** Disruptif teknolojiler, uzun vadeli pazar trendleri, AI'daki yeni paradigmalar, platformun 3-5 yıl sonraki konumu, potansiyel yeni iş modelleri veya araştırma alanları, AzuraForge'un benzersiz değer önerisini geliştirme.
*   **Sorulacak Sorular:**
    *   "Sıfırdan inşa" ettiğimiz AI çekirdeğimiz (`azuraforge-core`), hangi **gelecekteki AI trendlerine** (örn. çok modlu modeller, küçük dil modelleri, özerk AI ajanları, pekiştirmeli öğrenme) adapte olabilir veya bu trendlere öncülük edebilir?
    *   AzuraForge'u sadece bir MLOps aracı olmaktan çıkarıp, örneğin bir **"AI Eğitim Akademisi"** veya **"Görsel AI Laboratuvarına"** dönüştürecek ne gibi deneysel ve devrim niteliğindeki özellikler geliştirebiliriz? (Örn. görsel model oluşturucu, interaktif öğrenme simülatörleri, AI deneylerinin hikayeleştirilmesi).
    *   Metaverse, Web3, Edge AI veya Quantum Computing gibi **yeni teknolojiler**, AzuraForge'un gelecekteki mimarisini veya uygulama alanlarını nasıl etkileyebilir? Uzun vadede bu alanlara nasıl entegre olabiliriz?
    *   Platformun sürdürülebilirliğini ve büyümesini sağlayacak, **topluluk odaklı yeni iş modelleri** (örn. eklenti mağazası, premium analiz araçları, model servis API'leri için abonelik) veya stratejik ortaklıklar neler olabilir?
    *   Sadece AI modelleri eğitmekle kalmayıp, modellerin **etik, adil ve şeffaf** olmasını sağlayan araçları platforma nasıl entegre edebiliriz? Bu, kullanıcıların güvenini nasıl artırır?
    *   AzuraForge, AI eğitimi ve geliştirme için **sektörde standart bir referans veya öğrenme aracı** haline gelebilir mi? Bunun için kısa, orta ve uzun vadede ne gibi adımlar atmalıyız? (Örn. sertifikasyon programları, açık ders materyalleri).
*   **Actionable Çıktılar (İterasyon Planı için):**
    *   Yeni teknoloji veya pazar trendleri üzerine araştırma raporları ve prototipleme görevleri.
    *   Potansiyel yeni özellikler için kavram kanıtlama (PoC) veya deneysel projeler.
    *   Uzun vadeli vizyon belgesine (`docs/PROJECT_JOURNEY.md`) eklenecek yeni fikirler ve yol haritası önerileri.
    *   Stratejik iş ortaklıkları veya topluluk büyüme girişimleri için başlangıç adımları.

