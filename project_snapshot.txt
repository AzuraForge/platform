PROJE KOD SNAPSHOT (TAM)
Toplam 99 dosya bulundu ve eklendi.
Dahil Edilen Dizinler: .
Dahil Edilen Uzantılar: .toml, .py, .yaml, .yml, .json, .md, .txt, .html, .bat, .sh, .jsx, .js, .json, .css, Dockerfile, docker-compose.yml, Makefile, Procfile, .env, .gitignore, .dockerignore
Hariç Tutulan Desenler/Yollar: __pycache__, .git, .venv, .vscode, .idea, build, dist, *.egg-info, *.pyc, *.so, *.pyd, .pytest_cache, .mypy_cache, .dataset, dataset, .logs, logs, .output, output, inputs, outputs, .tmp, checkpoints, reports, docs/_build, site, node_modules, .DS_Store, Thumbs.db, package-lock.json, yarn.lock, *.lock, *.min.js, *.min.css
================================================================================

========== FILE: docker-compose.yml ==========
services:
  # 1. Redis Servisi
  redis:
    image: redis:alpine
    container_name: azuraforge_redis
    ports: ["6379:6379"]
    volumes: ["redis_data:/data"]

  # 2. PostgreSQL Veritabanı Servisi
  postgres:
    image: postgres:15-alpine
    container_name: azuraforge_postgres
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    restart: always
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 5s
      timeout: 5s
      retries: 5

  # --- ANA PLATFORM SERVİSLERİ ---

  # 3. API Servisi
  api:
    container_name: azuraforge_api
    build:
      context: ./api
      dockerfile: Dockerfile
    # === DEĞİŞİKLİK: Bu satır kaldırıldı. Artık Dockerfile'daki CMD kullanılacak. ===
    # command: start-api 
    ports: ["8000:8000"]
    volumes:
      - ./api:/app
      - ${REPORTS_DIR}:/app/reports
      - ${CACHE_DIR}:/app/.cache
    environment:
      - REDIS_URL=${REDIS_URL}
      - REPORTS_DIR=/app/reports
      - CACHE_DIR=/app/.cache
      - DATABASE_URL=${DATABASE_URL}
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_started

  # 4. Worker Servisi
  worker:
    container_name: azuraforge_worker
    build:
      context: ./worker
      dockerfile: Dockerfile
    # === DEĞİŞİKLİK: Bu satır kaldırıldı. Artık Dockerfile'daki CMD kullanılacak. ===
    # command: start-worker
    volumes:
      - ./worker:/app
      - ${REPORTS_DIR}:/app/reports
      - ${CACHE_DIR}:/app/.cache
    environment:
      - REDIS_URL=${REDIS_URL}
      - REPORTS_DIR=/app/reports
      - CACHE_DIR=/app/.cache
      - AZURAFORGE_DEVICE=gpu
      - DATABASE_URL=${DATABASE_URL}
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_started
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  # 5. Dashboard Servisi
  dashboard:
    container_name: azuraforge_dashboard
    build:
      context: ./dashboard
      dockerfile: Dockerfile
    # Bu servis Node.js tabanlı olduğu için command'ın kalması doğru.
    command: npm run dev -- --host 0.0.0.0
    ports: ["5173:5173"]
    volumes:
      - ./dashboard:/app
      - /app/node_modules
    depends_on: [api]

volumes:
  redis_data:
  postgres_data:
========== FILE: README.md ==========
# AzuraForge Platform 🚀

**AzuraForge**, yapay zeka modellerini sıfırdan oluşturmak, eğitmek, canlı olarak takip etmek ve sonuçlarını interaktif raporlarla analiz etmek için tasarlanmış, **olay güdümlü, eklenti tabanlı ve dağıtık bir MLOps platformudur.**

Bu depo, AzuraForge ekosistemindeki tüm ana servisleri ve kütüphaneleri bir araya getiren **orkestrasyon katmanıdır**.

## 🏛️ Platform Mimarisi ve Felsefesi

AzuraForge, basit bir araç setinden daha fazlasıdır; modern yapay zeka sistemlerinin nasıl inşa edilmesi gerektiğine dair bir felsefeyi temsil eder. Bu felsefeyi, yol haritamızı ve projenin gelişim hikayesini derinlemesine anlamak için **[Proje Vizyonu ve Yol Haritası](./docs/VISION_AND_ROADMAP.md)** belgemizi inceleyin.

Platformumuz dört temel prensip üzerine kuruludur: **"The AzuraForge Way"**

1.  **Sıfırdan İnşa ve Derin Anlayış:**
    Temel algoritmaları (`Tensor`, `LSTM` vb.) sıfırdan yazarak sistem üzerinde tam kontrol, şeffaflık ve derinlemesine bir "know-how" sağlıyoruz. Dış dünyaya minimal bağımlılıkla, "kara kutu"lardan arınmış bir yapı hedefliyoruz.

2.  **Modüler ve Ölçeklenebilir Ekosistem:**
    Her bileşen (`api`, `worker`, `learner` vb.) kendi bağımsız reposunda yaşar, bağımsız olarak geliştirilebilir ve kurulabilir. Bu mikroservis yaklaşımı, projenin bakımını ve ölçeklenmesini kolaylaştırır.

3.  **Olay Güdümlü ve Asenkron Akış:**
    `Celery` ve `Redis Pub/Sub` üzerine kurulu mimari sayesinde, yoğun model eğitimleri bile sistemi bloklamaz. Bu, platformun en kritik gücüdür ve kullanıcıya akıcı, gerçek zamanlı bir deneyim sunar. Bu mimarinin detayları için **[Mimari Belgesi](./docs/ARCHITECTURE.md)**'ne göz atın.

4.  **Genişletilebilir Eklenti Sistemi:**
    Yeni AI uygulamaları, platformun çekirdek koduna dokunmadan, Python'un `entry_points` mekanizması kullanılarak sisteme "eklenti" olarak dahil edilebilir. Bu, platformun yeteneklerinin organik olarak büyümesini sağlar.

---

## ✨ Ana Yetenekler

*   **Sıfırdan İnşa Edilmiş Çekirdek:** Otomatik türev, `LSTM` gibi gelişmiş katmanlar ve `Adam` optimizer içeren, saf Python/NumPy tabanlı bir derin öğrenme motoru.
*   **Canlı Deney Takibi:** `WebSocket` aracılığıyla, devam eden bir eğitimin ilerleme çubuğunu, anlık kayıp değerini ve tahmin grafiklerinin canlı evrimini anlık olarak izleme imkanı.
*   **Dinamik ve İnteraktif Raporlama:** Tamamlanan her deney için, `Dashboard` üzerinden erişilebilen, `Chart.js` ile çizilmiş interaktif grafikler ve detaylı metrikler içeren rapor sayfaları.
*   **Deney Karşılaştırma:** Birden fazla deney sonucunu tek bir arayüzde görsel olarak karşılaştırarak en iyi modeli kolayca belirleme.

---

## 🗺️ Ekosisteme Genel Bakış

AzuraForge platformu, aşağıdaki bağımsız GitHub depolarından oluşur:

| Repo                         | Sorumluluk                                                                       | Teknoloji      |
| ---------------------------- | -------------------------------------------------------------------------------- | -------------- |
| **Çekirdek Kütüphaneler**    |                                                                                  |                |
| `core`                       | Temel tensör matematiği ve otomatik türev (geri yayılım) motoru.                   | `Python`, `NumPy` |
| `learner`                    | Yüksek seviyeli öğrenme kütüphanesi (Katmanlar, Optimizatörler, Pipeline'lar).     | `Python`       |
| **Uygulama Eklentileri**     |                                                                                  |                |
| `applications`               | Resmi ve test edilmiş uygulama eklentilerinin katalogunu tutar.                    | `JSON`         |
| `app-stock-predictor`        | Gerçek bir zaman serisi tahmin eklentisi örneği.                                 | `Python`       |
| **Platform Servisleri**      |                                                                                  |                |
| `api`                        | RESTful API ve WebSocket (Pub/Sub) sunan merkezi iletişim katmanı.                 | `FastAPI`      |
| `worker`                     | Arka plan görevlerini (model eğitimi) işleyen ve raporları oluşturan işçi servisi. | `Celery`, `Redis` |
| `dashboard`                  | React tabanlı, canlı takip ve raporlama yeteneklerine sahip web arayüzü.           | `React`, `Vite` |
| **Orkestrasyon (Bu Repo)**   |                                                                                  |                |
| `platform`                   | Tüm servisleri `docker-compose` ile bir araya getirir ve ana dokümantasyonu barındırır. | `Docker`, `YAML` |

---

## 🚀 Hızlı Başlangıç (Docker Compose ile)

1.  **Docker Desktop'ın yüklü ve çalıştığından emin olun.**
2.  **Bu repoyu klonlayın:** `git clone https://github.com/AzuraForge/platform.git && cd platform`
3.  **.env dosyasını oluşturun:** Proje kök dizininde `.env.example` dosyasını kopyalayarak `.env` adıyla yeni bir dosya oluşturun. (Varsayılan değerler genellikle yeterlidir).
    ```bash
    cp .env.example .env
    ```
4.  **Gerekli Dizinleri Oluşturun:**
    ```bash
    mkdir -p ./reports ./.cache
    ```
5.  **Platformu başlatın:** (İlk başlatma, imajlar build edileceği için biraz zaman alabilir.)
    ```bash
    docker-compose up --build -d
    ```
6.  **Platforma erişin:**
    *   **Dashboard:** `http://localhost:5173`
    *   **API Dokümantasyonu:** `http://localhost:8000/api/v1/docs`
7.  **Keşfedin:** Dashboard'dan bir deney başlatın, canlı takip panelini izleyin ve deney bittiğinde "Raporu Görüntüle" butonuyla interaktif sonuçları inceleyin.

---

## 🛠️ Geliştirme ve Katkıda Bulunma

Platformda geliştirme yapmak, yeni bir eklenti oluşturmak veya projeye katkıda bulunmak için aşağıdaki rehberlerimize göz atın. Tüm geliştirme süreçlerimiz, "The AzuraForge Way" prensiplerine dayanmaktadır.

*   **[Geliştirme Rehberi](./docs/DEVELOPMENT_GUIDE.md):** Yerel geliştirme ortamınızı nasıl kuracağınızı ve servisleri nasıl çalıştıracağınızı öğrenin.
*   **[Katkıda Bulunma Rehberi](./docs/CONTRIBUTING.md):** Kodlama standartlarımız, commit mesaj formatımız ve Pull Request sürecimiz hakkında bilgi edinin.


========== FILE: api/Dockerfile ==========
# Base image olarak Python 3.10'un slim versiyonunu kullan
FROM python:3.10-slim-bullseye

# Gerekli sistem paketlerini kur
RUN apt-get update && \
    apt-get install -y git --no-install-recommends && \
    rm -rf /var/lib/apt/lists/*

# Çalışma dizinini ayarla
WORKDIR /app

# === BASİT VE GARANTİ YÖNTEM ===
# Önce projenin TÜM dosyalarını kopyala
COPY . .

# Şimdi, tüm dosyalar içerideyken, tek bir komutla her şeyi kur.
# -e modu sayesinde scriptler PATH'e eklenir ve bağımlılıklar çözülür.
RUN pip install --no-cache-dir -e .[dev]
# === BİTTİ ===

# Konteyner başlatıldığında çalıştırılacak komut
CMD ["start-api"]
========== FILE: api/pyproject.toml ==========
# api/pyproject.toml (TAM KOD - Sadece projeyle ilgili kısımlar)
[build-system]
requires = ["setuptools>=61.0"]
build-backend = "setuptools.build_meta"

[project]
name = "azuraforge-api"
version = "0.2.4"
description = "The API server for the AzuraForge Platform."
requires-python = ">=3.8"

dependencies = [
    "azuraforge-learner @ git+https://github.com/AzuraForge/learner.git@v0.1.5",
    "azuraforge-worker @ git+https://github.com/AzuraForge/worker.git@v0.2.4",
    "azuraforge-applications @ git+https://github.com/AzuraForge/applications.git@v0.1.0",
    "fastapi",
    "uvicorn[standard]",
    "pydantic-settings",
    "python-dotenv",
    "pyyaml",
    "redis",
    "SQLAlchemy",
    "psycopg2-binary",
]

[project.scripts]
start-api = "azuraforge_api.main:run_server"

[project.urls]
"Homepage" = "https://github.com/AzuraForge/api"

[project.optional-dependencies]
dev = [
    "pytest",
    "pytest-asyncio",
    "httpx",
]

[tool.pytest.ini_options]
asyncio_mode = "auto"
========== FILE: api/README.md ==========
# AzuraForge API Servisi

Bu servis, AzuraForge platformunun merkezi iletişim katmanı ve dış dünyaya açılan ağ geçididir.

## 🎯 Ana Sorumluluklar

1.  **RESTful API Sunucusu:**
    *   `Dashboard` ve potansiyel diğer istemciler için standart HTTP endpoint'leri sağlar (`/experiments`, `/pipelines` vb.).
    *   Gelen istekleri doğrular ve işlenmesi için görevleri `Celery` kuyruğuna (Redis) iletir.

2.  **WebSocket Sunucusu:**
    *   Devam eden deneylerin durumunu canlı olarak takip etmek için (`/ws/task_status/{task_id}`) WebSocket bağlantıları sunar.

3.  **Redis Pub/Sub Dinleyicisi:**
    *   `Worker` tarafından yayınlanan ilerleme mesajlarını (`task-progress:*` kanalları) dinler ve bu mesajları ilgili WebSocket istemcisine anında iletir.

## 🛠️ Yerel Geliştirme ve Test

Bu servisi yerel ortamda çalıştırmak ve test etmek için, ana `platform` reposundaki **[Geliştirme Rehberi](../../platform/docs/DEVELOPMENT_GUIDE.md)**'ni takip edin.

Servis bağımlılıkları kurulduktan ve sanal ortam aktive edildikten sonra, aşağıdaki komutla API sunucusunu başlatabilirsiniz:

```bash
# api/ kök dizinindeyken
start-api
```

Sunucu `http://localhost:8000` adresinde çalışmaya başlayacaktır.

**Birim Testleri (Yakında):**
Birim testlerini çalıştırmak için:
```bash
pytest
```

========== FILE: api/setup.py ==========
from setuptools import setup, find_packages

setup(
    # Bu satır, setuptools'a paketlerin 'src' klasörünün içinde
    # olduğunu söyler.
    package_dir={"": "src"},
    
    # Bu satır, 'src' klasörünün içindeki tüm Python paketlerini
    # (azuraforge_api ve altındakiler) otomatik olarak bulur.
    packages=find_packages(where="src"),
)

========== FILE: api/src/azuraforge_api/database.py ==========
# api/src/azuraforge_api/database.py

import os
from sqlalchemy import create_engine, Column, String, JSON, DateTime
from sqlalchemy.orm import sessionmaker, declarative_base
from sqlalchemy.sql import func

DATABASE_URL = os.getenv("DATABASE_URL")
if not DATABASE_URL:
    raise ValueError("API: DATABASE_URL ortam değişkeni ayarlanmamış!")

engine = create_engine(DATABASE_URL)
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

# === YENİ BÖLÜM: Model tanımını buraya ekliyoruz ===
Base = declarative_base()

class Experiment(Base):
    __tablename__ = "experiments"
    id = Column(String, primary_key=True, index=True)
    task_id = Column(String, index=True, nullable=False)
    batch_id = Column(String, index=True, nullable=True)
    batch_name = Column(String, nullable=True)
    pipeline_name = Column(String, index=True, nullable=False)
    status = Column(String, index=True, default="PENDING")
    config = Column(JSON, nullable=True)
    results = Column(JSON, nullable=True)
    error = Column(JSON, nullable=True)
    created_at = Column(DateTime(timezone=True), server_default=func.now())
    completed_at = Column(DateTime(timezone=True), nullable=True)
    failed_at = Column(DateTime(timezone=True), nullable=True)
# === DEĞİŞİKLİK SONU ===
========== FILE: api/src/azuraforge_api/main.py ==========
# api/src/azuraforge_api/main.py

import uvicorn
from fastapi import FastAPI, APIRouter
from fastapi.middleware.cors import CORSMiddleware
from contextlib import asynccontextmanager

from .core.config import settings
from .routes import experiments, pipelines, streaming
# === DEĞİŞİKLİK BURADA: Kendi veritabanı modülümüzden import ediyoruz ===
from .database import Base, engine 
# === DEĞİŞİKLİK SONU ===

def init_db():
    """Veritabanı tablolarını oluşturur."""
    Base.metadata.create_all(bind=engine)

@asynccontextmanager
async def lifespan(app: FastAPI):
    print("API: Veritabanı tabloları kontrol ediliyor/oluşturuluyor...")
    init_db()
    print("API: Veritabanı hazır.")
    yield

def create_app() -> FastAPI:
    app = FastAPI(
        title=settings.PROJECT_NAME, 
        version="0.1.0",
        lifespan=lifespan
    )
    
    if settings.CORS_ORIGINS == "*":
        allowed_origins = ["*"]
    else:
        allowed_origins = [origin.strip() for origin in settings.CORS_ORIGINS.split(',')]

    app.add_middleware(
        CORSMiddleware,
        allow_origins=allowed_origins,
        allow_credentials=True,
        allow_methods=["*"],
        allow_headers=["*"],
    )

    api_router = APIRouter()
    api_router.include_router(experiments.router)
    api_router.include_router(pipelines.router)
    
    app.include_router(api_router, prefix=settings.API_V1_PREFIX)
    app.include_router(streaming.router)
    
    @app.get("/", tags=["Root"])
    def read_root():
        return {"message": f"Welcome to {settings.PROJECT_NAME}"}
        
    return app

app = create_app()

def run_server():
    print(f"🚀 Starting {settings.PROJECT_NAME}...")
    uvicorn.run("azuraforge_api.main:app", host="0.0.0.0", port=8000, reload=True)
========== FILE: api/src/azuraforge_api/__init__.py ==========

========== FILE: api/src/azuraforge_api/core/config.py ==========
from pydantic_settings import BaseSettings, SettingsConfigDict

class Settings(BaseSettings):
    PROJECT_NAME: str = "AzuraForge API"
    API_V1_PREFIX: str = "/api/v1"
    
    # Yeni CORS ayarı
    # Virgülle ayrılmış URL'ler veya tümüne izin vermek için "*"
    CORS_ORIGINS: str = "*" # Varsayılan olarak tümüne izin ver (geliştirme için)
    
    model_config = SettingsConfigDict(env_file=".env", env_file_encoding='utf-8')

settings = Settings()

========== FILE: api/src/azuraforge_api/core/__init__.py ==========

========== FILE: api/src/azuraforge_api/routes/experiments.py ==========
# api/src/azuraforge_api/routes/experiments.py

from fastapi import APIRouter, HTTPException
from typing import List, Dict, Any
from ..services import experiment_service

router = APIRouter(tags=["Experiments"])

@router.get("/experiments", response_model=List[Dict[str, Any]])
def get_all_experiments():
    return experiment_service.list_experiments()

@router.post("/experiments", status_code=202, response_model=Dict[str, Any])
def create_new_experiment(config: Dict[str, Any]):
    return experiment_service.start_experiment(config)

@router.get("/experiments/{task_id}/status", response_model=Dict[str, Any])
def get_experiment_status(task_id: str):
    # Bu endpoint artık çok gerekli değil ama kalabilir.
    return experiment_service.get_task_status(task_id)

# YENİ ENDPOINT (read_experiment_report yerine)
@router.get("/experiments/{experiment_id}/details", response_model=Dict[str, Any])
def read_experiment_details(experiment_id: str):
    """
    Belirli bir deneyin tüm detaylarını (config, results, metrics, history)
     içeren JSON verisini döndürür.
    """
    try:
        return experiment_service.get_experiment_details(experiment_id)
    except HTTPException as e:
        raise e
========== FILE: api/src/azuraforge_api/routes/pipelines.py ==========
from fastapi import APIRouter, HTTPException
from typing import List, Dict, Any
from ..services import experiment_service

router = APIRouter(tags=["Pipelines"])

@router.get("/pipelines", response_model=List[Dict[str, Any]])
def get_all_available_pipelines():
    return experiment_service.get_available_pipelines()

@router.get("/pipelines/{pipeline_id}/config", response_model=Dict[str, Any])
def get_pipeline_default_config(pipeline_id: str):
    try:
        return experiment_service.get_default_pipeline_config(pipeline_id)
    except ValueError as e:
        raise HTTPException(status_code=404, detail=str(e))
========== FILE: api/src/azuraforge_api/routes/streaming.py ==========
import asyncio
import logging
import json
import os
from fastapi import APIRouter, WebSocket, WebSocketDisconnect
import redis.asyncio as redis

router = APIRouter()

async def redis_listener(websocket: WebSocket, task_id: str):
    """Redis Pub/Sub kanalını dinler ve gelen mesajları WebSocket'e iletir."""
    redis_url = os.environ.get("REDIS_URL", "redis://localhost:6379/0")
    r = await redis.from_url(redis_url)
    pubsub = r.pubsub()
    channel = f"task-progress:{task_id}"
    await pubsub.subscribe(channel)
    
    try:
        while True:
            # `listen` bir coroutine'dir, bu yüzden `await` edilmelidir.
            message = await pubsub.get_message(ignore_subscribe_messages=True, timeout=1.0)
            if message and message.get("type") == "message":
                # Gelen veri bytes, string'e çevirip JSON olarak parse et.
                data_str = message['data'].decode('utf-8')
                progress_data = json.loads(data_str)
                # UI'ın beklediği formatla gönder
                await websocket.send_json({
                    "state": "PROGRESS",
                    "details": progress_data
                })
            # WebSocket bağlantısı hala açık mı kontrol et
            # Bu, istemci bağlantıyı kapattığında döngüden çıkmayı sağlar.
            await asyncio.sleep(0.1) # CPU'yu yormamak için kısa bir bekleme
    except asyncio.CancelledError:
        logging.info(f"Redis listener for task {task_id} cancelled.")
    except Exception as e:
        logging.error(f"Redis listener error for task {task_id}: {e}")
    finally:
        await pubsub.unsubscribe(channel)
        await r.close()
        logging.info(f"Redis listener for task {task_id} cleaned up.")

@router.websocket("/ws/task_status/{task_id}")
async def websocket_task_status(websocket: WebSocket, task_id: str):
    await websocket.accept()
    logging.info(f"WebSocket connection accepted for task: {task_id}")
    
    # Redis dinleyicisini bir arka plan görevi olarak başlat
    listener_task = asyncio.create_task(redis_listener(websocket, task_id))
    
    try:
        # İstemcinin bağlantıyı kapatmasını bekle
        # Bu döngü, bağlantı açık olduğu sürece çalışır.
        while True:
            await websocket.receive_text() # Bu satır aslında istemciden mesaj beklemez,
                                           # sadece bağlantının kopup kopmadığını kontrol eder.
    except WebSocketDisconnect:
        logging.warning(f"WebSocket disconnected by client for task: {task_id}")
    finally:
        # İstemci bağlantıyı kapattığında, arka plandaki Redis dinleyicisini iptal et
        listener_task.cancel()
        # Görevin bitmesini bekle (kaynakların temizlenmesi için)
        await listener_task
        logging.info(f"Closing WebSocket connection for task {task_id}")
========== FILE: api/src/azuraforge_api/routes/__init__.py ==========

========== FILE: api/src/azuraforge_api/services/experiment_service.py ==========
# api/src/azuraforge_api/services/experiment_service.py

import json
import itertools
import uuid
from datetime import datetime
from importlib import resources
from typing import List, Dict, Any, Generator
from fastapi import HTTPException
from celery.result import AsyncResult
from sqlalchemy import desc

from ..database import SessionLocal, Experiment
from azuraforge_worker import celery_app
# Worker'daki pipeline keşfini kullanmak için import
# Bu önemli! Worker'ın keşfettiği pipeline'lar burada da API tarafından kullanılabilir olmalı.
# Bunun için worker pyproject.toml'da `azuraforge-worker`'ı bir bağımlılık olarak gösterir ve
# worker'ın `__init__.py`'si `celery_app` ve `AVAILABLE_PIPELINES_AND_CONFIGS`'i export eder.
from azuraforge_worker.tasks.training_tasks import AVAILABLE_PIPELINES_AND_CONFIGS


# --- Helper Fonksiyonlar ---

def _generate_config_combinations(config: Dict[str, Any]) -> Generator[Dict[str, Any], None, None]:
    """
    Konfigürasyon içindeki listeleri tespit eder ve tüm olası kombinasyonları üretir.
    """
    varying_params = {}
    static_params = {}
    
    def _traverse_and_split(conf, path=""):
        for key, value in conf.items():
            new_path = f"{path}.{key}" if path else key
            if isinstance(value, list):
                varying_params[new_path] = value
            elif isinstance(value, dict):
                _traverse_and_split(value, new_path)
            else:
                static_params[new_path] = value

    _traverse_and_split(config)

    if not varying_params:
        yield config
        return

    param_names = list(varying_params.keys())
    param_values = list(varying_params.values())
    
    for combo in itertools.product(*param_values):
        new_config = {}
        for key_path, value in static_params.items():
            keys = key_path.split('.')
            d = new_config
            for k in keys[:-1]:
                d = d.setdefault(k, {})
            d[keys[-1]] = value
            
        for i, key_path in enumerate(param_names):
            keys = key_path.split('.')
            d = new_config
            for k in keys[:-1]:
                d = d.setdefault(k, {})
            d[keys[-1]] = combo[i]
            
        yield new_config


# --- API Servis Fonksiyonları ---

def get_available_pipelines() -> List[Dict[str, Any]]:
    """Yüklü tüm pipeline eklentilerini ve varsayılan konfigürasyon fonksiyonlarını döndürür."""
    official_apps_data = []
    try:
        # azuraforge_applications paketi içindeki official_apps.json dosyasını oku
        with resources.open_text("azuraforge_applications", "official_apps.json") as f:
            official_apps_data = json.load(f)
    except (FileNotFoundError, ModuleNotFoundError) as e:
        # Eğer dosya veya modül bulunamazsa, logla ve boş liste dön
        print(f"Warning: Could not load official_apps.json or azuraforge_applications module: {e}")
        official_apps_data = []
    
    # Sadece keşfedilmiş pipeline'ları listele
    available_pipelines = [app for app in official_apps_data if app.get("id") in AVAILABLE_PIPELINES_AND_CONFIGS]
    return available_pipelines

def get_default_pipeline_config(pipeline_id: str) -> Dict[str, Any]:
    """Belirli bir pipeline'ın varsayılan konfigürasyonunu döndürür."""
    pipeline_info = AVAILABLE_PIPELINES_AND_CONFIGS.get(pipeline_id)
    if not pipeline_info:
        raise ValueError(f"Pipeline '{pipeline_id}' not found.")
    
    get_config_func = pipeline_info.get('get_config_func')
    if not get_config_func:
        return {"message": "No specific default configuration available."}
    return get_config_func()


def start_experiment(config: Dict[str, Any]) -> Dict[str, Any]:
    """Yeni bir veya birden fazla deney başlatır (batch)."""
    task_ids = []
    batch_id = str(uuid.uuid4())
    batch_name = config.pop("batch_name", f"Batch-{datetime.now().strftime('%Y-%m-%d-%H%M%S')}")
    
    combinations = list(_generate_config_combinations(config))
    num_combinations = len(combinations)

    for single_config in combinations:
        if num_combinations > 1:
            single_config['batch_id'] = batch_id
            single_config['batch_name'] = batch_name
        else:
            single_config['batch_id'] = None
            single_config['batch_name'] = None
            
        # Celery görevini gönder
        task = celery_app.send_task("start_training_pipeline", args=[single_config])
        task_ids.append(task.id)

    if num_combinations > 1:
        return {
            "message": f"{num_combinations} experiments submitted as a batch.",
            "batch_id": batch_id,
            "task_ids": task_ids
        }
    else:
        return {"message": "Experiment submitted to worker.", "task_id": task_ids[0]}

def list_experiments() -> List[Dict[str, Any]]:
    """
    Veritabanındaki tüm deneylerin özetini ve tam detaylarını (config, results)
    en yeniden eskiye doğru listeler.
    """
    db = SessionLocal()
    try:
        # Tüm Experiment objelerini çek
        experiments_from_db = db.query(Experiment).order_by(desc(Experiment.created_at)).all()
        
        all_experiments_data = []
        for exp in experiments_from_db:
            summary = {
                "experiment_id": exp.id,
                "task_id": exp.task_id,
                "pipeline_name": exp.pipeline_name,
                "status": exp.status,
                "created_at": exp.created_at.isoformat() if exp.created_at else None,
                "completed_at": exp.completed_at.isoformat() if exp.completed_at else None,
                "failed_at": exp.failed_at.isoformat() if exp.failed_at else None,
                "batch_id": exp.batch_id,
                "batch_name": exp.batch_name,
                # config_summary alanını, full config'den türetelim
                "config_summary": {
                    "ticker": exp.config.get("data_sourcing", {}).get("ticker", "N/A") if exp.config else "N/A",
                    # Epochs ve LR için liste veya tekil değer alabilen uyumlu özet
                    "epochs": exp.config.get("training_params", {}).get("epochs", "N/A") if exp.config else "N/A",
                    "lr": exp.config.get("training_params", {}).get("lr", "N/A") if exp.config else "N/A",
                },
                "results_summary": {
                    "final_loss": exp.results.get("final_loss") if exp.results else None,
                    "r2_score": exp.results.get("metrics", {}).get("r2_score") if exp.results else None
                },
                # Tam config, results ve error objelerini doğrudan ekliyoruz!
                "config": exp.config,
                "results": exp.results,
                "error": exp.error
            }
            all_experiments_data.append(summary)
        return all_experiments_data
    finally:
        db.close()

def get_experiment_details(experiment_id: str) -> Dict[str, Any]:
    """Belirli bir deneyin tüm detaylarını veritabanından çeker."""
    db = SessionLocal()
    try:
        exp = db.query(Experiment).filter(Experiment.id == experiment_id).first()
        if not exp:
            raise HTTPException(status_code=404, detail=f"Experiment '{experiment_id}' not found.")
        
        # Bu fonksiyon da zaten tam detay dönüyordu, ama API'nin list_experiments'i güncellendiği için
        # UI'da bu fonksiyona gerek kalmayacak. Ancak yine de geriye dönük uyumluluk için burada bırakalım.
        return {
            "experiment_id": exp.id, "task_id": exp.task_id, "pipeline_name": exp.pipeline_name,
            "status": exp.status, "config": exp.config, "results": exp.results, "error": exp.error,
            "created_at": exp.created_at.isoformat() if exp.created_at else None,
            "completed_at": exp.completed_at.isoformat() if exp.completed_at else None,
            "failed_at": exp.failed_at.isoformat() if exp.failed_at else None,
            "batch_id": exp.batch_id, "batch_name": exp.batch_name,
        }
    finally:
        db.close()

def get_task_status(task_id: str) -> Dict[str, Any]:
    """Belirli bir Celery görevinin anlık durumunu döndürür (Celery'den doğrudan sorgu)."""
    # Bu fonksiyon da UI'da artık kullanılmayacak, çünkü task_progress doğrudan WebSocket'ten geliyor
    task_result = AsyncResult(task_id, app=celery_app)
    return {"status": task_result.state, "details": task_result.info}

========== FILE: api/src/azuraforge_api/services/__init__.py ==========

========== FILE: api/src/azuraforge_api/tasks/training_tasks.py ==========

========== FILE: api/src/azuraforge_api/tasks/__init__.py ==========

========== FILE: api/tests/azuraforge_api/test_api_endpoints.py ==========
import pytest
from httpx import AsyncClient, ASGITransport
from unittest.mock import patch

# Test edilecek FastAPI uygulamasını import et
from azuraforge_api.main import app

# pytest'in asenkron testleri çalıştırmasını sağlar
pytestmark = pytest.mark.asyncio

# === DEĞİŞİKLİK BURADA ===
# API'ye yapılan tüm çağrılar için bir istemci oluşturalım
# 'app' yerine ASGITransport kullanarak istemcinin doğrudan uygulama ile konuşmasını sağlıyoruz.
@pytest.fixture
async def async_client():
    transport = ASGITransport(app=app)
    async with AsyncClient(transport=transport, base_url="http://test") as client:
        yield client
# === DEĞİŞİKLİK SONU ===

async def test_read_root(async_client: AsyncClient):
    """Kök endpoint'in doğru mesajı döndürdüğünü test eder."""
    response = await async_client.get("/")
    assert response.status_code == 200
    assert response.json() == {"message": "Welcome to AzuraForge API"}

@patch('azuraforge_api.services.experiment_service.get_available_pipelines')
async def test_get_all_pipelines(mock_get_pipelines, async_client: AsyncClient):
    """/pipelines endpoint'inin doğru veriyi ve 200 kodunu döndürdüğünü test eder."""
    # Servis katmanını mock'layarak veritabanı veya dosya sistemi bağımlılığını ortadan kaldırıyoruz.
    mock_pipelines_data = [
        {"id": "stock_predictor", "name": "Hisse Senedi Fiyat Tahmini"},
        {"id": "weather_forecaster", "name": "Hava Durumu Tahmini"}
    ]
    mock_get_pipelines.return_value = mock_pipelines_data

    response = await async_client.get("/api/v1/pipelines")
    
    assert response.status_code == 200
    assert response.json() == mock_pipelines_data
    # Servis fonksiyonunun çağrıldığını doğrula
    mock_get_pipelines.assert_called_once()


@patch('azuraforge_api.services.experiment_service.start_experiment')
async def test_create_experiment_success(mock_start_experiment, async_client: AsyncClient):
    """Bir deney başarıyla gönderildiğinde 202 kodunu ve task_id'yi döndürdüğünü test eder."""
    test_config = {"pipeline_name": "stock_predictor", "data_sourcing": {"ticker": "GOOG"}}
    mock_start_experiment.return_value = {"message": "Experiment submitted", "task_id": "fake-task-id-123"}

    response = await async_client.post("/api/v1/experiments", json=test_config)
    
    assert response.status_code == 202 # Accepted
    assert response.json()["task_id"] == "fake-task-id-123"
    mock_start_experiment.assert_called_once_with(test_config)
========== FILE: app-stock-predictor/Dockerfile ==========
# ========== GÜNCELLEME: app-stock-predictor/Dockerfile ==========
# Stage 1: Builder
FROM python:3.10-slim-bullseye AS builder

RUN apt-get update && apt-get install -y git --no-install-recommends && rm -rf /var/lib/apt/lists/*

# KRİTİK DÜZELTME: Çalışma dizinini doğrudan 'src' klasörünün içine ayarla
WORKDIR /app/src 

# src klasörünün içeriğini (yani azuraforge_stockapp klasörünü) mevcut WORKDIR'e kopyala
COPY src ./src

# pyproject.toml ve setup.py'ı bir üst dizine (/app) kopyala, 
# çünkü pip install oradan çalışacak.
COPY pyproject.toml /app/
COPY setup.py /app/

# pip install komutunu ana paketin kök dizininden (/app) çalıştır.
# Bu, setup.py'ın package_dir={"": "src"} ayarını doğru algılamasını sağlar.
RUN --mount=type=cache,target=/root/.cache/pip pip install --no-cache-dir /app

# Stage 2: Runtime
FROM python:3.10-slim-bullseye AS runtime

# Runtime'da da aynı çalışma dizinini koru
WORKDIR /app/src

# Builder aşamasından kurulu paketi kopyala
COPY --from=builder /usr/local/lib/python3.10/site-packages /usr/local/lib/python3.10/site-packages
# src klasörünün içeriğini kopyala
COPY --from=builder /app/src ./src

CMD ["python", "-c", "print('AzuraForge App Stock Predictor built successfully!')"]
========== FILE: app-stock-predictor/pyproject.toml ==========
[build-system]
requires = ["setuptools>=61.0"]
build-backend = "setuptools.build_meta"

[project]
name = "azuraforge-app-stock-predictor"
version = "0.1.3" # Versiyonu artırıyoruz
description = "A stock prediction pipeline application for the AzuraForge platform."
requires-python = ">=3.8"
dependencies = [
    # === DEĞİŞİKLİK BURADA: learner'ın en son versiyonuna işaret ediyor ===
    "azuraforge-learner @ git+https://github.com/AzuraForge/learner.git@v0.1.5",
    "yfinance",
    "pandas",
    "scikit-learn",
    "PyYAML",
]

[project.entry-points]
"azuraforge.pipelines" = { stock_predictor = "azuraforge_stockapp.pipeline:StockPredictionPipeline" }
"azuraforge.configs" = { stock_predictor = "azuraforge_stockapp.pipeline:get_default_config" }
========== FILE: app-stock-predictor/README.md ==========
# app-stock-predictor

========== FILE: app-stock-predictor/setup.py ==========
from setuptools import setup, find_packages
setup(
    package_dir={"": "src"},
    packages=find_packages(where="src"),
    # DÜZELTME: Paket kurulduğunda .yml gibi Python dışı dosyaların da
    # kopyalanmasını sağlar. Bu, API ve Worker loglarındaki hatayı çözer.
    include_package_data=True, 
    package_data={
        # "azuraforge_stockapp" paketi içindeki tüm .yml dosyalarını dahil et.
        "azuraforge_stockapp": ["config/*.yml"], 
    },
)
========== FILE: app-stock-predictor/src/azuraforge_stockapp/pipeline.py ==========
# app-stock-predictor/src/azuraforge_stockapp/pipeline.py

import logging
from typing import Any, Dict, Tuple, List

import yaml
from importlib import resources
import pandas as pd
import yfinance as yf

from azuraforge_learner import Sequential, LSTM, Linear
from azuraforge_learner.pipelines import TimeSeriesPipeline

def get_default_config() -> Dict[str, Any]:
    try:
        with resources.open_text("azuraforge_stockapp.config", "stock_predictor_config.yml") as f:
            return yaml.safe_load(f)
    except Exception as e:
        # Bu log, worker'ın ana sürecinde görünmeli
        logging.error(f"Hisse senedi uygulaması için varsayılan config yüklenemedi: {e}", exc_info=True)
        return {"error": f"Varsayılan konfigürasyon yüklenemedi: {e}"}

class StockPredictionPipeline(TimeSeriesPipeline):
    # DÜZELTME: __init__ metodunu, temel sınıfı çağırmak ve loglamayı doğrulamak için geri ekliyoruz.
    def __init__(self, config: Dict[str, Any]):
        # Bu, BasePipeline'in __init__'ini çağıracak ve self.logger'ı ayarlayacaktır.
        super().__init__(config)
        self.logger.info(f"StockPredictionPipeline (Eklenti) başarıyla başlatıldı.")

    def _load_data_from_source(self) -> pd.DataFrame:
        """Sadece yfinance'ten veri çekme işini yapar. Caching bu metodun dışındadır."""
        ticker = self.config.get("data_sourcing", {}).get("ticker", "MSFT")
        self.logger.info(f"'_load_data_from_source' çağrıldı. Ticker: {ticker}")
        
        data = yf.download(ticker, period="max", progress=False, actions=False, auto_adjust=True)
        if data.empty:
            self.logger.error(f"'{ticker}' için yfinance'ten boş veri döndü.")
            raise ValueError(f"'{ticker}' için veri indirilemedi.")
            
        self.logger.info(f"{len(data)} satır veri indirildi.")
        return data

    def get_caching_params(self) -> Dict[str, Any]:
        """Önbellek anahtarı için sadece ticker'ın yeterli olduğunu belirtir."""
        ticker = self.config.get("data_sourcing", {}).get("ticker", "MSFT")
        self.logger.info(f"'get_caching_params' çağrıldı. Ticker: {ticker}")
        return {"ticker": ticker}

    def _get_target_and_feature_cols(self) -> Tuple[str, List[str]]:
        """Bu basit model için hedef ve özellik aynı sütundur: 'Close'."""
        self.logger.info("'_get_target_and_feature_cols' çağrıldı. Hedef: Close")
        return "Close", ["Close"]

    def _create_model(self, input_shape: Tuple) -> Sequential:
        """LSTM ve bir Linear katmandan oluşan modeli oluşturur."""
        self.logger.info(f"'_create_model' çağrıldı. Girdi şekli: {input_shape}")
        input_size = input_shape[2] 
        hidden_size = self.config.get("model_params", {}).get("hidden_size", 50)
        
        model = Sequential(
            LSTM(input_size=input_size, hidden_size=hidden_size),
            Linear(hidden_size, 1)
        )
        self.logger.info("LSTM modeli başarıyla oluşturuldu.")
        return model
========== FILE: app-stock-predictor/src/azuraforge_stockapp/__init__.py ==========

========== FILE: app-stock-predictor/src/azuraforge_stockapp/config/stock_predictor_config.yml ==========
# app-stock-predictor/src/azuraforge_stockapp/config/stock_predictor_config.yml

pipeline_name: "stock_predictor"

data_sourcing:
  ticker: "MSFT"

# YENİ: Özellik mühendisliği ve dönüşüm ayarları
feature_engineering:
  target_col_transform: "log" # "log" veya "none" olabilir

model_params:
  sequence_length: 60
  hidden_size: 5

training_params:
  epochs: 50
  lr: 0.001
  optimizer: "adam"
  test_size: 0.2
  validate_every: 5

system:
  caching_enabled: true
  cache_max_age_hours: 24
========== FILE: app-stock-predictor/src/azuraforge_stockapp/config/__init__.py ==========

========== FILE: applications/Dockerfile ==========
# ========== GÜNCELLEME: applications/Dockerfile ==========
# Stage 1: Builder
FROM python:3.10-slim-bullseye AS builder

RUN apt-get update && apt-get install -y git --no-install-recommends && rm -rf /var/lib/apt/lists/*

WORKDIR /app/src

COPY src ./src
COPY pyproject.toml /app/
COPY setup.py /app/

RUN --mount=type=cache,target=/root/.cache/pip pip install --no-cache-dir /app

# Stage 2: Runtime
FROM python:3.10-slim-bullseye AS runtime

WORKDIR /app/src

COPY --from=builder /usr/local/lib/python3.10/site-packages /usr/local/lib/python3.10/site-packages
COPY --from=builder /app/src ./src

CMD ["python", "-c", "print('AzuraForge Applications Catalog built successfully!')"]
========== FILE: applications/pyproject.toml ==========
[build-system]
requires = ["setuptools>=61.0"]
build-backend = "setuptools.build_meta"

[project]
name = "azuraforge-applications"
version = "0.1.0"
description = "A catalog of official applications for the AzuraForge platform."

========== FILE: applications/README.md ==========
# applications

========== FILE: applications/setup.py ==========
from setuptools import setup, find_packages

setup(
    package_dir={"": "src"},
    packages=find_packages(where="src"),
    # EN ÖNEMLİ KISIM: Paket kurulduğunda .json dosyasının da kopyalanmasını sağlar
    include_package_data=True, 
    package_data={
        "azuraforge_applications": ["*.json"], # "azuraforge_apps_catalog" -> "azuraforge_applications"
    },
)


========== FILE: applications/src/azuraforge_applications/official_apps.json ==========
[
  {
    "id": "stock_predictor",
    "name": "Hisse Senedi Fiyat Tahmini",
    "repository": "https://github.com/AzuraForge/app-stock-predictor",
    "description": "LSTM tabanlı hisse senedi fiyat tahmini yapar."
  },
  {
    "id": "weather_forecaster",
    "name": "Hava Durumu Tahmini",
    "repository": "https://github.com/AzuraForge/app-weather-forecaster",
    "description": "Gelecekteki hava durumunu tahmin eder (Henüz Geliştirilmedi)."
  }
]

========== FILE: applications/src/azuraforge_applications/__init__.py ==========


========== FILE: core/Dockerfile ==========
# ========== GÜNCELLEME: core/Dockerfile ==========
# Stage 1: Builder
FROM python:3.10-slim-bullseye AS builder

RUN apt-get update && apt-get install -y git --no-install-recommends && rm -rf /var/lib/apt/lists/*

# KRİTİK DÜZELTME: Çalışma dizinini doğrudan 'src' klasörünün içine ayarla
WORKDIR /app/src 

# src klasörünün içeriğini (yani azuraforge_core klasörünü) mevcut WORKDIR'e kopyala
COPY src ./src

# pyproject.toml ve setup.py'ı bir üst dizine (/app) kopyala, 
# çünkü pip install oradan çalışacak.
COPY pyproject.toml /app/
COPY setup.py /app/

# pip install komutunu ana paketin kök dizininden (/app) çalıştır.
# Bu, setup.py'ın package_dir={"": "src"} ayarını doğru algılamasını sağlar.
RUN --mount=type=cache,target=/root/.cache/pip pip install --no-cache-dir /app

# Stage 2: Runtime
FROM python:3.10-slim-bullseye AS runtime

# Runtime'da da aynı çalışma dizinini koru
WORKDIR /app/src

# Builder aşamasından kurulu paketi kopyala
COPY --from=builder /usr/local/lib/python3.10/site-packages /usr/local/lib/python3.10/site-packages
# src klasörünün içeriğini kopyala
COPY --from=builder /app/src ./src

CMD ["python", "-c", "print('AzuraForge Core library image built successfully!')"]
========== FILE: core/pyproject.toml ==========
[build-system]
requires = ["setuptools>=61.0"]
build-backend = "setuptools.build_meta"

[project]
name = "azuraforge-core"
version = "0.1.3"
authors = [{ name = "Azmi Sahin" }]
description = "The core automatic differentiation engine (Tensor object) for the AzuraForge ecosystem."
readme = "README.md"
requires-python = ">=3.8"
license = { text = "MIT" }
classifiers = ["Programming Language :: Python :: 3"]
dependencies = ["numpy"]

# --- YENİ BÖLÜM ---
[project.optional-dependencies]
dev = ["pytest"]

========== FILE: core/README.md ==========
# core

========== FILE: core/setup.py ==========
from setuptools import setup, find_packages
setup(
    package_dir={"": "src"},
    packages=find_packages(where="src"),
)

========== FILE: core/src/azuraforge_core/tensor.py ==========
import os
from typing import Callable, List, Optional, Set, Tuple, Union, Any
import numpy as np
import logging # Loglama için import et

# === DEĞİŞİKLİK BURADA: Cihaz algılandığında logla ===
# Loglamayı yapılandır
logging.basicConfig(level=logging.INFO, format='%(asctime)s - CORE - %(levelname)s - %(message)s')

DEVICE = os.environ.get("AZURAFORGE_DEVICE", "cpu").lower()

xp: Any
if DEVICE == "gpu":
    try:
        import cupy
        xp = cupy
        logging.info("✅ AzuraForge Core: CuPy (GPU) backend successfully loaded.")
    except ImportError:
        import numpy
        xp = numpy
        logging.warning("⚠️ AzuraForge Core: AZURAFORGE_DEVICE set to 'gpu' but CuPy not found. Falling back to NumPy (CPU).")
        DEVICE = "cpu"
else:
    import numpy
    xp = numpy
    logging.info("ℹ️ AzuraForge Core: NumPy (CPU) backend is active.")
# === DEĞİŞİKLİK SONU ===

ArrayType = Any
ScalarType = Union[int, float, bool, np.number, xp.number]

def _empty_backward_op() -> None: pass

class Tensor:
    def __init__(self, data: Any, _children: Tuple["Tensor", ...] = (), _op: str = "", requires_grad: bool = False):
        if isinstance(data, Tensor): self.data = data.data.copy()
        else: 
            # Veriyi doğru cihaza taşı
            try:
                # Eğer xp, cupy ise bu veriyi GPU'ya taşır.
                self.data = xp.array(data, dtype=np.float64)
            except Exception as e:
                # GPU'ya taşıma sırasında hata olursa (örn. CUDA context hatası) logla
                logging.error(f"Error transferring data to device '{DEVICE}': {e}. Falling back to CPU.")
                self.data = np.array(data, dtype=np.float64)

        self.requires_grad = requires_grad
        self.grad: Optional[ArrayType] = xp.zeros_like(self.data) if requires_grad else None
        self._backward: Callable[[], None] = _empty_backward_op
        self._prev: Set["Tensor"] = set(_children)
        self._op: str = _op

    def backward(self, grad_output: Optional[ArrayType] = None) -> None:
        if not self.requires_grad: return
        topo: List[Tensor] = []
        visited: Set[Tensor] = set()
        def build_topo(v):
            if v not in visited:
                visited.add(v); [build_topo(child) for child in v._prev]; topo.append(v)
        build_topo(self)
        for t in topo:
            if t.grad is not None:
                t.grad.fill(0.0)
        
        self.grad = xp.ones_like(self.data) if grad_output is None else xp.asarray(grad_output, dtype=np.float64).reshape(self.data.shape)
        
        for v in reversed(topo):
            v._backward()

    def to_cpu(self) -> np.ndarray:
        if hasattr(self.data, 'get'): return self.data.get()
        return np.array(self.data, copy=True)

    def __add__(self, other: Any) -> "Tensor":
        other = _ensure_tensor(other)
        out = Tensor(self.data + other.data, (self, other), "+", self.requires_grad or other.requires_grad)
        def _backward():
            if self.requires_grad and self.grad is not None: self.grad += _unbroadcast_to(self.data.shape, out.grad)
            if other.requires_grad and other.grad is not None: other.grad += _unbroadcast_to(other.data.shape, out.grad)
        out._backward = _backward
        return out

    def __mul__(self, other: Any) -> "Tensor":
        other = _ensure_tensor(other)
        out = Tensor(self.data * other.data, (self, other), "*", self.requires_grad or other.requires_grad)
        def _backward():
            if self.requires_grad and self.grad is not None: self.grad += _unbroadcast_to(self.data.shape, other.data * out.grad)
            if other.requires_grad and other.grad is not None: other.grad += _unbroadcast_to(other.data.shape, self.data * out.grad)
        out._backward = _backward
        return out

    def __pow__(self, power: float) -> "Tensor":
        out = Tensor(self.data ** power, (self,), f"**{power}", self.requires_grad)
        def _backward():
            if self.requires_grad and self.grad is not None: self.grad += (power * (self.data ** (power - 1))) * out.grad
        out._backward = _backward
        return out

    def dot(self, other: "Tensor") -> "Tensor":
        other = _ensure_tensor(other)
        out = Tensor(self.data @ other.data, (self, other), "@", self.requires_grad or other.requires_grad)
        def _backward():
            if self.requires_grad and self.grad is not None: self.grad += out.grad @ other.data.T
            if other.requires_grad and other.grad is not None: other.grad += self.data.T @ out.grad
        out._backward = _backward
        return out

    def sum(self, axis=None, keepdims=False) -> "Tensor":
        out = Tensor(xp.sum(self.data, axis=axis, keepdims=keepdims), (self,), "sum", self.requires_grad)
        def _backward(_axis=axis, _keepdims=keepdims):
            if self.requires_grad and self.grad is not None:
                grad_val = out.grad
                if _axis is not None and not _keepdims:
                    grad_val = xp.expand_dims(grad_val, axis=_axis)
                self.grad += xp.ones_like(self.data) * grad_val
        out._backward = _backward
        return out

    def mean(self, axis=None, keepdims=False) -> "Tensor":
        sum_val = self.sum(axis=axis, keepdims=keepdims)
        num_elements = float(np.prod(self.data.shape) / np.prod(sum_val.data.shape))
        return sum_val * (1.0 / num_elements)
    
    def relu(self) -> "Tensor":
        out = Tensor(xp.maximum(0, self.data), (self,), "ReLU", self.requires_grad)
        def _backward():
            if self.requires_grad and self.grad is not None: self.grad += (self.data > 0) * out.grad
        out._backward = _backward
        return out

    def sigmoid(self) -> "Tensor":
        s = 1 / (1 + xp.exp(-self.data))
        out = Tensor(s, (self,), "Sigmoid", self.requires_grad)
        def _backward():
            if self.requires_grad and self.grad is not None: self.grad += out.data * (1 - out.data) * out.grad
        out._backward = _backward
        return out
    
    def tanh(self) -> "Tensor":
        t = xp.tanh(self.data)
        out = Tensor(t, (self,), "Tanh", self.requires_grad)
        def _backward():
            if self.requires_grad and self.grad is not None:
                self.grad += (1 - t**2) * out.grad
        out._backward = _backward
        return out
        
    def __repr__(self): return f"Tensor(data={self.data}, requires_grad={self.requires_grad})"
    def __neg__(self): return self * -1
    def __sub__(self, other): return self + (-other)
    def __truediv__(self, other): return self * (_ensure_tensor(other) ** -1)
    __radd__ = __add__
    def __rmul__(self, other): return self * other
    def __rsub__(self, other): return _ensure_tensor(other) - self
    def __rtruediv__(self, other): return _ensure_tensor(other) / self

def _ensure_tensor(val: Any) -> "Tensor":
    return val if isinstance(val, Tensor) else Tensor(val)

def _unbroadcast_to(target_shape: Tuple[int, ...], grad: ArrayType) -> ArrayType:
    if target_shape == grad.shape:
        return grad
    
    ndim_diff = grad.ndim - len(target_shape)
    if ndim_diff > 0:
        grad = grad.sum(axis=tuple(range(ndim_diff)))

    axes_to_sum = []
    for i, dim in enumerate(target_shape):
        if dim == 1 and grad.shape[i] > 1:
            axes_to_sum.append(i)
    
    if axes_to_sum:
        grad = grad.sum(axis=tuple(axes_to_sum), keepdims=True)
        
    return grad
========== FILE: core/src/azuraforge_core/__init__.py ==========
from .tensor import Tensor, xp, DEVICE, ArrayType, ScalarType, _unbroadcast_to

__all__ = ["Tensor", "xp", "DEVICE", "ArrayType", "ScalarType", "_unbroadcast_to"]

========== FILE: core/tests/azuraforge_core/test_tensor.py ==========
import pytest
import numpy as np

# Test edilecek paketi import et
from azuraforge_core import Tensor

def test_tensor_creation_and_defaults():
    """Tensor nesnesinin doğru şekilde ve varsayılan değerlerle oluşturulduğunu test eder."""
    t = Tensor([1, 2, 3])
    assert isinstance(t.data, np.ndarray)
    assert t.requires_grad is False
    assert t.grad is None

def test_tensor_requires_grad():
    """`requires_grad=True` olduğunda gradyan dizisinin oluşturulduğunu test eder."""
    t = Tensor([1, 2], requires_grad=True)
    assert t.requires_grad is True
    assert isinstance(t.grad, np.ndarray)
    assert np.array_equal(t.grad, np.array([0.0, 0.0]))

def test_addition_backward():
    """Basit toplama işlemi için geri yayılımın doğru çalıştığını test eder."""
    a = Tensor([1, 2, 3], requires_grad=True)
    b = Tensor(5, requires_grad=True)
    
    # c = a.sum() + b  ->  dc/da = [1, 1, 1], dc/db = 1
    c = a.sum() + b
    
    c.backward()

    assert a.grad is not None
    assert b.grad is not None
    assert np.array_equal(a.grad, [1, 1, 1])
    assert b.grad == 1.0

def test_multiplication_backward():
    """Basit çarpma işlemi için geri yayılımın doğru çalıştığını test eder."""
    x = Tensor(2.0, requires_grad=True)
    y = Tensor(3.0, requires_grad=True)
    
    z = x * y
    
    z.backward() # dz/dx = y = 3,  dz/dy = x = 2

    assert x.grad == 3.0
    assert y.grad == 2.0

def test_chained_rule_backward():
    """Zincir kuralının birden çok işlemde doğru çalıştığını test eder."""
    x = Tensor(2.0, requires_grad=True)
    y = Tensor(3.0, requires_grad=True)

    z = x * y  # dz/dx = y, dz/dy = x
    q = z + x  # dq/dz = 1, dq/dx = 1
    
    # Zincir Kuralı:
    # dq/dx = (dq/dz * dz/dx) + dq/dx = (1 * y) + 1 = 3 + 1 = 4
    # dq/dy = (dq/dz * dz/dy) = 1 * x = 2
    q.backward()

    assert x.grad == 4.0
    assert y.grad == 2.0

def test_dot_product_backward():
    """Matris çarpımı için geri yayılımı test eder."""
    a_data = np.random.randn(2, 3)
    b_data = np.random.randn(3, 4)
    a = Tensor(a_data, requires_grad=True)
    b = Tensor(b_data, requires_grad=True)
    
    c = a.dot(b)
    
    # Gradyanı 1'lerden oluşan bir matrisle başlat
    c.backward(np.ones_like(c.data))
    
    # Manuel olarak hesaplanan gradyanlar
    grad_a_manual = np.ones_like(c.data) @ b_data.T
    grad_b_manual = a_data.T @ np.ones_like(c.data)
    
    assert np.allclose(a.grad, grad_a_manual)
    assert np.allclose(b.grad, grad_b_manual)


def test_relu_backward():
    """ReLU aktivasyonu için geri yayılımı test eder."""
    a = Tensor([-1, 0, 5], requires_grad=True)
    r = a.relu()
    r.backward(np.array([10, 20, 30]))

    # Gradyan sadece pozitif değerler için akar (self.data > 0)
    assert np.array_equal(a.grad, [0, 0, 30])

========== FILE: dashboard/Dockerfile ==========
# ========== GÜNCEL VE KAPSAMLI DÜZELTME: dashboard/Dockerfile ==========

# Node.js LTS sürümünü Alpine Linux üzerinde kullan
FROM node:22-alpine AS dashboard_builder

# Çalışma dizinini ayarla
WORKDIR /app

# package.json ve package-lock.json dosyalarını kopyala
# Bu adım, host makinenizdeki dosyaları Docker container'ına taşır.
COPY package.json package-lock.json ./

# KRİTİK DÜZELTME 1: Host'tan gelen package-lock.json'ı sil.
# Bu, npm'in container'ın kendi Linux ortamına uygun, yeni bir package-lock.json oluşturmasını sağlar.
# Bu adımın cache tarafından atlanmadığından emin olmak için sonraki build adımları önemlidir.
RUN rm -f package-lock.json

# KRİTİK DÜZELTME 2: npm cache'ini temizle
# Bu, npm'in eski veya bozuk cache verilerini kullanmasını engeller.
RUN npm cache clean --force

# KRİTİK DÜZELTME 3: Bağımlılıkları yükle.
# Bu adım, container ortamında sıfırdan bir kurulum yapar ve Rollup'ın doğru binary'sini indirmesini sağlar.
# Bu işlem, yeni ve doğru bir package-lock.json dosyası da oluşturacaktır.
RUN npm install --verbose

# Geri kalan uygulama kodunu kopyala
# .dockerignore dosyası varsa, buraya kopyalanacaklar filtrelecektir.
COPY . .

# Vite geliştirme sunucusunu başlatmak için komut.
# docker-compose.yml tarafından override edildiği için burada CMD satırı aslında çalışmaz.
# Ancak iyi bir practice olarak tutulur.
CMD ["npm", "run", "dev", "--", "--host", "0.0.0.0"]

# Dashboard servisi 5173 portunda çalışır
EXPOSE 5173
========== FILE: dashboard/eslint.config.js ==========
import js from '@eslint/js'
import globals from 'globals'
import reactHooks from 'eslint-plugin-react-hooks'
import reactRefresh from 'eslint-plugin-react-refresh'
import { defineConfig, globalIgnores } from 'eslint/config'

export default defineConfig([
  globalIgnores(['dist']),
  {
    files: ['**/*.{js,jsx}'],
    extends: [
      js.configs.recommended,
      reactHooks.configs['recommended-latest'],
      reactRefresh.configs.vite,
    ],
    languageOptions: {
      ecmaVersion: 2020,
      globals: globals.browser,
      parserOptions: {
        ecmaVersion: 'latest',
        ecmaFeatures: { jsx: true },
        sourceType: 'module',
      },
    },
    rules: {
      'no-unused-vars': ['error', { varsIgnorePattern: '^[A-Z_]' }],
    },
  },
])

========== FILE: dashboard/index.html ==========
<!doctype html>
<html lang="tr">
  <head>
    <meta charset="UTF-8" />
    <link rel="icon" type="image/svg+xml" href="/favicon.svg" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>AzuraForge | MLOps Dashboard</title>
  </head>
  <body>
    <div id="root"></div>
    <script type="module" src="/src/main.jsx"></script>
  </body>
</html>
========== FILE: dashboard/package.json ==========
{
  "name": "dashboard",
  "private": true,
  "version": "0.0.0",
  "type": "module",
  "scripts": {
    "dev": "vite",
    "build": "vite build",
    "lint": "eslint .",
    "preview": "vite preview"
  },
  "dependencies": {
    "@fontsource/inter": "^5.2.6",
    "axios": "^1.10.0",
    "chart.js": "^4.5.0",
    "chartjs-adapter-date-fns": "^3.0.0",
    "chartjs-plugin-annotation": "^3.1.0",
    "chartjs-plugin-zoom": "^2.2.0",
    "date-fns": "^4.1.0",
    "prop-types": "^15.8.1",
    "react": "^19.1.0",
    "react-chartjs-2": "^5.3.0",
    "react-dom": "^19.1.0",
    "react-markdown": "^10.1.0",
    "react-router-dom": "^7.6.3",
    "react-toastify": "^11.0.5",
    "remark-gfm": "^4.0.1"
  },
  "devDependencies": {
    "@eslint/js": "^9.30.0",
    "@types/react": "^19.1.8",
    "@types/react-dom": "^19.1.6",
    "@vitejs/plugin-react": "^4.6.0",
    "eslint": "^9.30.0",
    "eslint-plugin-react-hooks": "^5.2.0",
    "eslint-plugin-react-refresh": "^0.4.20",
    "globals": "^16.2.0",
    "npm-check-updates": "^18.0.1",
    "vite": "^7.0.0"
  }
}

========== FILE: dashboard/README.md ==========
# AzuraForge Dashboard

Bu proje, AzuraForge platformunun kullanıcı arayüzüdür. React ve Vite kullanılarak geliştirilmiştir.

## ✨ Ana Yetenekler

*   Sistemde mevcut olan tüm AI pipeline'larını listeleme ve yeni deneyler başlatma.
*   Geçmişte çalıştırılmış tüm deneylerin sonuçlarını görüntüleme ve filtreleme.
*   Seçilen deneyleri tek bir ekranda karşılaştırarak performanslarını analiz etme.
*   Devam eden bir deneyi, anlık kayıp ve tahmin grafikleriyle **canlı olarak takip etme**.
*   Tamamlanan deneyler için oluşturulmuş interaktif raporları görüntüleme.

## 🚀 Yerel Geliştirme Ortamı

Bu projeyi yerel ortamda çalıştırmak için, ana `platform` reposundaki **[Geliştirme Rehberi](../../platform/docs/DEVELOPMENT_GUIDE.md)**'ni takip edin.

Proje bağımlılıkları kurulduktan sonra, aşağıdaki komutlarla geliştirme sunucusunu başlatabilir ve testleri çalıştırabilirsiniz.

**Geliştirme Sunucusunu Başlatma:**
```bash
# dashboard/ kök dizinindeyken
npm run dev
```
Uygulama `http://localhost:5173` adresinde erişilebilir olacaktır.

**Lint Kontrolü:**
```bash
npm run lint
```

**Not:** Dashboard'un tam olarak çalışabilmesi için `api` servisinin `http://localhost:8000` adresinde çalışıyor olması gerekmektedir.
```

========== FILE: dashboard/vite.config.js ==========
import { defineConfig } from 'vite'
import react from '@vitejs/plugin-react'

// https://vite.dev/config/
export default defineConfig({
  plugins: [react()],
})

========== FILE: dashboard/src/App.css ==========
/* ==========================================================================
   1. KÖK DEĞİŞKENLER (Tasarım Sistemi)
   ========================================================================== */
:root {
  /* Koyu Tema (Varsayılan) */
  --primary-color: #42b983; --primary-color-dark: #369c70; --secondary-color: #3b82f6;
  --text-color: #e2e8f0; --text-color-darker: #94a3b8; --text-inverse: #ffffff;
  --bg-color: #0f172a; --content-bg: #1e293b; --border-color: #334155; --hover-bg: #2a3a52;
  --success-color: #22c55e; --error-color: #ef4444; --warning-color: #f59e0b; --info-color: #3b82f6;
  --font-sans: 'Inter', system-ui, sans-serif; --font-mono: ui-monospace, Menlo, monospace;
  --shadow-md: 0 4px 6px -1px rgb(0 0 0 / 0.1), 0 2px 4px -2px rgb(0 0 0 / 0.1);
  --shadow-lg: 0 10px 15px -3px rgb(0 0 0 / 0.1), 0 4px 6px -2px rgb(0 0 0 / 0.1);
  --border-radius: 12px;
}
body.light-theme {
  /* Açık Tema */
  --text-color: #1e293b; --text-color-darker: #475569; --bg-color: #f8fafc;
  --content-bg: #ffffff; --border-color: #e2e8f0; --hover-bg: #f1f5f9;
  --success-color: #16a34a; --error-color: #dc2626; --warning-color: #d97706; --info-color: #2563eb;
}
/* ==========================================================================
   2. TEMEL RESET VE GLOBAL STİLLER
   ========================================================================== */
*, *::before, *::after { box-sizing: border-box; }
body {
  margin: 0; font-family: var(--font-sans); background-color: var(--bg-color); color: var(--text-color);
  font-synthesis: none; text-rendering: optimizeLegibility; -webkit-font-smoothing: antialiased;
  transition: background-color 0.3s, color 0.3s;
}
#root, .app-layout { 
  display: flex; 
  flex-direction: column; /* Dikey düzen: navbar üstte, main içerik altta */
  width: 100vw; 
  height: 100vh; 
  overflow: hidden; 
  position: relative; /* Yan panel için */
}
/* ==========================================================================
   3. ANA YAPI (Layout) - SİDEBAR KALDIRILDI, YENİ NAV VE PANEL VAR
   ========================================================================== */
/* Eski .sidebar ve .sidebar nav stilleri kaldırıldı */

.main-content { 
  flex-grow: 1; 
  padding: 30px; 
  overflow-y: auto; 
  position: relative; 
  z-index: 10; /* Panelin altında kalması için */
}
.page-header { margin-bottom: 30px; }
.page-header h1 {
  font-size: 2.2em; font-weight: 700; color: var(--text-color); margin: 0 0 5px 0;
  display: flex; align-items: center; gap: 15px; transition: color 0.3s;
}
.page-header p { color: var(--text-color-darker); font-size: 1.1em; margin: 0; }
/* ==========================================================================
   4. LOGO VE TEMA DEĞİŞTİRME - ARTIK TOPNAVBAR'DA
   ========================================================================== */
.logo-container {
  display: flex; align-items: center; justify-content: flex-start; gap: 12px;
  margin-bottom: 0; /* Artık sidebar'da değil, özel bir margin yok */
  padding: 0; 
}
.logo-container h1 {
  color: var(--text-color); font-size: 1.6em; font-weight: 600; margin: 0;
  letter-spacing: 0.5px; transition: color 0.3s;
}
.theme-toggle-button {
  background-color: var(--bg-color); color: var(--text-color-darker); border: 1px solid var(--border-color);
  border-radius: 8px; padding: 8px; cursor: pointer; display: flex; align-items: center;
  justify-content: center; margin-top: 0; /* Artık sidebar'da değil */
  transition: all 0.2s ease;
}
.theme-toggle-button:hover { border-color: var(--primary-color); color: var(--primary-color); }
/* ==========================================================================
   5. BİLEŞENLER (Components)
   ========================================================================== */
.card, .table-container, .form-container, .pipeline-details {
  background-color: var(--content-bg); border: 1px solid var(--border-color);
  border-radius: var(--border-radius); box-shadow: var(--shadow-md);
  transition: background-color 0.3s, border-color 0.3s;
}
.table-container { padding: 0; }
.card { padding: 25px; }
.button-primary {
  background-color: var(--primary-color); color: var(--text-inverse); padding: 10px 20px; border: none;
  border-radius: 8px; cursor: pointer; font-size: 1em; font-weight: 600;
  transition: background-color 0.2s ease, transform 0.2s ease; display: inline-flex;
  align-items: center; gap: 8px;
}
.button-primary:hover:not(:disabled) { background-color: var(--primary-color-dark); transform: translateY(-2px); }
.button-primary:disabled { background-color: var(--border-color); cursor: not-allowed; opacity: 0.6; transform: none; }
.status-badge {
  display: inline-flex; align-items: center; gap: 6px; padding: 4px 12px; border-radius: 9999px;
  font-size: 0.8em; font-weight: 600; text-transform: uppercase; justify-content: center;
}
.status-badge::before { content: ''; display: inline-block; width: 8px; height: 8px; border-radius: 50%; }
.status-badge.status-started, .status-badge.status-progress, .status-badge.status-connecting { background-color: rgba(59, 130, 246, 0.2); color: #60a5fa; }
.status-badge.status-started::before, .status-badge.status-progress::before, .status-badge.status-connecting::before { background-color: var(--info-color); animation: pulse 2s infinite; }
@keyframes pulse { 0%, 100% { opacity: 1; } 50% { opacity: 0.5; } }
.status-badge.status-success { background-color: rgba(34, 197, 94, 0.2); color: #4ade80; }
.status-badge.status-success::before { background-color: var(--success-color); }
.status-badge.status-failure, .status-badge.status-error { background-color: rgba(239, 68, 68, 0.2); color: #f87171; }
.status-badge.status-failure::before, .status-badge.status-error::before { background-color: var(--error-color); }
.status-badge.status-pending, .status-badge.status-unknown, .status-badge.status-disconnected { background-color: rgba(148, 163, 184, 0.2); color: var(--text-color-darker); }
.status-badge.status-pending::before, .status-badge.status-unknown::before, .status-badge.status-disconnected::before { background-color: var(--text-color-darker); }
.form-group { margin-bottom: 20px; }
.form-group label { display: block; margin-bottom: 8px; font-weight: 500; color: var(--text-color-darker); }
.form-group input, .form-group select {
  width: 100%; padding: 12px; background-color: var(--bg-color); border: 1px solid var(--border-color);
  border-radius: 8px; color: var(--text-color); font-size: 1em; font-family: var(--font-sans);
  transition: background-color 0.3s, border-color 0.3s, color 0.3s;
}
.form-group input:focus, .form-group select:focus {
  outline: none; border-color: var(--primary-color); box-shadow: 0 0 0 2px color-mix(in srgb, var(--primary-color) 30%, transparent);
}
/* Tablo ile ilgili eski stiller kaldırıldı, yerine kartlar var */
/* .table-container, table, table th, table td, .actions-cell kaldırıldı */

/* Ortak aksiyon menüsü stilleri */
.actions-cell { 
  position: relative; 
  text-align: right; /* Sağa hizalı olsun */
  flex-shrink: 0; 
}
.actions-button {
  background: none; border: none; font-size: 24px; line-height: 1; color: var(--text-color-darker);
  cursor: pointer; border-radius: 4px; padding: 0 8px;
}
.actions-button:hover { background-color: var(--border-color); color: var(--text-color); }
.actions-menu {
  position: absolute; right: 0; top: 35px; /* Konum ayarlandı */
  background-color: var(--hover-bg); border: 1px solid var(--border-color);
  border-radius: 8px; box-shadow: var(--shadow-lg); z-index: 100; display: flex;
  flex-direction: column; padding: 8px; min-width: 180px;
}
.actions-menu button, .actions-menu-button {
  background: none; border: none; color: var(--text-color); padding: 10px 15px; text-align: left;
  cursor: pointer; border-radius: 6px; display: flex; align-items: center; gap: 10px; font-size: 0.9em;
  width: 100%; text-decoration: none;
}
.actions-menu button:hover, .actions-menu-button:hover { background-color: var(--secondary-color); color: var(--text-inverse); }

/* ==========================================================================
   6. ÖZEL PANELLER VE MODALLAR (LiveTrackerPane ve ReportViewer kaldırıldı)
   ========================================================================== */
.comparison-modal-overlay {
  position: fixed; top: 0; left: 0; right: 0; bottom: 0;
  background-color: color-mix(in srgb, var(--bg-color) 70%, transparent); backdrop-filter: blur(8px);
  z-index: 5000; display: flex; align-items: center; justify-content: center;
}
.comparison-modal-content {
  background-color: var(--bg-color); border: 1px solid var(--border-color); border-radius: 16px;
  width: 90%; max-width: 1200px; height: 90vh; box-shadow: var(--shadow-lg);
  display: flex; flex-direction: column;
}
.comparison-header {
  display: flex; justify-content: space-between; align-items: center; padding: 20px 30px;
  border-bottom: 1px solid var(--border-color); flex-shrink: 0;
}
.comparison-header h2 { margin: 0; font-size: 1.5em; }
.close-button {
  background: none; border: none; font-size: 24px; color: var(--text-color-darker);
  cursor: pointer; transition: color 0.2s;
}
.close-button:hover { color: var(--text-color); }
.comparison-body {
  padding: 30px; flex-grow: 1; overflow-y: auto; display: flex;
  flex-direction: column; gap: 30px;
}
.comparison-chart-container { height: 400px; min-height: 300px; width: 100%; position: relative; }
.chart-instructions {
  position: absolute; bottom: 5px; right: 10px; font-size: 0.75em;
  color: var(--text-color-darker); background-color: color-mix(in srgb, var(--content-bg) 80%, transparent);
  padding: 2px 8px; border-radius: 4px; opacity: 0.7;
}
.color-indicator {
  display: inline-block; width: 12px; height: 12px; border-radius: 50%;
  margin-right: 10px; vertical-align: middle;
}
/* ==========================================================================
   7. ÜÇÜNCÜ PARTİ KÜTÜPHANE STİLLERİ
   ========================================================================== */
.Toastify__toast {
  background-color: var(--content-bg) !important; color: var(--text-color) !important;
  border: 1px solid var(--border-color) !important; border-radius: 8px !important;
  font-family: var(--font-sans) !important;
}
.Toastify__progress-bar { background: var(--primary-color) !important; }
.Toastify__close-button { color: var(--text-color) !important; }

/* ==========================================================================
   8. YENİ DENEY SAYFASI / PANELİ STİLLERİ
   ========================================================================== */

/* Yeni deney panelinin kendi içinde bir form yapısı olacak */
.new-experiment-panel-form {
  display: flex;
  flex-direction: column;
  height: 100%; /* Panelin tamamını kaplasın */
}

.new-experiment-panel-form-content {
  flex-grow: 1; /* Kalan tüm alanı kapla */
  overflow-y: auto; /* İçerik taşmasını engelle */
  padding: 25px; /* İç padding */
}


.form-action-bar {
  flex-shrink: 0; 
  padding: 15px 25px;
  background-color: var(--bg-color);
  border-top: 1px solid var(--border-color);
  display: flex;
  justify-content: space-between;
  align-items: center;
  transition: background-color 0.3s, border-color 0.3s;
}

.pipeline-info {
  display: flex;
  align-items: center;
  gap: 10px;
  color: var(--text-color-darker);
}
.pipeline-info span {
  font-weight: 600;
  color: var(--text-color);
}

.form-fieldset {
  border: 1px solid var(--border-color);
  border-radius: 8px;
  padding: 20px;
  margin: 0 0 20px 0;
}
.form-fieldset legend {
  padding: 0 10px;
  font-weight: 600;
  color: var(--text-color);
}

/* ==========================================================================
   9. FORM HATA STİLLERİ
   ========================================================================== */
.form-group input.input-error,
.form-group select.input-error,
.form-group textarea.input-error {
  border-color: var(--error-color);
  box-shadow: 0 0 0 2px color-mix(in srgb, var(--error-color) 30%, transparent);
}
.form-error-message {
  color: var(--error-color);
  font-size: 0.85em;
  margin-top: 5px;
  display: block;
}

/* ==========================================================================
   10. KATLANABİLİR BÖLÜMLER (Form İçin)
   ========================================================================== */
.collapsible-fieldset {
  margin-bottom: 20px;
}

.collapsible-header {
  display: flex;
  align-items: center;
  justify-content: space-between;
  padding: 10px 15px;
  background-color: var(--hover-bg);
  border-radius: 8px 8px 0 0;
  cursor: pointer;
  font-weight: 600;
  color: var(--text-color);
  border-bottom: 1px solid var(--border-color);
  transition: background-color 0.2s ease;
}

.collapsible-header:hover {
  background-color: color-mix(in srgb, var(--primary-color) 10%, var(--hover-bg));
}

.collapsible-header .icon {
  transition: transform 0.2s ease;
}

.collapsible-header.collapsed .icon {
  transform: rotate(-90deg);
}

.collapsible-content {
  max-height: 0;
  overflow: hidden;
  transition: max-height 0.3s ease-out, padding 0.3s ease-out;
  padding: 0 20px;
  background-color: var(--content-bg);
  border-radius: 0 0 var(--border-radius) var(--border-radius);
}

.collapsible-fieldset.expanded .collapsible-content {
  max-height: 1000px; 
  transition: max-height 0.3s ease-in, padding 0.3s ease-in;
  padding: 20px;
}

/* İlk fieldset varsayılan olarak açık */
.collapsible-fieldset:first-of-type .collapsible-content {
    max-height: 1000px;
    padding: 20px;
}
.collapsible-fieldset:first-of-type .collapsible-header .icon {
    transform: rotate(0deg);
}
.collapsible-fieldset:first-of-type .collapsible-header.collapsed .icon {
    transform: rotate(0deg);
}

/* ==========================================================================
   11. DENEY KARTLARI VE LİSTE DÜZENİ
   ========================================================================== */
.experiments-list-container {
  display: flex;
  flex-direction: column; /* Kartları dikey olarak alt alta sırala */
  gap: 25px; /* Kartlar arası boşluk */
}

.experiment-card {
  display: flex;
  flex-direction: column; /* Üst bölüm, gövde ve detaylar dikeyde sıralanır */
  background-color: var(--content-bg);
  border: 1px solid var(--border-color);
  border-radius: var(--border-radius);
  box-shadow: var(--shadow-md);
  transition: all 0.2s ease;
  overflow: hidden; /* İçindeki öğelerin taşmasını engeller */
}

.experiment-card:hover {
  border-color: var(--primary-color);
  box-shadow: var(--shadow-lg);
  transform: translateY(-2px);
}

.experiment-card.selected-card {
  border-color: var(--secondary-color);
  box-shadow: 0 0 0 3px color-mix(in srgb, var(--secondary-color) 30%, transparent);
}

.experiment-card .card-top-section {
    display: flex;
    align-items: center;
    justify-content: space-between;
    padding: 15px 20px;
    border-bottom: 1px solid var(--border-color);
    background-color: var(--bg-color); /* Başlık için biraz daha koyu */
    gap: 15px; /* Öğeler arası boşluk */
}

.experiment-card .card-checkbox-status {
    display: flex;
    align-items: center;
    gap: 10px;
    flex-shrink: 0; /* Küçülmesini engelle */
}

.experiment-card .card-main-info {
    flex-grow: 1; /* Ortadaki bilgilerin alanı doldurmasını sağlar */
    display: flex;
    flex-direction: column; /* İsim, ID, Batch alt alta gelsin */
    align-items: flex-start;
    overflow: hidden; /* Uzun isimler için taşmayı engelle */
}

.experiment-card .card-main-info .pipeline-name {
  margin: 0;
  font-size: 1.1em;
  font-weight: 600;
  color: var(--text-color);
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  max-width: 100%; /* İçeriğin genişliğini sınırlama */
}

.experiment-card .card-main-info .experiment-id,
.experiment-card .card-main-info .batch-name {
    font-family: var(--font-mono);
    font-size: 0.8em;
    color: var(--text-color-darker);
    white-space: nowrap;
    overflow: hidden;
    text-overflow: ellipsis;
    max-width: 100%;
}


.experiment-card .card-body {
  padding: 20px;
  display: flex;
  flex-wrap: wrap; /* Eğer sığmazsa alt satıra geçsin */
  gap: 20px; /* Metrikler ve grafikler arası boşluk */
  align-items: flex-start; /* Üstten başlasınlar */
}

.experiment-card .card-metrics-summary {
  display: grid; /* Metrikleri düzenli göstermek için grid kullan */
  grid-template-columns: auto 1fr; /* Etiket ve değer yan yana */
  column-gap: 15px;
  row-gap: 5px;
  flex-basis: 300px; /* Bu bölümün minimum genişliği */
  flex-grow: 1; /* Büyüyebilsin */
  min-width: 250px; /* Daha dar ekranlarda küçülmesini engelle */
}

.experiment-card .card-metrics-summary p {
  margin: 0;
  font-size: 0.9em;
  color: var(--text-color-darker);
  white-space: nowrap; /* Metni tek satırda tut */
  overflow: hidden;
  text-overflow: ellipsis;
}
.experiment-card .card-metrics-summary p strong {
  color: var(--text-color);
}
/* Grid'de etiketlerin sağa hizalanması */
.experiment-card .card-metrics-summary p:nth-child(odd) {
    text-align: right;
    color: var(--text-color); /* Etiketleri biraz daha belirgin yap */
    font-weight: 500;
}
.experiment-card .card-metrics-summary p:nth-child(even) {
    text-align: left;
}


.experiment-card .card-charts-section {
  display: flex;
  flex-wrap: wrap; /* Sığmazsa alt satıra geçsin */
  gap: 15px; /* Grafikler arası boşluk */
  flex-grow: 2; /* Metriklerden daha fazla alan kaplasın */
  min-width: 400px; /* Minimum grafik alanı genişliği */
  justify-content: center; /* Grafikleri ortala */
}

.experiment-card .single-chart-container {
  flex-basis: 220px; /* Her bir grafiğin temel genişliği */
  flex-grow: 1; /* Büyüyebilsin */
  height: 120px; /* Grafiğin yüksekliği */
  position: relative; /* instructions için */
  background-color: var(--bg-color); /* Grafik arkaplanı */
  border-radius: 8px;
  padding: 5px;
  box-shadow: inset 0 0 5px rgba(0,0,0,0.1);
}
.experiment-card .no-chart-data-message {
    display: flex;
    align-items: center;
    justify-content: center;
    height: 100%;
    color: var(--text-color-darker);
    font-size: 0.8em;
}

/* Detaylar Bölümü (Katlanabilir) */
.card-expanded-details {
  max-height: 0;
  overflow: hidden;
  transition: max-height 0.3s ease-out, padding 0.3s ease-out;
  padding: 0 20px; 
  border-top: 1px solid var(--border-color); /* Üst çizgi */
}

/* Genişletilmiş durumda */
.experiment-card.expanded .card-expanded-details {
  max-height: 500px; /* Yeterince büyük bir değer */
  transition: max-height 0.3s ease-in, padding 0.3s ease-in;
  padding: 20px; /* Açıldığında padding ver */
}


/* Canlı ilerleme çubuğu stili (ExperimentCard içinde) */
.live-progress-bar-section {
    width: 100%;
    margin-top: 10px;
    padding-top: 10px;
    border-top: 1px solid var(--border-color);
}
.live-progress-bar-section progress {
    width: 100%;
    height: 8px;
    -webkit-appearance: none;
    appearance: none;
    border-radius: 4px;
    overflow: hidden;
}
.live-progress-bar-section progress::-webkit-progress-bar {
    background-color: var(--border-color);
    border-radius: 4px;
}
.live-progress-bar-section progress::-webkit-progress-value {
    background-color: var(--info-color); /* Mavi tonu */
    border-radius: 4px;
    transition: width 0.3s ease;
}
.live-progress-bar-section progress::-moz-progress-bar {
    background-color: var(--info-color);
    border-radius: 4px;
    transition: width 0.3s ease;
}

/* ==========================================================================
   12. ÜST NAVİGASYON ÇUBUĞU (TOPNAVBAR) VE YAN PANEL (NEWEXPERIMENTPANEL)
   ========================================================================== */
.top-navbar {
  display: flex;
  justify-content: space-between;
  align-items: center;
  padding: 15px 30px;
  background-color: var(--content-bg);
  border-bottom: 1px solid var(--border-color);
  box-shadow: var(--shadow-md);
  flex-shrink: 0; /* Küçülmesini engelle */
  z-index: 100; /* Main content'in üzerinde olsun */
}

.new-experiment-panel-overlay {
  position: fixed;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background-color: rgba(0,0,0,0.5); /* Koyu arkaplan */
  backdrop-filter: blur(5px);
  z-index: 2000;
  display: flex;
  justify-content: flex-end; /* Paneli sağa yasla */
  opacity: 0; /* Başlangıçta gizli */
  visibility: hidden; /* Başlangıçta görünmez */
  transition: opacity 0.3s ease, visibility 0.3s ease;
}

.new-experiment-panel-overlay.open {
  opacity: 1;
  visibility: visible;
}

.new-experiment-panel {
  width: 500px; /* Sabit genişlik */
  max-width: 90%; /* Küçük ekranlarda taşmasını engelle */
  height: 100%;
  background-color: var(--bg-color);
  box-shadow: var(--shadow-lg);
  display: flex;
  flex-direction: column;
  transform: translateX(100%); /* Başlangıçta ekran dışı */
  transition: transform 0.3s ease-out;
  z-index: 2001; /* Overlay'in üzerinde olsun */
}

.new-experiment-panel-overlay.open .new-experiment-panel {
  transform: translateX(0); /* Açıldığında içeri kaydır */
}

.new-experiment-panel-header {
  display: flex;
  justify-content: space-between;
  align-items: center;
  padding: 20px 25px;
  border-bottom: 1px solid var(--border-color);
  background-color: var(--content-bg);
  flex-shrink: 0;
}

.new-experiment-panel-header h2 {
  margin: 0;
  font-size: 1.5em;
  color: var(--text-color);
}

.new-experiment-panel-body {
  flex-grow: 1; /* Kalan alanı kapla */
  overflow-y: auto; /* İçerik kaydırılabilir olsun */
  padding: 25px;
}

.new-experiment-panel-footer {
  padding: 15px 25px;
  border-top: 1px solid var(--border-color);
  background-color: var(--content-bg);
  display: flex;
  justify-content: flex-end;
  flex-shrink: 0;
}

/* =============== Ek CSS İyileştirmeleri =============== */

/* Daha keskin grafikler için canvas rendering */
/* Bu, grafiklerin pixelated görünmesini engeller */
.single-chart-container canvas {
    image-rendering: -webkit-optimize-contrast;
    image-rendering: crisp-edges;
    image-rendering: pixelated; /* Safari/macOS için */
}

/* Zoom instructions yazısını daha az rahatsız edici hale getir */
.chart-instructions {
  position: absolute; 
  bottom: 0px; /* Biraz yukarı çek */
  left: 50%; /* Ortala */
  transform: translateX(-50%); /* Tam ortala */
  padding: 1px 6px; /* Daha küçük padding */
  font-size: 0.7em; /* Daha küçük font */
  opacity: 0.9; /* Biraz daha belirgin */
  background-color: var(--bg-color); /* Koyu arkaplan, daha iyi okunurluk */
  border: 1px solid var(--border-color); /* Çerçeve */
  border-radius: 4px;
  white-space: nowrap; /* Tek satırda tut */
  pointer-events: none; /* Mouse etkileşimini engelle */
  z-index: 10; /* Grafiğin üzerinde olsun */
}

/* Dikey kartların liste konteyneri için daha iyi hizalama */
.experiments-list-container {
  align-items: stretch; /* Kartların genişliğini eşitle */
}

/* Her kartın içindeki metrikler ve grafiklerin sığması için */
.experiment-card .card-body {
    justify-content: space-between; /* İçerikleri yay */
    align-items: flex-start;
}

.experiment-card .card-metrics-summary {
    min-width: 200px; /* Bu bölümün minimum genişliği */
}

.experiment-card .card-charts-section {
    min-width: 350px; /* iki grafik + gap için yeterli minimum */
    gap: 10px; /* Grafiklerin arası biraz daralsın */
}

.experiment-card .single-chart-container {
    flex-basis: calc(50% - 5px); /* %50 - yarım gap */
    max-width: calc(50% - 5px); /* Her grafik için max %50 genişlik */
    height: 100px; /* Grafikleri daha kompakt yap */
}

/* Kart içindeki başlık/ID/Batch alanları için taşma görünümü */
.experiment-card .card-main-info {
    max-width: calc(100% - 120px); 
}
========== FILE: dashboard/src/App.jsx ==========
// dashboard/src/App.jsx

import { useState, useContext } from 'react';
import { Routes, Route, useNavigate } from 'react-router-dom';
import { ToastContainer } from 'react-toastify';
import 'react-toastify/dist/ReactToastify.css';

import './App.css';
import { ThemeContext } from './context/ThemeContext';

// Yeni Navigasyon ve Panel Bileşenleri
import TopNavbar from './components/TopNavbar';
import NewExperimentPanel from './components/NewExperimentPanel';

// Dashboard Overview hala ana içeriğimiz
import DashboardOverview from './pages/DashboardOverview';

function App() {
  const { theme } = useContext(ThemeContext);
  const navigate = useNavigate();
  const [isNewExperimentPanelOpen, setIsNewExperimentPanelOpen] = useState(false);

  // Deney başlatıldığında panelin kapanması ve ana sayfaya yönlendirme
  const handleExperimentStarted = () => {
    setIsNewExperimentPanelOpen(false); // Paneli kapat
    navigate('/'); // Ana sayfaya yönlendir
  };

  const handleOpenNewExperimentPanel = () => {
    setIsNewExperimentPanelOpen(true);
  };

  const handleCloseNewExperimentPanel = () => {
    setIsNewExperimentPanelOpen(false);
  };

  return (
    <div className="app-layout">
      <ToastContainer position="bottom-right" autoClose={5000} theme={theme} />
      
      {/* Sol menü kaldırıldı, yerine üst navigasyon çubuğu */}
      <TopNavbar onNewExperimentClick={handleOpenNewExperimentPanel} />

      <main className="main-content">
        <Routes>
          <Route path="/" element={<DashboardOverview />} />
          {/* NewExperiment sayfası artık bir rota olarak değil, yan panel olarak açılacak */}
        </Routes>
      </main>

      {/* Yeni Deney Yan Paneli */}
      <NewExperimentPanel 
        isOpen={isNewExperimentPanelOpen} 
        onClose={handleCloseNewExperimentPanel} 
        onExperimentStarted={handleExperimentStarted} 
      />
    </div>
  );
}

export default App;
========== FILE: dashboard/src/index.css ==========
/*
  Bu dosya, gelecekte çok temel, uygulama geneli reset kuralları için kullanılabilir.
  Şimdilik, projenin tüm özel stil mantığı App.css dosyasında merkezileştirilmiştir.
*/
========== FILE: dashboard/src/main.jsx ==========
import React from 'react';
import { createRoot } from 'react-dom/client';
import { BrowserRouter } from 'react-router-dom';
import { ThemeProvider } from './context/ThemeContext';

// Fontsource
import '@fontsource/inter/400.css';
import '@fontsource/inter/500.css';
import '@fontsource/inter/600.css';
import '@fontsource/inter/700.css';

// Stil dosyaları
import './index.css'; 
import './App.css';
import App from './App.jsx';

createRoot(document.getElementById('root')).render(
  // StrictMode'u bilinçli olarak kapalı tutuyoruz
  // <React.StrictMode>
    <ThemeProvider>
      <BrowserRouter> 
        <App />
      </BrowserRouter>
    </ThemeProvider>
  // </React.StrictMode>
);
========== FILE: dashboard/src/components/ComparisonView.jsx ==========
import PropTypes from 'prop-types';
import { Line } from 'react-chartjs-2';
import { Chart as ChartJS, CategoryScale, LinearScale, PointElement, LineElement, Title, Tooltip, Legend } from 'chart.js';
import zoomPlugin from 'chartjs-plugin-zoom';

ChartJS.register(CategoryScale, LinearScale, PointElement, LineElement, Title, Tooltip, Legend, zoomPlugin);

const chartColors = ['#42b983', '#3b82f6', '#ef4444', '#f59e0b', '#8b5cf6', '#ec4899'];

function ComparisonView({ experiments, onClose }) {
  const chartData = {
    labels: Array.from({ length: Math.max(...experiments.map(e => e.results?.history?.loss?.length || 0)) }, (_, i) => `E${i + 1}`),
    datasets: experiments.map((exp, i) => ({
      label: `${exp.config.data_sourcing.ticker} (${exp.experiment_id.slice(-6)})`,
      data: exp.results?.history?.loss || [], 
      borderColor: chartColors[i % chartColors.length],
      backgroundColor: `${chartColors[i % chartColors.length]}33`,
      tension: 0.1, fill: false, borderWidth: 2, pointRadius: 1, pointHoverRadius: 5,
    })),
  };

  const chartOptions = {
      responsive: true, maintainAspectRatio: false,
      interaction: { mode: 'index', intersect: false, },
      plugins: { 
        legend: { position: 'top', labels: { font: { size: 14 } } },
        tooltip: {
          backgroundColor: 'var(--content-bg)',
          borderColor: 'var(--border-color)',
          borderWidth: 1,
        },
        zoom: {
          pan: { enabled: true, mode: 'xy', modifierKey: 'alt', },
          zoom: { wheel: { enabled: true }, pinch: { enabled: true }, mode: 'xy' }
        }
      },
      scales: {
          y: { title: { display: true, text: 'Kayıp Değeri (Loss)' }, beginAtZero: false, }, 
          x: { title: { display: true, text: 'Epoch' }, grid: { display: false } } 
      }
  };

  return (
    <div className="comparison-modal-overlay" onClick={onClose}>
      <div className="comparison-modal-content" onClick={e => e.stopPropagation()}>
        <div className="comparison-header">
          <h2>Deney Karşılaştırması ({experiments.length} adet)</h2>
          <button className="close-button" onClick={onClose}>×</button>
        </div>
        <div className="comparison-body">
          <div className="comparison-chart-container">
            <Line data={chartData} options={chartOptions} />
            <p className="chart-instructions">Yakınlaştırmak için fare tekerleğini kullanın. Sıfırlamak için çift tıklayın. Kaydırmak için <strong>Alt + Sürükle</strong>.</p>
          </div>
          <h4 className="section-title" style={{ marginTop: 0 }}>Özet Tablosu</h4>
          <div className="table-container">
            <table>
              <thead><tr><th>Deney ID</th><th>Ticker</th><th>Epochs</th><th>LR</th><th>Final Kayıp</th></tr></thead>
              <tbody>
                {experiments.map((exp, i) => (
                  <tr key={exp.experiment_id}>
                    <td><span className="color-indicator" style={{backgroundColor: chartColors[i % chartColors.length]}}></span>{exp.experiment_id.slice(0, 18)}...</td>
                    <td>{exp.config?.data_sourcing?.ticker ?? 'N/A'}</td>
                    <td>{Array.isArray(exp.config?.training_params?.epochs) ? exp.config.training_params.epochs[0] : exp.config?.training_params?.epochs ?? 'N/A'}</td>
                    <td>{Array.isArray(exp.config?.training_params?.lr) ? exp.config.training_params.lr[0] : exp.config?.training_params?.lr ?? 'N/A'}</td>
                    <td>{exp.results?.final_loss?.toFixed(6) ?? 'N/A'}</td>
                  </tr>
                ))}
              </tbody>
            </table>
          </div>
        </div>
      </div>
    </div>
  );
}
ComparisonView.propTypes = { experiments: PropTypes.array.isRequired, onClose: PropTypes.func.isRequired, };
export default ComparisonView;
========== FILE: dashboard/src/components/ExperimentCard.jsx ==========
// dashboard/src/components/ExperimentCard.jsx

// DÜZELTME: React ve tüm hook'lar doğru şekilde import edildi.
import React, { useState, useEffect, useRef } from 'react'; 
import PropTypes from 'prop-types';
import { toast } from 'react-toastify';
import SingleExperimentChart from './SingleExperimentChart'; 
import { getCssVar } from '../utils/cssUtils'; 

const Icon = ({ path, className }) => <svg className={className} width="16" height="16" viewBox="0 0 24 24" fill="currentColor" xmlns="http://www.w3.org/2000/svg"><path d={path} /></svg>;
Icon.propTypes = { path: PropTypes.string.isRequired, className: PropTypes.string };

const ICONS = {
  copy: "M16 1H4c-1.1 0-2 .9-2 2v14h2V3h12V1zm3 4H8c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h11c1.1 0 2-.9 2-2V7c0-1.1-.9-2-2-2zm0 16H8V7h11v14z",
  expand: "M19 19H5V5h14v14zm0-16H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z" 
};

function ExperimentCard({ experiment, isSelected, onSelect }) {
  const [actionsOpen, setActionsOpen] = useState(false);
  const [isDetailsExpanded, setIsDetailsExpanded] = useState(false); // Detayların katlanabilir durumu

  const { 
    experiment_id, status, task_id, pipeline_name,
    created_at, completed_at, failed_at,
    config_summary, results_summary, config: full_config, results: full_results, error: full_error // Tam config ve results
  } = experiment;

  const handleCopyId = () => {
    navigator.clipboard.writeText(experiment_id);
    toast.success('Deney ID panoya kopyalandı!');
    setActionsOpen(false);
  };

  const isRunning = ['STARTED', 'PROGRESS'].includes(status);
  const isFinished = ['SUCCESS', 'FAILURE'].includes(status);

  const finalLoss = results_summary?.final_loss;
  const displayLoss = (finalLoss !== null && finalLoss !== undefined) ? finalLoss.toFixed(6) : 'N/A';
  const startTime = created_at ? new Date(created_at).toLocaleString() : 'N/A';
  const endTime = completed_at || failed_at ? new Date(completed_at || failed_at).toLocaleString() : 'N/A';

  // config_summary'den epochs'u al, eğer liste ise ilk elemanı al (API'ye tekli gönderdiğimiz için)
  const totalEpochs = Array.isArray(full_config?.training_params?.epochs) ? full_config.training_params.epochs[0] : full_config?.training_params?.epochs;

  // Canlı takip için ilerleme yüzdesi ve metin
  // Bu state artık sadece bu bileşen içinde canlı WebSocket verisini tutacak
  const [liveProgress, setLiveProgress] = useState({ epoch: 0, totalEpochs: totalEpochs, text: 'Başlatıldı' });

  // WebSocket'ten gelen canlı veriyi yakalamak için useEffect
  useEffect(() => {
    // Sadece çalışır durumdaki görevler için WebSocket başlat
    if (!isRunning || !task_id) {
        // Eğer görev artık çalışmıyorsa veya task_id yoksa, state'i sıfırla veya varsayılan yap
        setLiveProgress({ epoch: 0, totalEpochs: totalEpochs, text: 'Başlatıldı' });
        return;
    }

    const socket = new WebSocket(`ws://localhost:8000/ws/task_status/${task_id}`);

    socket.onmessage = (event) => {
      const data = JSON.parse(event.data);
      if (data.state === 'PROGRESS' && data.details) {
        setLiveProgress({
          epoch: data.details.epoch,
          totalEpochs: data.details.total_epochs,
          text: data.details.status_text,
        });
      } else if (data.state === 'SUCCESS' || data.state === 'FAILURE') {
        // Görev bittiğinde, progress bar'ı ve text'i final duruma getir
        setLiveProgress(prev => ({
          ...prev,
          epoch: prev.totalEpochs, // Son epoch'a getir
          text: data.state === 'SUCCESS' ? 'Tamamlandı' : `Hata: ${data.result?.error?.message || data.details?.status_text}`,
        }));
      }
    };

    socket.onerror = (err) => {
      console.error(`WebSocket Error for task ${task_id}:`, err);
      setLiveProgress(prev => ({ ...prev, text: 'WebSocket Hatası!' }));
    };

    socket.onclose = () => {
        // Zaten başarılı veya başarısız olduysa, state'i değiştirmeyelim
        if (!isFinished) { 
            setLiveProgress(prev => ({ ...prev, text: 'Bağlantı kesildi.' }));
        }
    };

    return () => {
      if (socket.readyState === WebSocket.OPEN) {
        socket.close(1000, "Component unmounting or task finished");
      }
    };
  }, [isRunning, task_id, totalEpochs, isFinished]);

  const progressPercent = liveProgress.totalEpochs > 0 ? (liveProgress.epoch / liveProgress.totalEpochs) * 100 : 0;

  return (
    <div className={`experiment-card card ${isSelected ? 'selected-card' : ''} ${isDetailsExpanded ? 'expanded' : ''}`}>
      {/* Kart Üst Bölümü: Checkbox, Durum, İsim, ID, Batch Adı, Aksiyonlar */}
      <div className="card-top-section">
        <div className="card-checkbox-status">
          <input type="checkbox" checked={isSelected} onChange={onSelect} title="Karşılaştırmak için seç"/>
          <span className={`status-badge status-${status?.toLowerCase() || 'unknown'}`}>{status || 'Bilinmiyor'}</span>
        </div>
        <div className="card-main-info">
            <h3 className="pipeline-name">{pipeline_name || 'N/A'}</h3>
            <span className="experiment-id">ID: {experiment_id.slice(0, 10)}...</span>
            {full_config?.batch_name && <span className="batch-name">Grup: {full_config.batch_name}</span>}
        </div>
        
        {/* Aksiyon Menüsü */}
        <div className="actions-cell">
          <button className="actions-button" onClick={() => setActionsOpen(!actionsOpen)}>⋮</button>
          {actionsOpen && (
            <div className="actions-menu" onMouseLeave={() => setActionsOpen(false)}>
              <button onClick={() => { setIsDetailsExpanded(!isDetailsExpanded); setActionsOpen(false); }}>
                <Icon path={ICONS.expand} /> {isDetailsExpanded ? 'Detayları Gizle' : 'Detayları Göster'}
              </button>
              <button onClick={handleCopyId}><Icon path={ICONS.copy} /> ID'yi Kopyala</button>
            </div>
          )}
        </div>
      </div>

      {/* Ana Gövde: Özet Metrikler, İlerleme Çubuğu ve Grafikler */}
      <div className="card-body">
        <div className="card-metrics-summary">
          <p><strong>Sembol:</strong> {full_config?.data_sourcing?.ticker || 'N/A'}</p> 
          <p><strong>Epochs:</strong> {totalEpochs || 'N/A'}</p>
          <p><strong>LR:</strong> {full_config?.training_params?.lr || 'N/A'}</p> 
          <p><strong>Final Kayıp:</strong> {displayLoss}</p>
          <p><strong>Başlangıç:</strong> {startTime}</p>
          <p><strong>Bitiş:</strong> {endTime}</p>
          {isFinished && full_results?.metrics?.r2_score !== undefined && (
            <p><strong>R² Skoru:</strong> {full_results.metrics.r2_score.toFixed(4)}</p>
          )}
          {isFinished && full_results?.metrics?.mae !== undefined && (
            <p><strong>MAE:</strong> {full_results.metrics.mae.toFixed(4)}</p>
          )}
        </div>

        {/* Canlı İlerleme Çubuğu (sadece çalışırken) */}
        {isRunning && (
            <div className="live-progress-bar-section">
                <div style={{ display: 'flex', justifyContent: 'space-between', alignItems: 'baseline', marginBottom: '5px' }}>
                    <p style={{ margin: 0, color: getCssVar('--text-color-darker'), fontSize: '0.8em' }}>
                        Canlı Takip: {liveProgress.text}
                    </p>
                    {liveProgress.totalEpochs > 0 && (
                        <span style={{ fontWeight: 'bold', fontFamily: 'var(--font-mono)', fontSize: '0.8em' }}>
                            {liveProgress.epoch} / {liveProgress.totalEpochs}
                        </span>
                    )}
                </div>
                <progress value={progressPercent} max="100"></progress>
            </div>
        )}

        {/* Grafik Bölümü (Her zaman görünür) */}
        <div className="card-charts-section">
          {/* Kayıp Grafiği */}
          <SingleExperimentChart 
            taskId={task_id} 
            mode={isRunning ? 'live' : 'report'} 
            chartType="loss" 
            reportData={full_results} 
          />
          {/* Tahmin Grafiği */}
          <SingleExperimentChart 
            taskId={task_id} 
            mode={isRunning ? 'live' : 'report'} 
            chartType="prediction" 
            reportData={full_results} 
          />
        </div>
      </div>

      {/* Detaylar Bölümü (Katlanabilir) */}
      <div className="card-expanded-details">
        {status === 'FAILURE' && full_error && (
            <div style={{marginBottom: '15px'}}>
                <h4 style={{marginTop: 0, color: getCssVar('--error-color')}}>Hata Detayı</h4>
                <pre style={{backgroundColor: getCssVar('--bg-color'), padding: '10px', borderRadius: '8px', whiteSpace: 'pre-wrap', maxHeight: '150px', overflowY: 'auto', fontSize: '0.8em', color: getCssVar('--error-color')}}>
                    <code>{JSON.stringify(full_error, null, 2)}</code>
                </pre>
            </div>
        )}
        <h4 style={{marginTop: 0}}>Detaylı Konfigürasyon</h4>
        <pre style={{backgroundColor: getCssVar('--bg-color'), padding: '10px', borderRadius: '8px', whiteSpace: 'pre-wrap', maxHeight: '200px', overflowY: 'auto', fontSize: '0.8em'}}>
          <code>{JSON.stringify(full_config, null, 2)}</code>
        </pre>
      </div>
    </div>
  );
}

ExperimentCard.propTypes = {
  experiment: PropTypes.object.isRequired,
  isSelected: PropTypes.bool.isRequired,
  onSelect: PropTypes.func.isRequired,
};

export default React.memo(ExperimentCard); // React.memo ile sarmalayın
========== FILE: dashboard/src/components/Logo.jsx ==========
import PropTypes from 'prop-types';

function Logo({ size = 36 }) {
  return (
    <div className="logo-container">
      <svg width={size} height={size} viewBox="0 0 100 100" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" style={{ flexShrink: 0 }}>
        <defs>
          <linearGradient id="azura-stream-gradient-component" x1="15" y1="50" x2="85" y2="50" gradientUnits="userSpaceOnUse">
            <stop offset="0%" stopColor="var(--secondary-color)"/>
            <stop offset="100%" stopColor="var(--primary-color)"/>
          </linearGradient>
        </defs>
        <path d="M50 10 L10 90 H32 L42 70 H58 L68 90 H90 Z" fill="var(--content-bg)" stroke="var(--text-color-darker)" strokeWidth="4" strokeLinejoin="round"/>
        <path d="M15 55 C 35 45, 65 45, 85 55" stroke="url(#azura-stream-gradient-component)" strokeWidth="8" strokeLinecap="round" fill="none"/>
      </svg>
      <h1>AzuraForge</h1>
    </div>
  );
}
Logo.propTypes = { size: PropTypes.number, };
export default Logo;
========== FILE: dashboard/src/components/NewExperimentPanel.jsx ==========
// dashboard/src/components/NewExperimentPanel.jsx

import React from 'react';
import PropTypes from 'prop-types';
// NewExperiment artık sadece form içeriği, sayfa başlığı kaldırıldı
import NewExperimentFormContent from '../pages/NewExperiment'; 

function CloseIcon() {
  return (
    <svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2" strokeLinecap="round" strokeLinejoin="round">
      <line x1="18" y1="6" x2="6" y2="18"></line>
      <line x1="6" y1="6" x2="18" y2="18"></line>
    </svg>
  );
}

function NewExperimentPanel({ isOpen, onClose, onExperimentStarted }) {
  const panelRef = React.useRef(null);

  React.useEffect(() => {
    if (isOpen && panelRef.current) {
      // Panelin içeriğine veya ilk inputa focus vermek için
      panelRef.current.focus(); 
    }
  }, [isOpen]);

  // Overlay'e tıklanınca paneli kapatma (event propagation'ı durdurmak için)
  const handleOverlayClick = (e) => {
    if (e.target === e.currentTarget) {
      onClose();
    }
  };

  return (
    <div className={`new-experiment-panel-overlay ${isOpen ? 'open' : ''}`} onClick={handleOverlayClick}>
      <div 
        ref={panelRef} 
        className={`new-experiment-panel ${isOpen ? 'open' : ''}`}
        onKeyDown={(e) => e.key === 'Escape' && onClose()}
        tabIndex="-1" 
      >
        <div className="new-experiment-panel-header">
          <h2>Yeni Deney Başlat</h2>
          <button className="close-button" onClick={onClose} title="Kapat">
            <CloseIcon />
          </button>
        </div>
        <div className="new-experiment-panel-body">
          <NewExperimentFormContent 
            onExperimentStarted={onExperimentStarted} 
            onClosePanel={onClose} 
          />
        </div>
      </div>
    </div>
  );
}

NewExperimentPanel.propTypes = {
  isOpen: PropTypes.bool.isRequired,
  onClose: PropTypes.func.isRequired,
  onExperimentStarted: PropTypes.func.isRequired,
};

export default NewExperimentPanel;
========== FILE: dashboard/src/components/SingleExperimentChart.jsx ==========
// dashboard/src/components/SingleExperimentChart.jsx

import React, { useState, useEffect, useMemo, useRef } from 'react'; 
import PropTypes from 'prop-types';
import { Line } from 'react-chartjs-2';
import { 
  Chart as ChartJS, CategoryScale, LinearScale, PointElement, LineElement, 
  Title, Tooltip, Legend, Filler, TimeScale 
} from 'chart.js';
import 'chartjs-adapter-date-fns';
import zoomPlugin from 'chartjs-plugin-zoom'; 
import { getCssVar } from '../utils/cssUtils';

ChartJS.register(CategoryScale, LinearScale, PointElement, LineElement, Title, Tooltip, Legend, Filler, TimeScale, zoomPlugin);

const getChartOptions = (title, chartColors, isTimeScale = false, enableZoom = false, compactMode = false) => {
  const options = {
    responsive: true, 
    maintainAspectRatio: false,
    animation: { duration: 300, easing: 'linear' },
    plugins: { 
      legend: { display: compactMode ? false : true, position: 'top', labels: { font: { size: compactMode ? 8 : 10, color: chartColors.textColor } } },
      title: { display: compactMode ? false : true, text: title, font: { size: compactMode ? 10 : 14, color: chartColors.textColor } },
      tooltip: {
        enabled: true, backgroundColor: chartColors.contentBg,
        titleColor: chartColors.textColor, bodyColor: chartColors.textColor,
        borderColor: chartColors.border, borderWidth: 1, padding: 5, 
        displayColors: true,
        bodyFont: { size: compactMode ? 9 : 12 }, 
        titleFont: { size: compactMode ? 9 : 12 },
        callbacks: {
            label: (ctx) => `${ctx.dataset.label}: ${typeof ctx.parsed.y === 'number' ? ctx.parsed.y.toFixed(4) : ctx.parsed.y}`,
        }
      },
    },
    scales: { 
      y: { 
        grid: { color: chartColors.border, borderDash: [2, 4], drawTicks: false },
        ticks: { display: compactMode ? false : true, padding: 5, maxTicksLimit: compactMode ? 2 : 5, font: { size: compactMode ? 8 : 10, color: chartColors.textColorDarker } },
        beginAtZero: true, 
      }, 
      x: {
        grid: { display: false },
        ticks: { display: compactMode ? false : true, padding: 5, maxRotation: 0, autoSkip: true, maxTicksLimit: compactMode ? 3 : 7, font: { size: compactMode ? 8 : 10, color: chartColors.textColorDarker } },
      } 
    },
    layout: {
      padding: {
        left: compactMode ? 5 : 10, right: compactMode ? 5 : 10, top: compactMode ? 0 : 5, bottom: compactMode ? 0 : 5
      }
    }
  };

  if (isTimeScale) {
    options.scales.x = { 
      type: 'time', 
      time: { unit: 'day', tooltipFormat: 'yyyy-MM-dd' },
      ticks: { font: { size: compactMode ? 8 : 10, color: chartColors.textColorDarker } } 
    };
  }

  if (enableZoom) {
    options.plugins.zoom = {
      pan: { enabled: true, mode: 'x', modifierKey: 'alt', },
      zoom: { wheel: { enabled: true }, pinch: { enabled: true }, mode: 'x' }
    };
  }

  return options;
};


function SingleExperimentChart({ 
  taskId, 
  mode, 
  chartType, 
  reportData, 
}) {
  const [liveData, setLiveData] = useState({
    loss: [],
    prediction: { x_axis: [], y_true: [], y_pred: [] }
  });

  const chartRef = useRef(null); 

  const chartColors = useMemo(() => ({
    primary: getCssVar('--primary-color'),
    info: getCssVar('--info-color'), 
    error: getCssVar('--error-color'), 
    border: getCssVar('--border-color'),
    textColor: getCssVar('--text-color'),
    textColorDarker: getCssVar('--text-color-darker'),
    contentBg: getCssVar('--content-bg'),
    textInverse: getCssVar('--text-inverse'),
  }), []);

  // Canlı Takip (WebSocket) Mantığı
  useEffect(() => {
    let socket;
    if (mode === 'live' && taskId) {
        socket = new WebSocket(`ws://localhost:8000/ws/task_status/${taskId}`);
        
        // Hız sorununu gidermek için bir throttle mekanizması düşünebiliriz.
        // Ancak bu, grafiklerin anlık akışını bozabilir. Şimdilik bu kısmı optimize etmiyoruz.
        // Eğer yavaşlık devam ederse, buraya bir throttle ekleyebiliriz.

        socket.onmessage = (event) => {
            const data = JSON.parse(event.data);
            if (data.state === 'PROGRESS' && data.details) {
                setLiveData(prev => {
                    let updatedLoss = [...prev.loss];
                    let updatedPrediction = { ...prev.prediction };

                    if (data.details.loss !== undefined) {
                        const newLoss = data.details.loss;
                        const newEpoch = data.details.epoch;
                        const lastEpochIndex = updatedLoss.length - 1;
                        if (newEpoch > updatedLoss.length) { 
                            updatedLoss.push(newLoss);
                        } else if (lastEpochIndex >= 0) { 
                            updatedLoss[lastEpochIndex] = newLoss;
                        } else { 
                            updatedLoss.push(newLoss);
                        }
                    }
                    // BURADAKİ GÜNCELLEME: validation_data varsa prediction'ı güncelle
                    if (data.details.validation_data) {
                        updatedPrediction = data.details.validation_data;
                    }
                    return { loss: updatedLoss, prediction: updatedPrediction };
                });
            } else if (data.state === 'SUCCESS' && data.result?.results) {
                setLiveData({
                    loss: data.result.results.history?.loss || [],
                    prediction: {
                        x_axis: data.result.results.time_index || [],
                        y_true: data.result.results.y_true || [],
                        y_pred: data.result.results.y_pred || [],
                    }
                });
            }
        };
        
        socket.onerror = (err) => { console.error(`WebSocket Error for task ${taskId}:`, err); };
        socket.onclose = () => {}; 
    }
    
    return () => { 
      if (socket && socket.readyState === WebSocket.OPEN) {
        socket.close(1000, "Component unmounting or task finished"); 
      }
    };
  }, [mode, taskId]); 

  const currentLossHistory = mode === 'live' ? liveData.loss : reportData?.history?.loss || [];
  const currentPredictionXAxis = mode === 'live' ? liveData.prediction.x_axis : reportData?.time_index || [];
  const currentPredictionYTrue = mode === 'live' ? liveData.prediction.y_true : reportData?.y_true || [];
  const currentPredictionYPred = mode === 'live' ? liveData.prediction.y_pred : reportData?.y_pred || [];


  const chartData = useMemo(() => {
    if (chartType === 'loss') {
      return {
        labels: currentLossHistory.map((_, i) => `E${i + 1}`),
        datasets: [{
          label: 'Eğitim Kaybı',
          data: currentLossHistory,
          borderColor: chartColors.primary,
          backgroundColor: `color-mix(in srgb, ${chartColors.primary} 20%, transparent)`,
          tension: 0.4,
          borderWidth: 2,
          pointRadius: 0,
          fill: 'origin',
        }]
      };
    } else if (chartType === 'prediction') {
      return {
        labels: currentPredictionXAxis,
        datasets: [
          {
            label: 'Gerçek', 
            data: currentPredictionYTrue,
            borderColor: chartColors.info,
            backgroundColor: `color-mix(in srgb, ${chartColors.info} 20%, transparent)`,
            pointRadius: 0,
            fill: 'origin'
          },
          {
            label: 'Tahmin', 
            data: currentPredictionYPred,
            borderColor: chartColors.error,
            borderDash: [5, 5],
            pointRadius: 0,
            fill: false
          }
        ].map(dataset => ({
            ...dataset,
            data: dataset.data.map((val, i) => ({ x: currentPredictionXAxis[i], y: val }))
        }))
      };
    }
    return { labels: [], datasets: [] };
  }, [chartType, currentLossHistory, currentPredictionXAxis, currentPredictionYTrue, currentPredictionYPred, chartColors]);

  const chartTitle = chartType === 'loss' ? 'Kayıp' : 'Tahmin'; 

  const hasData = chartType === 'loss' ? currentLossHistory.length > 0 : currentPredictionYTrue.length > 0;

  return (
    <div className="single-chart-container">
      {hasData ? (
        <Line 
          ref={chartRef} 
          data={chartData} 
          options={getChartOptions(
            chartTitle, 
            chartColors, 
            chartType === 'prediction', 
            chartType === 'prediction' && mode === 'report', 
            true 
          )} 
        />
      ) : (
        <div className="no-chart-data-message">
          {mode === 'live' ? 'Canlı veri bekleniyor...' : 'Veri mevcut değil.'}
        </div>
      )}
       {(chartType === 'prediction' && mode === 'report') && ( 
            <p className="chart-instructions">Yakınlaştırmak için fare tekerleği, kaydırmak için Alt + Sürükle.</p>
        )}
    </div>
  );
}

export default React.memo(SingleExperimentChart);
========== FILE: dashboard/src/components/ThemeToggle.jsx ==========
import { useContext } from 'react';
import { ThemeContext } from '../context/ThemeContext';

const SunIcon = () => <svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2" strokeLinecap="round" strokeLinejoin="round"><circle cx="12" cy="12" r="5"></circle><line x1="12" y1="1" x2="12" y2="3"></line><line x1="12" y1="21" x2="12" y2="23"></line><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line><line x1="1" y1="12" x2="3" y2="12"></line><line x1="21" y1="12" x2="23" y2="12"></line><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line></svg>;
const MoonIcon = () => <svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2" strokeLinecap="round" strokeLinejoin="round"><path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path></svg>;

function ThemeToggle() {
  const { theme, toggleTheme } = useContext(ThemeContext);

  return (
    <button onClick={toggleTheme} className="theme-toggle-button" title="Temayı Değiştir">
      {theme === 'light' ? <MoonIcon /> : <SunIcon />}
    </button>
  );
}

export default ThemeToggle;
========== FILE: dashboard/src/components/TopNavbar.jsx ==========
// dashboard/src/components/TopNavbar.jsx

import React from 'react';
import PropTypes from 'prop-types';
import Logo from './Logo';
import ThemeToggle from './ThemeToggle';

function TopNavbar({ onNewExperimentClick }) {
  return (
    <nav className="top-navbar">
      <Logo />
      <div style={{ display: 'flex', alignItems: 'center', gap: '15px' }}>
        <button className="button-primary" onClick={onNewExperimentClick}>
          <span role="img" aria-label="rocket">🚀</span> Yeni Deney Başlat
        </button>
        <ThemeToggle />
      </div>
    </nav>
  );
}

TopNavbar.propTypes = {
  onNewExperimentClick: PropTypes.func.isRequired,
};

export default TopNavbar;
========== FILE: dashboard/src/context/ThemeContext.jsx ==========
import { createContext, useState, useEffect, useMemo } from 'react';
import PropTypes from 'prop-types';

export const ThemeContext = createContext();

export function ThemeProvider({ children }) {
  const [theme, setTheme] = useState(() => {
    const savedTheme = localStorage.getItem('theme');
    const prefersDark = window.matchMedia('(prefers-color-scheme: dark)').matches;
    return savedTheme || (prefersDark ? 'dark' : 'light');
  });

  useEffect(() => {
    const body = document.body;
    // body'nin class'ını mevcut temaya göre ayarla
    body.classList.toggle('light-theme', theme === 'light');
    // Seçimi tarayıcı hafızasına kaydet
    localStorage.setItem('theme', theme);
  }, [theme]);

  const toggleTheme = () => {
    setTheme(prevTheme => (prevTheme === 'light' ? 'dark' : 'light'));
  };

  // Sadece theme ve toggleTheme'i dışarıya veriyoruz.
  const value = useMemo(() => ({ theme, toggleTheme }), [theme]);

  return (
    <ThemeContext.Provider value={value}>
      {children}
    </ThemeContext.Provider>
  );
}

ThemeProvider.propTypes = {
  children: PropTypes.node.isRequired,
};
========== FILE: dashboard/src/pages/DashboardOverview.jsx ==========
import { useState, useEffect, useMemo } from 'react';
import ExperimentCard from '../components/ExperimentCard'; 
import ComparisonView from '../components/ComparisonView';
import { fetchExperiments } from '../services/api'; // fetchExperimentDetails kaldırıldı, tek çağrı yeterli
import { toast } from 'react-toastify'; 

function DashboardOverview() {
  const [experiments, setExperiments] = useState([]);
  const [loading, setLoading] = useState(true);
  const [error, setError] = useState(null);
  
  const [searchTerm, setSearchTerm] = useState('');
  const [filterStatus, setFilterStatus] = useState('ALL');
  
  const [selectedForComparison, setSelectedForComparison] = useState(new Set());
  const [comparisonData, setComparisonData] = useState(null);

  // API'den tüm deney verilerini tek çağrıda çekiyoruz
  const getExperiments = async (showLoadingIndicator = false) => {
    if (showLoadingIndicator) setLoading(true);
    try {
      // Artık API'nin kendisi tüm detayları döndürüyor olmalı
      const response = await fetchExperiments();
      setExperiments(response.data); // Data zaten detailed olarak geliyor
      setError(null);
    } catch (err) {
      setError('API sunucusuna bağlanılamadı veya veri çekilemedi. Servislerin çalıştığından emin olun.');
      console.error(err);
    } finally {
      if (showLoadingIndicator) setLoading(false);
    }
  };

  useEffect(() => {
    getExperiments(true);
    // Performansı iyileştirmek için, bu intervalı daha uzun tutabiliriz (örn: 10-15 saniye)
    // Veya sadece active görevler için daha sık, diğerleri için daha az sık güncelleme yapılabilir.
    const intervalId = setInterval(() => getExperiments(false), 5000); 
    return () => clearInterval(intervalId);
  }, []);

  const allStatuses = useMemo(() => {
    const statuses = new Set(experiments.map(exp => exp.status));
    return ['ALL', ...Array.from(statuses).sort()];
  }, [experiments]);

  const filteredExperiments = useMemo(() => {
    return experiments.filter(exp => {
      const statusMatch = filterStatus === 'ALL' || exp.status === filterStatus;
      if (!statusMatch) return false;

      if (searchTerm) {
        const lowerCaseSearchTerm = searchTerm.toLowerCase();
        const searchFields = [
          exp.experiment_id,
          exp.pipeline_name,
          exp.config_summary?.ticker, // config_summary kullanılabilir
          exp.batch_name,
          // exp.config?.data_sourcing?.ticker, // Zaten config_summary'de var, gereksiz tekrar
        ];
        // Ek olarak, full_config'ten diğer alanlarda da arama yapılabilir (örn. model_params içinde bir değer)
        // Ancak bu, searchFields array'ini daha karmaşık hale getirir.
        return searchFields.some(field => typeof field === 'string' && field.toLowerCase().includes(lowerCaseSearchTerm));
      }

      return true;
    });
  }, [experiments, filterStatus, searchTerm]);
  
  const handleComparisonSelect = (experimentId) => {
    setSelectedForComparison(prev => {
      const newSelection = new Set(prev);
      if (newSelection.has(experimentId)) {
        newSelection.delete(experimentId);
      } else {
        newSelection.add(experimentId);
      }
      return newSelection;
    });
  };

  const handleStartComparison = async () => {
    const idsToCompare = Array.from(selectedForComparison);
    if (idsToCompare.length < 2) {
        toast.warn('Karşılaştırma için en az 2 deney seçmelisiniz.');
        return;
    }
    
    // API'den zaten tüm detaylar geldiği için burada tekrar fetch yapmaya gerek yok.
    const dataToCompare = idsToCompare.map(id => 
        experiments.find(exp => exp.experiment_id === id)
    ).filter(Boolean); 

    const validDataForComparison = dataToCompare.filter(exp => 
        exp.status === 'SUCCESS' && exp.results?.history?.loss && exp.results.history.loss.length > 0
    );

    if (validDataForComparison.length < 2) {
        toast.warn('Karşılaştırma için en az 2 adet, başarılı ve kayıp geçmişi olan deney seçmelisiniz.');
        setComparisonData(null); 
        return;
    }

    setComparisonData(validDataForComparison);
  };

  if (loading) return <p style={{textAlign: 'center', padding: '40px'}}>Deney verileri yükleniyor...</p>;
  if (error) return <p style={{textAlign: 'center', padding: '40px', color: 'var(--error-color)'}}>{error}</p>;

  return (
    <div className="dashboard-overview">
      {comparisonData && <ComparisonView experiments={comparisonData} onClose={() => setComparisonData(null)}/>}
      
      <div className="page-header">
        <h1>Genel Bakış</h1>
        <p>Tüm deneylerinizi tek bir yerden yönetin, takip edin ve karşılaştırın.</p>
      </div>
      
      <div className="card" style={{ marginBottom: '25px' }}>
        <div style={{ display: 'flex', justifyContent: 'space-between', alignItems: 'center', flexWrap: 'wrap', gap: '20px' }}>
          <div style={{ display: 'flex', gap: '20px', flexWrap: 'wrap', alignItems: 'flex-end' }}>
            <div className="form-group" style={{ marginBottom: 0 }}>
              <label htmlFor="search-term">Arama</label>
              <input type="text" id="search-term" placeholder="ID, Pipeline, Sembol ara..." value={searchTerm} onChange={(e) => setSearchTerm(e.target.value)} />
            </div>
            <div className="form-group" style={{ marginBottom: 0 }}>
              <label htmlFor="filter-status">Durum</label>
              <select id="filter-status" value={filterStatus} onChange={(e) => setFilterStatus(e.target.value)}>
                {allStatuses.map(s => <option key={s} value={s}>{s === 'ALL' ? 'Tümü' : s}</option>)}
              </select>
            </div>
          </div>
          <button 
            className="button-primary" 
            onClick={handleStartComparison} 
            disabled={selectedForComparison.size < 2} 
            title={selectedForComparison.size < 2 ? 'Karşılaştırmak için en az 2 deney seçin' : ''}
          >
            <span role="img" aria-label="scales">⚖️</span> Seçilenleri Karşılaştır ({selectedForComparison.size})
          </button>
        </div>
      </div>
      
      {/* Kartları dikey olarak sıralamak için flex column kullanıyoruz */}
      <div className="experiments-list-container"> 
        {filteredExperiments.length === 0 ? (
          <p style={{textAlign: 'center', padding: '20px'}}>Filtrelerinize uyan bir deney bulunamadı.</p>
        ) : (
          filteredExperiments.map((exp) => (
            <ExperimentCard 
              key={exp.experiment_id} 
              experiment={exp} 
              isSelected={selectedForComparison.has(exp.experiment_id)}
              onSelect={() => handleComparisonSelect(exp.experiment_id)}
            />
          ))
        )}
      </div>
    </div>
  );
}

export default DashboardOverview;
========== FILE: dashboard/src/pages/NewExperiment.jsx ==========
// dashboard/src/pages/NewExperiment.jsx
// Bu dosya artık bir React sayfası değil, sadece form içeriği sağlayan bir bileşen.

import { useState, useEffect, useCallback } from 'react';
import PropTypes from 'prop-types';
import { toast } from 'react-toastify';
import { fetchAvailablePipelines, fetchPipelineDefaultConfig, startNewExperiment } from '../services/api';

// Helper: Aşağı ok ikonu (Katlanabilir bölümler için)
const ChevronDownIcon = ({ className = '' }) => (
  <svg className={className} width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2" strokeLinecap="round" strokeLinejoin="round">
    <polyline points="6 9 12 15 18 9"></polyline>
  </svg>
);
ChevronDownIcon.propTypes = { className: PropTypes.string };


// Yardımcı fonksiyon: Bir değeri (string, number, array) sayı dizisine dönüştürür.
const parseNumberListInput = (value) => {
  if (value === null || value === undefined || value === '') return []; 
  
  if (Array.isArray(value)) { 
    return value.map(v => typeof v === 'string' ? parseFloat(v.replace(',', '.')) : v); 
  }
  
  if (typeof value === 'number') { 
    return [value]; 
  }

  if (typeof value === 'string') {
    const parts = value.split(',').map(s => s.trim()).filter(s => s !== '');
    return parts.map(s => {
      const decimalReadyString = s.replace(',', '.'); 
      const num = parseFloat(decimalReadyString);
      return isNaN(num) ? NaN : num; 
    });
  }
  
  return [NaN]; 
};

// Yardımcı fonksiyon: Input değerini string'e dönüştürür (UI'da görüntülemek için).
const formatListInput = (value) => {
  if (Array.isArray(value)) {
    return value.join(', ');
  }
  return value?.toString() ?? ''; 
};


// --- Her Pipeline İçin Özel Form Bileşeni ---

function StockPredictorConfigForm({ config, onConfigChange, errors }) {
  const localConfig = JSON.parse(JSON.stringify(config || {}));
  
  const [expandedSections, setExpandedSections] = useState({
    data_sourcing: true, 
    feature_engineering: false, 
    model_params: false,
    training_params: false,
    system: false,
  });

  useEffect(() => {
    setExpandedSections(prev => ({ ...prev, data_sourcing: true }));
  }, [config]);

  const toggleSection = (sectionName) => {
    setExpandedSections(prev => ({ ...prev, [sectionName]: !prev[sectionName] }));
  };

  const handleChange = (e, path) => {
    const { value, type } = e.target;
    let newValue = value;

    if (type === 'select-one' && (value === 'true' || value === 'false')) {
        newValue = (value === 'true');
    }

    let updatedConfig = JSON.parse(JSON.stringify(localConfig));
    let current = updatedConfig;
    const pathParts = path.split('.'); 

    for (let i = 0; i < pathParts.length - 1; i++) {
      current = current[pathParts[i]] = current[pathParts[i]] || {};
    }
    current[pathParts[pathParts.length - 1]] = newValue; 
    onConfigChange(updatedConfig);
  };

  if (!config) return <p>Konfigürasyon yüklenemedi.</p>;

  const renderFieldset = (sectionName, legendText, content) => (
    <fieldset className={`form-fieldset collapsible-fieldset ${expandedSections[sectionName] ? 'expanded' : ''}`}>
      <div className={`collapsible-header ${!expandedSections[sectionName] ? 'collapsed' : ''}`} onClick={() => toggleSection(sectionName)}>
        <span>{legendText}</span>
        <ChevronDownIcon className="icon" />
      </div>
      <div className="collapsible-content">
        {content}
      </div>
    </fieldset>
  );


  return (
    <>
      {renderFieldset('data_sourcing', 'Veri Kaynağı', (
        <div className="form-group">
          <label htmlFor="ticker">Ticker Sembolü:</label>
          <input
            type="text"
            id="ticker"
            value={formatListInput(localConfig.data_sourcing?.ticker)}
            onChange={(e) => handleChange(e, 'data_sourcing.ticker')}
            className={errors['data_sourcing-ticker'] ? 'input-error' : ''}
            placeholder="Örn: MSFT, AAPL, GOOG"
          />
          <small>Tek bir değer veya virgülle ayrılmış birden fazla değer (örn: MSFT, AAPL, GOOG)</small>
          {errors['data_sourcing-ticker'] && <span className="form-error-message">{errors['data_sourcing-ticker']}</span>}
        </div>
      ))}

      {renderFieldset('feature_engineering', 'Özellik Mühendisliği', (
        <div className="form-group">
          <label htmlFor="target_col_transform">Hedef Sütun Dönüşümü:</label>
          <select
            id="target_col_transform"
            value={localConfig.feature_engineering?.target_col_transform || 'none'}
            onChange={(e) => handleChange(e, 'feature_engineering.target_col_transform')}
            className={errors['feature_engineering-target_col_transform'] ? 'input-error' : ''}
          >
            <option value="none">Yok</option>
            <option value="log">Log (log1p)</option>
          </select>
          <small>Modelin hedef sütunu üzerinde uygulanacak dönüşüm.</small>
          {errors['feature_engineering-target_col_transform'] && <span className="form-error-message">{errors['feature_engineering-target_col_transform']}</span>}
        </div>
      ))}

      {renderFieldset('model_params', 'Model Parametreleri', (
        <>
          <div className="form-group">
            <label htmlFor="sequence_length">Sekans Uzunluğu:</label>
            <input
              type="text" 
              id="sequence_length"
              value={formatListInput(localConfig.model_params?.sequence_length)}
              onChange={(e) => handleChange(e, 'model_params.sequence_length')}
              className={errors['model_params-sequence_length'] ? 'input-error' : ''}
              placeholder="Örn: 30, 60, 90"
            />
            <small>Geçmiş kaç günün verisinin girdi olarak kullanılacağı.</small>
            {errors['model_params-sequence_length'] && <span className="form-error-message">{errors['model_params-sequence_length']}</span>}
          </div>
          <div className="form-group">
            <label htmlFor="hidden_size">Gizli Katman Boyutu:</label>
            <input
              type="text" 
              id="hidden_size"
              value={formatListInput(localConfig.model_params?.hidden_size)}
              onChange={(e) => handleChange(e, 'model_params.hidden_size')}
              className={errors['model_params-hidden_size'] ? 'input-error' : ''}
              placeholder="Örn: 50, 100, 150"
            />
            <small>LSTM katmanındaki gizli birim sayısı.</small>
            {errors['model_params-hidden_size'] && <span className="form-error-message">{errors['model_params-hidden_size']}</span>}
          </div>
        </>
      ))}

      {renderFieldset('training_params', 'Eğitim Parametreleri', (
        <>
          <div className="form-group">
            <label htmlFor="epochs">Epoch Sayısı:</label>
            <input
              type="text" 
              id="epochs"
              value={formatListInput(localConfig.training_params?.epochs)}
              onChange={(e) => handleChange(e, 'training_params.epochs')}
              className={errors['training_params-epochs'] ? 'input-error' : ''}
              placeholder="Örn: 50, 100"
            />
            <small>Modelin eğitim veri seti üzerinden kaç kez geçeceği.</small>
            {errors['training_params-epochs'] && <span className="form-error-message">{errors['training_params-epochs']}</span>}
          </div>
          <div className="form-group">
            <label htmlFor="lr">Öğrenme Oranı (LR):</label>
            <input
              type="text" 
              id="lr"
              value={formatListInput(localConfig.training_params?.lr)}
              onChange={(e) => handleChange(e, 'training_params.lr')}
              className={errors['training_params-lr'] ? 'input-error' : ''}
              placeholder="Örn: 0.001, 0.0001"
            />
            <small>Optimizer'ın ağırlıkları ne kadar hızlı güncelleyeceği.</small>
            {errors['training_params-lr'] && <span className="form-error-message">{errors['training_params-lr']}</span>}
          </div>
          <div className="form-group">
            <label htmlFor="optimizer">Optimizer:</label>
            <select
              id="optimizer"
              value={localConfig.training_params?.optimizer || 'adam'}
              onChange={(e) => handleChange(e, 'training_params.optimizer')}
              className={errors['training_params-optimizer'] ? 'input-error' : ''}
            >
              <option value="adam">Adam</option>
              <option value="sgd">SGD</option>
            </select>
            <small>Modelin ağırlıklarını güncellemek için kullanılan algoritma.</small>
            {errors['training_params-optimizer'] && <span className="form-error-message">{errors['training_params-optimizer']}</span>}
          </div>
          <div className="form-group">
            <label htmlFor="test_size">Test Seti Boyutu (0.0 - 1.0):</label>
            <input
              type="text" 
              id="test_size"
              value={formatListInput(localConfig.training_params?.test_size)}
              onChange={(e) => handleChange(e, 'training_params.test_size')}
              className={errors['training_params-test_size'] ? 'input-error' : ''}
              placeholder="Örn: 0.1, 0.2"
            />
            <small>Veri setinin test için ayrılacak oranı.</small>
            {errors['training_params-test_size'] && <span className="form-error-message">{errors['training_params-test_size']}</span>}
          </div>
          <div className="form-group">
            <label htmlFor="validate_every">Her Kaç Epoch'ta Bir Doğrula:</label>
            <input
              type="text" 
              id="validate_every"
              value={formatListInput(localConfig.training_params?.validate_every)}
              onChange={(e) => handleChange(e, 'training_params.validate_every')}
              className={errors['training_params-validate_every'] ? 'input-error' : ''}
              placeholder="Örn: 5, 10"
            />
            <small>Canlı takip panelindeki tahmin grafiğinin kaç epoch'ta bir güncelleneceği.</small>
            {errors['training_params-validate_every'] && <span className="form-error-message">{errors['training_params-validate_every']}</span>}
          </div>
        </>
      ))}
      
      {renderFieldset('system', 'Sistem Ayarları', (
        <>
          <div className="form-group">
            <label htmlFor="caching_enabled">Önbellek Etkin mi?</label>
            <select
              id="caching_enabled"
              value={localConfig.system?.caching_enabled ? 'true' : 'false'}
              onChange={(e) => handleChange(e, 'system.caching_enabled')} 
              className={errors['system-caching_enabled'] ? 'input-error' : ''}
            >
              <option value="true">Evet</option>
              <option value="false">Hayır</option>
            </select>
            <small>Veri çekme işleminin önbelleğe alınıp alınmayacağı.</small>
            {errors['system-caching_enabled'] && <span className="form-error-message">{errors['system-caching_enabled']}</span>}
          </div>
          <div className="form-group">
            <label htmlFor="cache_max_age_hours">Önbellek Yaşam Süresi (saat):</label>
            <input
              type="text" 
              id="cache_max_age_hours"
              value={formatListInput(localConfig.system?.cache_max_age_hours)}
              onChange={(e) => handleChange(e, 'system.cache_max_age_hours')}
              className={errors['system-cache_max_age_hours'] ? 'input-error' : ''}
              placeholder="Örn: 12, 24"
            />
            <small>Önbellekteki verinin kaç saat sonra geçersiz sayılacağı.</small>
            {errors['system-cache_max_age_hours'] && <span className="form-error-message">{errors['system-cache_max_age_hours']}</span>}
          </div>
        </>
      ))}
    </>
  );
}

StockPredictorConfigForm.propTypes = {
  config: PropTypes.object,
  onConfigChange: PropTypes.func.isRequired,
  errors: PropTypes.object.isRequired,
};

// --- Ana NewExperiment Bileşeni (Formu ve Butonları Yöneten Dış Bileşen) ---
// Bu bileşen artık bir React sayfası değil, NewExperimentPanel içinde kullanılacak.

function NewExperiment({ onExperimentStarted, onClosePanel }) { 
  const [pipelines, setPipelines] = useState([]);
  const [selectedPipelineId, setSelectedPipelineId] = useState('');
  const [currentConfig, setCurrentConfig] = useState(null);
  const [defaultConfig, setDefaultConfig] = useState(null); 
  const [batchName, setBatchName] = useState('');
  const [isLoading, setIsLoading] = useState(true);
  const [isSubmitting, setIsSubmitting] = useState(false);
  const [formErrors, setFormErrors] = useState({});

  useEffect(() => {
    const loadPipelines = async () => {
      setIsLoading(true);
      try {
        const response = await fetchAvailablePipelines();
        if (response.data && response.data.length > 0) {
          setPipelines(response.data);
          if (!selectedPipelineId) {
            setSelectedPipelineId(response.data[0].id);
          }
        }
      } catch (error) { 
        toast.error('Pipeline listesi yüklenemedi. API servisinin çalıştığından emin olun.'); 
        console.error("Pipeline yükleme hatası:", error);
      } finally { setIsLoading(false); }
    };
    loadPipelines();
  }, [selectedPipelineId]); 

  useEffect(() => {
    const loadPipelineConfig = async (pipelineId) => {
      if (!pipelineId) {
        setCurrentConfig(null);
        setDefaultConfig(null);
        setIsLoading(false);
        return;
      }
      setIsLoading(true);
      setCurrentConfig(null); 
      setDefaultConfig(null);
      setFormErrors({});
      try {
        const { data } = await fetchPipelineDefaultConfig(pipelineId);
        const formattedData = formatConfigForUI(data); 
        setCurrentConfig(formattedData); 
        setDefaultConfig(JSON.parse(JSON.stringify(data))); 
      } catch (error) { 
        toast.error(`Konfigürasyon yüklenemedi: ${error.response?.data?.detail || error.message}`); 
        console.error("Konfigürasyon yükleme hatası:", error);
        setCurrentConfig({}); 
      } finally { 
        setIsLoading(false); 
      }
    };
    loadPipelineConfig(selectedPipelineId);
  }, [selectedPipelineId]);

  const formatConfigForUI = (config) => {
    const formatted = {};
    for (const key in config) {
        if (typeof config[key] === 'object' && config[key] !== null && !Array.isArray(config[key])) {
            formatted[key] = formatConfigForUI(config[key]); 
        } 
        else if (Array.isArray(config[key]) || typeof config[key] === 'number') {
            formatted[key] = formatListInput(config[key]); 
        }
        else {
            formatted[key] = config[key];
        }
    }
    return formatted;
  };

  const handleResetToDefault = useCallback(() => {
    if (defaultConfig) {
      setCurrentConfig(formatConfigForUI(defaultConfig));
      setFormErrors({});
      toast.info('Konfigürasyon varsayılan ayarlara sıfırlandı.');
    }
  }, [defaultConfig]);

  const validateConfig = (config) => {
    const errors = {};

    const validateNumberField = (value, path, min = -Infinity, max = Infinity) => {
      const parsedValues = parseNumberListInput(value); 
      
      if (parsedValues.length === 0) {
          errors[path.join('-')] = 'Bu alan boş bırakılamaz.';
          return;
      }
      if (parsedValues.some(v => typeof v !== 'number' || isNaN(v) || v < min || v > max)) {
          errors[path.join('-')] = `${path[path.length - 1]} için tüm değerler sayısal olmalı ve ${min} ile ${max} arasında olmalıdır.`;
      }
    };

    const validateStringField = (value, path) => {
        if (Array.isArray(value)) { 
            if (value.length === 0 || value.some(v => typeof v !== 'string' || v.trim() === '')) {
                errors[path.join('-')] = `${path[path.length - 1]} boş bırakılamaz veya boş öğe içeremez.`;
            }
        } else if (typeof value !== 'string' || value.trim() === '') { 
            errors[path.join('-')] = `${path[path.length - 1]} boş bırakılamaz.`;
        }
    };

    if (config.data_sourcing) {
        validateStringField(config.data_sourcing.ticker, ['data_sourcing', 'ticker']);
    }

    if (config.feature_engineering) {
        if (typeof config.feature_engineering.target_col_transform !== 'string' || !['none', 'log'].includes(config.feature_engineering.target_col_transform.toLowerCase())) {
            errors['feature_engineering-target_col_transform'] = 'Geçersiz dönüşüm seçimi.';
        }
    }

    if (config.model_params) {
      validateNumberField(config.model_params.sequence_length, ['model_params', 'sequence_length'], 1); 
      validateNumberField(config.model_params.hidden_size, ['model_params', 'hidden_size'], 1);     
    }

    if (config.training_params) {
      validateNumberField(config.training_params.epochs, ['training_params', 'epochs'], 1);         
      validateNumberField(config.training_params.lr, ['training_params', 'lr'], 0);                 
      validateNumberField(config.training_params.test_size, ['training_params', 'test_size'], 0, 1); 
      validateNumberField(config.training_params.validate_every, ['training_params', 'validate_every'], 1); 
      
      if (typeof config.training_params.optimizer !== 'string' || !['adam', 'sgd'].includes(config.training_params.optimizer.toLowerCase())) {
          errors['training_params-optimizer'] = 'Geçersiz optimizer seçimi.';
      }
    }

    if (config.system) {
        if (typeof config.system.caching_enabled !== 'boolean') { 
            errors['system-caching_enabled'] = 'Önbellek etkinleştirme seçimi yapılmalı.';
        }
        validateNumberField(config.system.cache_max_age_hours, ['system', 'cache_max_age_hours'], 0); 
    }
    
    return errors;
  };

  const handleSubmit = async (e) => {
    e.preventDefault();
    if (!currentConfig) {
        toast.error('Konfigürasyon henüz yüklenmedi.');
        return;
    }

    const configToSendToApi = JSON.parse(JSON.stringify(currentConfig));
    
    const numericFieldsPaths = [
        ['model_params', 'sequence_length'],
        ['model_params', 'hidden_size'],
        ['training_params', 'epochs'],
        ['training_params', 'lr'],
        ['training_params', 'test_size'],
        ['training_params', 'validate_every'],
        ['system', 'cache_max_age_hours']
    ];

    numericFieldsPaths.forEach(path => {
        let current = configToSendToApi;
        for (let i = 0; i < path.length - 1; i++) {
            current = current[path[i]];
            if (current === undefined || current === null) return; 
        }
        const fieldName = path[path.length - 1];
        
        if (current && current[fieldName] !== undefined && current[fieldName] !== null) {
            const parsed = parseNumberListInput(current[fieldName]);
            if (parsed.length === 1 && !isNaN(parsed[0])) {
                current[fieldName] = parsed[0];
            } else {
                current[fieldName] = parsed; 
            }
        }
    });

    if (configToSendToApi.data_sourcing?.ticker && Array.isArray(configToSendToApi.data_sourcing.ticker) && configToSendToApi.data_sourcing.ticker.length === 1) {
        configToSendToApi.data_sourcing.ticker = configToSendToApi.data_sourcing.ticker[0];
    }
    
    const errors = validateConfig(configToSendToApi); 
    if (Object.keys(errors).length > 0) {
      setFormErrors(errors); 
      toast.error('Lütfen formdaki hataları düzeltin.');
      return;
    }
    setFormErrors({}); 

    setIsSubmitting(true);
    configToSendToApi.pipeline_name = selectedPipelineId;

    if (batchName.trim()) { 
      configToSendToApi.batch_name = batchName.trim();
    } else {
        delete configToSendToApi.batch_name;
    }

    try {
      const { data } = await startNewExperiment(configToSendToApi); 
      if (data.batch_id) {
        toast.success(`🎉 Batch görevi (${data.task_ids.length} deney) başarıyla gönderildi! Batch ID: ${data.batch_id.slice(0, 8)}...`);
      } else {
        toast.success(`🚀 Görev başarıyla gönderildi! Deney ID: ${data.task_id.slice(0, 8)}...`);
      }
      if (onExperimentStarted) onExperimentStarted(data.task_id); // Paneli kapatıp ana sayfaya yönlendirir
    } catch (err) {
      toast.error('Deney başlatılamadı. API/Worker loglarını veya tarayıcı konsolunu kontrol edin.');
      console.error("Deney başlatma hatası:", err.response?.data?.detail || err.message || err);
    } finally {
      setIsSubmitting(false);
    }
  };
  
  const selectedPipelineDetails = pipelines.find(p => p.id === selectedPipelineId);

  const renderSelectedPipelineForm = () => {
    if (isLoading) {
        return <p>Parametreler yükleniyor...</p>;
    }
    if (!currentConfig) { 
        return <p>Bu pipeline için düzenlenebilir konfigürasyon bulunamadı.</p>;
    }
    
    switch (selectedPipelineId) {
      case 'stock_predictor':
        return <StockPredictorConfigForm config={currentConfig} onConfigChange={setCurrentConfig} errors={formErrors} />;
      default:
        return <p>Lütfen bir pipeline seçin veya bu pipeline için yapılandırma formu bulunamadı.</p>;
    }
  };

  return (
    <form onSubmit={handleSubmit} className="new-experiment-panel-form"> 
        <div className="new-experiment-panel-form-content"> 
          <div className="card">
            <div className="form-group">
              <label htmlFor="pipeline-select">Çalıştırılacak Pipeline Eklentisi</label>
              <select id="pipeline-select" value={selectedPipelineId} onChange={(e) => setSelectedPipelineId(e.target.value)} disabled={isLoading || isSubmitting}>
                {pipelines.map(p => <option key={p.id} value={p.id}>{p.name} ({p.id})</option>)}
              </select>
            </div>
            <div className="form-group">
              <label htmlFor="batch-name">Deney Grubu Adı (İsteğe Bağlı)</label>
              <input 
                type="text" 
                id="batch-name" 
                value={batchName} 
                onChange={(e) => setBatchName(e.target.value)} 
                placeholder="Örn: LR ve Epoch Optimizasyonu"
                disabled={isLoading || isSubmitting}
              />
              <small style={{ color: 'var(--text-color-darker)', fontSize: '0.85em' }}>
                Birden fazla parametre kombinasyonu gönderirken grubu isimlendirmek için kullanılır.
              </small>
            </div>
          </div>
          
          <div className="card" style={{padding: 0}}> 
            <div className="collapsible-header" onClick={handleResetToDefault} style={{borderBottom: 'none', borderRadius: '8px', marginBottom: '15px', justifyContent: 'center'}}>
                <span role="img" aria-label="reset">🔄</span> Varsayılan Konfigürasyona Dön
            </div>
            <h3>Deney Parametreleri</h3>
            {renderSelectedPipelineForm()}
          </div>
        </div>

        <div className="form-action-bar">
          <div className="pipeline-info">
            <strong>Pipeline:</strong>
            <span>{selectedPipelineDetails?.name || '...'}</span>
          </div>
          <button type="submit" disabled={isLoading || isSubmitting} className="button-primary">
            {isSubmitting ? 'Başlatılıyor...' : 'Eğitimi Başlat'}
          </button>
        </div>
    </form>
  );
}

NewExperiment.propTypes = { 
    onExperimentStarted: PropTypes.func.isRequired,
    onClosePanel: PropTypes.func.isRequired, 
};
export default NewExperiment;
========== FILE: dashboard/src/services/api.js ==========
// dashboard/src/services/api.js

import axios from 'axios';

export const API_BASE_URL = 'http://localhost:8000/api/v1';

const apiClient = axios.create({
  baseURL: API_BASE_URL,
  headers: { 'Content-Type': 'application/json' },
});

// fetchExperiments artık tüm detayları getiriyor
export const fetchExperiments = () => apiClient.get('/experiments');
export const startNewExperiment = (config) => apiClient.post('/experiments', config);
export const fetchAvailablePipelines = () => apiClient.get('/pipelines'); 
export const fetchPipelineDefaultConfig = (pipelineId) => apiClient.get(`/pipelines/${pipelineId}/config`);

// fetchExperimentDetails artık UI'da doğrudan kullanılmayacak, ancak API'de kalabilir.
export const fetchExperimentDetails = (experimentId) => {
  return apiClient.get(`/experiments/${experimentId}/details`);
};
========== FILE: dashboard/src/utils/cssUtils.js ==========
/**
 * Belirtilen CSS değişkeninin hesaplanmış değerini döndürür.
 * @param {string} varName - '--primary-color' gibi CSS değişken adı.
 * @returns {string} - Değişkenin renk değeri (örn. '#42b983').
 */
export const getCssVar = (varName) => {
  if (typeof window === 'undefined') return '';
  return getComputedStyle(document.documentElement).getPropertyValue(varName).trim();
};
========== FILE: docs/ARCHITECTURE.md ==========
# 🏗️ AzuraForge Mimarisi

Bu belge, AzuraForge platformunu oluşturan servislerin ve bileşenlerin birbirleriyle nasıl etkileşime girdiğini, özellikle de **asenkron ve olay güdümlü yapının** nasıl çalıştığını detaylandırmaktadır.

## 1. Temel Bileşenler ve Sorumlulukları

Platform, her biri belirli bir göreve odaklanmış bağımsız servislerden oluşur:

*   **Dashboard (Arayüz Katmanı):**
    *   Kullanıcının etkileşime girdiği React tabanlı web uygulaması.
    *   Deneyleri başlatır, canlı ilerlemeyi gösterir, raporları görüntüler.
    *   Sadece `API` servisi ile konuşur.

*   **API (İletişim ve Ağ Geçidi Katmanı):**
    *   Platformun dış dünyaya açılan kapısıdır.
    *   Gelen istekleri doğrular ve görevleri `Celery` kuyruğuna (Redis) iletir.
    *   `Dashboard`'dan gelen canlı takip istekleri için `WebSocket` bağlantılarını yönetir.
    *   Redis Pub/Sub kanallarına **abone (subscribe)** olarak `Worker`'dan gelen olayları dinler.

*   **Worker (İşleme Katmanı):**
    *   Ağır hesaplama yükünü üstlenir (model eğitimi, rapor oluşturma vb.).
    *   `Celery` kuyruğundan görevleri alır ve işler.
    *   Eğitim sırasında ilerleme bilgilerini (`loss`, `epoch` vb.) Redis Pub/Sub kanallarına **yayınlar (publish)**.
    *   `Learner` ve `Core` kütüphanelerini kullanarak AI modellerini çalıştırır.

*   **Redis (Mesajlaşma ve Önbellek Katmanı):**
    *   Platformun merkezi sinir sistemidir.
    *   **Celery Broker & Backend:** `API` ve `Worker` arasındaki görev kuyruğu ve sonuç deposu olarak hizmet eder.
    *   **Pub/Sub Sunucusu:** `Worker` ile `API` arasında gerçek zamanlı, bloklamayan iletişim için kullanılır.

## 2. Bir Deneyin Yaşam Döngüsü: Olay Güdümlü Akış

Aşağıdaki şema, kullanıcı bir deneyi başlattığı andan itibaren sistemde gerçekleşen olaylar zincirini göstermektedir.

```mermaid
sequenceDiagram
    participant D as Dashboard
    participant A as API Server
    participant R as Redis
    participant W as Worker

    D->>A: 1. POST /experiments (config ile)
    A->>R: 2. send_task('start_training', config)
    A-->>D: 3. { task_id: 'xyz' }

    D->>A: 4. WebSocket /ws/task_status/xyz
    Note over A: WebSocket bağlantısı açılır.
    A->>R: 5. SUBSCRIBE 'task-progress:xyz'
    Note over A: API artık bu kanalı dinliyor.

    R->>W: 6. Görevi (task_id: 'xyz') teslim eder.
    Note over W: Worker, Pipeline'ı başlatır ve<br/>RedisProgressCallback'i ekler.
    
    loop Eğitim Döngüsü (Her Epoch Sonu)
        W->>W: Learner, on_epoch_end olayını tetikler.
        W->>R: 7. PUBLISH 'task-progress:xyz'<br/>{ epoch: n, loss: 0.123, ... }
    end

    R-->>A: 8. Kanalda yeni mesaj var!
    A-->>D: 9. WebSocket ile veriyi anında iletir.
    Note over D: LiveTrackerPane güncellenir.
    
    Note over W: Eğitim biter.
    W->>R: 10. Görev sonucunu (results.json) yazar.
    W-->>A: (Opsiyonel) Görev durumu 'SUCCESS' olur.
```

### Akışın Adım Adım Açıklaması:

1.  **Deney Başlatma:** `Dashboard`, `API`'ye deney konfigürasyonunu içeren bir HTTP POST isteği gönderir.
2.  **Görev Kuyruğa Atma:** `API`, bu isteği alır ve `Celery`'nin `send_task` metoduyla görevi Redis'teki kuyruğa bırakır.
3.  **Anında Geri Dönüş:** `API`, görevin işlenmesini beklemeden, `Dashboard`'a anında bir `task_id` döndürür. Arayüz "donmaz".
4.  **Canlı Takip Bağlantısı:** `Dashboard`, aldığı `task_id` ile `API`'nin WebSocket endpoint'ine bağlanır.
5.  **Kanala Abone Olma:** `API`, bu `task_id`'ye özel bir Redis Pub/Sub kanalına (`task-progress:xyz`) abone olur ve sessizce beklemeye başlar.
6.  **Görevi Alma:** `Worker`, Redis kuyruğundaki görevi alır ve `start_training_pipeline` görevini çalıştırmaya başlar.
7.  **İlerleme Yayınlama:** Eğitim sırasında, `Learner`'daki `RedisProgressCallback`, her epoch sonunda ilerleme verisini (kayıp, epoch vb.) ilgili Redis kanalına yayınlar.
8.  **Mesajı Yakalama:** `API`, abone olduğu kanalda bir mesaj belirdiğini anında fark eder.
9.  **Anında İletim:** `API`, bu mesajı alır ve olduğu gibi WebSocket üzerinden `Dashboard`'a iletir. `Dashboard`'daki ilgili bileşen (grafik, ilerleme çubuğu) kendini günceller.
10. **Görevin Tamamlanması:** Eğitim bittiğinde, `Worker` nihai sonuçları (`results.json`) yazar ve Celery görevini `SUCCESS` olarak işaretler.

Bu mimari, hesaplama (`Worker`) ve iletişim (`API`) katmanlarını birbirinden tamamen ayırarak platforma **sağlamlık, ölçeklenebilirlik ve gerçek zamanlılık** kazandırır.


========== FILE: docs/CONTRIBUTING.md ==========
========== FILE: docs/CONTRIBUTING.md ==========
# 🤝 AzuraForge Platformuna Katkıda Bulunma Rehberi

AzuraForge projesine gösterdiğiniz ilgi ve katkılarınız için teşekkür ederiz! Bu proje, modern yapay zeka sistemlerinin nasıl inşa edilmesi gerektiğine dair bir vizyonu hayata geçirmeyi amaçlamaktadır. Bu rehber, kod tabanının tutarlı, okunabilir, sürdürülebilir ve yüksek kalitede kalmasını sağlamak için benimsediğimiz çalışma prensiplerini ve standartlarını açıklamaktadır.

## 🚀 Hızlı Başlangıç

Eğer henüz geliştirme ortamınızı kurmadıysanız, lütfen platformun ana [Geliştirme Rehberi](./DEVELOPMENT_GUIDE.md) belgesindeki "Geliştirme Ortamı Kurulumu" bölümünü takip edin.

## 🛠️ Kodlama Standartları

Projeye eklenen her kodun aşağıdaki standartları karşılaması beklenmektedir. Bu standartların birçoğu, ilgili reponun kök dizinindeki `pre-commit` hook'ları ile otomatik olarak kontrol edilir.

1.  **Stil Kılavuzu (PEP8 & Black):**
    *   Tüm Python kodları, PEP8 stil kurallarına uymalıdır.
    *   Kodunuzu `black` ile otomatik formatlayın.
    *   **Kontrol:** `black .` komutunu çalıştırın.
    *   **Otomasyon:** `pre-commit` hook'ları bu formatlamayı zorunlu kılar.

2.  **Linting (`flake8`):**
    *   Tüm Python kodları, `flake8` denetiminden hatasız geçmelidir.
    *   **Kontrol:** İlgili repo içinde `flake8 src` komutunu çalıştırın.
    *   **Otomasyon:** `pre-commit` hook'ları linting'i zorunlu kılar.

3.  **Tip İpuçları (Type Hinting & Mypy):**
    *   Tüm fonksiyon ve metod imzaları, parametreler ve dönüş değerleri için tip ipuçları (`typing` modülü kullanılarak) içermelidir.
    *   **Kontrol:** İlgili repo içinde `mypy src` komutunu çalıştırın.
    *   **Otomasyon:** `pre-commit` hook'ları statik tip denetimini zorunlu kılar.

4.  **Dokümantasyon (Docstrings):**
    *   Tüm public modüller, sınıflar ve fonksiyonlar, ne işe yaradıklarını, aldıkları argümanları (`Args:`) ve ne döndürdüklerini (`Returns:`) açıklayan Google-style docstring'ler içermelidir.

5.  **Testler (`pytest`):**
    *   Eklenen her yeni özellik veya fonksiyon için ilgili birim testleri (`unit tests`) `tests/` klasörüne eklenmelidir.
    *   Yapılan bir hata düzeltmesi (bug fix) için, o hatanın tekrar oluşmasını engelleyecek bir regresyon testi yazılmalıdır.
    *   **Kontrol:** İlgili reponun kök dizinindeyken `pytest` komutunu çalıştırın.

## 📝 Commit Mesajları

Commit mesajları, yapılan değişikliği net bir şekilde açıklamalıdır ve [Conventional Commits](https://www.conventionalcommits.org/en/v1.0.0/) standardına uymalıdır. Bu, otomatik versiyonlama ve değişiklik günlüğü oluşturmak için hayati önem taşır.

**Format:**
```
<tip>(<kapsam>): <açıklama>

[opsiyonel gövde]
```

**Örnek Tipler:**
*   `feat`: Yeni bir özellik ekler (Minor versiyon artırımı).
*   `fix`: Bir hata düzeltmesi (Patch versiyon artırımı).
*   `docs`: Sadece dokümantasyon değişiklikleri.
*   `style`: Kod formatı, eksik noktalı virgül gibi stil düzeltmeleri.
*   `refactor`: Kodu yeniden yapılandırma, davranış değişikliği yok.
*   `perf`: Performans iyileştirmesi yapan kod değişikliği.
*   `test`: Eksik testlerin eklenmesi veya mevcut testlerin düzeltilmesi.
*   `build`: Build sistemi veya dış bağımlılık değişiklikleri.
*   `ci`: CI/CD yapılandırma dosyaları ve script'leri değişiklikleri.

**Örnekler:**
*   `feat(learner): Add LSTM backward pass implementation`
*   `fix(api): Handle null values from experiment results`
*   `docs(platform): Update development guide with Pub/Sub architecture`
*   `refactor(worker): Extract Redis publishing logic into a callback`

## 🔄 Pull Request (PR) Süreci

1.  **Branch Oluşturma:** `main` branch'inden kendi feature branch'inizi (`feat/yeni-ozellik` veya `fix/hata-adi` gibi) oluşturun.
2.  **Değişikliklerinizi Yapın:** Yukarıdaki standartlara uyduğunuzdan emin olun.
3.  **Test Edin:** Yerel testlerinizi (`pytest`) çalıştırın ve geçtiğinden emin olun.
4.  **Commit ve Push:** Değişikliklerinizi anlamlı commit mesajlarıyla branch'inize `push` edin.
5.  **Pull Request Açın:** GitHub üzerinden `main` branch'ine bir "Pull Request" (PR) açın.
6.  **CI Kontrolleri:** PR'ınızın CI kontrollerinden (testler, linting) başarıyla geçtiğinden emin olun.
7.  **Kod İncelemesi:** Kodunuz incelenecek ve gerekli geri bildirimler sağlanacaktır.

Bu standartlara uyarak, AzuraForge platformunun uzun vadede sağlıklı, sürdürülebilir ve yüksek kalitede kalmasına yardımcı olursunuz.


## 📦 Versiyonlama ve Bağımlılık Yönetimi

Platformun kararlılığını sağlamak için tüm Python paketlerimiz Anlamsal Versiyonlama (Semantic Versioning) ve Git etiketlerini kullanır. Bağımlılıklar asla `@main` branch'ine işaret etmemelidir.

### Bir Kütüphanede Değişiklik Yapıldığında İzlenecek Adımlar:

Bir kütüphanede (örn: `learner`) bir hata düzeltmesi veya yeni bir özellik eklendiğinde, aşağıdaki adımlar izlenmelidir:

1.  **Değişiklikleri Tamamlayın:** Gerekli kod değişikliklerini yapın, testleri güncelleyin ve `main` branch'ine birleştirin.

2.  **Versiyonu Yükseltin:** `pyproject.toml` dosyasındaki `version` numarasını anlamsal versiyonlama kurallarına göre artırın.
    *   `fix` (hata düzeltmesi): `0.1.3` -> `0.1.4` (Patch artışı)
    *   `feat` (yeni özellik): `0.1.3` -> `0.2.0` (Minor artış)

3.  **Yeni Versiyonu Etiketleyin:** Yeni versiyon numarasını bir Git etiketi olarak oluşturun ve GitHub'a gönderin.
    ```bash
    # learner/ dizinindeyken
    git tag v0.2.0
    git push origin v0.2.0
    ```

4.  **Bağımlı Repoları Güncelleyin:** `learner` kütüphanesini kullanan tüm diğer repoların (`api`, `app-stock-predictor` vb.) `pyproject.toml` dosyalarındaki ilgili satırı yeni versiyon etiketiyle (`...@v0.2.0`) güncelleyin.
========== FILE: docs/DEVELOPMENT_GUIDE.md ==========
========== FILE: docs/DEVELOPMENT_GUIDE.md ==========
# 🛠️ AzuraForge Platform Geliştirme Rehberi

Bu belge, AzuraForge platformunda geliştirme yapmak isteyenler için adım adım kurulum, çalışma prensipleri ve katkıda bulunma yönergelerini içerir.

## 🎯 Temel Felsefemiz

AzuraForge'da geliştirme yaparken, iki temel prensibi aklımızda tutarız:

1.  **Bağımsız Paketler:** Her repo (`core`, `learner`, `api` vb.), kendi başına yaşayan, kurulabilir ve test edilebilir bağımsız bir Python/JavaScript paketidir.
2.  **Düzenlenebilir Kurulum:** Repolar arası bağımlılıklar, yerel geliştirmeyi hızlandırmak için `pip install -e` (editable) komutuyla kurulur. Bu sayede bir kütüphanede yaptığınız değişiklik, diğerlerine anında yansır.


Her repomuz, kendi başına yaşayan, kurulabilir ve test edilebilir bağımsız bir Python/JavaScript paketidir. Repolar arası bağımlılıklar, Git adresleri (`@git+https://...`) üzerinden kurulur.

## 📦 Proje Repolarına Genel Bakış

AzuraForge platformu, aşağıdaki bağımsız GitHub depolarından oluşur. Geliştirme yaparken bu repoların bir kısmını veya tamamını yerel makinenizde klonlamanız gerekecektir.

*   **`core`**: Temel otomatik türev motoru.
*   **`learner`**: `core` üzerinde yüksek seviyeli öğrenme kütüphanesi.
*   **`app-stock-predictor`**: Bir uygulama eklentisi örneği.
*   **`applications`**: Resmi uygulama katalogu.
*   **`api`**: RESTful API ve WebSocket sunucusu (Redis Pub/Sub dinleyicisi).
*   **`worker`**: Arka plan görevlerini işleyen Celery worker (Redis Pub/Sub yayıncısı).
*   **`dashboard`**: React tabanlı web kullanıcı arayüzü.
*   **`platform`**: Tüm servisleri bir araya getiren ana orkestrasyon deposu (bu repo).

## ⚙️ Geliştirme Ortamı Kurulumu

Bu adımlar, platformun tüm parçalarını yerel geliştirme için hazır hale getirir.

1.  **Gerekli Araçlar:** Git, Python 3.8+, Node.js & npm, Docker Desktop.

2.  **Repoları Klonlama:**
    Tüm ilgili repoları aynı seviyede bir klasöre klonlayın:
    ```bash
    mkdir azuraforge-dev
    cd azuraforge-dev

    git clone https://github.com/AzuraForge/platform.git
    git clone https://github.com/AzuraForge/core.git
    git clone https://github.com/AzuraForge/learner.git
    git clone https://github.com/AzuraForge/applications.git
    git clone https://github.com/AzuraForge/app-stock-predictor.git
    git clone https://github.com/AzuraForge/api.git
    git clone https://github.com/AzuraForge/worker.git
    git clone https://github.com/AzuraForge/dashboard.git
    ```

3.  **Sanal Ortam ve Bağımlılıklar (Python):**

    **`.env` Dosyasını Oluşturma:**
    Platformu çalıştırmadan önce, ana `platform` dizininde bir `.env` dosyası oluşturun. Bu dosya, servislerin ortak dizinlere erişimini sağlar.
    ```
    # .env
    REDIS_URL=redis://redis:6379/0
    REPORTS_DIR=./reports
    CACHE_DIR=./.cache
    ```

    Yerel geliştirme için, **`platform` projesinin** kök dizininde tek bir sanal ortam oluşturup tüm Python bağımlılıklarını oraya kurmak en pratik yoldur.

    ```bash
    cd platform # Ana `platform` reposunun içine gir
    python -m venv .venv
    # Windows: .\.venv\Scripts\activate | Linux/macOS: source ./.venv/bin/activate
    ```
    # Tüm Python repolarını "düzenlenebilir" modda kur
    ```bash
    pip install -e ../core 
    pip install -e ../learner
    pip install -e ../applications
    pip install -e ../app-stock-predictor
    pip install -e ../api
    pip install -e ../worker
    ```

4.  **JavaScript Bağımlılıkları (Dashboard):**
    ```bash
    cd ../dashboard # `dashboard` reposunun içine gir
    npm install
    ```

5.  **Redis Kurulumu (Docker ile):**
    ```bash
    docker run -d -p 6379:6379 --name azuraforge_redis redis
    ```

## ▶️ Servisleri Çalıştırma (Yerel Geliştirme)

Sanal ortamınız aktifken ve Redis çalışırken, her servisi ayrı bir terminalde başlatın.

1.  **API Sunucusu (`api` reposundan):**
    ```bash
    cd ../api # veya bulunduğunuz yere göre ayarlayın
    # Gerekirse sanal ortamı aktive et
    start-api
    ```

2.  **Worker Servisi (`worker` reposundan):**
    ```bash
    cd ../worker
    # Gerekirse sanal ortamı aktive et
    start-worker
    ```

3.  **Dashboard (`dashboard` reposundan):**
    ```bash
    cd ../dashboard
    npm run dev
    ```

##  🔄 İteratif Geliştirme Akışı

Çoğu zaman, kodda küçük değişiklikler yapıp bunları hızla test etmek istersiniz.

1.  **Kütüphanede Değişiklik (örn: `core/src/azuraforge_core/tensor.py`):**
    *   Değişikliği yapın ve kaydedin.
    *   Bu değişikliğin diğer kütüphanelerde anında etkili olması için **ekstra bir `pip install` komutuna GEREK YOKTUR**, çünkü `-e` ile kuruldukları için doğrudan kaynak dosyayı kullanırlar.
    *   `core` projesine geri dönüp birim testlerini (`pytest`) koşarak değişikliği doğrulayın.
    *   Değişikliği `commit`'leyin ve `push`'layın.

2.  **Uygulama/Servis Değişikliği (örn: `app-stock-predictor/src/azuraforge_stockapp/pipeline.py`):**
    *   Değişikliği yapın ve kaydedin.
    *   `api` veya `worker` servisleri otomatik olarak `reload` (yeniden yükleme) yapacaktır (eğer `uvicorn --reload` ile çalışıyorlarsa). Değişikliğin etkisini görmek için genellikle ilgili servisi (API veya Worker) yeniden başlatmak yeterlidir.
    *   Değişikliği `commit`'leyin ve `push`'layın.

3.  **Yeni Bir Bağımlılık Eklendiğinde (`pyproject.toml` değiştiğinde):**
    *   Bir reponun (örn: `learner`) `pyproject.toml` dosyasına yeni bir bağımlılık (örn: `pandas`) eklediyseniz, bu değişikliğin diğer repolar tarafından tanınması için **bağımlılık zincirini yeniden kurmanız gerekir.**
    *   `platform` klasöründeki ana sanal ortamınızı aktive edin.
    *   `pip install -e ../learner` komutunu tekrar çalıştırın. `pip`, sadece eksik olan yeni bağımlılıkları (`pandas`) ekleyecektir.

##  Canlı Takip Mimarisi Nasıl Çalışır?

1.  `Dashboard`, `API`'ye bir `/experiments` POST isteği atar.
2.  `API`, görevi `Celery` kuyruğuna bırakır ve `Dashboard`'a bir `task_id` döner.
3.  `Dashboard`, bu `task_id` ile `API`'nin `/ws/task_status/{task_id}` WebSocket endpoint'ine bağlanır.
4.  `API`, bu bağlantı için bir Redis istemcisi oluşturur ve `task-progress:{task_id}` kanalına **abone (subscribe)** olur.
5.  `Worker`, görevi kuyruktan alır ve `Learner`'ı, içine `RedisProgressCallback` enjekte edilmiş şekilde çalıştırır.
6.  `Learner`, her epoch sonunda `on_epoch_end` olayını yayınlar.
7.  `RedisProgressCallback`, bu olayı yakalar ve ilerleme verisini (epoch, loss) Redis'teki `task-progress:{task_id}` kanalına **yayınlar (publish)**.
8.  `API`, abone olduğu kanalda yeni bir mesaj duyar, onu alır ve WebSocket üzerinden anında `Dashboard`'a iletir.
9.  `Dashboard`'daki `LiveTrackerPane` bileşeni, gelen bu veriyle kendini günceller.

Bu yapı, `Worker`'ın CPU kullanımı ne kadar yoğun olursa olsun, raporlama ve arayüz güncellemesinin bloklanmadan, anlık olarak gerçekleşmesini sağlar.

##  Platform Mimarisi Nasıl Çalışır?

### Standart Bir Deney Akışı

1.  **Başlatma (`Dashboard` -> `API` -> `Worker`):**
    *   `Dashboard`, kullanıcıdan aldığı konfigürasyon ile `API`'nin `/experiments` endpoint'ine bir `POST` isteği atar.
    *   `API`, görevi `Celery` kuyruğuna bırakır ve bir `task_id` döner.
    *   `Worker`, görevi kuyruktan alır ve ilgili `Pipeline` eklentisinin bir örneğini oluşturur.

2.  **Eğitim ve Canlı Takip (`Worker` -> `Learner` -> `API` -> `Dashboard`):**
    *   `Worker`, eklentinin standart `run` metodunu çağırır. Bu metot, `azuraforge-learner` içindeki `TimeSeriesPipeline`'den gelir.
    *   `run` metodu, `LivePredictionCallback` ve `RedisProgressCallback` gibi özel `Callback`'ler oluşturur.
    *   `Learner`'ın `fit` metodu çalıştırılır. Her epoch sonunda:
        *   `LivePredictionCallback`, doğrulama seti üzerinde tahmin yapar.
        *   `RedisProgressCallback`, hem kayıp bilgisini hem de canlı tahmin verisini birleştirerek Redis Pub/Sub kanalına yayınlar.
    *   `API`, bu kanala abone olduğu için mesajı anında alır ve `WebSocket` üzerinden `Dashboard`'a iletir.
    *   `LiveTrackerPane`, gelen bu zengin veriyle kendini (kayıp grafiği, tahmin grafiği, ilerleme çubuğu) günceller.

3.  **Tamamlama ve Raporlama (`Worker` -> `Learner`):**
    *   Eğitim bittiğinde, `TimeSeriesPipeline`'in `run` metodu, son değerlendirmeyi yapar ve `azuraforge_learner.reporting` içindeki `generate_regression_report` fonksiyonunu çağırır.
    *   Bu fonksiyon, `/reports` dizini altına, grafikleri içeren bir `report.md` dosyası oluşturur.
    *   `run` metodu, deneyin tüm sonuçlarını (`history`, `metrics`, ham veriler) içeren bir JSON objesini `worker` görevine döndürür.
    *   `Worker`, bu sonucu `results.json` dosyasına yazar ve görevi `SUCCESS` olarak işaretler.

## 🤝 Katkıda Bulunma

Bu proje bir açık kaynak projesi olarak geliştirilmektedir. Katkıda bulunmak için lütfen `platform/docs/CONTRIBUTING.md` dosyasını inceleyin.
========== FILE: docs/PROJECT_JOURNEY.md ==========
# 🗺️ Proje Yolculuğu: AzuraForge'un Gelişim Hikayesi ve Gelecek Vizyonu

Bu belge, AzuraForge platformunun başlangıcından mevcut durumuna kadar olan gelişim sürecini, karşılaşılan zorlukları, bulunan çözümleri ve projenin **kendi kendini anlayan, sıfırdan inşa edilmiş, eklenti tabanlı ve evrensel bir yapay zeka geliştirme platformuna** dönüşme vizyonunu özetlemektedir.

## 🚀 Proje Vizyonu ve Felsefesi

AzuraForge, basit bir araç seti olmanın ötesinde, bir felsefeyi temsil eder: **Ferrari motorunu (kanıtlanmış, sıfırdan inşa edilmiş AI gücü) alıp, modüler ve genişletilebilir bir uzay gemisi şasisine (dağıtık MLOps mimarisi) monte etmek.** Bu uzay gemisi, yeni eklentilerle (`app-xx`) sürekli geliştirilerek farklı görevleri yerine getirebilen, akıllı ve kendi kendini yönetebilen bir yapıya dönüşür.

Bu vizyonu gerçekleştirmek için iki temel anayasal prensibe bağlıyız:

1.  **Çekirdek Bağımsızlığı ve Derin Anlayış ("Smart Learner" Ruhu):**
    Platformun kalbindeki (`azuraforge-core`, `azuraforge-learner`) algoritmalar ve yapılar, dış kütüphanelere minimal bağımlılıkla, temel prensipleri anlaşılarak sıfırdan inşa edilir. Bu bize tam kontrol, esneklik, şeffaflık ve derinlemesine bir "know-how" sağlar.

2.  **Modüler ve Ölçeklenebilir Ekosistem ("AzuraForge" Mimarisi):**
    Çekirdeğin saf gücü; dağıtık, asenkron, olay güdümlü ve eklenti tabanlı bir mimariyle sunulur. Bu sayede platform; sağlam, esnek, büyümeye açık ve modern mühendislik standartlarına uygun kalır.

---

## ✅ Tamamlanan Fazlar ve Elde Edilen Başarılar

### Faz 0: Fikir ve Prototip ("Smart Learner" Projesi)
- **Düşünce:** Mevcut ML araçlarının karmaşıklığına, "kara kutu" yapısına ve aşırı bağımlılıklarına bir tepki olarak, sıfırdan bir derin öğrenme motoru (`mininn`) inşa etme fikri doğdu.
- **Kanıt:** Monolitik bir prototip olan "Smart Learner" projesi geliştirildi. Sıfırdan yazılan `LSTM` mimarisi, hava durumu tahmininde **R² > 0.98**, hisse senedi fiyat tahmininde ise **R² ≈ 0.73** gibi somut ve etkileyici başarılar elde etti.
- **Öğrenilen Ders:** Monolitik yapı hızlı prototipleme sağlasa da, ölçeklenebilirlik, canlı takip ve modüler genişleme için yetersizdi. Daha büyük bir vizyon için paradigma değişimi gerekiyordu.

### Faz 1-3: Mikroservis Mimarisine Geçiş ve Temel Yapının İnşası
- **Karar:** Uzun vadeli sürdürülebilirlik için platform, bağımsız repolara (`azuraforge-core`, `learner`, `api`, `worker`, `dashboard` vb.) sahip bir mikroservis mimarisine dönüştürüldü.
- **Yapı:** `docker-compose` ile orkestrasyon, `pip install -e` ile yerel geliştirme ve `git+https` ile repo'lar arası bağımlılıklar kuruldu.
- **İlk Başarı:** `Dashboard` -> `API` -> `Worker` -> `Uygulama` -> `Learner` -> `Core` şeklindeki temel görev akışı başarıyla çalıştırıldı.

### Faz 4-8: Gerçek Zamanlı Akışın Sağlanması (Pub/Sub Mimarisi - Dönüm Noktası)
- **Sorun:** CPU-yoğun eğitim görevleri, Worker'ın durum güncelleme mesajlarını göndermesini engelleyerek arayüzün "donmasına" neden oluyordu.
- **Çözüm:** Hesaplama ve raporlama görevlerini tamamen ayırmak için Redis Pub/Sub modeline geçildi.
    - `Learner` sadece olay (`on_epoch_end`) yayınlayan saf bir bileşen haline getirildi.
    - `Worker`, `RedisProgressCallback` aracılığıyla bu olayları dinleyip bir Redis kanalına yayınlar hale geldi.
    - `API`, bu kanala abone olup, gelen her mesajı WebSocket üzerinden anında `Dashboard`'a iletir hale geldi.
- **BAŞARI:** Bu mimari değişiklik sayesinde, anlık ve akıcı bir canlı takip deneyimi mümkün oldu.

### Faz 9-17: Mimari Olgunluk ve Gelişmiş Yetenekler ("Checkpoint Echo")
- **Standardizasyon (`BasePipeline`):** Uygulama eklentisi geliştirmeyi standartlaştıran `TimeSeriesPipeline` soyut sınıfı oluşturuldu.
- **Verimlilik (Caching):** Harici API çağrılarını önbelleğe alan merkezi bir caching mekanizması eklendi.
- **Akıllı Ön İşleme:** `TimeSeriesPipeline`'a, hedef değişkene otomatik logaritmik dönüşüm ve ters dönüşüm uygulama yeteneği kazandırıldı.
- **Dinamik Raporlama:** Raporlama, statik Markdown dosyalarından, `results.json` verisini kullanan, `Chart.js` ile çizilmiş **interaktif ve canlı grafikler** sunan bir yapıya dönüştürüldü.
- **BAŞARI:** Platform, kararlı, canlı takip yetenekli, dinamik raporlama sunan, verimli bir önbellekleme mekanizmasına ve gelişmiş ön işleme yeteneklerine sahip "Checkpoint Echo" kilometre taşına ulaştı.

---

## 🗺️ Gelecek Vizyonu ve Stratejik Yol Haritası

Bu sağlam temel üzerine inşa edilecek adımlar, AzuraForge'u daha da zenginleştirmeyi ve kapsamını genişletmeyi hedefleyecektir.

### **Faz 0: Büyük Birleşme (The Grand Unification) - Mevcut Güçleri Konsolide Etme**
*Bu faz, "Smart Learner" prototipinin kanıtlanmış başarılarını ve olgunlaşmış kodunu AzuraForge ekosistemine tam olarak entegre etmeyi hedefler.*

-   **1. Kanıtlanmış Pipeline'ları Eklenti Haline Getirme:**
    -   `weather_forecaster` (R² > 0.98) ve `stock_predictor` (R² ≈ 0.73) pipeline'larını, AzuraForge standartlarına uygun, bağımsız `app-weather-forecaster` ve `app-stock-predictor` eklentileri olarak hayata geçirmek.
-   **2. Motor ve Öğreniciyi Yükseltme:**
    -   "Smart Learner"daki daha olgun `Tensor` ve `LSTM` implementasyonlarını, birim testleriyle birlikte `azuraforge-core` ve `azuraforge-learner` paketlerine taşımak.
-   **3. Hikayeyi Birleştirme:**
    -   Projenin tüm evrim hikayesini, bu belgede olduğu gibi tek ve tutarlı bir anlatıda birleştirmek.

### **Faz 1: Deneyimi Derinleştirme ve Zenginleştirme**
*Bu faz, platformu daha profesyonel ve güçlü kılacak temel MLOps yeteneklerini eklemeyi hedefler.*

-   **1. Gelişmiş Model Yönetimi ve Sunumu:**
    -   `ModelCheckpoint` callback'ini entegre ederek en iyi modelleri kalıcı olarak kaydetmek.
    -   `API`'ye `/models` ve `/models/{model_id}/predict` gibi yeni endpoint'ler ekleyerek, kaydedilmiş modellere erişim ve onlar üzerinden tahmin yapma imkanı sağlamak.
    -   `Dashboard`'a bir "Model Kayıt Defteri" sayfası eklemek.
-   **2. "Hiper Sürücü" - Otomatik Hiperparametre Optimizasyonu:**
    -   `Dashboard` üzerinden parametre aralıkları tanımlayarak hiperparametre optimizasyon görevleri başlatma arayüzü geliştirmek.
    -   `Worker`'ın bu görevleri yüzlerce alt göreve bölerek paralel çalıştırmasını sağlamak.
    -   Sonuçları `Dashboard`'da interaktif bir tablo veya ısı haritası ile görselleştirmek.
-   **3. GPU Desteğinin Aktivasyonu (`CuPy`):**
    -   `docker-compose.yml` dosyasına GPU desteği eklemek ve platformun uyumlu donanımlarda `CuPy` ile hızlandırılmasını sağlamak.

### **Faz 2: Evreni Genişletme (Yeni Veri Modaliteleri ve Yetenekler)**
*Bu faz, platformun farklı veri türleriyle çalışabilme yeteneğini kanıtlamayı hedefler.*

-   **1. Görüntü İşleme Modülü (`app-image-classifier`):**
    -   `azuraforge-core`'a `Conv2D`, `MaxPool2D`, `Flatten` katmanlarını sıfırdan eklemek.
    -   `azuraforge-learner`'a `BaseImagePipeline` soyut sınıfını ve sınıflandırma raporlaması (`Confusion Matrix` vb.) eklemek.
    -   `app-image-classifier` eklentisini geliştirmek.
-   **2. Üretken Yapay Zeka Modülü (`app-gan-generator`):**
    -   `azuraforge-core` ile basit bir GAN veya VAE mimarisi implemente etmek ve temel rakamlar üreten bir eklenti geliştirmek.
-   **3. Doğal Dil İşleme / Ses Modülü (Projenin Kökenine Dönüş):**
    -   `azuraforge-core`'a `Embedding` katmanı ve temel bir `Attention` mekanizması eklemek.
    -   Metin sınıflandırma veya ses tanıma gibi görevler için temel pipeline'ları ve eklentileri oluşturarak daha karmaşık hedeflere (örn: TTS) zemin hazırlamak.

### **Faz 3: Geleceği Kucaklamak (2025 ve Ötesi Trendleri)**
*Bu faz, platformu endüstri standardı ve gerçekten "akıllı" bir sisteme dönüştürmeyi hedefler.*

-   **1. Model Birleştirme ve Transfer Öğrenmesi:**
    -   Platforma, sıfırdan eğitmek yerine, daha önce eğitilmiş bir modeli (model kayıt defterinden) yükleyip yeni bir veri setiyle **ince ayar (fine-tuning)** yapabilme yeteneği kazandırmak.
-   **2. Açıklanabilir Yapay Zeka (XAI) Entegrasyonu:**
    -   Raporlara, modelin bir tahmini "neden" yaptığını basitçe açıklayan (örn: SHAP, LIME entegrasyonu ile) bir bölüm eklemek.
-   **3. Otomatik MLOps (AutoML-light):**
    -   Hiperparametre optimizasyonu sonuçlarını analiz edip, bir sonraki deney için en olası parametre setini kullanıcıya öneren bir "Akıllı Asistan" özelliği geliştirmek.
-   **4. Çoklu-Modalite (Multi-Modality):**
    -   Tek bir pipeline'ın hem metin hem de görüntü gibi farklı türde girdileri aynı anda alarak tahmin yapabildiği mimarileri desteklemek.
========== FILE: docs/ROADMAP.md ==========
# 🗺️ AzuraForge Stratejik Yol Haritası

Bu belge, AzuraForge platformunun stratejik hedeflerini, tamamlanan kilometre taşlarını ve gelecekteki geliştirme fazlarını özetlemektedir. Bu yol haritası, projenin nereye gittiğini gösteren canlı bir dokümandır.

**Daha detaylı proje geçmişi ve evrimi için [Proje Yolculuğu](./PROJECT_JOURNEY.md) belgesini inceleyebilirsiniz.**

---

### **📍 MEVCUT DURUM: Faz 0 - "Checkpoint Echo" (Fonksiyonel MVP)**

Platform, temel MLOps yeteneklerine sahip, çalışan ve kararlı bir MVP (Minimum Viable Product) aşamasındadır.

*   **Tamamlananlar:**
    *   Sıfırdan inşa edilmiş `core` ve `learner` motorları.
    *   Olay güdümlü mimari ile asenkron görev işleme.
    *   `docker-compose` ile tam orkestrasyon.
    *   Canlı deney takibi (WebSocket & Redis Pub/Sub).
    *   Dinamik ve interaktif raporlama arayüzü.
    *   Genişletilebilir eklenti sistemi (`entry_points`).

---

### **➡️ FAZ 1: TEMELİ SAĞLAMLAŞTIRMA (Foundation Hardening)**

*   **Hedef:** Projeyi üretim kalitesine, endüstri standardı geliştirme pratiklerine ve yüksek güvenilirliğe taşımak.
*   **Durum:** `🟢 Aktif`
*   **Ana Başlıklar:**
    *   `[✔️]` Kapsamlı Dokümantasyon (`VISION.md`, `ROADMAP.md`, `ARCHITECTURE.md`).
    *   `[⏳]` Anlamsal Versiyonlama ve Git Etiketleme Stratejisi.
    *   `[⏳]` Test Kapsamının Artırılması (Unit & Integration Tests).
    *   `[⏳]` Sürekli Entegrasyon (CI) Pipeline'ları Kurulumu (GitHub Actions).
    *   `[⬜]` Deney Verilerinin Dosya Sisteminden Veritabanına (PostgreSQL) Taşınması.

---

### **➡️ FAZ 2: DENEYİMİ DERİNLEŞTİRME (MLOps Capability Expansion)**

*   **Hedef:** Platformu, temel bir araçtan daha profesyonel ve güçlü bir MLOps çözümüne dönüştürmek.
*   **Durum:** `⬜ Planlanıyor`
*   **Ana Başlıklar:**
    *   `[⬜]` **Model Kayıt Defteri (Model Registry):** Eğitilen en iyi modellerin kalıcı olarak saklanması ve yönetilmesi.
    *   `[⬜]` **Model Sunumu (Model Serving):** Kayıtlı modeller üzerinden tahmin yapmak için API endpoint'leri (`/models/{id}/predict`).
    *   `[⬜]` **Hiperparametre Optimizasyonu:** `Dashboard` üzerinden optimizasyon görevleri başlatma ve sonuçları görselleştirme.
    *   `[⬜]` **Kimlik Doğrulama ve Yetkilendirme:** Çok kullanıcılı ortamlar için güvenlik katmanı (JWT).
    *   `[⬜]` **GPU Desteği:** Uyumlu donanımlarda `CuPy` ile eğitimi hızlandırma.

---

### **➡️ FAZ 3: EVRENİ GENİŞLETME (New Data Modalities)**

*   **Hedef:** Platformun yeteneklerini zaman serilerinin ötesine taşıyarak farklı veri türleri ile çalışabildiğini kanıtlamak.
*   **Durum:** `⬜ Planlanıyor`
*   **Ana Başlıklar:**
    *   `[⬜]` **Görüntü İşleme Desteği:** `Conv2D`, `MaxPool2D` katmanları ve `ImageClassificationPipeline` eklentisi.
    *   `[⬜]` **Doğal Dil İşleme Temelleri:** `Embedding`, `Attention` katmanları ve metin sınıflandırma pipeline'ı.
    *   `[⬜]` **Açıklanabilir Yapay Zeka (XAI):** Raporlara, modelin tahminlerini "neden" yaptığını açıklayan SHAP/LIME gibi görseller eklemek.

---
`[✔️] Tamamlandı` `[🟢 Aktif]` `[⏳ Devam Ediyor]` `[⬜ Planlanıyor]`

========== FILE: docs/VISION.md ==========
# 📜 AzuraForge Vizyonu ve Felsefesi

AzuraForge, sadece bir yazılım projesi değil, modern yapay zeka sistemlerinin nasıl inşa edilmesi ve anlaşılması gerektiğine dair bir manifestodur. Vizyonumuz, **şeffaf, modüler ve derinlemesine anlaşılmış bir AI motorunu, sağlam ve ölçeklenebilir bir MLOps şasisi üzerine yerleştirerek**, hem öğrenme aracı hem de güçlü bir üretim platformu olarak hizmet edebilen bir ekosistem yaratmaktır.

## 🎯 Temel Felsefe: Ferrari Motoru ve Uzay Gemisi Şasisi

Bu vizyonu, basit bir metaforla özetliyoruz:

*   **Ferrari Motoru:** Platformun kalbindeki (`core`, `learner`) AI motoru, kanıtlanmış temel algoritmalardan oluşur. Bu motor, dış kütüphanelere minimal bağımlılıkla, temel prensipleri anlaşılarak sıfırdan inşa edilmiştir. Bu bize tam kontrol, esneklik, şeffaflık ve en önemlisi, bir "kara kutu" ile çalışmak yerine sistemin ruhunu anlama imkanı verir.

*   **Uzay Gemisi Şasisi:** Bu saf güç, modern mühendislik pratikleriyle tasarlanmış, dağıtık ve ölçeklenebilir bir MLOps mimarisiyle sunulur. Bu şasi, Ferrari motorunun gücünü güvenli, verimli ve yönetilebilir bir şekilde kullanılabilir hale getirir.

## ⭐ "The AzuraForge Way": Dört Anayasal Prensip

Platforma yapılan her katkı ve alınan her karar, bu dört temel prensibe uygun olmalıdır.

1.  **Önce Kalite, Sonra Hız (Quality First, Velocity Second):**
    Hızlı prototipleme dönemi başarıyla tamamlanmıştır. Artık her yeni özellik, testlerle güvence altına alınmış, dokümante edilmiş ve standartlara uygun olmalıdır. Sürdürülebilir hız, ancak sağlam bir temel üzerine inşa edilebilir.

2.  **Şeffaflık ve Sahiplenme (Transparency and Ownership):**
    Kod "kara kutu" olamaz. Alınan önemli mimari kararların "nedenleri" (`ARCHITECTURE.md` gibi belgelerle) açıkça belgelenir. Her bileşenin (`api`, `worker` vb.) net bir sorumluluğu ve amacı vardır.

3.  **Pragmatik Mükemmeliyetçilik (Pragmatic Perfectionism):**
    En iyi mühendislik pratiklerini (olay güdümlü mimari, eklenti sistemi, CI/CD) hedefleriz, ancak bunları projenin mevcut ihtiyaçlarına ve hedeflerine hizmet edecek şekilde pragmatik bir yaklaşımla uygularız. Mükemmellik, karmaşıklık demek değildir.

4.  **Kullanıcı Odaklı Değer (User-Centric Value):**
    Geliştirdiğimiz her özellik, son kullanıcıya (bu durumda platformu kullanan AI geliştiricisi/araştırmacısı) somut bir değer katmalıdır. Canlı deney takibi, interaktif raporlama ve deney karşılaştırma gibi özellikler bu prensibin en güzel örnekleridir.

Bu vizyon ve prensipler, AzuraForge'un gelecekteki gelişimine rehberlik edecek olan kutup yıldızımızdır.

========== FILE: learner/Dockerfile ==========
# ========== GÜNCELLEME: learner/Dockerfile ==========
# Stage 1: Builder
FROM python:3.10-slim-bullseye AS builder

RUN apt-get update && apt-get install -y git --no-install-recommends && rm -rf /var/lib/apt/lists/*

# KRİTİK DÜZELTME: Çalışma dizinini doğrudan 'src' klasörünün içine ayarla
WORKDIR /app/src 

# src klasörünün içeriğini (yani azuraforge_learner klasörünü) mevcut WORKDIR'e kopyala
COPY src ./src

# pyproject.toml ve setup.py'ı bir üst dizine (/app) kopyala, 
# çünkü pip install oradan çalışacak.
COPY pyproject.toml /app/
COPY setup.py /app/

# pip install komutunu ana paketin kök dizininden (/app) çalıştır.
# Bu, setup.py'ın package_dir={"": "src"} ayarını doğru algılamasını sağlar.
RUN --mount=type=cache,target=/root/.cache/pip pip install --no-cache-dir /app

# Stage 2: Runtime
FROM python:3.10-slim-bullseye AS runtime

# Runtime'da da aynı çalışma dizinini koru
WORKDIR /app/src

# Builder aşamasından kurulu paketi kopyala
COPY --from=builder /usr/local/lib/python3.10/site-packages /usr/local/lib/python3.10/site-packages
# src klasörünün içeriğini kopyala
COPY --from=builder /app/src ./src

CMD ["python", "-c", "print('AzuraForge Learner library image built successfully!')"]
========== FILE: learner/pyproject.toml ==========
# learner/pyproject.toml

[build-system]
requires = ["setuptools>=61.0"]
build-backend = "setuptools.build_meta"

[project]
name = "azuraforge-learner"
version = "0.1.5"
authors = [{ name = "Azmi Sahin" }]
description = "High-level deep learning library for model training and management, using the AzuraForge Core engine."
readme = "README.md"
requires-python = ">=3.8"
license = { text = "MIT" }
dependencies = [
    "azuraforge-core @ git+https://github.com/AzuraForge/core.git@v0.1.3",
    "scikit-learn",
    "numpy",
    "redis",
    "matplotlib",
    "pandas",
    "pyarrow"
]

[project.optional-dependencies]
dev = ["pytest"]
========== FILE: learner/README.md ==========
# AzuraForge Learner 🧠

**AzuraForge Learner**, `azuraforge-core` motorunu kullanarak modelleri kolayca oluşturmak, eğitmek ve yönetmek için tasarlanmış yüksek seviyeli bir kütüphanedir.

## Kurulum

```bash
pip install azuraforge-learner@git+https://github.com/AzuraForge/learner.git
```

========== FILE: learner/setup.py ==========
from setuptools import setup, find_packages
setup(
    package_dir={"": "src"},
    packages=find_packages(where="src"),
)

========== FILE: learner/src/azuraforge_learner/caching.py ==========
# learner/src/azuraforge_learner/caching.py

import logging
import os
import hashlib
from datetime import datetime, timedelta, timezone
from typing import Any, Dict, Optional
import pandas as pd

def get_cache_filepath(cache_dir: str, context: str, params: Dict[str, Any]) -> str:
    """
    Verilen parametrelere göre deterministik bir önbellek dosya yolu oluşturur.
    Dosya adı, parametrelerin sıralı bir karmasından (hash) türetilir.
    
    Args:
        cache_dir (str): Önbellek dosyalarının saklanacağı ana dizin.
        context (str): Önbelleğin ait olduğu bağlam (örn: 'stock_predictor').
        params (Dict[str, Any]): Dosya adını oluşturmak için kullanılacak parametreler.
        
    Returns:
        str: Oluşturulan tam dosya yolu.
    """
    # Parametreleri anahtarlarına göre sıralayarak tutarlı bir string oluştur
    param_str = str(sorted(params.items()))
    # Bu string'in hash'ini alarak benzersiz ve dosya sistemi için güvenli bir kimlik oluştur
    param_hash = hashlib.md5(param_str.encode()).hexdigest()
    filename = f"{context}_{param_hash}.parquet"
    
    # Bağlama özel bir alt klasör oluşturarak karışıklığı önle
    full_cache_dir = os.path.join(cache_dir, context)
    os.makedirs(full_cache_dir, exist_ok=True)
    
    return os.path.join(full_cache_dir, filename)

def load_from_cache(filepath: str, max_age_hours: int) -> Optional[pd.DataFrame]:
    """
    Veriyi önbellekten yükler. Eğer dosya yoksa veya belirtilen süreden eskiyse
    None döner.
    
    Args:
        filepath (str): Önbellek dosyasının yolu.
        max_age_hours (int): Önbelleğin saat cinsinden maksimum geçerlilik süresi.
        
    Returns:
        Optional[pd.DataFrame]: Geçerli önbellek verisi varsa DataFrame, yoksa None.
    """
    if not os.path.exists(filepath):
        return None
        
    try:
        # Dosyanın son değiştirilme zamanını al (UTC olarak)
        mod_time = datetime.fromtimestamp(os.path.getmtime(filepath), tz=timezone.utc)
        # Eğer dosyanın yaşı, izin verilen maksimum yaştan küçükse, geçerlidir
        if (datetime.now(timezone.utc) - mod_time) < timedelta(hours=max_age_hours):
            logging.info(f"Geçerli önbellek bulundu, buradan okunuyor: {filepath}")
            return pd.read_parquet(filepath)
        else:
            logging.info(f"Önbellek süresi dolmuş: {filepath}")
            os.remove(filepath) # Süresi dolmuş dosyayı temizle
            return None
    except Exception as e:
        logging.error(f"Önbellekten okuma hatası {filepath}: {e}")
        return None

def save_to_cache(df: pd.DataFrame, filepath: str) -> None:
    """
    Verilen DataFrame'i belirtilen yola Parquet formatında kaydeder.
    
    Args:
        df (pd.DataFrame): Kaydedilecek veri.
        filepath (str): Kaydedilecek dosyanın tam yolu.
    """
    try:
        # Dosyanın kaydedileceği dizinin var olduğundan emin ol
        os.makedirs(os.path.dirname(filepath), exist_ok=True)
        df.to_parquet(filepath)
        logging.info(f"Veri önbelleğe kaydedildi: {filepath}")
    except Exception as e:
        logging.error(f"Önbelleğe yazma hatası {filepath}: {e}")
========== FILE: learner/src/azuraforge_learner/callbacks.py ==========
# learner/src/azuraforge_learner/callbacks.py

import os
import numpy as np
from typing import TYPE_CHECKING, Optional, Any
from .events import Event # Event'i de import edelim

# Döngüsel importu önlemek için, sadece tip kontrolü sırasında Learner'ı import et
if TYPE_CHECKING:
    from .learner import Learner

class Callback:
    """
    Tüm callback'lerin temel sınıfı.
    Kendisini çalıştıran Learner'a bir referans tutar.
    """
    def __init__(self):
        self.learner: Optional['Learner'] = None

    def set_learner(self, learner: 'Learner'):
        """Bu metod, Learner tarafından çağrılarak referansı ayarlar."""
        self.learner = learner

    def __call__(self, event: Event):
        """
        Gelen olaya göre ilgili metodu (örn: on_epoch_end) çağırır.
        """
        method = getattr(self, f"on_{event.name}", None)
        if method:
            method(event)

    # Olay metotları
    def on_train_begin(self, event: Event) -> None: pass
    def on_train_end(self, event: Event) -> None: pass
    def on_epoch_begin(self, event: Event) -> None: pass
    def on_epoch_end(self, event: Event) -> None: pass
    def on_batch_begin(self, event: Event) -> None: pass
    def on_batch_end(self, event: Event) -> None: pass


# ÖNEMLİ: ModelCheckpoint ve EarlyStopping sınıflarını koruyoruz ve
# yeni temel sınıftan miras almalarını sağlıyoruz.
class ModelCheckpoint(Callback):
    """Her epoch sonunda performansı izler ve sadece en iyi modeli kaydeder."""
    def __init__(self, filepath: str, monitor: str = "val_loss", mode: str = "min", verbose: int = 1):
        super().__init__() # Temel sınıfın init'ini çağır
        self.filepath = filepath
        self.monitor = monitor
        self.mode = mode
        self.verbose = verbose
        self.best = np.inf if mode == "min" else -np.inf

        dir_path = os.path.dirname(self.filepath)
        if dir_path:
            os.makedirs(dir_path, exist_ok=True)

    def on_epoch_end(self, event: Event):
        current_val = event.payload.get(self.monitor)
        if current_val is None:
            if event.payload.get("epoch") == 0 and self.verbose > 0:
                print(f"ModelCheckpoint Warning: Can't find metric '{self.monitor}' to save model.")
            return

        is_better = (self.mode == "min" and current_val < self.best) or \
                    (self.mode == "max" and current_val > self.best)

        if is_better:
            if self.verbose > 0:
                print(f"ModelCheckpoint: {self.monitor} improved from {self.best:.6f} to {current_val:.6f}. Saving model...")
            self.best = current_val
            if self.learner and hasattr(self.learner, 'save_model'): # Learner'da save_model metodu varsa
                 self.learner.save_model(self.filepath)


class EarlyStopping(Callback):
    """Performans belirli bir epoch sayısı boyunca iyileşmediğinde eğitimi durdurur."""
    def __init__(self, monitor: str = "val_loss", patience: int = 10, mode: str = "min", verbose: int = 1):
        super().__init__() # Temel sınıfın init'ini çağır
        self.monitor = monitor
        self.patience = patience
        self.mode = mode
        self.verbose = verbose
        self.wait = 0
        self.best = np.inf if mode == "min" else -np.inf

    def on_train_begin(self, event: Event):
        self.wait = 0
        self.best = np.inf if self.mode == "min" else -np.inf

    def on_epoch_end(self, event: Event):
        current_val = event.payload.get(self.monitor)
        if current_val is None:
            return
            
        is_better = (self.mode == "min" and current_val < self.best) or \
                    (self.mode == "max" and current_val > self.best)

        if is_better:
            self.best = current_val
            self.wait = 0
        else:
            self.wait += 1
            if self.wait >= self.patience:
                if self.verbose > 0:
                    print(f"EarlyStopping: Stopping training. {self.monitor} did not improve for {self.patience} epochs.")
                if self.learner:
                    self.learner.stop_training = True
========== FILE: learner/src/azuraforge_learner/events.py ==========
from dataclasses import dataclass, field
from typing import Dict, Any, Literal, TYPE_CHECKING

if TYPE_CHECKING:
    from .learner import Learner

EventName = Literal["train_begin", "train_end", "epoch_begin", "epoch_end"]

@dataclass
class Event:
    name: EventName
    learner: 'Learner'
    payload: Dict[str, Any] = field(default_factory=dict)

========== FILE: learner/src/azuraforge_learner/layers.py ==========
from typing import List, Tuple, Optional
import numpy as np
from azuraforge_core import Tensor, xp, ArrayType

class Layer:
    def forward(self, x: Tensor) -> Tensor: raise NotImplementedError
    def parameters(self) -> List[Tensor]: return []
    def __call__(self, x: Tensor) -> Tensor: return self.forward(x)

class Linear(Layer):
    def __init__(self, input_dim: int, output_dim: int):
        limit = np.sqrt(2.0 / input_dim)
        self.weights = Tensor(xp.random.randn(input_dim, output_dim) * limit, requires_grad=True)
        self.bias = Tensor(xp.zeros(output_dim), requires_grad=True)
    def forward(self, x: Tensor) -> Tensor:
        return x.dot(self.weights) + self.bias
    def parameters(self) -> List[Tensor]:
        return [self.weights, self.bias]

class ReLU(Layer):
    def forward(self, x: Tensor) -> Tensor:
        return x.relu()

class Sigmoid(Layer):
    def forward(self, x: Tensor) -> Tensor:
        return x.sigmoid()

# DÜZELTME: LSTM katmanı tam backward pass ile yeniden yazıldı.
class LSTM(Layer):
    def __init__(self, input_size: int, hidden_size: int):
        super().__init__()
        self.input_size = input_size
        self.hidden_size = hidden_size
        H = hidden_size
        D = input_size
        
        limit = np.sqrt(1.0 / H)
        self.W_x = Tensor(xp.random.randn(D, H * 4) * limit, requires_grad=True)
        self.W_h = Tensor(xp.random.randn(H, H * 4) * limit, requires_grad=True)
        self.b = Tensor(xp.zeros(H * 4), requires_grad=True)
        
        self.cache: Optional[Tuple] = None

    def parameters(self) -> List[Tensor]:
        return [self.W_x, self.W_h, self.b]

    def forward(self, x: Tensor) -> Tensor:
        N, T, D = x.data.shape
        H = self.hidden_size

        h_prev = xp.zeros((N, H))
        c_prev = xp.zeros((N, H))
        
        h_all = xp.zeros((N, T, H))
        c_all = xp.zeros((N, T, H))
        gates_all = xp.zeros((N, T, 4 * H))
        i_all = xp.zeros((N, T, H))
        f_all = xp.zeros((N, T, H))
        o_all = xp.zeros((N, T, H))
        g_all = xp.zeros((N, T, H))

        for t in range(T):
            x_t = x.data[:, t, :]
            gates = x_t @ self.W_x.data + h_prev @ self.W_h.data + self.b.data
            
            i = 1 / (1 + xp.exp(-gates[:, :H]))
            f = 1 / (1 + xp.exp(-gates[:, H:2*H]))
            o = 1 / (1 + xp.exp(-gates[:, 2*H:3*H]))
            g = xp.tanh(gates[:, 3*H:])
            
            c_next = f * c_prev + i * g
            h_next = o * xp.tanh(c_next)

            h_prev, c_prev = h_next, c_next
            
            h_all[:, t, :] = h_next
            c_all[:, t, :] = c_next
            gates_all[:, t, :] = gates
            i_all[:, t, :] = i
            f_all[:, t, :] = f
            o_all[:, t, :] = o
            g_all[:, t, :] = g

        # Çıktı olarak tüm zaman adımlarındaki gizli durumları döndür
        out = Tensor(h_all, _children=(x, self.W_x, self.W_h, self.b), _op="lstm", requires_grad=x.requires_grad)
        
        # Geriye yayılım için gerekli tüm ara değerleri sakla
        self.cache = (x.data, h_all, c_all, i_all, f_all, o_all, g_all)

        def _backward():
            if not out.requires_grad or out.grad is None: return
            assert self.cache is not None, "Cache is not set"
            
            x_data, h_data, c_data, i_data, f_data, o_data, g_data = self.cache
            _N, _T, _D = x_data.shape
            _H = self.hidden_size
            
            # Başlangıç gradyanları
            dx = xp.zeros_like(x_data)
            dW_x = xp.zeros_like(self.W_x.data)
            dW_h = xp.zeros_like(self.W_h.data)
            db = xp.zeros_like(self.b.data)
            
            dh_next = xp.zeros((_N, _H))
            dc_next = xp.zeros((_N, _H))

            for t in reversed(range(_T)):
                dh = out.grad[:, t, :] + dh_next
                
                # Geriye yayılım adımları
                dc = dc_next + dh * o_data[:, t, :] * (1 - xp.tanh(c_data[:, t, :])**2)
                
                di = dc * g_data[:, t, :]
                df = dc * (c_data[:, t-1, :] if t > 0 else 0)
                do = dh * xp.tanh(c_data[:, t, :])
                dg = dc * i_data[:, t, :]
                
                d_gates_i = di * i_data[:, t, :] * (1 - i_data[:, t, :])
                d_gates_f = df * f_data[:, t, :] * (1 - f_data[:, t, :])
                d_gates_o = do * o_data[:, t, :] * (1 - o_data[:, t, :])
                d_gates_g = dg * (1 - g_data[:, t, :]**2)
                
                dgates = xp.concatenate((d_gates_i, d_gates_f, d_gates_o, d_gates_g), axis=1)

                # Gradyanları biriktir
                x_t = x_data[:, t, :]
                h_prev = h_data[:, t-1, :] if t > 0 else xp.zeros((_N, _H))
                
                dx[:, t, :] = dgates @ self.W_x.data.T
                dh_next = dgates @ self.W_h.data.T
                dc_next = dc * f_data[:, t, :]
                
                dW_x += x_t.T @ dgates
                dW_h += h_prev.T @ dgates
                db += xp.sum(dgates, axis=0)

            # Hesaplanan gradyanları tensörlere ata
            if x.requires_grad and x.grad is not None: x.grad += dx
            if self.W_x.requires_grad and self.W_x.grad is not None: self.W_x.grad += dW_x
            if self.W_h.requires_grad and self.W_h.grad is not None: self.W_h.grad += dW_h
            if self.b.requires_grad and self.b.grad is not None: self.b.grad += db

        out._backward = _backward
        # Sadece son gizli durumu döndürerek uyumluluğu koru
        return Tensor(h_all[:, -1, :], _children=(out,), _op="lstm_last_step")


    def forward_old(self, x: Tensor) -> Tensor:
        # Eski forward metodu referans için burada bırakılabilir
        # ...
        pass
========== FILE: learner/src/azuraforge_learner/learner.py ==========
# learner/src/azuraforge_learner/learner.py

import time
from typing import Any, Dict, List, Optional
import numpy as np

from azuraforge_core import Tensor
from .events import Event
from .models import Sequential
from .losses import Loss
from .optimizers import Optimizer
from .callbacks import Callback

class Learner:
    def __init__(self, model: Sequential, criterion: Loss, optimizer: Optimizer, callbacks: Optional[List[Callback]] = None):
        self.model = model
        self.criterion = criterion
        self.optimizer = optimizer
        self.callbacks = callbacks or []
        
        # KRİTİK DÜZELTME: Tüm callback'lere bu learner örneğini tanıt.
        # Bu, callback'lerin `self.learner` üzerinden `predict` gibi metotlara erişmesini sağlar.
        for cb in self.callbacks:
            cb.set_learner(self)
                 
        self.history: Dict[str, List[float]] = {}
        self.stop_training: bool = False

    def _publish(self, event_name: str, payload: Optional[Dict[str, Any]] = None):
        """Olayı tüm callback'lere yayınlar."""
        event = Event(name=event_name, learner=self, payload=payload or {})
        for cb in self.callbacks:
            cb(event)

    def fit(self, X_train: np.ndarray, y_train: np.ndarray, epochs: int, pipeline_name: str = "Bilinmiyor"):
        self.history = {"loss": []}
        X_train_t, y_train_t = Tensor(X_train), Tensor(y_train)
        
        self._publish("train_begin", payload={"total_epochs": epochs, "status_text": "Eğitim başlıyor...", "pipeline_name": pipeline_name})
        
        for epoch in range(epochs):
            if self.stop_training:
                break
            
            self._publish("epoch_begin", payload={"epoch": epoch, "total_epochs": epochs, "pipeline_name": pipeline_name})
            
            y_pred = self.model(X_train_t)
            loss = self.criterion(y_pred, y_train_t)
            
            self.optimizer.zero_grad()
            loss.backward()
            self.optimizer.step()
            
            current_loss = loss.to_cpu().item() if hasattr(loss, 'to_cpu') else float(loss.data)
            
            epoch_logs = {
                "epoch": epoch + 1, "total_epochs": epochs, "loss": current_loss,
                "status_text": f"Epoch {epoch + 1}/{epochs} tamamlandı, Kayıp: {current_loss:.6f}",
                "pipeline_name": pipeline_name
            }
            
            self.history["loss"].append(current_loss)
            self._publish("epoch_end", payload=epoch_logs)
            
        self._publish("train_end", payload={"status_text": "Eğitim tamamlandı.", "pipeline_name": pipeline_name})
        return self.history
        
    def predict(self, X_test: np.ndarray) -> np.ndarray:
        if not isinstance(X_test, np.ndarray):
            raise TypeError("Girdi (X_test) bir NumPy dizisi olmalıdır.")
        
        input_tensor = Tensor(X_test)
        predictions_tensor = self.model(input_tensor)
        return predictions_tensor.to_cpu()

    def evaluate(self, X_val: np.ndarray, y_val: np.ndarray) -> Dict[str, float]:
        from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
        
        y_val_t = Tensor(y_val)
        y_pred_t = self.model(Tensor(X_val))
        
        val_loss = self.criterion(y_pred_t, y_val_t).to_cpu().item()
        y_pred_np = y_pred_t.to_cpu()
        
        y_val_np = y_val if isinstance(y_val, np.ndarray) else np.array(y_val)
        
        val_r2 = r2_score(y_val_np, y_pred_np)
        val_mae = mean_absolute_error(y_val_np, y_pred_np)
        val_rmse = np.sqrt(mean_squared_error(y_val_np, y_pred_np))

        return {"val_loss": val_loss, "val_r2": val_r2, "val_mae": val_mae, "val_rmse": val_rmse}
========== FILE: learner/src/azuraforge_learner/losses.py ==========
from azuraforge_core import Tensor

class Loss:
    def __call__(self, y_pred: Tensor, y_true: Tensor) -> Tensor: raise NotImplementedError

class MSELoss(Loss):
    def __call__(self, y_pred: Tensor, y_true: Tensor) -> Tensor:
        return ((y_pred - y_true) ** 2).mean()

========== FILE: learner/src/azuraforge_learner/models.py ==========
from typing import List
from .layers import Layer
from azuraforge_core import Tensor

class Sequential(Layer):
    def __init__(self, *layers: Layer):
        self.layers = list(layers)
    def forward(self, x: Tensor) -> Tensor:
        for layer in self.layers:
            x = layer(x)
        return x
    def parameters(self) -> List[Tensor]:
        return [p for layer in self.layers for p in layer.parameters()]

========== FILE: learner/src/azuraforge_learner/optimizers.py ==========
from typing import List
from azuraforge_core import Tensor

class Optimizer:
    def __init__(self, params: List[Tensor], lr: float):
        self.params = [p for p in params if p.requires_grad]
        self.lr = lr
    def step(self) -> None: raise NotImplementedError
    def zero_grad(self) -> None:
        for p in self.params:
            if p.grad is not None: p.grad.fill(0.0)

class SGD(Optimizer):
    def step(self) -> None:
        for p in self.params:
            if p.grad is not None: p.data -= self.lr * p.grad

# YENİ: Adam Optimizer eklendi
class Adam(Optimizer):
    def __init__(self, params: List[Tensor], lr: float = 0.001, beta1: float = 0.9, beta2: float = 0.999, epsilon: float = 1e-8):
        super().__init__(params, lr)
        from azuraforge_core import xp # xp'yi burada import ediyoruz
        self.beta1 = beta1
        self.beta2 = beta2
        self.epsilon = epsilon
        self.m = {id(p): xp.zeros_like(p.data) for p in self.params}
        self.v = {id(p): xp.zeros_like(p.data) for p in self.params}
        self.t = 0

    def step(self) -> None:
        self.t += 1
        from azuraforge_core import xp # xp'yi burada import ediyoruz
        for p in self.params:
            if p.grad is not None:
                param_id = id(p)
                self.m[param_id] = self.beta1 * self.m[param_id] + (1 - self.beta1) * p.grad
                self.v[param_id] = self.beta2 * self.v[param_id] + (1 - self.beta2) * (p.grad**2)

                m_hat = self.m[param_id] / (1 - self.beta1**self.t)
                v_hat = self.v[param_id] / (1 - self.beta2**self.t)

                update_val = self.lr * m_hat / (xp.sqrt(v_hat) + self.epsilon)
                p.data -= update_val
========== FILE: learner/src/azuraforge_learner/pipelines.py ==========
# learner/src/azuraforge_learner/pipelines.py

import logging
import os
from abc import ABC, abstractmethod
from typing import Dict, Any, Tuple, Optional, List

import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler

from .learner import Learner, Callback
from .models import Sequential
from .reporting import generate_regression_report
from .optimizers import Adam, SGD
from .losses import MSELoss
from .events import Event
from .caching import get_cache_filepath, load_from_cache, save_to_cache

def _create_sequences(data: np.ndarray, seq_length: int) -> Tuple[np.ndarray, np.ndarray]:
    xs, ys = [], []
    for i in range(len(data) - seq_length):
        x = data[i:(i + seq_length)]
        y = data[i + seq_length]
        xs.append(x)
        ys.append(y)
    return np.array(xs), np.array(ys).reshape(-1, data.shape[1])

class BasePipeline(ABC):
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.logger = logging.getLogger(self.__class__.__name__)

    @abstractmethod
    def run(self, callbacks: Optional[List[Callback]] = None) -> Dict[str, Any]:
        pass

class LivePredictionCallback(Callback):
    def __init__(self, pipeline: 'TimeSeriesPipeline', X_val: np.ndarray, y_val: np.ndarray, time_index_val: pd.Index):
        super().__init__()
        self.pipeline = pipeline
        self.X_val = X_val
        self.y_val = y_val
        self.time_index_val = time_index_val
        # Düzeltme: validate_every config'den gelmeli, yoksa varsayılan 5.
        self.validate_every = self.pipeline.config.get("training_params", {}).get("validate_every", 5)
        self.last_results: Dict[str, Any] = {}

    def on_epoch_end(self, event: Event) -> None:
        epoch = event.payload.get("epoch", 0)
        total_epochs = event.payload.get("total_epochs", 1)

        # BURADAKİ DÜZELTME: validate_every kontrolü.
        # Eğer validate_every > 0 ise, sadece o aralıklarda ve son epoch'ta gönder.
        # Eğer validate_every <= 0 ise, her epoch'ta gönder (devre dışı bırakma gibi).
        should_validate_and_send = False
        if self.validate_every > 0:
            if (epoch % self.validate_every == 0 and epoch > 0) or \
               (epoch == total_epochs and total_epochs > 0): # Son epoch ise her zaman gönder
                should_validate_and_send = True
        else: # validate_every 0 veya negatifse, her epoch'ta gönder
            should_validate_and_send = True

        if should_validate_and_send:
            if not self.learner: return

            y_pred_scaled = self.learner.predict(self.X_val)
            
            y_test_unscaled, y_pred_unscaled = self.pipeline._inverse_transform_all(
                self.y_val, y_pred_scaled
            )
            
            # validation_data'yı payload'a ekliyoruz.
            event.payload['validation_data'] = {
                "x_axis": [d.isoformat() for d in self.time_index_val],
                "y_true": y_test_unscaled.tolist(), 
                "y_pred": y_pred_unscaled.tolist(), 
                "x_label": "Tarih", 
                "y_label": self.pipeline._get_target_and_feature_cols()[0]
            }
            
            # Metrikleri hesapla ve sakla (API'ye nihai results olarak gitmek için)
            from sklearn.metrics import r2_score, mean_absolute_error
            self.last_results = {
                "history": self.learner.history,
                "metrics": {
                    'r2_score': float(r2_score(y_test_unscaled, y_pred_unscaled)), 
                    'mae': float(mean_absolute_error(y_test_unscaled, y_pred_unscaled))
                },
                "final_loss": event.payload.get("loss"), 
                "y_true": y_test_unscaled.tolist(),
                "y_pred": y_pred_unscaled.tolist(),
                "time_index": [d.isoformat() for d in self.time_index_val],
                "y_label": self.pipeline._get_target_and_feature_cols()[0]
            }

class TimeSeriesPipeline(BasePipeline):
    def __init__(self, config: Dict[str, Any]):
        super().__init__(config)
        self.scaler = MinMaxScaler(feature_range=(-1, 1))
        self.feature_scaler = MinMaxScaler(feature_range=(-1, 1))
        self.learner: Optional[Learner] = None
        self.X_train: Optional[np.ndarray] = None
        self.y_train: Optional[np.ndarray] = None
        self.X_test: Optional[np.ndarray] = None
        self.y_test: Optional[np.ndarray] = None
        self.time_index_test: Optional[pd.Index] = None

    @abstractmethod
    def _load_data_from_source(self) -> pd.DataFrame:
        pass
        
    def get_caching_params(self) -> Dict[str, Any]:
        return self.config.get("data_sourcing", {})

    @abstractmethod
    def _get_target_and_feature_cols(self) -> Tuple[str, List[str]]:
        pass
    
    @abstractmethod
    def _create_model(self, input_shape: Tuple) -> Sequential:
        pass

    def _create_learner(self, model: Sequential, callbacks: Optional[List[Callback]]) -> Learner:
        training_params = self.config.get("training_params", {})
        lr = float(training_params.get("lr", 0.001))
        optimizer_type = str(training_params.get("optimizer", "adam")).lower()
        optimizer = Adam(model.parameters(), lr=lr) if optimizer_type == "adam" else SGD(model.parameters(), lr=lr)
        return Learner(model, MSELoss(), optimizer, callbacks=callbacks)

    def _inverse_transform_all(self, y_true_scaled, y_pred_scaled):
        y_true_unscaled_transformed = self.scaler.inverse_transform(y_true_scaled)
        y_pred_unscaled_transformed = self.scaler.inverse_transform(y_pred_scaled)

        target_transform = self.config.get("feature_engineering", {}).get("target_col_transform")
        if target_transform == 'log':
            self.logger.info(f"Target column will be exponentiated from log-transformed data.")
            y_true_final = np.expm1(y_true_unscaled_transformed)
            y_pred_final = np.expm1(y_pred_unscaled_transformed)
        else:
            y_true_final = y_true_unscaled_transformed
            y_pred_final = y_pred_unscaled_transformed
            
        return y_true_final.flatten(), y_pred_final.flatten()

    def run(self, callbacks: Optional[List[Callback]] = None) -> Dict[str, Any]:
        self.logger.info(f"'{self.config.get('pipeline_name')}' pipeline başlatılıyor...")
        
        system_config = self.config.get("system", {})
        cache_enabled = system_config.get("caching_enabled", True)
        cache_dir = os.getenv("CACHE_DIR", ".cache")
        cache_max_age = system_config.get("cache_max_age_hours", 24)
        
        cache_params = self.get_caching_params()
        cache_filepath = get_cache_filepath(cache_dir, self.config.get('pipeline_name', 'default_context'), cache_params)

        raw_data = None
        if cache_enabled: raw_data = load_from_cache(cache_filepath, cache_max_age)
        if raw_data is None:
            self.logger.info("Önbellek boş veya geçersiz. Veri kaynaktan çekiliyor...")
            raw_data = self._load_data_from_source()
            if cache_enabled and isinstance(raw_data, pd.DataFrame) and not raw_data.empty:
                save_to_cache(raw_data, cache_filepath)

        target_col, feature_cols = self._get_target_and_feature_cols()
        
        features_df = raw_data[feature_cols].copy()
        target_series = raw_data[target_col].copy()

        target_transform = self.config.get("feature_engineering", {}).get("target_col_transform")
        if target_transform == 'log':
            self.logger.info(f"'{target_col}' sütununa log(1+x) dönüşümü uygulanıyor.")
            target_series = np.log1p(target_series)
        
        scaled_features = self.feature_scaler.fit_transform(features_df)
        scaled_target = self.scaler.fit_transform(target_series.values.reshape(-1, 1))
        
        scaled_data = np.concatenate([scaled_features, scaled_target], axis=1)

        sequence_length = self.config.get("model_params", {}).get("sequence_length", 60)
        if len(scaled_data) <= sequence_length:
            return {"status": "failed", "message": "Sekans oluşturmak için yeterli veri yok."}
        
        X, y_unsequenced = _create_sequences(scaled_data, sequence_length)
        
        target_idx = feature_cols.index(target_col)
        y = y_unsequenced[:, target_idx].reshape(-1, 1)
        
        test_size = self.config.get("training_params", {}).get("test_size", 0.2)
        split_idx = int(len(X) * (1 - test_size))
        self.X_train, self.X_test = X[:split_idx], X[split_idx:]
        self.y_train, self.y_test = y[:split_idx], y[split_idx:]
        self.time_index_test = raw_data.index[split_idx + sequence_length:]

        model = self._create_model(self.X_train.shape)
        
        live_predict_cb = LivePredictionCallback(pipeline=self, X_val=self.X_test, y_val=self.y_test, time_index_val=self.time_index_test)
        all_callbacks = (callbacks or []) + [live_predict_cb]
        
        self.learner = self._create_learner(model, all_callbacks)

        epochs = int(self.config.get("training_params", {}).get("epochs", 50))
        self.logger.info(f"{epochs} epoch için model eğitimi başlıyor...")
        history = self.learner.fit(self.X_train, self.y_train, epochs=epochs, pipeline_name=self.config.get("pipeline_name"))
        
        final_results = live_predict_cb.last_results
        if not final_results:
            self.logger.warning("Eğitim tamamlandı ancak LivePredictionCallback'den sonuç alınamadı. Manuel olarak toplanıyor.")
            final_results = {
                "history": history,
                "final_loss": history['loss'][-1] if history.get('loss') else None,
                "metrics": {},
                "y_true": [], "y_pred": [], "time_index": []
            }


        self.logger.info("Rapor oluşturuluyor...")
        # Raporlamayı sadece gerekli verilerle çağır
        generate_regression_report(
            {
                "metrics": final_results.get('metrics', {}),
                "history": final_results.get('history', {}),
                "y_true": final_results.get('y_true', []),
                "y_pred": final_results.get('y_pred', []),
                "time_index": final_results.get('time_index', []),
                "y_label": final_results.get('y_label', self._get_target_and_feature_cols()[0])
            },
            self.config
        )
        
        return {
            "final_loss": final_results.get('final_loss'),
            "metrics": final_results.get('metrics', {}),
            "history": final_results.get('history', {}), 
            "y_true": final_results.get('y_true', []),
            "y_pred": final_results.get('y_pred', []),
            "time_index": final_results.get('time_index', [])
        }
========== FILE: learner/src/azuraforge_learner/reporting.py ==========
# learner/src/azuraforge_learner/reporting.py

import os
import logging
import json # EKSİK OLAN IMPORT EKLENDİ
from datetime import datetime
from typing import Any, Dict, List, Optional
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

def set_professional_style():
    """Matplotlib için profesyonel bir stil ayarlar."""
    try:
        plt.style.use('seaborn-v0_8-whitegrid')
        plt.rcParams.update({
            'font.family': 'sans-serif', 'font.sans-serif': 'DejaVu Sans',
            'figure.figsize': (12, 7), 'axes.labelweight': 'bold',
            'axes.titleweight': 'bold', 'grid.color': '#dddddd'
        })
    except Exception as e:
        logging.warning(f"Matplotlib stili yüklenemedi: {e}. Varsayılan kullanılacak.")

def plot_loss_history(history: Dict[str, List[float]], save_path: str):
    set_professional_style()
    fig, ax = plt.subplots()
    ax.plot(history.get('loss', []), label='Eğitim Kaybı')
    if 'val_loss' in history:
        ax.plot(history['val_loss'], label='Doğrulama Kaybı')
    ax.set_title('Model Öğrenme Eğrisi')
    ax.set_xlabel('Epoch')
    ax.set_ylabel('Kayıp (Loss)')
    ax.legend()
    ax.grid(True)
    fig.savefig(save_path)
    plt.close(fig)

def plot_prediction_comparison(y_true: np.ndarray, y_pred: np.ndarray, time_index: pd.Index, save_path: str, y_label: str):
    set_professional_style()
    fig, ax = plt.subplots()
    ax.plot(time_index, y_true, label='Gerçek Değerler', marker='.', markersize=4, linestyle='-')
    ax.plot(time_index, y_pred, label='Tahmin Edilen Değerler', linestyle='--')
    ax.set_title('Tahmin vs Gerçek Değerler')
    ax.set_xlabel('Tarih')
    ax.set_ylabel(y_label)
    ax.legend()
    ax.grid(True)
    plt.xticks(rotation=45)
    fig.tight_layout()
    fig.savefig(save_path)
    plt.close(fig)

def generate_regression_report(results: Dict[str, Any], config: Dict[str, Any]):
    experiment_dir = config.get('experiment_dir')
    if not experiment_dir:
        logging.error("Rapor oluşturmak için 'experiment_dir' konfigürasyonda bulunamadı.")
        return
        
    report_name = config.get('pipeline_name', 'Bilinmeyen Deney')
    
    img_dir = os.path.join(experiment_dir, "images")
    os.makedirs(img_dir, exist_ok=True)
    report_path = os.path.join(experiment_dir, "report.md")
    logging.info(f"Regresyon raporu oluşturuluyor: {report_path}")

    loss_img_path = os.path.join(img_dir, "loss_history.png")
    if 'history' in results and results['history'].get('loss'):
        plot_loss_history(results['history'], save_path=loss_img_path)

    comparison_img_path = os.path.join(img_dir, "prediction_comparison.png")
    if 'y_true' in results and 'y_pred' in results and 'time_index' in results:
        plot_prediction_comparison(
            y_true=np.asarray(results['y_true']), y_pred=np.asarray(results['y_pred']),
            time_index=results['time_index'], save_path=comparison_img_path,
            y_label=results.get('y_label', 'Değer')
        )

    metrics = results.get('metrics', {})
    r2 = metrics.get('r2_score')
    mae = metrics.get('mae')
    
    with open(report_path, "w", encoding="utf-8") as f:
        f.write(f"# Regresyon Analiz Raporu: {report_name}\n\n")
        f.write(f"**Rapor Tarihi:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        f.write("## 1. Performans Özeti\n\n")
        if r2 is not None:
            f.write(f"- **R² Skoru:** `{r2:.4f}`\n")
        if mae is not None:
            f.write(f"- **Ortalama Mutlak Hata (MAE):** `{mae:.4f}`\n\n")

        f.write("## 2. Tahmin Karşılaştırması\n\n")
        f.write("Aşağıdaki grafik, modelin test seti üzerindeki tahminlerini (turuncu) gerçek değerlerle (mavi) karşılaştırır.\n\n")
        if os.path.exists(comparison_img_path):
            f.write(f"![Tahmin Karşılaştırma Grafiği](images/{os.path.basename(comparison_img_path)})\n\n")
        
        f.write("## 3. Eğitim Süreci\n\n")
        f.write("Bu grafik, modelin eğitim sırasındaki kayıp değerinin epoch'lara göre değişimini gösterir.\n\n")
        if os.path.exists(loss_img_path):
            f.write(f"![Eğitim Kaybı](images/{os.path.basename(loss_img_path)})\n\n")

        f.write("## 4. Deney Konfigürasyonu\n\n")
        f.write("```json\n")
        f.write(json.dumps(config, indent=4, default=str))
        f.write("\n```\n")
========== FILE: learner/src/azuraforge_learner/__init__.py ==========
# learner/src/azuraforge_learner/__init__.py

from .events import Event
from .callbacks import Callback
from .losses import Loss, MSELoss
from .layers import Layer, Linear, ReLU, Sigmoid, LSTM
from .models import Sequential
from .optimizers import Optimizer, SGD, Adam
from .learner import Learner
from .pipelines import BasePipeline, TimeSeriesPipeline # YENİ

__all__ = [
    "Event", "Callback",
    "Loss", "MSELoss", 
    "Layer", "Linear", "ReLU", "Sigmoid", "LSTM",
    "Sequential", 
    "Optimizer", "SGD", "Adam",
    "Learner",
    "BasePipeline", 
    "TimeSeriesPipeline" # YENİ
]
========== FILE: learner/tests/azuraforge_learner/test_learner_components.py ==========
import pytest
import numpy as np

from azuraforge_learner import Learner, Sequential, Linear, ReLU, MSELoss, SGD

def test_learner_fit_simple_regression():
    X_train = np.array([[-1.0], [0.0], [1.0], [2.0]], dtype=np.float32)
    y_train = np.array([[-1.0], [1.0], [3.0], [5.0]], dtype=np.float32)
    
    model = Sequential(Linear(1, 1))
    criterion = MSELoss()
    optimizer = SGD(model.parameters(), lr=0.1)
    learner = Learner(model, criterion, optimizer)
    
    initial_loss = learner.evaluate(X_train, y_train)['val_loss']
    
    learner.fit(X_train, y_train, epochs=30)
    
    final_loss = learner.history['loss'][-1]
    
    print(f"Initial Loss: {initial_loss}, Final Loss: {final_loss}")
    assert final_loss < initial_loss / 5

def test_sequential_model_forward_pass():
    model = Sequential(Linear(2, 4), ReLU(), Linear(4, 1))
    from azuraforge_core import Tensor
    
    input_tensor = Tensor(np.random.randn(10, 2))
    output_tensor = model(input_tensor)
    
    assert output_tensor.data.shape == (10, 1)

========== FILE: learner/tests/azuraforge_learner/test_pipelines.py ==========
import pytest
import numpy as np
import pandas as pd
from unittest.mock import MagicMock, patch

from azuraforge_learner.pipelines import TimeSeriesPipeline, _create_sequences

# --- Helper Fonksiyon Testleri ---

def test_create_sequences():
    """_create_sequences fonksiyonunun doğru şekil ve içerikte diziler oluşturduğunu test eder."""
    data = np.arange(10).reshape(-1, 1) # [0, 1, ..., 9]
    seq_length = 3
    
    X, y = _create_sequences(data, seq_length)
    
    # Beklenen çıktı sayısı: 10 - 3 = 7
    assert X.shape == (7, 3, 1)
    assert y.shape == (7, 1)
    
    # İlk sekansı kontrol et
    assert np.array_equal(X[0], np.array([[0], [1], [2]]))
    assert np.array_equal(y[0], np.array([3]))
    
    # Son sekansı kontrol et
    assert np.array_equal(X[-1], np.array([[6], [7], [8]]))
    assert np.array_equal(y[-1], np.array([9]))

# --- TimeSeriesPipeline Testleri ---

# Test için somut bir Pipeline sınıfı oluşturalım
class MockTimeSeriesPipeline(TimeSeriesPipeline):
    def _load_data_from_source(self) -> pd.DataFrame:
        dates = pd.to_datetime(pd.date_range(start="2023-01-01", periods=100))
        data = {'Close': np.linspace(100, 200, 100), 'Volume': np.random.rand(100) * 1000}
        return pd.DataFrame(data, index=dates)

    def _get_target_and_feature_cols(self) -> tuple[str, list[str]]:
        return "Close", ["Close", "Volume"]

    def _create_model(self, input_shape: tuple):
        # Gerçek bir model oluşturmaya gerek yok, sadece bir mock nesne döndür
        return MagicMock()

@pytest.fixture
def pipeline_instance():
    """Her test için taze bir pipeline örneği oluşturur."""
    config = {
        "pipeline_name": "test_pipeline",
        "model_params": {"sequence_length": 10},
        "training_params": {"test_size": 0.2},
        "feature_engineering": {"target_col_transform": "none"},
        "system": {"caching_enabled": False}
    }
    return MockTimeSeriesPipeline(config)

def test_pipeline_data_split(pipeline_instance):
    """Pipeline'ın veriyi doğru şekilde train/test olarak ayırdığını test eder."""
    
    # run metodunun içindeki ilgili kısımları taklit ederek test edelim
    # Normalde run() metodunu çağırırdık ama o çok fazla şey yapıyor.
    # Bu yüzden sadece veri hazırlama adımlarını test ediyoruz.
    
    with patch.object(pipeline_instance, '_create_learner', return_value=MagicMock()) as mock_create_learner:
        with patch('azuraforge_learner.pipelines.generate_regression_report'): # Raporlamayı mock'la
             # `run` metodunu çağırdığımızda, içindeki bazı adımları doğrulamak istiyoruz.
             # LivePredictionCallback'in sahte sonuçlar döndürmesini sağlıyoruz
            with patch('azuraforge_learner.pipelines.LivePredictionCallback') as mock_live_cb:
                # Callback'in last_results özelliğine sahte bir değer atıyoruz
                mock_instance = mock_live_cb.return_value
                mock_instance.last_results = {'metrics': {}, 'history': {'loss': [0.1]}}

                pipeline_instance.run()

    # run() çağrıldıktan sonra, pipeline'ın iç state'ini kontrol edelim
    total_samples = 100 - pipeline_instance.config["model_params"]["sequence_length"] # 90
    expected_test_size = int(total_samples * 0.2) # 18
    expected_train_size = total_samples - expected_test_size # 72
    
    assert pipeline_instance.X_train.shape[0] == expected_train_size
    assert pipeline_instance.y_train.shape[0] == expected_train_size
    assert pipeline_instance.X_test.shape[0] == expected_test_size
    assert pipeline_instance.y_test.shape[0] == expected_test_size
    assert len(pipeline_instance.time_index_test) == expected_test_size


def test_pipeline_log_transform(pipeline_instance):
    """Pipeline'ın logaritmik dönüşümü ve ters dönüşümü doğru yaptığını test eder."""
    pipeline_instance.config["feature_engineering"]["target_col_transform"] = "log"
    
    # Orijinal değerler (ölçeklenmiş ve log alınmış gibi davranalım)
    y_true_scaled = np.array([[0.5], [0.6]])
    y_pred_scaled = np.array([[0.51], [0.59]])
    
    # Ters ölçekleme için sahte scaler'lar
    mock_scaler = MagicMock()
    # np.log1p(100) -> 4.615, np.log1p(200) -> 5.303. Scaler bu aralıkta çalışsın.
    # inverse_transform'un un-log'lanmış ama hala ölçekli değerler döndürdüğünü varsayalım.
    mock_scaler.inverse_transform.side_effect = lambda x: np.expm1(x * 5) # Basit bir ters ölçekleme taklidi
    pipeline_instance.scaler = mock_scaler
    
    # Metodu çağır
    y_true_final, y_pred_final = pipeline_instance._inverse_transform_all(y_true_scaled, y_pred_scaled)
    
    # Sonuçların beklendiği gibi üssü alınmış (un-logged) olduğunu kontrol et
    # mock_scaler.inverse_transform'dan gelen değerlerin expm1'den geçtiğini doğrulamalıyız.
    # Beklenen davranış:
    # 1. unscaled_transformed = mock_scaler.inverse_transform(y_true_scaled)
    # 2. y_true_final = np.expm1(unscaled_transformed)
    # Bizim testimizde mock_scaler.inverse_transform zaten expm1'i içeriyor gibi davrandık.
    # Bu yüzden doğrudan sonuçları kontrol edebiliriz.
    
    # Testi daha basit yapalım:
    # Gerçek değerler
    original_value = np.array([[100]]) 
    # Log dönüşümü
    log_value = np.log1p(original_value) 
    # Ters dönüşüm
    unlog_value = np.expm1(log_value)
    
    assert np.allclose(original_value, unlog_value)
========== FILE: tools/README.md ==========
Here are some example usages of the enhanced Project Snapshot Tool:

### 1. Basic Snapshot Creation
```bash
# Create a snapshot of the current directory (default settings)
python tools\snapshot_tool.py collect project_snapshot.txt

# Create a snapshot with custom include/exclude patterns
python tools\snapshot_tool.py collect my_snapshot.txt \
    --include-dir src \
    --include-dir config \
    --include-ext .java \
    --include-ext .xml \
    --exclude-pattern target \
    --exclude-pattern *.iml
```

### 2. Snapshot with Comment Cleaning
```bash
# Create snapshot while removing comments from code files
python tools\snapshot_tool.py collect clean_snapshot.txt --clean-comments
```

### 3. Snapshot from Specific Base Directory
```bash
# Create snapshot from a different base directory
python tools\snapshot_tool.py collect ../snapshots/project_backup.txt --base-dir ~/projects/my_project
```

### 4. Restoration Examples
```bash
# Dry run (simulate restoration without writing files)
python tools\snapshot_tool.py restore project_snapshot.txt --dry-run

# Actual restoration to current directory
python tools\snapshot_tool.py restore project_snapshot.txt

# Restoration to different directory with overwrite
python tools\snapshot_tool.py restore project_snapshot.txt \
    --target-dir ~/projects/restored_project \
    --overwrite
```

### 5. Complex Example with Multiple Directories
```bash
# Snapshot specific directories with custom settings
python tools\snapshot_tool.py collect full_backup.txt \
    --include-dir src \
    --include-dir tests \
    --include-dir config \
    --include-ext .py \
    --include-ext .yaml \
    --include-ext Dockerfile \
    --exclude-pattern __pycache__ \
    --exclude-pattern *.log \
    --exclude-pattern temp \
    --base-dir ~/projects/my_project \
    --clean-comments
```

### 6. Checking What Will Be Included
```bash
# First see what would be included with current settings
python tools\snapshot_tool.py collect test_snapshot.txt --dry-run

# Then create the actual snapshot
python tools\snapshot_tool.py collect test_snapshot.txt
```

The tool will:
1. For `collect` command:
   - Show warnings for non-existent directories
   - Display total files included at the end
   - Preserve all file content exactly (or clean comments if requested)

2. For `restore` command:
   - Show detailed progress of each file being restored
   - Provide a summary of files restored/skipped
   - Handle directory creation automatically

Remember that the default settings already include most common development files while excluding build artifacts and temporary files, so you can often just use the basic command for most cases.
========== FILE: tools/snapshot_tool.py ==========
import os
import sys
import json
import argparse
from typing import List, Dict, Any, Set, Optional, Tuple
import re

# Enhanced configuration for included/excluded paths and extensions
DEFAULT_INCLUDE_DIRS = ["."]
DEFAULT_INCLUDE_EXTENSIONS = [
    ".toml",
    ".py",
    ".yaml",
    ".yml",
    ".json",
    ".md",
    ".txt",
    ".html",
    ".bat",
    ".sh",
    ".jsx",
    ".js",
    ".json",
    ".css",
    "Dockerfile",  # Explicitly include Dockerfile
    "docker-compose.yml",  # Common docker-compose filename
    "Makefile",
    "Procfile",
    ".env",
    ".gitignore",
    ".dockerignore"
]
DEFAULT_EXCLUDE_PATTERNS = [
    "__pycache__",
    ".git",
    ".venv",
    ".vscode",
    ".idea",
    "build",
    "dist",
    "*.egg-info",
    "*.pyc",
    "*.so",
    "*.pyd",
    ".pytest_cache",
    ".mypy_cache",
    ".dataset",
    "dataset",
    ".logs",
    "logs",
    ".output",
    "output",
    "inputs",
    "outputs",
    ".tmp",
    "checkpoints",
    "reports",
    "docs/_build",
    "site",
    "node_modules",
    ".DS_Store",
    "Thumbs.db",
    "package-lock.json",  # Explicitly exclude package-lock.json
    "yarn.lock",         # Explicitly exclude yarn.lock
    "*.lock",            # General lock files
    "*.min.js",          # Minified JS files
    "*.min.css",         # Minified CSS files
]

FILE_HEADER_TEMPLATE = "========== FILE: {file_path} =========="
SNAPSHOT_INFO_TEMPLATE = """PROJE KOD SNAPSHOT (TAM)
Toplam {total_files_placeholder} dosya bulundu ve eklendi.
Dahil Edilen Dizinler: {included_dirs_placeholder}
Dahil Edilen Uzantılar: {included_extensions_placeholder}
Hariç Tutulan Desenler/Yollar: {excluded_patterns_placeholder}
================================================================================
"""

def clean_code_comments(content: str, file_extension: str) -> str:
    """Removes most comments from code, attempting to preserve shebangs and type hints."""
    if file_extension not in [".py", ".sh", ".bat"]: return content
    lines = content.splitlines()
    cleaned_lines = []
    for line in lines:
        stripped_line = line.strip()
        if file_extension == ".py":
            # Preserve special comments like '# type:' and shebangs
            if stripped_line.startswith("# type:") or stripped_line.startswith("# noqa"): 
                cleaned_lines.append(line)
            elif stripped_line.startswith("#!/"): 
                cleaned_lines.append(line)
            # Remove inline comments
            elif "#" in line and not stripped_line.startswith("#"): 
                cleaned_lines.append(line.split("#", 1)[0].rstrip())
            # Remove full-line comments
            elif stripped_line.startswith("#"):
                continue # Skip full line comments
            else: 
                cleaned_lines.append(line)
        elif file_extension == ".sh":
            if stripped_line.startswith("#!/"): 
                cleaned_lines.append(line)
            elif not stripped_line.startswith("#"): 
                cleaned_lines.append(line)
        elif file_extension == ".bat":
            if not stripped_line.lower().startswith("rem "): 
                cleaned_lines.append(line)
        else: 
            cleaned_lines.append(line)
    return "\n".join(cleaned_lines)


def should_exclude(item_path: str, root_path: str, exclude_patterns: List[str]) -> bool:
    """Enhanced exclusion check with better pattern matching."""
    normalized_item_path = os.path.normpath(item_path)
    normalized_root_path = os.path.normpath(os.path.abspath(root_path))
    
    try:
        relative_item_path = os.path.relpath(normalized_item_path, normalized_root_path)
    except ValueError:
        relative_item_path = normalized_item_path
    
    relative_item_path_slashes = relative_item_path.replace(os.sep, "/")
    filename = os.path.basename(normalized_item_path)

    for pattern in exclude_patterns:
        # Exact filename match (e.g., "package-lock.json")
        if filename == pattern:
            return True
            
        # Extension pattern (e.g., "*.lock")
        if pattern.startswith("*.") and filename.endswith(pattern[1:]):
            return True
            
        # Directory name match (e.g., "node_modules")
        if "/" not in pattern and "." not in pattern and not pattern.startswith("*"):
            path_segments = relative_item_path_slashes.split("/")
            if pattern in path_segments:
                return True
                
        # Path prefix match (e.g., "docs/_build")
        if pattern in relative_item_path_slashes:
            return True
            
    return False


def collect_project_files_full(
    output_file: str,
    include_dirs: Optional[List[str]] = None,
    include_extensions: Optional[List[str]] = None,
    exclude_patterns: Optional[List[str]] = None,
    base_dir: str = ".",
    clean_comments: bool = False,
) -> None:
    if include_dirs is None: include_dirs = DEFAULT_INCLUDE_DIRS
    if include_extensions is None: include_extensions = DEFAULT_INCLUDE_EXTENSIONS
    if exclude_patterns is None: exclude_patterns = DEFAULT_EXCLUDE_PATTERNS

    abs_base_dir = os.path.abspath(base_dir)
    
    snapshot_content_header = SNAPSHOT_INFO_TEMPLATE.format(
        total_files_placeholder="{total_files_counter}",
        included_dirs_placeholder=", ".join(include_dirs),
        included_extensions_placeholder=", ".join(include_extensions),
        excluded_patterns_placeholder=", ".join(exclude_patterns),
    )

    all_found_relative_paths: Set[str] = set()
    content_parts: List[str] = [snapshot_content_header]
    processed_files_count = 0

    for inc_dir_pattern in include_dirs:
        current_scan_dir = os.path.abspath(os.path.join(abs_base_dir, inc_dir_pattern))
        if not os.path.exists(current_scan_dir):
            print(f"Warning: Include directory '{inc_dir_pattern}' (resolved to '{current_scan_dir}') does not exist. Skipping.")
            continue

        for root, dirs, files in os.walk(current_scan_dir, topdown=True):
            # Filter directories in-place to prevent os.walk from entering excluded ones
            dirs[:] = [
                d for d in dirs
                if not should_exclude(os.path.join(root, d), abs_base_dir, exclude_patterns)
            ]
            
            for file_name in files:
                file_path = os.path.join(root, file_name)
                relative_file_path = os.path.relpath(file_path, abs_base_dir)
                display_path = relative_file_path.replace(os.sep, "/")

                # Skip if already processed
                if display_path in all_found_relative_paths:
                    continue 

                # Apply exclusion patterns to files
                if should_exclude(file_path, abs_base_dir, exclude_patterns):
                    continue

                _, file_extension = os.path.splitext(file_name)
                filename_lower = file_name.lower()
                
                # Check if file should be included based on:
                # 1. Extension match (e.g., ".py")
                # 2. Full filename match (e.g., "Dockerfile")
                # 3. Extensionless but in include_extensions (e.g., "Makefile")
                should_include = (
                    file_extension.lower() in [ext.lower() for ext in include_extensions if ext.startswith('.')] or
                    filename_lower in [ext.lower() for ext in include_extensions if not ext.startswith('.')] or
                    (not file_extension and filename_lower in [ext.lower() for ext in include_extensions if not ext.startswith('.')])
                )
                
                if should_include:
                    all_found_relative_paths.add(display_path)
                    try:
                        with open(file_path, "r", encoding="utf-8", errors="ignore") as f:
                            file_content = f.read()
                        
                        if clean_comments:
                            file_content = clean_code_comments(file_content, file_extension)
                        
                        content_parts.append(f"\n{FILE_HEADER_TEMPLATE.format(file_path=display_path)}\n")
                        content_parts.append(file_content)
                        processed_files_count += 1
                    except Exception as e:
                        print(f"Error reading file {relative_file_path}: {e}")
                        content_parts.append(f"\nError reading file {relative_file_path}: {e}\n")

    final_header_with_count = content_parts[0].replace("{total_files_counter}", str(processed_files_count))
    content_parts[0] = final_header_with_count

    with open(output_file, "w", encoding="utf-8") as f:
        f.write("".join(content_parts))

    print(f"Project snapshot (full) generated: {output_file}")
    print(f"Total {processed_files_count} files included.")


def restore_from_full_snapshot(
    snapshot_file: str,
    target_dir: str = ".",
    dry_run: bool = False,
    overwrite_existing: bool = False,
) -> None:
    print(f"Restoring project from snapshot: {snapshot_file}")
    if dry_run: print("DRY RUN: No files will be written.")

    try:
        with open(snapshot_file, "r", encoding="utf-8") as f:
            full_content = f.read()
    except FileNotFoundError:
        print(f"Error: Snapshot file '{snapshot_file}' not found.")
        return
    except Exception as e:
        print(f"Error reading snapshot file: {e}")
        return

    file_block_pattern = re.compile(
        r"^========== FILE: (.*?) ==========\n"
        r"(.*?)"
        r"(?=\n========== FILE: |\Z)",
        re.MULTILINE | re.DOTALL
    )
    
    info_header_last_line = SNAPSHOT_INFO_TEMPLATE.splitlines()[-1]
    content_start_index = full_content.find(info_header_last_line)
    if content_start_index == -1:
        print("Error: Could not find the end of the snapshot info header.")
        return
    
    content_to_parse = full_content[content_start_index + len(info_header_last_line):].lstrip('\n')

    files_restored = 0
    files_skipped = 0
    files_overwritten = 0
    
    matches = file_block_pattern.finditer(content_to_parse)

    for match in matches:
        relative_file_path = match.group(1).strip()
        content_part = match.group(2) 

        os_specific_relative_path = relative_file_path.replace("/", os.sep)
        target_file_path = os.path.join(target_dir, os_specific_relative_path)
        
        print(f"Processing file: {relative_file_path} (Content length: {len(content_part)}) -> {target_file_path}")

        if os.path.exists(target_file_path) and not overwrite_existing:
            print(f"  SKIPPED: File '{target_file_path}' already exists (overwrite_existing is False).")
            files_skipped += 1
            continue

        if os.path.exists(target_file_path) and overwrite_existing:
            print(f"  OVERWRITING: File '{target_file_path}'.")
            files_overwritten += 1

        if not dry_run:
            try:
                os.makedirs(os.path.dirname(target_file_path), exist_ok=True)
                with open(target_file_path, "w", encoding="utf-8") as f:
                    f.write(content_part)
                files_restored += 1
            except Exception as e:
                print(f"  ERROR: Could not write file '{target_file_path}': {e}")
        else:
            if not os.path.exists(os.path.dirname(target_file_path)):
                print(f"  DRY RUN: Would create directory {os.path.dirname(target_file_path)}")
            print(f"  DRY RUN: Would write {len(content_part)} bytes to {target_file_path}")
            files_restored += 1

    print("\n--- Restoration Summary ---")
    print(f"Files processed for restoration: {files_restored}")
    if not dry_run:
        print(f"Files actually written/overwritten: {files_restored - files_skipped}")
        print(f"Files overwritten: {files_overwritten}")
    print(f"Files skipped (already exist and overwrite=False): {files_skipped}")


def main():
    parser = argparse.ArgumentParser(description="Enhanced Project Snapshot Tool")
    subparsers = parser.add_subparsers(dest="command", required=True)

    parser_collect = subparsers.add_parser(
        "collect", help="Collect project files into a single snapshot file."
    )
    parser_collect.add_argument(
        "output_file",
        type=str,
        default="project_snapshot_full.txt",
        nargs="?",
        help="Path to the output snapshot file (default: project_snapshot_full.txt)",
    )
    parser_collect.add_argument(
        "--include-dir",
        action="append",
        dest="include_dirs",
        help="Directory to include (relative to base_dir or absolute). Can be used multiple times.",
    )
    parser_collect.add_argument(
        "--include-ext",
        action="append",
        dest="include_extensions",
        help="File extension to include (e.g., .py, .md). Can be used multiple times.",
    )
    parser_collect.add_argument(
        "--exclude-pattern",
        action="append",
        dest="exclude_patterns",
        help="Pattern/path to exclude. Can be used multiple times.",
    )
    parser_collect.add_argument(
        "--base-dir",
        type=str,
        default=".",
        help="Base directory for the project (default: current directory).",
    )
    parser_collect.add_argument(
        "--clean-comments",
        action="store_true",
        help="Attempt to remove comments from collected code files (.py, .sh, .bat).",
    )

    parser_restore = subparsers.add_parser(
        "restore", help="Restore project files from a snapshot."
    )
    parser_restore.add_argument(
        "snapshot_file", type=str, help="Path to the snapshot file to restore from."
    )
    parser_restore.add_argument(
        "--target-dir",
        type=str,
        default=".",
        help="Directory where files will be restored (default: current directory).",
    )
    parser_restore.add_argument(
        "--dry-run",
        action="store_true",
        help="Simulate restoration without writing any files.",
    )
    parser_restore.add_argument(
        "--overwrite",
        action="store_true",
        dest="overwrite_existing",
        help="Overwrite files if they already exist in the target directory.",
    )

    args = parser.parse_args()

    if args.command == "collect":
        final_include_dirs = args.include_dirs if args.include_dirs is not None else DEFAULT_INCLUDE_DIRS
        final_include_extensions = args.include_extensions if args.include_extensions is not None else DEFAULT_INCLUDE_EXTENSIONS
        final_exclude_patterns = args.exclude_patterns if args.exclude_patterns is not None else DEFAULT_EXCLUDE_PATTERNS
        
        collect_project_files_full(
            output_file=args.output_file,
            include_dirs=final_include_dirs,
            include_extensions=final_include_extensions,
            exclude_patterns=final_exclude_patterns,
            base_dir=args.base_dir,
            clean_comments=args.clean_comments,
        )
    elif args.command == "restore":
        restore_from_full_snapshot(
            snapshot_file=args.snapshot_file,
            target_dir=args.target_dir,
            dry_run=args.dry_run,
            overwrite_existing=args.overwrite_existing,
        )


if __name__ == "__main__":
    print("Enhanced Project Snapshot Tool")
    print("Collects project files into a single snapshot file or restores from a snapshot.")
    print("Use 'collect' to create a snapshot and 'restore' to restore files from it.")    
    main()
========== FILE: worker/Dockerfile ==========
# Base image olarak Python 3.10'un slim versiyonunu kullan
FROM python:3.10-slim-bullseye

# Gerekli sistem paketlerini kur
RUN apt-get update && \
    apt-get install -y git --no-install-recommends && \
    rm -rf /var/lib/apt/lists/*

# Çalışma dizinini ayarla
WORKDIR /app

# === BASİT VE GARANTİ YÖNTEM ===
# Önce projenin TÜM dosyalarını kopyala
COPY . .

# Adım 5: CuPy ve proje bağımlılıklarını kur
# RUN pip install --no-cache-dir cupy-cuda12x
RUN pip install --no-cache-dir -e .
# === BİTTİ ===

# Adım 6: Konteyner başlatıldığında çalıştırılacak komut
CMD ["start-worker"]
========== FILE: worker/pyproject.toml ==========
[build-system]
requires = ["setuptools>=61.0"]
build-backend = "setuptools.build_meta"

[project]
name = "azuraforge-worker"
version = "0.2.4" # Versiyonu artırıyoruz
description = "The Celery worker for the AzuraForge Platform. Discovers and runs pipeline plugins."
requires-python = ">=3.8"
dependencies = [
    # === DEĞİŞİKLİK BURADA: app-stock-predictor'ın en son versiyonuna işaret ediyor ===
    "azuraforge-app-stock-predictor @ git+https://github.com/AzuraForge/app-stock-predictor.git@v0.1.3",
    "celery[redis]",
    "pyyaml",
    "SQLAlchemy",
    "psycopg2-binary",
]

[project.scripts]
start-worker = "azuraforge_worker.main:run_azuraforge_worker"
========== FILE: worker/README.md ==========
# AzuraForge Worker Servisi

Bu servis, AzuraForge platformunun ağır iş yükünü taşıyan, arka plan görevlerini işleyen motorudur.

## 🎯 Ana Sorumluluklar

1.  **Görev İşleyici (Celery Worker):**
    *   `Redis`'teki görev kuyruğunu dinler ve `API` tarafından gönderilen yeni görevleri (örn: model eğitimi) alır.
    *   Platforma "eklenti" olarak kurulan AI pipeline'larını (`azuraforge-app-*`) keşfeder ve çalıştırır.

2.  **Raporlama ve Sonuç Üretimi:**
    *   Tamamlanan her deney için sonuçları (`results.json`) ve görsel raporları (`report.md`) oluşturur ve paylaşılan `/reports` dizinine yazar.

3.  **Redis Pub/Sub Yayıncısı:**
    *   Eğitim sırasında, `RedisProgressCallback` aracılığıyla, anlık ilerleme verilerini (epoch, kayıp değeri vb.) ilgili Redis kanalına (`task-progress:*`) yayınlayarak `API` servisinin canlı takip yapmasını sağlar.

## 🛠️ Yerel Geliştirme ve Test

Bu servisi yerel ortamda çalıştırmak ve test etmek için, ana `platform` reposundaki **[Geliştirme Rehberi](../../platform/docs/DEVELOPMENT_GUIDE.md)**'ni takip edin.

Servis bağımlılıkları kurulduktan ve sanal ortam aktive edildikten sonra, aşağıdaki komutla Worker'ı başlatabilirsiniz:

```bash
# worker/ kök dizinindeyken
start-worker
```

Worker, Redis'e bağlanacak ve yeni görevleri beklemeye başlayacaktır.

**Birim Testleri (Yakında):**
Birim testlerini çalıştırmak için:
```bash
pytest
```

========== FILE: worker/setup.py ==========
from setuptools import setup, find_packages

setup(
    package_dir={"": "src"},
    packages=find_packages(where="src"),
)

========== FILE: worker/src/azuraforge_worker/callbacks.py ==========
# worker/src/azuraforge_worker/callbacks.py

import json
import os
import redis
from typing import Any, Optional
from azuraforge_learner import Callback
import logging # Loglama modülünü import ediyoruz

class RedisProgressCallback(Callback):
    """
    Learner'dan gelen olayları dinler ve Redis Pub/Sub kanalı üzerinden
    ilerleme durumunu yayınlar.
    """
    def __init__(self, task_id: str):
        super().__init__()
        self.task_id = task_id
        self._redis_client: Optional[redis.Redis] = None
        try:
            redis_url = os.environ.get("REDIS_URL", "redis://redis:6379/0")
            self._redis_client = redis.from_url(redis_url)
            logging.info(f"RedisProgressCallback initialized for task {task_id}. Connected to Redis.")
        except Exception as e:
            logging.error(f"HATA: RedisProgressCallback içinde Redis'e bağlanılamadı: {e}")

    def on_epoch_end(self, event: Any) -> None:
        """
        Her epoch sonunda Learner tarafından tetiklenir ve
        ilerleme verisini ilgili Redis kanalına yayınlar.
        """
        if not self._redis_client or not self.task_id:
            return
            
        payload = event.payload
        if not payload:
            logging.warning(f"RedisProgressCallback: Empty payload for task {self.task_id}.")
            return

        try:
            channel = f"task-progress:{self.task_id}"
            
            # --- YENİ LOGLAMA İLE TEŞHİS ---
            validation_data = payload.get('validation_data')
            if validation_data:
                y_true_len = len(validation_data.get('y_true', []))
                y_pred_len = len(validation_data.get('y_pred', []))
                x_axis_len = len(validation_data.get('x_axis', []))
                logging.info(f"RedisProgressCallback: Publishing progress for task {self.task_id}, epoch {payload.get('epoch')}. Loss: {payload.get('loss'):.4f}. Validation data size: y_true={y_true_len}, y_pred={y_pred_len}, x_axis={x_axis_len}")
            else:
                logging.info(f"RedisProgressCallback: Publishing progress for task {self.task_id}, epoch {payload.get('epoch')}. Loss: {payload.get('loss'):.4f}. No validation data in payload.")
            # --- TEŞHİS SONU ---

            message = json.dumps(payload)
            self._redis_client.publish(channel, message)
            
        except Exception as e:
            logging.error(f"HATA: Redis'e ilerleme durumu yayınlanamadı: {e}", exc_info=True)
========== FILE: worker/src/azuraforge_worker/celery_app.py ==========
# worker/src/azuraforge_worker/celery_app.py

import os
from celery import Celery
from celery.signals import worker_process_init, worker_process_shutdown

REDIS_URL = os.getenv("REDIS_URL", "redis://localhost:6379/0")

celery_app = Celery(
    "azuraforge_worker",
    broker=REDIS_URL,
    backend=REDIS_URL,
    include=["azuraforge_worker.tasks.training_tasks"]
)

# Bu değişken, her bir worker sürecinin kendi motorunu tutmasını sağlar.
engine = None

@worker_process_init.connect
def init_worker_db_connection(**kwargs):
    """Her bir Celery alt süreci başladığında çağrılır."""
    global engine
    print("Initializing DB connection for worker process...")
    # === DEĞİŞİKLİK BURADA ===
    # database.py'den 'sa_create_engine' olarak import edip ismini değiştiriyoruz.
    from .database import sa_create_engine as db_create_engine
    # === DEĞİŞİKLİK SONU ===
    
    # DATABASE_URL'yi doğrudan ortamdan alıyoruz.
    db_url = os.getenv("DATABASE_URL")
    if not db_url:
        raise RuntimeError("DATABASE_URL not set, cannot initialize DB engine.")
        
    engine = db_create_engine(db_url)
    print(f"DB connection for worker process {os.getpid()} initialized.")


@worker_process_shutdown.connect
def shutdown_worker_db_connection(**kwargs):
    """Her bir Celery alt süreci kapandığında çağrılır."""
    global engine
    if engine:
        print(f"Disposing DB connection for worker process {os.getpid()}...")
        engine.dispose()
========== FILE: worker/src/azuraforge_worker/database.py ==========
# worker/src/azuraforge_worker/database.py

import os
from sqlalchemy import create_engine as sa_create_engine, Column, String, JSON, DateTime
from sqlalchemy.orm import sessionmaker, declarative_base
from sqlalchemy.sql import func

Base = declarative_base()

class Experiment(Base):
    __tablename__ = "experiments"
    id = Column(String, primary_key=True, index=True)
    task_id = Column(String, index=True, nullable=False)
    batch_id = Column(String, index=True, nullable=True)
    batch_name = Column(String, nullable=True)
    pipeline_name = Column(String, index=True, nullable=False)
    status = Column(String, index=True, default="PENDING")
    config = Column(JSON, nullable=True)
    results = Column(JSON, nullable=True)
    error = Column(JSON, nullable=True)
    created_at = Column(DateTime(timezone=True), server_default=func.now())
    completed_at = Column(DateTime(timezone=True), nullable=True)
    failed_at = Column(DateTime(timezone=True), nullable=True)

    def __repr__(self):
        return f"<Experiment(id='{self.id}', status='{self.status}')>"

_SessionLocal = None

def get_session_local():
    """SessionLocal fabrikasını yalnızca gerektiğinde oluşturur (singleton)."""
    global _SessionLocal
    if _SessionLocal is None:
        # celery_app'ten her süreç için özel olarak oluşturulmuş engine'i al
        from .celery_app import engine
        if engine is None:
            raise RuntimeError("Database engine not initialized for this worker process.")
        _SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)
    return _SessionLocal

def init_db():
    """Ana süreçte veritabanı tablolarını oluşturur."""
    DATABASE_URL = os.getenv("DATABASE_URL")
    if not DATABASE_URL:
        raise ValueError("DATABASE_URL ortam değişkeni ayarlanmamış!")
    
    # Tablo oluşturma işlemi için geçici bir motor oluştur.
    engine = sa_create_engine(DATABASE_URL)
    Base.metadata.create_all(bind=engine)
    engine.dispose()
========== FILE: worker/src/azuraforge_worker/main.py ==========
# worker/src/azuraforge_worker/main.py

import logging
import sys
import platform
import multiprocessing
import os

from .celery_app import celery_app

def get_concurrency():
    """Cihaz türüne göre uygun concurrency değerini belirler."""
    device = os.environ.get("AZURAFORGE_DEVICE", "cpu").lower()
    if device == "gpu":
        # Tek bir GPU varken, çok fazla paralel süreç başlatmak verimsizdir.
        concurrency = 4
        logging.info(f"GPU modu aktif. Concurrency = {concurrency} (sabit).")
        return concurrency
    else:
        concurrency = multiprocessing.cpu_count() / 4
        logging.info(f"CPU modu aktif. Concurrency = {concurrency} (CPU çekirdek sayısı).")
        return concurrency

def run_azuraforge_worker():
    """
    Bu fonksiyon, worker'ı programatik olarak, subprocess kullanmadan başlatır.
    """
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s:%(lineno)d - %(levelname)s - %(message)s',
        stream=sys.stdout
    )
    logging.info("👷‍♂️ Starting AzuraForge Worker via Celery's programmatic API...")
    
    # Celery worker'ını başlatmak için argüman listesi oluştur
    worker_argv = [
        'worker',
        '--loglevel=info',
        # 'prefork' Linux'ta varsayılan olduğu için belirtmeye gerek yok.
        # 'solo' da hata ayıklama modundan kaldırıldı.
        f'--concurrency={get_concurrency()}',
    ]
    
    # Celery uygulamasının worker_main metodunu bu argümanlarla çağır
    celery_app.worker_main(argv=worker_argv)

if __name__ == "__main__":
    run_azuraforge_worker()
========== FILE: worker/src/azuraforge_worker/__init__.py ==========
from .celery_app import celery_app

# Bu, diğer projelerin 'from azuraforge_worker import celery_app' yapabilmesini sağlar.
__all__ = ("celery_app",)

========== FILE: worker/src/azuraforge_worker/tasks/training_tasks.py ==========
# worker/src/azuraforge_worker/tasks/training_tasks.py

import logging
import os
import traceback
from datetime import datetime
from importlib.metadata import entry_points
from contextlib import contextmanager

from ..celery_app import celery_app
from ..callbacks import RedisProgressCallback
from ..database import Experiment, get_session_local # DEĞİŞTİ

# --- Veritabanı Oturum Yönetimi ---
@contextmanager
def get_db():
    """Veritabanı oturumu için bir context manager sağlar."""
    # SessionLocal'ı dinamik olarak al
    SessionLocal = get_session_local()
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()

# --- Pipeline Keşfi (Değişiklik Yok) ---
def discover_pipelines():
    logging.info("Worker: Discovering installed AzuraForge pipeline plugins and configurations...")
    discovered = {}
    try:
        pipeline_entry_points = entry_points(group='azuraforge.pipelines')
        for ep in pipeline_entry_points:
            discovered[ep.name] = {'pipeline_class': ep.load()}
        
        config_entry_points = entry_points(group='azuraforge.configs')
        for ep in config_entry_points:
            if ep.name in discovered:
                discovered[ep.name]['get_config_func'] = ep.load()
    except Exception as e:
        logging.error(f"Worker: Error discovering pipelines or configs: {e}", exc_info=True)
    
    for p_id, p_info in discovered.items():
        logging.info(f"Worker: Discovered pipeline '{p_id}' (Config available: {'get_config_func' in p_info})")
    return discovered

AVAILABLE_PIPELINES_AND_CONFIGS = discover_pipelines()
REPORTS_BASE_DIR = os.path.abspath(os.getenv("REPORTS_DIR", "/app/reports"))
os.makedirs(REPORTS_BASE_DIR, exist_ok=True)

# --- Celery Görevi (Tamamen Yenilendi) ---
@celery_app.task(bind=True, name="start_training_pipeline")
def start_training_pipeline(self, config: dict):
    task_id = self.request.id
    pipeline_name = config.get("pipeline_name", "unknown_pipeline")
    run_timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    experiment_id = f"{pipeline_name}_{run_timestamp}_{task_id[:8]}"

    # Raporlama için hala dosya sistemini kullanabiliriz
    experiment_dir = os.path.join(REPORTS_BASE_DIR, pipeline_name, experiment_id)
    os.makedirs(experiment_dir, exist_ok=True)
    
    # Konfigürasyonu zenginleştir
    config['experiment_id'] = experiment_id
    config['task_id'] = task_id
    config['experiment_dir'] = experiment_dir
    config['start_time'] = datetime.now().isoformat()

    try:
        if not pipeline_name or pipeline_name not in AVAILABLE_PIPELINES_AND_CONFIGS:
            raise ValueError(f"Pipeline '{pipeline_name}' not found or installed.")

        # --- Veritabanı Kaydı Başlatma ---
        with get_db() as db:
            new_experiment = Experiment(
                id=experiment_id,
                task_id=task_id,
                pipeline_name=pipeline_name,
                status="STARTED",
                config=config
            )
            db.add(new_experiment)
            db.commit()
            logging.info(f"Worker: Experiment {experiment_id} 'STARTED' olarak veritabanına kaydedildi.")

        # Pipeline'ı çalıştır
        PipelineClass = AVAILABLE_PIPELINES_AND_CONFIGS[pipeline_name]['pipeline_class']
        pipeline_instance = PipelineClass(config)
        redis_callback = RedisProgressCallback(task_id=task_id)
        results = pipeline_instance.run(callbacks=[redis_callback])

        # --- Veritabanı Kaydını Başarıyla Güncelleme ---
        with get_db() as db:
            exp_to_update = db.query(Experiment).filter(Experiment.id == experiment_id).first()
            if exp_to_update:
                exp_to_update.status = "SUCCESS"
                exp_to_update.results = results
                exp_to_update.completed_at = datetime.now(datetime.utcnow().tzinfo)
                db.commit()
                logging.info(f"Worker: Experiment {experiment_id} 'SUCCESS' olarak güncellendi.")
        
        logging.info(f"Worker: Task {task_id} completed successfully.")
        return {"experiment_id": experiment_id, "status": "SUCCESS"}

    except Exception as e:
        tb_str = traceback.format_exc()
        logging.error(f"PIPELINE CRITICAL FAILURE in task {task_id} (experiment: {experiment_id}): {e}")
        logging.error(f"FULL TRACEBACK:\n{tb_str}")
        
        # --- Veritabanı Kaydını Hatayla Güncelleme ---
        with get_db() as db:
            exp_to_update = db.query(Experiment).filter(Experiment.id == experiment_id).first()
            if exp_to_update:
                exp_to_update.status = "FAILURE"
                exp_to_update.error = {"message": str(e), "traceback": tb_str}
                exp_to_update.failed_at = datetime.now(datetime.utcnow().tzinfo)
                db.commit()
                logging.error(f"Worker: Experiment {experiment_id} 'FAILURE' olarak güncellendi.")
        
        raise e
========== FILE: worker/src/azuraforge_worker/tasks/__init__.py ==========
