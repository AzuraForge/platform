PROJE KOD SNAPSHOT (TAM)
Toplam 76 dosya bulundu ve eklendi.
Dahil Edilen Dizinler: .
Dahil Edilen UzantÄ±lar: .toml, .py, .yaml, .yml, .json, .md, .txt, html, .bat, .sh, .jsx, .js, .json, .css
HariÃ§ Tutulan Desenler/Yollar: __pycache__, .git, .venv, .vscode, .idea, build, dist, *.egg-info, *.pyc, *.so, *.pyd, .pytest_cache, .mypy_cache, .dataset, dataset, .logs, logs, .output, output, inputs, outputs, .tmp, checkpoints, reports, docs/_build, site, node_modules, .DS_Store, Thumbs.db, *.lock, package-lock.json
================================================================================

========== FILE: docker-compose.yml ==========
services:
  # 1. Redis Servisi (Mesaj KuyruÄŸu ve SonuÃ§ Deposu)
  redis:
    image: "redis:alpine"
    container_name: azuraforge_redis
    ports: ["6379:6379"]
    volumes: ["redis_data:/data"]

  # --- KÃœTÃœPHANE SERVÄ°SLERÄ° (SADECE BUILD VE SAÄžLIK KONTROLÃœ Ä°Ã‡Ä°N) ---
  # Bu servisler, ana uygulamalarÄ±n (API, Worker) baÄŸÄ±mlÄ±lÄ±klarÄ±nÄ± kurabilmesi iÃ§in Ã¶nceden build edilir.
  # BaÄŸÄ±mlÄ±lÄ±k zincirinde alt seviyede olduklarÄ± iÃ§in 'depends_on' gerekmez,
  # API ve Worker Dockerfile'larÄ± onlarÄ± zaten pip ile Ã§eker.
  # Buradaki tanÄ±mlar, onlarÄ±n da build edildiÄŸini doÄŸrulamak iÃ§indir.

  # 2. Core KÃ¼tÃ¼phanesi
  core_lib:
    container_name: azuraforge_core_lib_build_test
    build:
      context: ./core # 'core' reposunun bulunduÄŸu klasÃ¶rÃ¼ gÃ¶ster
      dockerfile: Dockerfile # 'core' reposunun iÃ§indeki Dockerfile
    command: python -c "import azuraforge_core; print('AzuraForge Core built and imported successfully in Docker!')"
    # volumes: - ./core:/app # GeliÅŸtirme sÄ±rasÄ±nda kodu anÄ±nda yansÄ±tmak iÃ§in
    # Bu servis sadece build ediliyor, Ã§alÄ±ÅŸtÄ±rÄ±lmÄ±yor. Mount'a gerek yok.

  # 3. Learner KÃ¼tÃ¼phanesi
  learner_lib:
    container_name: azuraforge_learner_lib_build_test
    build:
      context: ./learner
      dockerfile: Dockerfile
    command: python -c "import azuraforge_learner; print('AzuraForge Learner built and imported successfully in Docker!')"
    # volumes: - ./learner:/app # Sadece build ediliyor.

  # 4. Applications Katalogu
  applications_catalog:
    container_name: azuraforge_applications_catalog_build_test
    build:
      context: ./applications
      dockerfile: Dockerfile
    command: python -c "import azuraforge_applications; print('AzuraForge Applications Catalog built and imported successfully in Docker!')"
    # volumes: - ./applications:/app # Sadece build ediliyor.

  # 5. App Stock Predictor (Uygulama Eklentisi)
  app_stock_predictor:
    container_name: azuraforge_app_stock_predictor_build_test
    build:
      context: ./app-stock-predictor
      dockerfile: Dockerfile
    command: python -c "import azuraforge_stockapp; print('AzuraForge App Stock Predictor built and imported successfully in Docker!')"
    # volumes: - ./app-stock-predictor:/app # Sadece build ediliyor.

  # --- ANA PLATFORM SERVÄ°SLERÄ° ---
  # Bu servisler, tÃ¼m ekosistemin temelidir ve diÄŸer kÃ¼tÃ¼phanelere baÄŸÄ±mlÄ±dÄ±r.

  # 6. API Servisi
  api:
    container_name: azuraforge_api
    build:
      context: ./api # 'api' reposunun bulunduÄŸu klasÃ¶rÃ¼ gÃ¶ster
      dockerfile: Dockerfile # 'api' reposunun iÃ§indeki Dockerfile
    command: start-api # 'api' reposundaki entrypoint script'i
    ports: ["8000:8000"]
    volumes:
      - ./api:/app # API'Ä±n kendi kodu
      - ${REPORTS_DIR}:/app/reports # Ortak rapor dizini (Host makineden mount ediliyor)
    environment:
      - REDIS_URL=${REDIS_URL}
      - REPORTS_DIR=/app/reports
    depends_on: [redis] # Redis'e baÄŸÄ±mlÄ±

  # 7. Worker Servisi
  worker:
    container_name: azuraforge_worker
    build:
      context: ./worker
      dockerfile: Dockerfile
    command: start-worker
    volumes:
      - ./worker:/app # Worker'Ä±n kendi kodu
      - ${REPORTS_DIR}:/app/reports # Raporlar iÃ§in
    environment:
      - REDIS_URL=${REDIS_URL}
      - REPORTS_DIR=/app/reports
    depends_on: [redis]

  # 8. Dashboard Servisi
  dashboard:
    container_name: azuraforge_dashboard
    build:
      context: ./dashboard
      dockerfile: Dockerfile
    command: npm run dev -- --host 0.0.0.0
    ports: ["5173:5173"]
    volumes:
      - ./dashboard:/app
      - /app/node_modules
    depends_on: [api]

volumes:
  redis_data: # Redis verilerini kalÄ±cÄ± tutmak iÃ§in volume

========== FILE: README.md ==========
# AzuraForge Platform ðŸš€

**AzuraForge Platform**, yapay zeka modellerini sÄ±fÄ±rdan oluÅŸturmak, eÄŸitmek ve yÃ¶netmek iÃ§in tasarlanmÄ±ÅŸ modÃ¼ler, daÄŸÄ±tÄ±k ve eklenti tabanlÄ± bir MLOps platformudur. Modern mikroservis mimarisi prensipleriyle inÅŸa edilmiÅŸtir.

Bu depo, AzuraForge ekosistemindeki tÃ¼m ana servisleri (API, Worker, Dashboard) ve kÃ¼tÃ¼phaneleri (Core, Learner, Applications) bir araya getiren **orkestrasyon katmanÄ±dÄ±r**.

## ðŸŽ¯ Temel AmaÃ§lar ve Felsefe

*   **SÄ±fÄ±rdan Ä°nÅŸa:** Derin Ã¶ÄŸrenme motoru ve temel bileÅŸenler sÄ±fÄ±rdan geliÅŸtirilmiÅŸtir.
*   **ModÃ¼lerlik ve BaÄŸÄ±msÄ±zlÄ±k:** Her bileÅŸen (kÃ¼tÃ¼phane, API, worker, UI, uygulama) kendi baÄŸÄ±msÄ±z repo'sunda yaÅŸar ve kendi sorumluluÄŸuna sahiptir.
*   **Olay GÃ¼dÃ¼mlÃ¼ Mimari:** Servisler arasÄ± iletiÅŸim olay tabanlÄ± (Celery, Redis, WebSockets) gerÃ§ekleÅŸir.
*   **Eklenti TabanlÄ±:** Yeni yapay zeka modelleri ve uygulamalarÄ±, platformun Ã§ekirdek koduna dokunmadan birer eklenti (plugin) olarak eklenebilir.
*   **Ã–lÃ§eklenebilirlik:** DaÄŸÄ±tÄ±k servisler sayesinde yatayda Ã¶lÃ§eklenebilir.
*   **Profesyonel GeliÅŸtirici Deneyimi:** Otomatik kurulum, test ve dokÃ¼mantasyon ile geliÅŸtirme sÃ¼recini kolaylaÅŸtÄ±rmak.

## ðŸ›ï¸ Mimari Genel BakÄ±ÅŸ

AzuraForge platformu, aÅŸaÄŸÄ±daki baÄŸÄ±msÄ±z GitHub depolarÄ±ndan oluÅŸan bir mikroservis mimarisini benimser:

-   **`core`** (`azuraforge-core`): Otomatik tÃ¼rev yeteneklerine sahip temel matematik motoru (NumPy/CuPy).
-   **`learner`** (`azuraforge-learner`): `core` Ã¼zerinde geliÅŸtirilmiÅŸ yÃ¼ksek seviyeli derin Ã¶ÄŸrenme kÃ¼tÃ¼phanesi (Katmanlar, OptimizatÃ¶rler, KayÄ±p FonksiyonlarÄ±, `Learner` sÄ±nÄ±fÄ±).
-   **`applications`** (`azuraforge-applications`): Platform iÃ§in resmi uygulama eklentilerinin katalogu (JSON dosyasÄ±).
-   **`app-stock-predictor`** (`azuraforge-app-stock-predictor`): GerÃ§ek bir uygulama eklentisi Ã¶rneÄŸi (Hisse Senedi Tahmini).
-   **`api`** (`azuraforge-api`): RESTful API ve WebSocket endpoint'leri sunan iletiÅŸim katmanÄ±.
-   **`worker`** (`azuraforge-worker`): Arka plan gÃ¶revlerini iÅŸleyen ve uygulama eklentilerini Ã§alÄ±ÅŸtÄ±ran iÅŸÃ§i servisi.
-   **`dashboard`** (`azuraforge-dashboard`): Platform iÃ§in web tabanlÄ± kullanÄ±cÄ± arayÃ¼zÃ¼.

Bu repo, tÃ¼m bu servisleri tek bir `docker-compose` komutuyla ayaÄŸa kaldÄ±ran ana orkestrasyon katmanÄ±dÄ±r.

## ðŸš€ HÄ±zlÄ± BaÅŸlangÄ±Ã§ (Docker Compose ile)

TÃ¼m platformu yerel makinenizde tek bir komutla baÅŸlatmak iÃ§in:

1.  **Docker Desktop'Ä±n yÃ¼klÃ¼ ve Ã§alÄ±ÅŸtÄ±ÄŸÄ±ndan emin olun.**
2.  **Bu repoyu klonlayÄ±n:**
    ```bash
    git clone https://github.com/AzuraForge/platform.git
    cd platform
    ```
3.  **.env dosyasÄ±nÄ± oluÅŸturun:**
    Proje kÃ¶k dizininde `.env` adÄ±nda bir dosya oluÅŸturun ve iÃ§ine raporlarÄ±n kaydedileceÄŸi dizini belirtin.
    ```
    # .env
    REDIS_URL=redis://redis:6379/0
    # Rapor dizini: Worker'Ä±n sonuÃ§larÄ± yazacaÄŸÄ± ve API'nin okuyacaÄŸÄ± host makinedeki dizin
    # Windows iÃ§in C:/azuraforge_platform_reports veya ./reports
    # Linux/macOS iÃ§in: ./reports
    REPORTS_DIR=./reports 
    ```
    (Windows kullanÄ±yorsanÄ±z `REPORTS_DIR`'i `C:/azuraforge_platform_reports` gibi bir mutlak yola ayarlamanÄ±z daha gÃ¼venli olabilir).
4.  **Platformu baÅŸlatÄ±n:**
    ```bash
    docker-compose up --build -d
    ```
    (`-d` parametresi arka planda Ã§alÄ±ÅŸtÄ±rmayÄ± saÄŸlar.)

5.  **Platforma eriÅŸin:**
    -   **Dashboard:** `http://localhost:5173`
    -   **API DokÃ¼mantasyonu:** `http://localhost:8000/api/v1/docs`

## ðŸ› ï¸ GeliÅŸtirme Rehberi ve Ä°Ã§ Detaylar

Bu rehber, platformun nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ±, nasÄ±l katkÄ±da bulunacaÄŸÄ±nÄ±zÄ± ve geliÅŸtirme ortamÄ±nÄ±zÄ± nasÄ±l yÃ¶neteceÄŸinizi detaylandÄ±rÄ±r.

**[Tam GeliÅŸtirme Rehberine Git](./docs/DEVELOPMENT_GUIDE.md)**

## ðŸ¤ KatkÄ±da Bulunma

Projenin geliÅŸimine katkÄ±da bulunmak iÃ§in [CONTRIBUTING.md](./docs/CONTRIBUTING.md) dosyasÄ±nÄ± inceleyin.

## ðŸ—ºï¸ Yol HaritasÄ± ve Gelecek Vizyonu

Projenin tamamlanan aÅŸamalarÄ±, mevcut durumu ve gelecek hedefleri hakkÄ±nda bilgi almak iÃ§in [PROJECT_JOURNEY.md](./docs/PROJECT_JOURNEY.md) dosyasÄ±nÄ± okuyun.

========== FILE: api/pyproject.toml ==========
[build-system]
requires = ["setuptools>=61.0"]
build-backend = "setuptools.build_meta"

[project]
name = "azuraforge-api"
version = "0.1.0"
description = "The API server for the AzuraForge Platform."
requires-python = ">=3.8"

dependencies = [
    "azuraforge-learner @ git+https://github.com/AzuraForge/learner.git@main",
    "azuraforge-worker @ git+https://github.com/AzuraForge/worker.git@main", # Worker baÄŸÄ±mlÄ±lÄ±ÄŸÄ±, streaming iÃ§in ÅŸart
    "azuraforge-applications @ git+https://github.com/AzuraForge/applications.git@main",
    "fastapi", "uvicorn[standard]", "pydantic-settings", "python-dotenv", "pyyaml",

]

[project.scripts]
start-api = "azuraforge_api.main:run_server"

========== FILE: api/README.md ==========
# api

========== FILE: api/setup.py ==========
from setuptools import setup, find_packages

setup(
    # Bu satÄ±r, setuptools'a paketlerin 'src' klasÃ¶rÃ¼nÃ¼n iÃ§inde
    # olduÄŸunu sÃ¶yler.
    package_dir={"": "src"},
    
    # Bu satÄ±r, 'src' klasÃ¶rÃ¼nÃ¼n iÃ§indeki tÃ¼m Python paketlerini
    # (azuraforge_api ve altÄ±ndakiler) otomatik olarak bulur.
    packages=find_packages(where="src"),
)

========== FILE: api/src/azuraforge_api/main.py ==========
import uvicorn
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware

from .core.config import settings
from .routes import experiments, pipelines, streaming

def create_app() -> FastAPI:
    app = FastAPI(title=settings.PROJECT_NAME, version="0.1.0")
    
    # CORS ayarlarÄ±nÄ± dinamik olarak belirle
    if settings.CORS_ORIGINS == "*":
        allowed_origins = ["*"]
    else:
        allowed_origins = [origin.strip() for origin in settings.CORS_ORIGINS.split(',')]

    app.add_middleware(
        CORSMiddleware,
        allow_origins=allowed_origins, # <-- BurasÄ± deÄŸiÅŸti
        allow_credentials=True,
        allow_methods=["*"],
        allow_headers=["*"],
    )

    # --- KRÄ°TÄ°K DÃœZELTME: Prefix'i geri ekliyoruz ---
    app.include_router(experiments.router, prefix=settings.API_V1_PREFIX)
    app.include_router(pipelines.router, prefix=settings.API_V1_PREFIX)
    app.include_router(streaming.router) # WebSocket router'Ä± eklendi
    
    @app.get("/", tags=["Root"])
    def read_root():
        return {"message": f"Welcome to {settings.PROJECT_NAME}"}
        
    return app

app = create_app()

def run_server():
    print(f"ðŸš€ Starting {settings.PROJECT_NAME}...")
    uvicorn.run("azuraforge_api.main:app", host="0.0.0.0", port=8000, reload=True)

========== FILE: api/src/azuraforge_api/__init__.py ==========

========== FILE: api/src/azuraforge_api/core/config.py ==========
from pydantic_settings import BaseSettings, SettingsConfigDict

class Settings(BaseSettings):
    PROJECT_NAME: str = "AzuraForge API"
    API_V1_PREFIX: str = "/api/v1"
    
    # Yeni CORS ayarÄ±
    # VirgÃ¼lle ayrÄ±lmÄ±ÅŸ URL'ler veya tÃ¼mÃ¼ne izin vermek iÃ§in "*"
    CORS_ORIGINS: str = "*" # VarsayÄ±lan olarak tÃ¼mÃ¼ne izin ver (geliÅŸtirme iÃ§in)
    
    model_config = SettingsConfigDict(env_file=".env", env_file_encoding='utf-8')

settings = Settings()

========== FILE: api/src/azuraforge_api/core/__init__.py ==========

========== FILE: api/src/azuraforge_api/routes/experiments.py ==========
from fastapi import APIRouter, HTTPException
from typing import List, Dict, Any
from ..services import experiment_service

router = APIRouter(prefix="/experiments", tags=["Experiments"])

@router.get("/", response_model=List[Dict[str, Any]])
def get_all_experiments():
    return experiment_service.list_experiments()

@router.post("/", status_code=202, response_model=Dict[str, Any])
def create_new_experiment(config: Dict[str, Any]):
    return experiment_service.start_experiment(config)

@router.get("/{task_id}/status", response_model=Dict[str, Any])
def get_experiment_status(task_id: str):
    return experiment_service.get_task_status(task_id)

========== FILE: api/src/azuraforge_api/routes/pipelines.py ==========
from fastapi import APIRouter, HTTPException
from typing import List, Dict, Any
from ..services import experiment_service

router = APIRouter(prefix="/pipelines", tags=["Pipelines"])

@router.get("/", response_model=List[Dict[str, Any]])
def get_all_available_pipelines():
    return experiment_service.get_available_pipelines()

========== FILE: api/src/azuraforge_api/routes/streaming.py ==========
import asyncio
import logging
from fastapi import APIRouter, WebSocket, WebSocketDisconnect
from celery.result import AsyncResult

# Worker projesinden celery_app'i import etmemiz gerekiyor.
# Bu, api projesinin worker'a baÄŸÄ±mlÄ± olmasÄ±nÄ± gerektirir.
from azuraforge_worker import celery_app

router = APIRouter()

@router.websocket("/ws/task_status/{task_id}")
async def websocket_task_status(websocket: WebSocket, task_id: str):
    """
    Bir Celery gÃ¶revinin durumunu bir WebSocket Ã¼zerinden anlÄ±k olarak yayÄ±nlar.
    """
    await websocket.accept()
    logging.info(f"WebSocket connection accepted for task: {task_id}")
    
    task_result = AsyncResult(task_id, app=celery_app)
    
    try:
        # GÃ¶rev tamamlanana kadar dÃ¶ngÃ¼de kal
        while not task_result.ready():
            # Sadece PROGRESS durumundaki ara bilgileri gÃ¶nder
            if task_result.state == 'PROGRESS':
                await websocket.send_json({
                    "state": task_result.state,
                    "details": task_result.info, # .info, update_state ile gÃ¶nderilen meta verisini iÃ§erir
                })
            # Ã‡ok sÄ±k kontrol etmemek iÃ§in kÄ±sa bir bekleme
            await asyncio.sleep(1)
        
        # GÃ¶rev bittiÄŸinde (SUCCESS, FAILURE vb.) son durumu ve sonucu gÃ¶nder
        await websocket.send_json({
            "state": task_result.state,
            "details": task_result.result, # BaÅŸarÄ± durumunda sonuÃ§, hata durumunda hata detaylarÄ±
        })

    except WebSocketDisconnect:
        logging.warning(f"WebSocket disconnected for task: {task_id}")
    except Exception as e:
        logging.error(f"An error occurred in WebSocket for task {task_id}: {e}")
        # Hata durumunda da istemciye bildirim gÃ¶nder
        try:
            await websocket.send_json({
                "state": "ERROR",
                "details": {"message": str(e), "task_id": task_id}
            })
        except Exception:
            pass # EÄŸer gÃ¶nderilemezse, baÄŸlantÄ± zaten kapanmÄ±ÅŸtÄ±r.
    finally:
        logging.info(f"Closing WebSocket for task {task_id}")
        # BaÄŸlantÄ±yÄ± her durumda kapat
        await websocket.close()

========== FILE: api/src/azuraforge_api/routes/__init__.py ==========

========== FILE: api/src/azuraforge_api/services/experiment_service.py ==========
import json
import os
import glob
from importlib import resources
from typing import List, Dict, Any, Optional
from celery.result import AsyncResult 

from azuraforge_worker import celery_app
from azuraforge_worker.tasks.training_tasks import start_training_pipeline # GÃ¶revi import et

REPORTS_BASE_DIR = os.path.abspath(os.getenv("REPORTS_DIR", "/app/reports"))

def get_available_pipelines() -> List[Dict[str, Any]]:
    try:
        with resources.open_text("azuraforge_applications", "official_apps.json") as f:
            return json.load(f)
    except (FileNotFoundError, ModuleNotFoundError) as e:
        print(f"ERROR: Could not find or read the official apps catalog. {e}")
        return []

def list_experiments() -> List[Dict[str, Any]]:
    # **GÃœNCELLENDÄ°:** completed_at bilgisi de results.json'dan okunacak.
    experiment_files = glob.glob(f"{REPORTS_BASE_DIR}/**/results.json", recursive=True)
    experiments = []
    for f_path in experiment_files:
        try:
            with open(f_path, 'r') as f:
                data = json.load(f)
                experiments.append({
                    "id": data.get("experiment_id", os.path.basename(os.path.dirname(f_path))),
                    "status": data.get("status", "UNKNOWN"),
                    "pipeline_name": data.get("config", {}).get("pipeline_name", "N/A"),
                    "ticker": data.get("config", {}).get("data_sourcing", {}).get("ticker", "N/A"),
                    "final_loss": data.get("results", {}).get("final_loss"),
                    "completed_at": data.get("completed_at"), # Yeni eklendi
                    "started_at": data.get("config", {}).get("start_time"), # EÄŸer config'de varsa
                })
        except Exception as e:
            print(f"Warning: Could not read results.json from {f_path}: {e}")
            continue
    experiments.sort(key=lambda x: x.get('id', ''), reverse=True)
    return experiments

def start_experiment(config: Dict[str, Any]) -> Dict[str, Any]:
    pipeline_name = config.get("pipeline_name", "unknown")
    print(f"Service: Sending task for pipeline '{pipeline_name}' to Celery.")
    task = start_training_pipeline.delay(config) 
    return {"message": "Experiment submitted to worker.", "task_id": task.id}

def get_task_status(task_id: str) -> Dict[str, Any]:
    task_result = AsyncResult(task_id, app=celery_app)
    status = task_result.state
    
    # --- KRÄ°TÄ°K DÃœZELTME: Exception objesini string'e Ã§evir ---
    details = task_result.info 
    if isinstance(details, Exception): # EÄŸer gelen bir hata objesiyse
        details = str(details) # Onu string'e Ã§evirerek JSON serileÅŸtirme hatasÄ±nÄ± Ã¶nle
    
    # BaÅŸarÄ± durumunda, Celery result.result'Ä± doÄŸrudan alÄ±p gÃ¶nder
    if status == 'SUCCESS' or status == 'FAILURE':
        return {"task_id": task_id, "status": status, "result": task_result.result}
    
    return {"task_id": task_id, "status": status, "details": details}

========== FILE: api/src/azuraforge_api/services/__init__.py ==========

========== FILE: api/src/azuraforge_api/tasks/training_tasks.py ==========

========== FILE: api/src/azuraforge_api/tasks/__init__.py ==========

========== FILE: app-stock-predictor/pyproject.toml ==========
[build-system]
requires = ["setuptools>=61.0"]
build-backend = "setuptools.build_meta"

[project]
name = "azuraforge-app-stock-predictor"
version = "0.1.0"
description = "A stock prediction pipeline application for the AzuraForge platform."
requires-python = ">=3.8"
dependencies = [
    "azuraforge-learner @ git+https://github.com/AzuraForge/learner.git@main",
    "yfinance",
    "pandas",
    "scikit-learn",
]

[project.entry-points]
# Var olan giriÅŸ noktasÄ±
"azuraforge.pipelines" = { stock_predictor = "azuraforge_stockapp.pipeline:StockPredictionPipeline" }

# --- YENÄ° GÄ°RÄ°Åž NOKTASI GRUBU ---
"azuraforge.configs" = { stock_predictor = "azuraforge_stockapp.pipeline:get_default_config" }

========== FILE: app-stock-predictor/README.md ==========
# app-stock-predictor

========== FILE: app-stock-predictor/setup.py ==========
from setuptools import setup, find_packages
setup(
    package_dir={"": "src"},
    packages=find_packages(where="src"),
)

========== FILE: app-stock-predictor/src/azuraforge_stockapp/pipeline.py ==========
import logging
import yfinance as yf
import numpy as np
from sklearn.preprocessing import MinMaxScaler
import os 
from typing import Any # <<<< KRÄ°TÄ°K DÃœZELTME

from azuraforge_learner import Learner, Sequential, Linear, MSELoss, SGD, ReLU

class StockPredictionPipeline:
    def __init__(self, config: dict, celery_task: Any = None):
        self.config = config
        self.logger = logging.getLogger(self.__class__.__name__)
        logging.basicConfig(level="INFO", format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        self.celery_task = celery_task # Celery Task objesi buraya iletilir

    def run(self):
        data_sourcing_config = self.config.get("data_sourcing", {})
        training_params_config = self.config.get("training_params", {})
        
        ticker = data_sourcing_config.get("ticker", "MSFT")
        start_date = data_sourcing_config.get("start_date", "2021-01-01")
        epochs = training_params_config.get("epochs", 10)
        lr = training_params_config.get("lr", 0.01)

        self.logger.info(f"--- Running Stock Prediction Pipeline for {ticker} ({epochs} epochs) ---")
        
        try:
            data = yf.download(ticker, start=start_date, progress=False, actions=False, auto_adjust=True)
            if data.empty:
                raise ValueError(f"No data downloaded for ticker: {ticker} from {start_date}")
            self.logger.info(f"Downloaded {len(data)} rows of data.")
            close_prices = data[['Close']].values.astype(np.float32)
        except Exception as e:
            self.logger.error(f"Data download failed for {ticker}: {e}")
            raise 

        scaler = MinMaxScaler(feature_range=(-1, 1))
        scaled_prices = scaler.fit_transform(close_prices)
        
        if len(scaled_prices) < 2:
            self.logger.warning("Not enough data to create sequences for training.")
            return {"status": "completed", "ticker": ticker, "final_loss": float('inf'), "message": "Not enough data for training"}

        X, y = scaled_prices[:-1], scaled_prices[1:]
        
        model = Sequential(Linear(1, 64), ReLU(), Linear(64, 1))
        criterion = MSELoss()
        optimizer = SGD(model.parameters(), lr=lr)
        
        # --- KRÄ°TÄ°K DÃœZELTME: Learner'a Celery Task objesini iletiyoruz ---
        learner = Learner(model, criterion, optimizer, current_task=self.celery_task)

        self.logger.info(f"Starting training for {epochs} epochs...")
        history = learner.fit(X, y, epochs=epochs)
        
        final_loss = history['loss'][-1]
        self.logger.info(f"Training complete. Final loss: {final_loss:.6f}")
        
        return {"status": "completed", "ticker": ticker, "final_loss": final_loss, "loss": history['loss']}

========== FILE: app-stock-predictor/src/azuraforge_stockapp/__init__.py ==========

========== FILE: app-stock-predictor/src/azuraforge_stockapp/config/stock_predictor_config.yml ==========
pipeline_name: "stock_predictor"

data_sourcing:
  ticker: "MSFT" # Microsoft
  start_date: "2021-01-01"

training_params:
  epochs: 10 # Test iÃ§in kÄ±sa tutalÄ±m
  lr: 0.01

========== FILE: app-stock-predictor/src/azuraforge_stockapp/config/__init__.py ==========

========== FILE: applications/pyproject.toml ==========
[build-system]
requires = ["setuptools>=61.0"]
build-backend = "setuptools.build_meta"

[project]
name = "azuraforge-applications"
version = "0.1.0"
description = "A catalog of official applications for the AzuraForge platform."

========== FILE: applications/README.md ==========
# applications

========== FILE: applications/setup.py ==========
from setuptools import setup, find_packages

setup(
    package_dir={"": "src"},
    packages=find_packages(where="src"),
    # EN Ã–NEMLÄ° KISIM: Paket kurulduÄŸunda .json dosyasÄ±nÄ±n da kopyalanmasÄ±nÄ± saÄŸlar
    include_package_data=True, 
    package_data={
        "azuraforge_applications": ["*.json"], # "azuraforge_apps_catalog" -> "azuraforge_applications"
    },
)


========== FILE: applications/src/azuraforge_applications/official_apps.json ==========
[
  {
    "id": "stock_predictor",
    "name": "Hisse Senedi Fiyat Tahmini",
    "repository": "https://github.com/AzuraForge/app-stock-predictor",
    "description": "LSTM tabanlÄ± hisse senedi fiyat tahmini yapar."
  },
  {
    "id": "weather_forecaster",
    "name": "Hava Durumu Tahmini",
    "repository": "https://github.com/AzuraForge/app-weather-forecaster",
    "description": "Gelecekteki hava durumunu tahmin eder (HenÃ¼z GeliÅŸtirilmedi)."
  }
]

========== FILE: applications/src/azuraforge_applications/__init__.py ==========


========== FILE: core/pyproject.toml ==========
[build-system]
requires = ["setuptools>=61.0"]
build-backend = "setuptools.build_meta"

[project]
name = "azuraforge-core"
version = "0.1.2"
authors = [{ name = "Azmi Sahin" }]
description = "The core automatic differentiation engine (Tensor object) for the AzuraForge ecosystem."
readme = "README.md"
requires-python = ">=3.8"
license = { text = "MIT" }
classifiers = ["Programming Language :: Python :: 3"]
dependencies = ["numpy"]

# --- YENÄ° BÃ–LÃœM ---
[project.optional-dependencies]
dev = ["pytest"]

========== FILE: core/README.md ==========
# core

========== FILE: core/setup.py ==========
from setuptools import setup, find_packages
setup(
    package_dir={"": "src"},
    packages=find_packages(where="src"),
)

========== FILE: core/src/azuraforge_core/tensor.py ==========
import os
from typing import Callable, List, Optional, Set, Tuple, Union, Any, cast
import numpy as np

DEVICE = os.environ.get("AZURAFORGE_DEVICE", "cpu").lower()

xp: Any
if DEVICE == "gpu":
    try:
        import cupy
        xp = cupy
    except ImportError:
        import numpy
        xp = numpy
        DEVICE = "cpu"
else:
    import numpy
    xp = numpy

ArrayType = Any
ScalarType = Union[int, float, bool, np.number, xp.number]

def _empty_backward_op() -> None: pass

class Tensor:
    def __init__(self, data: Any, _children: Tuple["Tensor", ...] = (), _op: str = "", requires_grad: bool = False):
        if isinstance(data, Tensor): self.data = data.data.copy()
        else: self.data = xp.array(data, dtype=np.float64)
        
        self.requires_grad = requires_grad
        self.grad: Optional[ArrayType] = xp.zeros_like(self.data) if requires_grad else None
        self._backward: Callable[[], None] = _empty_backward_op
        self._prev: Set["Tensor"] = set(_children)
        self._op: str = _op

    def backward(self, grad_output: Optional[ArrayType] = None) -> None:
        if not self.requires_grad: return
        topo: List[Tensor] = []
        visited: Set[Tensor] = set()
        def build_topo(v):
            if v not in visited:
                visited.add(v); [build_topo(child) for child in v._prev]; topo.append(v)
        build_topo(self)
        for t in topo:
            if t.grad is not None: t.grad.fill(0.0)
        self.grad = xp.ones_like(self.data) if grad_output is None else xp.asarray(grad_output, dtype=np.float64).reshape(self.data.shape)
        for v in reversed(topo): v._backward()

    def to_cpu(self) -> np.ndarray:
        if hasattr(self.data, 'get'): return self.data.get()
        return np.array(self.data, copy=True)

    def __add__(self, other: Any) -> "Tensor":
        other = _ensure_tensor(other)
        out = Tensor(self.data + other.data, (self, other), "+", self.requires_grad or other.requires_grad)
        def _backward():
            if self.requires_grad: self.grad += _unbroadcast_to(self.data.shape, out.grad)
            if other.requires_grad: other.grad += _unbroadcast_to(other.data.shape, out.grad)
        out._backward = _backward
        return out

    def __mul__(self, other: Any) -> "Tensor":
        other = _ensure_tensor(other)
        out = Tensor(self.data * other.data, (self, other), "*", self.requires_grad or other.requires_grad)
        def _backward():
            if self.requires_grad: self.grad += _unbroadcast_to(self.data.shape, other.data * out.grad)
            if other.requires_grad: other.grad += _unbroadcast_to(other.data.shape, self.data * out.grad)
        out._backward = _backward
        return out

    # ... (DiÄŸer tÃ¼m metodlar aynÄ± kalabilir, sadece __add__ ve __mul__ _unbroadcast_to kullanacak ÅŸekilde gÃ¼ncellendi)
    def __pow__(self, power: float) -> "Tensor":
        out = Tensor(self.data ** power, (self,), f"**{power}", self.requires_grad)
        def _backward():
            if self.requires_grad: self.grad += (power * (self.data ** (power - 1))) * out.grad
        out._backward = _backward
        return out

    def dot(self, other: "Tensor") -> "Tensor":
        out = Tensor(self.data @ other.data, (self, other), "@", self.requires_grad or other.requires_grad)
        def _backward():
            if self.requires_grad: self.grad += out.grad @ other.data.T
            if other.requires_grad: other.grad += self.data.T @ out.grad
        out._backward = _backward
        return out

    def sum(self, axis=None, keepdims=False) -> "Tensor":
        out = Tensor(xp.sum(self.data, axis=axis, keepdims=keepdims), (self,), "sum", self.requires_grad)
        def _backward(_axis=axis, _keepdims=keepdims):
            if self.requires_grad and self.grad is not None:
                grad_val = out.grad
                if _axis is not None and not _keepdims:
                    grad_val = xp.expand_dims(grad_val, axis=_axis)
                self.grad += grad_val
        out._backward = _backward
        return out

    def mean(self, axis=None, keepdims=False) -> "Tensor":
        sum_val = self.sum(axis=axis, keepdims=keepdims)
        num_elements = float(np.prod(self.data.shape) / np.prod(sum_val.data.shape))
        return sum_val * (1.0 / num_elements)
    
    def relu(self) -> "Tensor":
        out = Tensor(xp.maximum(0, self.data), (self,), "ReLU", self.requires_grad)
        def _backward():
            if self.requires_grad: self.grad += (self.data > 0) * out.grad
        out._backward = _backward
        return out
        
    def __repr__(self): return f"Tensor(data={self.data}, requires_grad={self.requires_grad})"
    def __neg__(self): return self * -1
    def __sub__(self, other): return self + (-other)
    def __truediv__(self, other): return self * (_ensure_tensor(other) ** -1)
    __radd__ = __add__
    def __rmul__(self, other): return self * other
    def __rsub__(self, other): return _ensure_tensor(other) - self
    def __rtruediv__(self, other): return _ensure_tensor(other) / self

def _ensure_tensor(val: Any) -> "Tensor":
    return val if isinstance(val, Tensor) else Tensor(val)

# --- YENÄ° VE SAÄžLAM _unbroadcast_to FONKSÄ°YONU ---
def _unbroadcast_to(target_shape: Tuple[int, ...], grad: ArrayType) -> ArrayType:
    """Bir gradyanÄ±, orijinal tensÃ¶rÃ¼n (yayÄ±nlamadan Ã¶nceki) ÅŸekline geri kÃ¼Ã§Ã¼ltÃ¼r."""
    if target_shape == grad.shape:
        return grad
    
    # Boyut sayÄ±sÄ±nÄ± eÅŸitle
    ndim_diff = grad.ndim - len(target_shape)
    if ndim_diff > 0:
        grad = grad.sum(axis=tuple(range(ndim_diff)))

    # Boyutu 1 olan eksenler boyunca topla
    axes_to_sum = []
    for i, dim in enumerate(target_shape):
        if dim == 1:
            axes_to_sum.append(i)
    
    if axes_to_sum:
        grad = grad.sum(axis=tuple(axes_to_sum), keepdims=True)
        
    return grad

========== FILE: core/src/azuraforge_core/__init__.py ==========
from .tensor import Tensor, xp, DEVICE, ArrayType, ScalarType, _unbroadcast_to

__all__ = ["Tensor", "xp", "DEVICE", "ArrayType", "ScalarType", "_unbroadcast_to"]

========== FILE: core/tests/azuraforge_core/test_tensor.py ==========
import pytest
import numpy as np

# Test edilecek paketi import et
from azuraforge_core import Tensor

def test_tensor_creation_and_defaults():
    """Tensor nesnesinin doÄŸru ÅŸekilde ve varsayÄ±lan deÄŸerlerle oluÅŸturulduÄŸunu test eder."""
    t = Tensor([1, 2, 3])
    assert isinstance(t.data, np.ndarray)
    assert t.requires_grad is False
    assert t.grad is None

def test_tensor_requires_grad():
    """`requires_grad=True` olduÄŸunda gradyan dizisinin oluÅŸturulduÄŸunu test eder."""
    t = Tensor([1, 2], requires_grad=True)
    assert t.requires_grad is True
    assert isinstance(t.grad, np.ndarray)
    assert np.array_equal(t.grad, np.array([0.0, 0.0]))

def test_addition_backward():
    """Basit toplama iÅŸlemi iÃ§in geri yayÄ±lÄ±mÄ±n doÄŸru Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± test eder."""
    a = Tensor([1, 2, 3], requires_grad=True)
    b = Tensor(5, requires_grad=True)
    
    # c = a.sum() + b  ->  dc/da = [1, 1, 1], dc/db = 1
    c = a.sum() + b
    
    c.backward()

    assert a.grad is not None
    assert b.grad is not None
    assert np.array_equal(a.grad, [1, 1, 1])
    assert b.grad == 1.0

def test_multiplication_backward():
    """Basit Ã§arpma iÅŸlemi iÃ§in geri yayÄ±lÄ±mÄ±n doÄŸru Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± test eder."""
    x = Tensor(2.0, requires_grad=True)
    y = Tensor(3.0, requires_grad=True)
    
    z = x * y
    
    z.backward() # dz/dx = y = 3,  dz/dy = x = 2

    assert x.grad == 3.0
    assert y.grad == 2.0

def test_chained_rule_backward():
    """Zincir kuralÄ±nÄ±n birden Ã§ok iÅŸlemde doÄŸru Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± test eder."""
    x = Tensor(2.0, requires_grad=True)
    y = Tensor(3.0, requires_grad=True)

    z = x * y  # dz/dx = y, dz/dy = x
    q = z + x  # dq/dz = 1, dq/dx = 1
    
    # Zincir KuralÄ±:
    # dq/dx = (dq/dz * dz/dx) + dq/dx = (1 * y) + 1 = 3 + 1 = 4
    # dq/dy = (dq/dz * dz/dy) = 1 * x = 2
    q.backward()

    assert x.grad == 4.0
    assert y.grad == 2.0

def test_dot_product_backward():
    """Matris Ã§arpÄ±mÄ± iÃ§in geri yayÄ±lÄ±mÄ± test eder."""
    a_data = np.random.randn(2, 3)
    b_data = np.random.randn(3, 4)
    a = Tensor(a_data, requires_grad=True)
    b = Tensor(b_data, requires_grad=True)
    
    c = a.dot(b)
    
    # GradyanÄ± 1'lerden oluÅŸan bir matrisle baÅŸlat
    c.backward(np.ones_like(c.data))
    
    # Manuel olarak hesaplanan gradyanlar
    grad_a_manual = np.ones_like(c.data) @ b_data.T
    grad_b_manual = a_data.T @ np.ones_like(c.data)
    
    assert np.allclose(a.grad, grad_a_manual)
    assert np.allclose(b.grad, grad_b_manual)


def test_relu_backward():
    """ReLU aktivasyonu iÃ§in geri yayÄ±lÄ±mÄ± test eder."""
    a = Tensor([-1, 0, 5], requires_grad=True)
    r = a.relu()
    r.backward(np.array([10, 20, 30]))

    # Gradyan sadece pozitif deÄŸerler iÃ§in akar (self.data > 0)
    assert np.array_equal(a.grad, [0, 0, 30])

========== FILE: dashboard/eslint.config.js ==========
import js from '@eslint/js'
import globals from 'globals'
import reactHooks from 'eslint-plugin-react-hooks'
import reactRefresh from 'eslint-plugin-react-refresh'
import { defineConfig, globalIgnores } from 'eslint/config'

export default defineConfig([
  globalIgnores(['dist']),
  {
    files: ['**/*.{js,jsx}'],
    extends: [
      js.configs.recommended,
      reactHooks.configs['recommended-latest'],
      reactRefresh.configs.vite,
    ],
    languageOptions: {
      ecmaVersion: 2020,
      globals: globals.browser,
      parserOptions: {
        ecmaVersion: 'latest',
        ecmaFeatures: { jsx: true },
        sourceType: 'module',
      },
    },
    rules: {
      'no-unused-vars': ['error', { varsIgnorePattern: '^[A-Z_]' }],
    },
  },
])

========== FILE: dashboard/index.html ==========
<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <link rel="icon" type="image/svg+xml" href="/vite.svg" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Vite + React</title>
  </head>
  <body>
    <div id="root"></div>
    <script type="module" src="/src/main.jsx"></script>
  </body>
</html>

========== FILE: dashboard/package.json ==========
{
  "name": "dashboard",
  "private": true,
  "version": "0.0.0",
  "type": "module",
  "scripts": {
    "dev": "vite",
    "build": "vite build",
    "lint": "eslint .",
    "preview": "vite preview"
  },
  "dependencies": {
    "axios": "^1.10.0",
    "chart.js": "^4.5.0",
    "react": "^19.1.0",
    "react-chartjs-2": "^5.3.0",
    "react-dom": "^19.1.0",
    "prop-types": "^15.8.1",  
    "react-router-dom": "^6.25.1"
  },
  "devDependencies": {
    "@eslint/js": "^9.29.0",
    "@types/react": "^19.1.8",
    "@types/react-dom": "^19.1.6",
    "@vitejs/plugin-react": "^4.5.2",
    "eslint": "^9.29.0",
    "eslint-plugin-react-hooks": "^5.2.0",
    "eslint-plugin-react-refresh": "^0.4.20",
    "globals": "^16.2.0",
    "vite": "^7.0.0"
  }
}

========== FILE: dashboard/README.md ==========
# React + Vite

This template provides a minimal setup to get React working in Vite with HMR and some ESLint rules.

Currently, two official plugins are available:

- [@vitejs/plugin-react](https://github.com/vitejs/vite-plugin-react/blob/main/packages/plugin-react) uses [Babel](https://babeljs.io/) for Fast Refresh
- [@vitejs/plugin-react-swc](https://github.com/vitejs/vite-plugin-react/blob/main/packages/plugin-react-swc) uses [SWC](https://swc.rs/) for Fast Refresh

## Expanding the ESLint configuration

If you are developing a production application, we recommend using TypeScript with type-aware lint rules enabled. Check out the [TS template](https://github.com/vitejs/vite/tree/main/packages/create-vite/template-react-ts) for information on how to integrate TypeScript and [`typescript-eslint`](https://typescript-eslint.io) in your project.

========== FILE: dashboard/vite.config.js ==========
import { defineConfig } from 'vite'
import react from '@vitejs/plugin-react'

// https://vite.dev/config/
export default defineConfig({
  plugins: [react()],
})

========== FILE: dashboard/src/App.css ==========
/* ========== YENÄ°/GÃœNCELLENECEK DOSYA: dashboard/src/App.css (KapsamlÄ± Stil DosyasÄ±) ========== */

/* Temel Reset ve Genel Stiller */
:root {
  font-family: 'Inter', system-ui, Avenir, Helvetica, Arial, sans-serif;
  line-height: 1.5;
  font-weight: 400;

  color-scheme: light dark;
  color: #333; /* VarsayÄ±lan metin rengi */
  background-color: #f0f2f5; /* Genel arkaplan */

  font-synthesis: none;
  text-rendering: optimizeLegibility;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}

body {
  margin: 0;
  display: flex;
  min-height: 100vh;
  width: 100vw;
  font-size: 16px;
  overflow: hidden; /* Dikey kaydÄ±rmayÄ± body'den kaldÄ±r, main-content'e bÄ±rak */
}

#root {
  display: flex; /* Sidebar ve ana iÃ§eriÄŸi yan yana koymak iÃ§in */
  flex-grow: 1; /* TÃ¼m alanÄ± kapla */
  width: 100%;
}

/* Ana Uygulama DÃ¼zeni */
.app-layout {
  display: flex;
  flex-grow: 1;
}

/* Sidebar Stilleri */
.sidebar {
  width: 250px;
  background-color: #2c3e50; /* Koyu gri */
  color: white;
  padding: 20px;
  box-shadow: 2px 0 5px rgba(0, 0, 0, 0.2);
  display: flex;
  flex-direction: column;
  flex-shrink: 0; /* KÃ¼Ã§Ã¼lmesini engelle */
}

.sidebar h2 {
  text-align: center;
  color: #42b983; /* AzuraForge yeÅŸili */
  margin-bottom: 30px;
  font-size: 1.5em;
  font-weight: bold;
}

.sidebar nav ul {
  list-style: none;
  padding: 0;
  margin: 0;
}

.sidebar nav ul li {
  margin-bottom: 10px;
}

.sidebar nav a {
  display: block;
  padding: 12px 15px;
  color: white;
  text-decoration: none;
  border-radius: 8px; /* Daha modern bir yuvarlaklÄ±k */
  transition: background-color 0.3s ease, color 0.3s ease;
  display: flex;
  align-items: center;
  gap: 12px; /* Ä°kon ve yazÄ± arasÄ± boÅŸluk */
  font-size: 1.05em;
}

.sidebar nav a:hover {
  background-color: #4a6680; /* Daha aÃ§Ä±k bir hover rengi */
}

.sidebar nav a.active {
  background-color: #42b983; /* Aktif menÃ¼ rengi */
  font-weight: bold;
}

/* Main Content Area */
.main-content {
  flex-grow: 1;
  padding: 30px;
  background-color: #f0f2f5; /* AÃ§Ä±k gri arkaplan */
  overflow-y: auto; /* Dikey kaydÄ±rma Ã§ubuÄŸu */
}

/* Header/Title */
.page-header {
  margin-bottom: 30px;
  color: #2c3e50;
  border-bottom: 1px solid #e0e0e0; /* Daha aÃ§Ä±k Ã§izgi */
  padding-bottom: 15px;
  display: flex;
  flex-direction: column;
}

.page-header h1 {
  font-size: 2.5em; /* Daha bÃ¼yÃ¼k baÅŸlÄ±k */
  margin: 0;
  display: flex;
  align-items: center;
  gap: 15px;
}

.page-header p {
  color: #777;
  margin-top: 8px;
  font-size: 1.1em;
}

/* Genel BileÅŸen Stilleri */
.card {
  background-color: white;
  border-radius: 10px; /* Daha belirgin yuvarlak kÃ¶ÅŸeler */
  box-shadow: 0 5px 15px rgba(0, 0, 0, 0.1); /* Daha belirgin gÃ¶lge */
  padding: 25px;
  margin-bottom: 25px;
  transition: transform 0.2s ease-in-out; /* Hover efekti iÃ§in */
}

.card.clickable:hover { /* Sadece tÄ±klanabilir kartlara hover efekti */
  transform: translateY(-5px); /* Hafif yukarÄ± kayma efekti */
}


.section-title {
  font-size: 2em;
  color: #2c3e50;
  margin-bottom: 25px;
  border-bottom: 1px solid #e0e0e0;
  padding-bottom: 10px;
}

/* Form Stilleri */
.form-container {
  max-width: 700px; /* Daha geniÅŸ form */
  margin: 0 auto;
  padding: 40px;
  background-color: white;
  border-radius: 10px;
  box-shadow: 0 5px 15px rgba(0, 0, 0, 0.1);
}

.form-group {
  margin-bottom: 25px;
}

.form-group label {
  display: block;
  margin-bottom: 10px;
  font-weight: bold;
  color: #555;
  font-size: 1.1em;
}

.form-group input[type="text"],
.form-group input[type="number"],
.form-group select,
.form-group textarea {
  width: calc(100% - 24px); /* Padding'i hesaba kat */
  padding: 12px;
  border: 1px solid #ccc;
  border-radius: 6px;
  font-size: 1em;
  box-sizing: border-box; /* Padding ve border geniÅŸliÄŸe dahil */
}

.form-group textarea {
  min-height: 150px; /* Daha uzun textarea */
  resize: vertical;
}

.button-primary {
  background-color: #42b983;
  color: white;
  padding: 15px 30px;
  border: none;
  border-radius: 8px;
  cursor: pointer;
  font-size: 1.1em;
  font-weight: bold;
  transition: background-color 0.3s ease, transform 0.2s ease;
  width: auto; /* GeniÅŸliÄŸi iÃ§eriÄŸe gÃ¶re ayarla */
}

.button-primary:hover:not(:disabled) {
  background-color: #369c70;
  transform: translateY(-2px);
}

.button-primary:disabled {
  background-color: #cccccc;
  cursor: not-allowed;
  opacity: 0.7;
}

.button-link { /* Ä°Ã§ metinlerde buton gibi gÃ¶rÃ¼nen linkler iÃ§in */
  background: none;
  border: none;
  color: #007bff;
  text-decoration: underline;
  cursor: pointer;
  font-size: 1em;
  padding: 0;
  font-family: inherit; /* YazÄ± tipini koru */
}
.button-link:hover {
  color: #0056b3;
}

/* Status Badges */
.status-badge {
  display: inline-block;
  padding: 6px 12px;
  border-radius: 20px;
  font-size: 0.85em;
  font-weight: bold;
  color: white;
  text-transform: uppercase;
  min-width: 90px;
  text-align: center;
  margin-left: 10px;
}

.status-badge.status-started, .status-badge.status-progress, .status-badge.status-connecting {
  background-color: #007bff; /* Mavi */
}

.status-badge.status-success {
  background-color: #28a745; /* YeÅŸil */
}

.status-badge.status-failure, .status-badge.status-error, .status-badge.status-disconnected {
  background-color: #dc3545; /* KÄ±rmÄ±zÄ± */
}

.status-badge.status-pending, .status-badge.status-unknown, .status-badge.status-no_task {
  background-color: #6c757d; /* Gri */
}

/* Feedback Messages */
.feedback {
  padding: 12px 20px;
  border-radius: 8px;
  margin-top: 20px;
  font-weight: bold;
  display: flex;
  align-items: center;
  gap: 10px;
}

.feedback.success {
  background-color: #d4edda;
  color: #155724;
  border: 1px solid #c3e6cb;
}

.feedback.error {
  background-color: #f8d7da;
  color: #721c24;
  border: 1px solid #f5c6cb;
}
.feedback.info {
  background-color: #d1ecf1;
  color: #0c5460;
  border: 1px solid #bee5eb;
}

/* Tablo Stilleri (ExperimentsList iÃ§in) */
.table-container {
  overflow-x: auto;
  border-radius: 10px;
  box-shadow: 0 5px 15px rgba(0, 0, 0, 0.1);
  background-color: white;
  margin-bottom: 25px;
}

table {
  width: 100%;
  border-collapse: collapse;
  min-width: 700px; /* KÃ¼Ã§Ã¼k ekranlarda kaydÄ±rma Ã§ubuÄŸu Ã§Ä±ksÄ±n */
}

table th, table td {
  padding: 15px 20px;
  text-align: left;
  border-bottom: 1px solid #eee;
}

table th {
  background-color: #e9ecef;
  color: #495057;
  font-weight: bold;
  text-transform: uppercase;
  font-size: 0.9em;
}

table tbody tr:hover {
  background-color: #f5f5f5;
}

.exp-id {
  font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, Courier, monospace;
}

.clickable-cell {
  cursor: pointer;
}

.clickable-cell a {
  text-decoration: none;
  color: #007bff;
  font-weight: bold;
  transition: color 0.2s ease;
}

.clickable-cell a:hover {
  color: #0056b3;
  text-decoration: underline;
}

/* JSON / Code Block */
.code-block {
  background-color: #eef1f5; /* Hafif daha aÃ§Ä±k gri */
  border: 1px solid #dcdcdc;
  padding: 20px;
  border-radius: 8px;
  overflow-x: auto;
  font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, Courier, monospace;
  font-size: 0.95em;
  color: #444;
  white-space: pre-wrap;
  word-break: break-all;
  margin-top: 15px;
  margin-bottom: 20px;
}

/* Chart Container */
.chart-container {
  position: relative;
  height: 450px; /* GrafiÄŸin yÃ¼ksekliÄŸini artÄ±r */
  width: 100%;
  margin-top: 25px;
  background-color: white; /* Grafik arkaplanÄ± beyaz */
  padding: 20px;
  border-radius: 10px;
  box-shadow: 0 4px 10px rgba(0, 0, 0, 0.08);
}
.chart-container h4 {
  margin-top: 0;
  color: #2c3e50;
  margin-bottom: 15px;
  font-size: 1.3em;
}

/* Progress Bar (HTML native) */
progress {
  width: 100%;
  height: 22px; /* Daha belirgin */
  -webkit-appearance: none;
  appearance: none;
  border-radius: 12px;
  overflow: hidden; /* For Safari */
  border: none;
}

progress::-webkit-progress-bar {
  background-color: #e0e0e0;
  border-radius: 12px;
}

progress::-webkit-progress-value {
  background-color: #42b983; /* YeÅŸilimsi */
  border-radius: 12px;
  transition: width 0.5s ease;
}

progress::-moz-progress-bar {
  background-color: #42b983;
  border-radius: 12px;
}

.progress-section {
  padding: 15px;
  background-color: #e7f3ff; /* AÃ§Ä±k mavi arkaplan */
  border: 1px solid #b3d9ff;
  border-radius: 8px;
  margin-top: 15px;
  margin-bottom: 15px;
}
.progress-section p {
  margin: 5px 0;
  color: #333;
}

/* Running Experiments Grid */
.running-experiments-grid {
  display: grid;
  grid-template-columns: repeat(auto-fill, minmax(320px, 1fr)); /* Daha bÃ¼yÃ¼k kartlar */
  gap: 25px;
  margin-bottom: 30px;
}
.experiment-card {
  cursor: pointer;
}
.experiment-card h3 {
  font-size: 1.4em;
  margin-top: 0;
  margin-bottom: 10px;
  color: #2c3e50;
}
.experiment-card p {
  margin-bottom: 5px;
  font-size: 0.95em;
}

/* Responsive Ayarlar */
@media (max-width: 992px) {
  .sidebar {
    width: 200px;
  }
  .sidebar h2 {
    font-size: 1.3em;
  }
  .sidebar nav a {
    font-size: 0.95em;
  }
  .main-content {
    padding: 20px;
  }
  .page-header h1 {
    font-size: 2em;
  }
  .section-title {
    font-size: 1.8em;
  }
  .running-experiments-grid {
    grid-template-columns: repeat(auto-fill, minmax(280px, 1fr));
    gap: 20px;
  }
}

@media (max-width: 768px) {
  .app-layout {
    flex-direction: column; /* KÃ¼Ã§Ã¼k ekranlarda sidebar Ã¼stte */
  }
  .sidebar {
    width: 100%;
    height: auto;
    flex-direction: row;
    justify-content: center;
    padding: 15px;
    box-shadow: 0 2px 5px rgba(0, 0, 0, 0.2);
  }
  .sidebar h2 {
    display: none; /* KÃ¼Ã§Ã¼k ekranlarda baÅŸlÄ±ÄŸÄ± gizle */
  }
  .sidebar nav {
    width: 100%;
  }
  .sidebar nav ul {
    display: flex;
    justify-content: space-around;
    flex-wrap: wrap;
  }
  .sidebar nav ul li {
    margin: 5px;
  }
  .sidebar nav a {
    padding: 10px 15px;
    font-size: 0.9em;
    gap: 8px;
  }
  .main-content {
    padding: 15px;
  }
  .form-container {
    padding: 25px;
  }
  .page-header h1 {
    font-size: 1.8em;
  }
  .section-title {
    font-size: 1.6em;
  }
  table {
    font-size: 0.9em;
  }
  table th, table td {
    padding: 10px 12px;
  }
}

@media (max-width: 480px) {
  .sidebar nav a {
    padding: 8px 10px;
    font-size: 0.85em;
    gap: 5px;
  }
  .running-experiments-grid {
    grid-template-columns: 1fr; /* Ã‡ok kÃ¼Ã§Ã¼k ekranlarda tek sÃ¼tun */
  }
  .chart-container {
    height: 300px; /* Daha kÃ¼Ã§Ã¼k grafik */
    padding: 15px;
  }
  .form-container {
    padding: 20px;
  }
}
========== FILE: dashboard/src/App.jsx ==========
// ========== GÃœNCELLENECEK DOSYA: dashboard/src/App.jsx (Yeni Ana Layout ve Router) ==========
import { useState } from 'react';
import { Routes, Route, Link, useNavigate, useLocation } from 'react-router-dom';
import './App.css'; // Yeni stil dosyasÄ±nÄ± import et

// BileÅŸenleri import et
import ExperimentsList from './components/ExperimentsList'; // Halen kullanÄ±lacak (sadece tablo gÃ¶sterimi iÃ§in)
import NewExperiment from './components/NewExperiment';
import ExperimentTracker from './components/ExperimentTracker';
import ExperimentDetailPage from './components/ExperimentDetailPage'; 
import DashboardOverview from './pages/DashboardOverview'; // Yeni Genel BakÄ±ÅŸ SayfasÄ±

function App() {
  const [trackingTaskId, setTrackingTaskId] = useState(null); // CanlÄ± takip edilen gÃ¶rev ID'si
  const navigate = useNavigate();
  const location = useLocation();

  // Yeni bir deney baÅŸlatÄ±ldÄ±ÄŸÄ±nda Ã§aÄŸrÄ±lacak callback
  const handleExperimentStarted = (taskId) => {
    // Yeni deney baÅŸladÄ±ÄŸÄ±nda direkt Tracker sayfasÄ±na yÃ¶nlendirme yapabiliriz.
    // Ancak ana Dashboard'un otomatik yenilemesi de bu gÃ¶revi yakalayacaktÄ±r.
    // Åžimdilik Tracker sayfasÄ±na yÃ¶nlendirme mantÄ±ÄŸÄ±nÄ± koruyalÄ±m,
    // ancak DashboardOverview'da anlÄ±k listeleme zaten yapÄ±lacaÄŸÄ± iÃ§in
    // bu navigasyonun zorunlu olmadÄ±ÄŸÄ±nÄ± unutmayalÄ±m.
    if (taskId) {
        setTrackingTaskId(taskId); // Takip edilecek gÃ¶revi ayarla
        navigate(`/tracker/${taskId}`); // CanlÄ± takip sayfasÄ±na yÃ¶nlendir
    }
  };

  // Aktif link stilini belirlemek iÃ§in yardÄ±mcÄ± fonksiyon
  const isActive = (path) => {
    if (path === '/') return location.pathname === '/' || location.pathname === '/experiments';
    if (path === '/tracker' && location.pathname.startsWith('/tracker/')) return true;
    if (path === '/experiments' && location.pathname.startsWith('/experiments/')) return true;
    return location.pathname === path;
  };

  return (
    <div className="app-layout"> {/* Yeni ana layout div'i */}
      {/* Sidebar */}
      <aside className="sidebar">
        <h2>AzuraForge</h2>
        <nav>
          <ul>
            <li>
              <Link to="/experiments" className={isActive('/experiments') ? 'active' : ''}>
                <span role="img" aria-label="dashboard">ðŸ“Š</span> Genel BakÄ±ÅŸ
              </Link>
            </li>
            <li>
              <Link to="/new-experiment" className={isActive('/new-experiment') ? 'active' : ''}>
                <span role="img" aria-label="rocket">ðŸš€</span> Yeni Deney BaÅŸlat
              </Link>
            </li>
            {/* EÄŸer bir gÃ¶rev takip ediliyorsa veya tracker sayfasÄ±ndaysak canlÄ± takip sekmesini gÃ¶ster */}
            {trackingTaskId && (
              <li>
                <Link to={`/tracker/${trackingTaskId}`} className={isActive('/tracker') ? 'active' : ''}>
                  <span role="img" aria-label="satellite">ðŸ›°ï¸</span> CanlÄ± Takip
                </Link>
              </li>
            )}
            {/* DiÄŸer menÃ¼ Ã¶ÄŸeleri (Uygulama KataloÄŸu, Model KaydÄ± vb.) buraya eklenebilir */}
          </ul>
        </nav>
      </aside>

      {/* Ana Ä°Ã§erik */}
      <main className="main-content">
        <Routes>
          {/* Ana sayfa "/experiments" ile aynÄ± iÃ§eriÄŸi gÃ¶stersin */}
          <Route path="/" element={<DashboardOverview 
            onExperimentSelect={(id) => navigate(`/experiments/${id}`)} 
            onNewExperimentClick={() => navigate('/new-experiment')}
          />} />
          <Route path="/experiments" element={<DashboardOverview 
            onExperimentSelect={(id) => navigate(`/experiments/${id}`)} 
            onNewExperimentClick={() => navigate('/new-experiment')}
          />} />
          <Route path="/new-experiment" element={<NewExperiment onExperimentStarted={handleExperimentStarted} />} />
          <Route path="/tracker/:taskId" element={<ExperimentTracker />} />
          <Route path="/experiments/:experimentId" element={<ExperimentDetailPage />} />
        </Routes>
      </main>
    </div>
  );
}

export default App;
========== FILE: dashboard/src/index.css ==========
:root {
  font-family: system-ui, Avenir, Helvetica, Arial, sans-serif;
  line-height: 1.5;
  font-weight: 400;

  color-scheme: light dark;
  color: rgba(255, 255, 255, 0.87);
  background-color: #242424;

  font-synthesis: none;
  text-rendering: optimizeLegibility;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}

a {
  font-weight: 500;
  color: #646cff;
  text-decoration: inherit;
}
a:hover {
  color: #535bf2;
}

body {
  margin: 0;
  display: flex;
  place-items: center;
  min-width: 320px;
  min-height: 100vh;
}

h1 {
  font-size: 3.2em;
  line-height: 1.1;
}

button {
  border-radius: 8px;
  border: 1px solid transparent;
  padding: 0.6em 1.2em;
  font-size: 1em;
  font-weight: 500;
  font-family: inherit;
  background-color: #1a1a1a;
  cursor: pointer;
  transition: border-color 0.25s;
}
button:hover {
  border-color: #646cff;
}
button:focus,
button:focus-visible {
  outline: 4px auto -webkit-focus-ring-color;
}

@media (prefers-color-scheme: light) {
  :root {
    color: #213547;
    background-color: #ffffff;
  }
  a:hover {
    color: #747bff;
  }
  button {
    background-color: #f9f9f9;
  }
}

========== FILE: dashboard/src/main.jsx ==========
// ========== GÃœNCELLENECEK DOSYA: dashboard/src/main.jsx ==========
import { StrictMode } from 'react';
import { createRoot } from 'react-dom/client';
import './index.css'; // Global stil dosyanÄ±z (varsa)
import App from './App.jsx';
import { BrowserRouter } from 'react-router-dom'; // BrowserRouter import edildi

createRoot(document.getElementById('root')).render(
  <StrictMode>
    {/* UygulamayÄ± BrowserRouter ile sarmala */}
    <BrowserRouter> 
      <App />
    </BrowserRouter>
  </StrictMode>,
);
========== FILE: dashboard/src/components/ExperimentCard.jsx ==========
// ========== YENÄ° DOSYA: dashboard/src/components/ExperimentCard.jsx ==========
import { useState, useEffect, useRef } from 'react';
import { useNavigate } from 'react-router-dom';
import PropTypes from 'prop-types';
import { Line } from 'react-chartjs-2'; // Grafik bileÅŸeni

// Chart.js bileÅŸenlerini kaydet
import {
  Chart as ChartJS, CategoryScale, LinearScale, PointElement, LineElement, Title, Tooltip, Legend
} from 'chart.js';
ChartJS.register(CategoryScale, LinearScale, PointElement, LineElement, Title, Tooltip, Legend);

function ExperimentCard({ experiment, onSelect }) {
  const navigate = useNavigate();
  // KartÄ±n kendi internal state'i, WebSocket'ten gelen canlÄ± verilerle gÃ¼ncellenecek
  const [currentStatus, setCurrentStatus] = useState(experiment.status);
  const [currentLoss, setCurrentLoss] = useState(experiment.final_loss);
  const [progress, setProgress] = useState(0);
  const [statusText, setStatusText] = useState(experiment.status || "Bilgi bekleniyor...");
  const [chartData, setChartData] = useState({ labels: [], datasets: [] });
  const ws = useRef(null); // WebSocket baÄŸlantÄ±sÄ±nÄ± tutmak iÃ§in ref

  useEffect(() => {
    // Sadece Ã§alÄ±ÅŸan veya henÃ¼z baÅŸlamÄ±ÅŸ deneyler iÃ§in WebSocket baÄŸlantÄ±sÄ± kur
    const isLiveStatus = (status) => status === 'STARTED' || status === 'PROGRESS';
    let cleanupNeeded = false;

    // Ä°lk yÃ¼klemede ve experiment.id deÄŸiÅŸtiÄŸinde sÄ±fÄ±rlama yap
    setCurrentStatus(experiment.status);
    setCurrentLoss(experiment.final_loss);
    setProgress(experiment.status === 'SUCCESS' ? 100 : 0);
    setStatusText(experiment.status || "Bilgi bekleniyor...");
    setChartData({ // GrafiÄŸi sÄ±fÄ±rla
        labels: [], 
        datasets: [{ 
            label: 'EÄŸitim KaybÄ±', 
            data: [], 
            borderColor: 'rgb(75, 192, 192)', 
            backgroundColor: 'rgba(75, 192, 192, 0.5)',
            tension: 0.1, 
            fill: false 
        }] 
    });


    if (isLiveStatus(experiment.status)) { // Ä°lk render'da statÃ¼ye gÃ¶re karar ver
      cleanupNeeded = true;
      const wsUrl = `ws://localhost:8000/ws/task_status/${experiment.id}`;
      
      // Ã–nceki baÄŸlantÄ±yÄ± temizle (varsa)
      if (ws.current) { ws.current.close(); }
      ws.current = new WebSocket(wsUrl);

      ws.current.onopen = () => {
        console.log(`WebSocket connected for card (Task: ${experiment.id})`);
        setStatusText("BaÄŸlantÄ± kuruldu, veri bekleniyor...");
      };

      ws.current.onmessage = (event) => {
        const data = JSON.parse(event.data);
        setCurrentStatus(data.state);
        
        if (data.state === 'PROGRESS') {
          setCurrentLoss(data.details?.loss);
          if (data.details?.total_epochs) {
            setProgress(((data.details.epoch || 0) / data.details.total_epochs) * 100);
          }
          setStatusText(data.details?.status_text || `Epoch ${data.details?.epoch}/${data.details?.total_epochs}`);
          
          setChartData(prevData => {
            const epoch = data.details.epoch;
            const loss = data.details.loss;

            if (loss !== undefined && epoch !== undefined) {
                // Sadece yeni bir epoch kaydÄ± geldiyse ekle
                if (!prevData.labels.includes(`Epoch ${epoch}`)) {
                    return {
                        labels: [...prevData.labels, `Epoch ${epoch}`],
                        datasets: [{
                            ...prevData.datasets[0], 
                            data: [...(prevData.datasets[0]?.data || []), loss]
                        }]
                    };
                }
            }
            return prevData;
        });

        } else if (data.state === 'SUCCESS' || data.state === 'FAILURE') {
          // GÃ¶rev bittiÄŸinde (SUCCESS, FAILURE vb.) son durumu ve sonucu al
          if (data.result?.final_loss !== undefined) {
             setCurrentLoss(data.result.final_loss);
          } else if (data.result?.loss && Array.isArray(data.result.loss)) { // EÄŸitim geÃ§miÅŸindeki son kayÄ±p
             setCurrentLoss(data.result.loss[data.result.loss.length - 1]);
             setChartData(prevData => { // TÃ¼m geÃ§miÅŸi grafik iÃ§in yÃ¼kle
                const losses = data.result.loss;
                const labels = Array.from({ length: losses.length }, (_, i) => `Epoch ${i + 1}`);
                return {
                    labels: labels,
                    datasets: [{
                        ...prevData.datasets[0], 
                        data: losses
                    }]
                };
             });
          }
          
          if (data.state === 'SUCCESS') setProgress(100);
          else setProgress(0); // BaÅŸarÄ±sÄ±z ise ilerleme 0
          setStatusText(data.result?.error_message || data.state); // Hata mesajÄ± varsa onu gÃ¶ster
          
          // GÃ¶rev bittiÄŸinde WebSocket baÄŸlantÄ±sÄ±nÄ± kapat
          if (ws.current) {
            ws.current.close();
          }
        }
      };

      ws.current.onerror = (error) => {
        console.error(`WebSocket Error for card (Task: ${experiment.id}):`, error);
        setCurrentStatus("ERROR");
        setStatusText("WebSocket baÄŸlantÄ± hatasÄ±!");
        if (ws.current) ws.current.close(); // Hata durumunda da kapat
      };

      ws.current.onclose = () => {
        console.log(`WebSocket disconnected for card (Task: ${experiment.id})`);
        setCurrentStatus(prevStatus => {
          // EÄŸer baÅŸarÄ± veya hata ile kapanmadÄ±ysa DISCONNECTED yap
          if (prevStatus === 'SUCCESS' || prevStatus === 'FAILURE' || prevStatus === 'ERROR') {
            return prevStatus;
          }
          return 'DISCONNECTED';
        });
        setStatusText(prevStatusText => {
            if (prevStatusText.startsWith("WebSocket")) return prevStatusText;
            return `BaÄŸlantÄ± kesildi. Son durum: ${currentStatus}`;
        });
      };
    } else {
        // EÄŸer deney baÅŸlangÄ±Ã§ta tamamlanmÄ±ÅŸ veya baÅŸarÄ±sÄ±z durumdaysa, WebSocket kurmaya gerek yok
        // Ve tamamlannÄ±ÅŸ veriyi yÃ¼kle
        setCurrentStatus(experiment.status);
        setCurrentLoss(experiment.final_loss);
        setProgress(experiment.status === 'SUCCESS' ? 100 : 0);
        setStatusText(experiment.status);
        if (experiment.results?.loss && Array.isArray(experiment.results.loss)) {
            const losses = experiment.results.loss;
            const labels = Array.from({ length: losses.length }, (_, i) => `Epoch ${i + 1}`);
            setChartData({
                labels: labels,
                datasets: [{
                    label: 'EÄŸitim KaybÄ±',
                    data: losses,
                    borderColor: 'rgb(75, 192, 192)',
                    backgroundColor: 'rgba(75, 192, 192, 0.5)',
                    tension: 0.1,
                    fill: false
                }]
            });
        }
    }

    // BileÅŸen DOM'dan kaldÄ±rÄ±ldÄ±ÄŸÄ±nda WebSocket baÄŸlantÄ±sÄ±nÄ± temizle
    return () => {
      if (cleanupNeeded && ws.current) {
        ws.current.close();
        ws.current = null;
      }
    };
  }, [experiment.id, experiment.status, experiment.final_loss, experiment.results]); // Deney verileri deÄŸiÅŸtiÄŸinde yeniden baÄŸlan

  const handleCardClick = () => {
    navigate(`/experiments/${experiment.id}`); // DoÄŸrudan yÃ¶nlendir
    if (onSelect) { // onSelect prop'u varsa (eski kullanÄ±m iÃ§in)
      onSelect(experiment.id);
    }
  };

  return (
    <div className="card experiment-card clickable" onClick={handleCardClick}>
      <h3>
        {experiment.pipeline_name || 'Bilinmeyen Pipeline'} 
        {experiment.ticker && <span className="exp-id"> ({experiment.ticker})</span>}
      </h3>
      <p><strong>ID:</strong> <span className="exp-id">{experiment.id}</span></p>
      <p><strong>Durum:</strong> 
        <span className={`status-badge status-${currentStatus?.toLowerCase()}`}>{currentStatus || 'Bilinmiyor'}</span>
      </p>
      
      {(currentStatus === 'STARTED' || currentStatus === 'PROGRESS' || currentStatus === 'CONNECTED') && (
        <div className="progress-section">
          <p>{statusText}</p>
          <progress value={progress} max="100"></progress>
          <p>Mevcut KayÄ±p: <strong>{currentLoss !== undefined && currentLoss !== null ? currentLoss.toFixed(6) : 'N/A'}</strong></p>
        </div>
      )}
      {(currentStatus === 'SUCCESS' || currentStatus === 'FAILURE' || currentStatus === 'ERROR' || currentStatus === 'DISCONNECTED') && (
        <p>Son KayÄ±p: <strong>{currentLoss !== undefined && currentLoss !== null ? currentLoss.toFixed(6) : 'N/A'}</strong></p>
      )}

      {/* Mini Grafik */}
      {chartData.labels.length > 0 && (
          <div className="mini-chart-container" style={{ height: '150px', width: '100%', marginTop: '15px' }}>
              <Line data={chartData} options={{
                  responsive: true,
                  maintainAspectRatio: false,
                  plugins: { legend: { display: false }, title: { display: false }, tooltip: { enabled: false } },
                  scales: {
                      x: { display: false },
                      y: { display: false, beginAtZero: false }
                  },
                  animation: false, // CanlÄ± grafik iÃ§in animasyonu kapat
                  elements: { point: { radius: 0 } } // NoktalarÄ± gizle
              }} />
          </div>
      )}
    </div>
  );
}

ExperimentCard.propTypes = {
  experiment: PropTypes.object.isRequired,
  onSelect: PropTypes.func, // Optional callback for parent component
};

export default ExperimentCard;
========== FILE: dashboard/src/components/ExperimentDetailPage.jsx ==========
// ========== YENÄ° DOSYA: dashboard/src/components/ExperimentDetailPage.jsx ==========
import { useState, useEffect } from 'react';
import { useParams } from 'react-router-dom';
import { getTaskStatus } from '../services/api';
import { Line } from 'react-chartjs-2';
import PropTypes from 'prop-types';

// Chart.js bileÅŸenlerini kaydet
import {
  Chart as ChartJS, CategoryScale, LinearScale, PointElement, LineElement, Title, Tooltip, Legend
} from 'chart.js';
ChartJS.register(CategoryScale, LinearScale, PointElement, LineElement, Title, Tooltip, Legend);


function ExperimentDetailPage() {
  const { experimentId } = useParams(); // URL'den experimentId'yi alÄ±yoruz
  const [experimentData, setExperimentData] = useState(null);
  const [loading, setLoading] = useState(true);
  const [error, setError] = useState(null);
  const [lossChartData, setLossChartData] = useState({ labels: [], datasets: [] });


  useEffect(() => {
    const fetchExperimentDetails = async () => {
      try {
        setLoading(true);
        const response = await getTaskStatus(experimentId);
        setExperimentData(response.data);
        setError(null);

        // KayÄ±p grafiÄŸi iÃ§in veriyi hazÄ±rla
        // Result objesi iÃ§inde loss array'i varsa grafik oluÅŸtur
        if (response.data.status === 'SUCCESS' && response.data.result?.loss && Array.isArray(response.data.result.loss)) {
            const losses = response.data.result.loss;
            const labels = Array.from({ length: losses.length }, (_, i) => `Epoch ${i + 1}`);
            setLossChartData({
                labels: labels,
                datasets: [{
                    label: 'EÄŸitim KaybÄ± (Loss)',
                    data: losses,
                    borderColor: 'rgb(75, 192, 192)',
                    backgroundColor: 'rgba(75, 192, 192, 0.5)',
                    tension: 0.1,
                    fill: false
                }]
            });
        }

      } catch (err) {
        setError(`Deney detaylarÄ± yÃ¼klenemedi: ${err.message || 'Bilinmeyen Hata'}. API'nizin Ã§alÄ±ÅŸtÄ±ÄŸÄ±ndan emin olun.`);
        console.error("Error fetching experiment details:", err);
      } finally {
        setLoading(false);
      }
    };

    fetchExperimentDetails();
  }, [experimentId]); // experimentId deÄŸiÅŸtiÄŸinde yeniden veri Ã§ek

  if (loading) return <p className="feedback info">Deney detaylarÄ± yÃ¼kleniyor...</p>;
  if (error) return <p className="feedback error">{error}</p>;
  if (!experimentData) return <p className="feedback info">Deney bulunamadÄ± veya henÃ¼z tamamlanmadÄ±.</p>;

  // API'dan gelen 'result' objesi, worker'dan dÃ¶nen nihai veriyi iÃ§erir (SUCCESS/FAILURE)
  // 'config' objesi ise doÄŸrudan celery task'Ä±na gÃ¶nderilen config'tir.
  const { status, config, result } = experimentData;

  // Hata mesajÄ± ayrÄ± bir alan olarak gelebilir veya result iÃ§inde olabilir
  const displayError = status === 'FAILURE' ? (result?.error_message || result || 'Bilinmeyen Hata') : null;
  const displayTraceback = status === 'FAILURE' ? result?.traceback : null;

  return (
    <div className="experiment-detail-page card"> {/* Card stilini uyguladÄ±k */}
      <div className="page-header">
        <h1><span role="img" aria-label="magnifying glass">ðŸ”</span> Deney DetaylarÄ±</h1>
        <p>SeÃ§ilen deneyin tÃ¼m detaylarÄ±nÄ±, konfigÃ¼rasyonunu ve sonuÃ§larÄ±nÄ± inceleyin.</p>
      </div>

      <h3>Genel Bilgiler</h3>
      <p><strong>Deney ID:</strong> <span className="exp-id">{experimentId}</span></p>
      <p><strong>Durum:</strong> <span className={`status-badge status-${status?.toLowerCase()}`}>{status || 'Bilinmiyor'}</span></p>
      <p><strong>Pipeline AdÄ±:</strong> {config?.pipeline_name || 'N/A'}</p>
      <p><strong>Sembol:</strong> {config?.data_sourcing?.ticker || 'N/A'}</p>
      <p><strong>BaÅŸlangÄ±Ã§ ZamanÄ±:</strong> {config?.start_time ? new Date(config.start_time).toLocaleString() : 'N/A'}</p> {/* EÄŸer config iÃ§inde start_time varsa */}
      <p><strong>BitiÅŸ ZamanÄ±:</strong> {experimentData.completed_at ? new Date(experimentData.completed_at).toLocaleString() : 'N/A'}</p>
      

      {displayError && <p className="feedback error">Deney HatasÄ±: {displayError}</p>}

      <h3>KonfigÃ¼rasyon</h3>
      <pre className="code-block">{JSON.stringify(config, null, 2)}</pre>

      {status === 'SUCCESS' && (
        <>
          <h3>SonuÃ§lar</h3>
          <pre className="code-block">{JSON.stringify(result, null, 2)}</pre>

          {lossChartData.labels.length > 0 && (
            <div className="chart-container">
              <h4>EÄŸitim KaybÄ± GeÃ§miÅŸi</h4>
              <Line data={lossChartData} options={{ 
                responsive: true, 
                maintainAspectRatio: false, 
                scales: { y: { beginAtZero: false }}
              }} />
            </div>
          )}
        </>
      )}

      {displayTraceback && (
        <>
          <h3>DetaylÄ± Hata Ä°zleme (Traceback)</h3>
          <pre className="code-block">{displayTraceback}</pre>
        </>
      )}

    </div>
  );
}

// PropTypes ekleyelim
ExperimentDetailPage.propTypes = {
  // experimentId URL parametresinden geldiÄŸi iÃ§in burada propType tanÄ±mlamÄ±yoruz
};

export default ExperimentDetailPage;
========== FILE: dashboard/src/components/ExperimentsList.jsx ==========
// ========== GÃœNCELLENECEK DOSYA: dashboard/src/components/ExperimentsList.jsx (Prop TabanlÄ±) ==========
import { Link } from 'react-router-dom';
import PropTypes from 'prop-types';

function ExperimentsList({ experiments }) { // Sadece experiments prop'unu alÄ±yoruz
  if (!experiments || experiments.length === 0) return <p className="feedback info">HenÃ¼z gÃ¶sterilecek bir deney bulunamadÄ±.</p>;

  return (
    <div className="table-container">
      <table>
        <thead>
          <tr>
            <th>Deney ID</th>
            <th>Durum</th>
            <th>Pipeline</th>
            <th>Sembol</th>
            <th>KayÄ±p</th>
            <th>BitiÅŸ Tarihi</th> {/* Yeni sÃ¼tun */}
          </tr>
        </thead>
        <tbody>
          {experiments.map((exp) => (
            <tr key={exp.id}>
              <td className="exp-id clickable-cell">
                <Link to={`/experiments/${exp.id}`}>
                  {exp.id}
                </Link>
              </td>
              <td><span className={`status-badge status-${exp.status?.toLowerCase() || 'unknown'}`}>{exp.status || 'Bilinmiyor'}</span></td>
              <td>{exp.config?.pipeline_name || exp.pipeline_name || 'N/A'}</td>
              <td>{exp.config?.data_sourcing?.ticker || exp.ticker || 'N/A'}</td>
              <td>{exp.final_loss !== undefined && exp.final_loss !== null ? exp.final_loss.toFixed(6) : 'N/A'}</td>
              <td>{exp.completed_at ? new Date(exp.completed_at).toLocaleString() : 'N/A'}</td> {/* Tarih formatlama */}
            </tr>
          ))}
        </tbody>
      </table>
    </div>
  );
}

// Prop tiplerini belirleyelim
ExperimentsList.propTypes = {
  experiments: PropTypes.array.isRequired,
};

export default ExperimentsList;
========== FILE: dashboard/src/components/ExperimentTracker.jsx ==========
// ========== GÃœNCELLENECEK DOSYA: dashboard/src/components/ExperimentTracker.jsx (URL'den taskId Okuma ve BaÅŸlÄ±k) ==========
import { useState, useEffect, useRef } from 'react';
import { useParams } from 'react-router-dom';
import { Line } from 'react-chartjs-2';
import {
  Chart as ChartJS, CategoryScale, LinearScale, PointElement, LineElement, Title, Tooltip, Legend
} from 'chart.js';

ChartJS.register(CategoryScale, LinearScale, PointElement, LineElement, Title, Tooltip, Legend);

function ExperimentTracker() { 
  const { taskId } = useParams(); // URL'den taskId'yi al
  const [status, setStatus] = useState(null); 
  const [chartData, setChartData] = useState({ 
    labels: [], 
    datasets: [{ 
      label: 'EÄŸitim KaybÄ±', data: [], 
      borderColor: 'rgb(75, 192, 192)', backgroundColor: 'rgba(75, 192, 192, 0.5)',
      tension: 0.1, fill: false
    }] 
  }); 
  const ws = useRef(null); 
  const [currentLoss, setCurrentLoss] = useState('N/A'); // CanlÄ± kayÄ±p iÃ§in state

  useEffect(() => {
    if (!taskId) {
      setStatus({ state: 'NO_TASK', details: { status_text: 'Takip edilecek gÃ¶rev ID\'si bulunamadÄ±.' } });
      return;
    }

    // Ã–nceki baÄŸlantÄ±yÄ± temizle (varsa)
    if (ws.current) { ws.current.close(); }
    
    // GeÃ§miÅŸ verilerini ve durumu sÄ±fÄ±rla
    setChartData({ labels: [], datasets: [{ 
        label: 'EÄŸitim KaybÄ±', data: [], 
        borderColor: 'rgb(75, 192, 192)', backgroundColor: 'rgba(75, 192, 192, 0.5)',
        tension: 0.1, fill: false
    }]});
    setStatus({ state: 'CONNECTING', details: { status_text: 'Worker\'a baÄŸlanÄ±lÄ±yor...' } });
    setCurrentLoss('N/A');


    const wsUrl = `ws://localhost:8000/ws/task_status/${taskId}`;
    ws.current = new WebSocket(wsUrl);

    ws.current.onopen = () => {
        console.log(`WebSocket connected for task ${taskId}`);
        setStatus({ state: 'CONNECTED', details: { status_text: 'BaÄŸlantÄ± kuruldu, veri bekleniyor...' } });
    };

    ws.current.onmessage = (event) => {
      const data = JSON.parse(event.data);
      console.log("Received data from WebSocket:", data);
      setStatus(data); // Genel durumu gÃ¼ncelle
      
      if(data.state === 'PROGRESS' && data.details?.loss !== undefined) {
        setCurrentLoss(data.details.loss.toFixed(6)); // CanlÄ± kayÄ±p
        setChartData(prevData => {
          const epoch = data.details.epoch;
          const loss = data.details.loss;

          // EÄŸer veri gelmiÅŸse ve epoch daha Ã¶nce eklenmemiÅŸse ekle
          if (!prevData.labels.includes(`Epoch ${epoch}`)) {
            return {
              labels: [...prevData.labels, `Epoch ${epoch}`],
              datasets: [{
                ...prevData.datasets[0], 
                data: [...prevData.datasets[0].data, loss]
              }]
            };
          }
          return prevData;
        });
      } else if (data.state === 'SUCCESS' || data.state === 'FAILURE') {
        // GÃ¶rev tamamlandÄ±ÄŸÄ±nda veya baÅŸarÄ±sÄ±z olduÄŸunda son durumu ve sonucu al
        const finalLoss = data.result?.final_loss || (data.result?.loss && Array.isArray(data.result.loss) ? data.result.loss[data.result.loss.length - 1] : undefined);
        if (finalLoss !== undefined) {
          setCurrentLoss(finalLoss.toFixed(6));
        } else if (data.state === 'FAILURE' && data.result?.error_message) {
            setCurrentLoss('Hata!');
        } else {
            setCurrentLoss('N/A');
        }

        // EÄŸer baÅŸarÄ±lÄ± olduysa ve tam loss history varsa grafiÄŸi onunla gÃ¼ncelle
        if (data.state === 'SUCCESS' && data.result?.loss && Array.isArray(data.result.loss)) {
            const losses = data.result.loss;
            const labels = Array.from({ length: losses.length }, (_, i) => `Epoch ${i + 1}`);
            setChartData({
                labels: labels,
                datasets: [{
                    label: 'EÄŸitim KaybÄ±',
                    data: losses,
                    borderColor: 'rgb(75, 192, 192)',
                    backgroundColor: 'rgba(75, 192, 192, 0.5)',
                    tension: 0.1,
                    fill: false
                }]
            });
        }
      }
    };
    
    ws.current.onerror = (error) => {
      console.error("WebSocket Error:", error);
      setStatus({ state: 'ERROR', details: { status_text: 'WebSocket baÄŸlantÄ± hatasÄ± veya sunucuya eriÅŸilemiyor!' } });
      setCurrentLoss('Hata!');
    };

    ws.current.onclose = () => {
      console.log(`WebSocket disconnected for task ${taskId}`);
      setStatus(prevStatus => {
        if (prevStatus?.state === 'SUCCESS' || prevStatus?.state === 'FAILURE' || prevStatus?.state === 'ERROR') {
          return prevStatus;
        }
        return { 
          ...prevStatus, 
          state: 'DISCONNECTED',
          details: { status_text: `BaÄŸlantÄ± kesildi. Son durum: ${prevStatus?.state}` }
        };
      });
    };

    return () => {
      if (ws.current) {
        ws.current.close();
        ws.current = null;
      }
    };
  }, [taskId]); // taskId deÄŸiÅŸtiÄŸinde yeniden baÄŸlan

  const progressPercent = status?.details?.total_epochs 
    ? ((status.details.epoch || 0) / status.details.total_epochs) * 100
    : 0;

  return (
    <div className="tracker-container card"> {/* Card stilini uyguladÄ±k */}
      <div className="page-header">
        <h1><span role="img" aria-label="satellite">ðŸ›°ï¸</span> CanlÄ± Deney Takibi</h1>
        <p>SeÃ§ilen deneyin gerÃ§ek zamanlÄ± ilerlemesini ve metriklerini izleyin.</p>
      </div>

      <h3>GÃ¶rev Bilgileri</h3>
      <p><strong>GÃ¶rev ID:</strong> <span className="exp-id">{taskId}</span></p>
      <p><strong>Durum:</strong> <span className={`status-badge status-${status?.state?.toLowerCase()}`}>{status?.state || 'Bilinmiyor'}</span></p>
      
      {(status?.state === 'STARTED' || status?.state === 'PROGRESS' || status?.state === 'CONNECTED') && (
        <div className="progress-section">
          <p>{status.details?.status_text || 'Ä°lerleme bilgisi bekleniyor...'}</p>
          <progress value={progressPercent} max="100"></progress>
          <p>Mevcut KayÄ±p (Loss): <strong>{currentLoss}</strong></p>
        </div>
      )}

      {status?.state === 'SUCCESS' && <p className="feedback success">EÄŸitim baÅŸarÄ±yla tamamlandÄ±! Final KayÄ±p: {currentLoss}</p>}
      {status?.state === 'FAILURE' && <p className="feedback error">EÄŸitimde bir hata oluÅŸtu! Detaylar iÃ§in aÅŸaÄŸÄ±daki bÃ¶lÃ¼me bakÄ±n veya deney detay sayfasÄ±na gidin.</p>}
      {status?.state === 'ERROR' && <p className="feedback error">{status.details.status_text}</p>}
      {status?.state === 'NO_TASK' && <p className="feedback info">{status.details.status_text}</p>}
      {status?.state === 'DISCONNECTED' && <p className="feedback info">CanlÄ± takip baÄŸlantÄ±sÄ± kesildi. GÃ¶rev tamamlanmÄ±ÅŸ veya bir hata oluÅŸmuÅŸ olabilir. Deney listesinden kontrol edin. Son KayÄ±p: {currentLoss}</p>}

      {chartData.labels.length > 0 && (
        <div className="chart-container">
          <h4>CanlÄ± KayÄ±p GrafiÄŸi</h4>
          <Line data={chartData} options={{ 
            animation: false, 
            responsive: true, 
            maintainAspectRatio: false, 
            scales: { y: { beginAtZero: false }}
          }} />
        </div>
      )}
      {chartData.labels.length === 0 && (status?.state === 'PROGRESS' || status?.state === 'CONNECTING' || status?.state === 'CONNECTED' || status?.state === 'STARTED') && <p className="feedback info">Grafik verisi bekleniyor (ilk epoch tamamlandÄ±ÄŸÄ±nda veya sonuÃ§ raporu hazÄ±rlandÄ±ÄŸÄ±nda gÃ¶rÃ¼necektir)...</p>}
      
      {/* Hata durumunda detaylar */}
      {status?.state === 'FAILURE' && status.details?.traceback && (
        <>
          <h3>DetaylÄ± Hata MesajÄ±</h3>
          <pre className="code-block">{status.details.traceback}</pre>
        </>
      )}
    </div>
  );
}

export default ExperimentTracker;
========== FILE: dashboard/src/components/NewExperiment.jsx ==========
// ========== GÃœNCELLENECEK DOSYA: dashboard/src/components/NewExperiment.jsx (PropTypes Eklendi) ==========
import { useState, useEffect } from 'react';
import { startNewExperiment, fetchAvailablePipelines } from '../services/api';
import PropTypes from 'prop-types'; // PropTypes import edildi

// KullanÄ±cÄ±ya daha iyi geri bildirim vermek iÃ§in bir bileÅŸen
const Feedback = ({ message, type }) => {
  if (!message) return null;
  return <p className={`feedback ${type}`}>{message}</p>;
};

Feedback.propTypes = {
  message: PropTypes.string,
  type: PropTypes.string.isRequired,
};


function NewExperiment({ onExperimentStarted }) {
  // State tanÄ±mlamalarÄ±
  const [pipelines, setPipelines] = useState([]); // API'dan gelen tÃ¼m pipeline'lar
  const [selectedPipelineId, setSelectedPipelineId] = useState(''); // SeÃ§ili pipeline'Ä±n ID'si
  const [selectedPipelineDetails, setSelectedPipelineDetails] = useState(null); // SeÃ§ili pipeline'Ä±n tam detaylarÄ±
  const [isLoading, setIsLoading] = useState(true); // YÃ¼klenme durumu
  const [feedback, setFeedback] = useState(null); // KullanÄ±cÄ± geri bildirimi

  // --- Pipeline listesini API'dan Ã§ek ---
  // BileÅŸen ilk yÃ¼klendiÄŸinde, mevcut tÃ¼m pipeline'larÄ± ve konfigÃ¼rasyonlarÄ±nÄ± API'dan Ã§ek
  useEffect(() => {
    const loadPipelines = async () => {
      try {
        const response = await fetchAvailablePipelines();
        setPipelines(response.data);
        // EÄŸer pipeline varsa, ilkini varsayÄ±lan olarak seÃ§
        if (response.data.length > 0) {
          const firstPipeline = response.data[0];
          setSelectedPipelineId(firstPipeline.id);
          setSelectedPipelineDetails(firstPipeline);
        }
      } catch (error) {
        setFeedback({ type: 'error', message: 'Pipeline listesi yÃ¼klenemedi. API\'nizin /api/v1/pipelines endpoint\'ini kontrol edin.' });
        console.error("Error fetching pipelines:", error);
      } finally {
        setIsLoading(false);
      }
    };
    loadPipelines();
  }, []); // BoÅŸ dizi, bu etkinin sadece bir kez Ã§alÄ±ÅŸmasÄ±nÄ± saÄŸlar

  // --- Form GÃ¶nderimi ---
  const handleSubmit = async (e) => {
    e.preventDefault();
    if (!selectedPipelineId) {
      setFeedback({ type: 'error', message: 'LÃ¼tfen bir pipeline seÃ§in.' });
      return;
    }

    setIsLoading(true);
    setFeedback(null);
    
    // Sadece pipeline_name'i gÃ¶nderiyoruz. DiÄŸer konfigÃ¼rasyonlar Worker'daki varsayÄ±lanlardan alÄ±nacak.
    const configToSend = {
      pipeline_name: selectedPipelineId,
      // Dashboard'dan ek parametre gÃ¶ndermek istersek buraya ekleyeceÄŸiz:
      // data_sourcing: { ticker: "MSFT" },
      // training_params: { epochs: 10 }
    };
    
    try {
      const response = await startNewExperiment(configToSend);
      const taskId = response.data.task_id;
      setFeedback({ type: 'success', message: `GÃ¶rev baÅŸarÄ±yla gÃ¶nderildi! ID: ${taskId}` });
      
      // GÃ¶rev baÅŸladÄ±ktan sonra canlÄ± takip ekranÄ±na geÃ§
      if (onExperimentStarted && taskId) {
        onExperimentStarted(taskId);
      }
      
    } catch (err) {
      setFeedback({ type: 'error', message: 'Deney baÅŸlatÄ±lamadÄ±. API ve Worker loglarÄ±nÄ± kontrol edin.' });
      console.error("Error starting experiment:", err);
    } finally {
      setIsLoading(false);
    }
  };

  // --- Render (GÃ¶rÃ¼nÃ¼m) ---
  if (isLoading) return <p className="feedback info">Pipeline'lar yÃ¼kleniyor...</p>;
  if (pipelines.length === 0) return <p className="feedback error">Platforma kurulu ve keÅŸfedilmiÅŸ pipeline eklentisi bulunamadÄ±.</p>;

  return (
    <form onSubmit={handleSubmit} className="form-container card"> {/* Card stilini uyguladÄ±k */}
      <div className="page-header">
        <h1><span role="img" aria-label="rocket">ðŸš€</span> Yeni Deney BaÅŸlat</h1>
        <p>Platformda kurulu mevcut yapay zeka pipeline'larÄ±ndan birini seÃ§erek yeni bir deney baÅŸlatÄ±n.</p>
      </div>

      <div className="form-group">
        <label htmlFor="pipeline-select">Ã‡alÄ±ÅŸtÄ±rÄ±lacak Pipeline Eklentisi</label>
        <select id="pipeline-select" value={selectedPipelineId} onChange={(e) => {
          const newId = e.target.value;
          setSelectedPipelineId(newId);
          setSelectedPipelineDetails(pipelines.find(p => p.id === newId));
        }}>
          {pipelines.map(p => (
            <option key={p.id} value={p.id}>{p.name} ({p.id})</option>
          ))}
        </select>
      </div>
      
      {selectedPipelineDetails && (
        <div className="pipeline-details card">
          <h3>{selectedPipelineDetails.name} DetaylarÄ±</h3>
          <p><strong>AÃ§Ä±klama:</strong> <i>{selectedPipelineDetails.description || 'AÃ§Ä±klama bulunmuyor.'}</i></p>
          <p><strong>Repository:</strong> <a href={selectedPipelineDetails.repository} target="_blank" rel="noopener noreferrer">{selectedPipelineDetails.repository}</a></p>
          {/* Gelecekte varsayÄ±lan konfigÃ¼rasyon JSON'unu gÃ¶stermek/dÃ¼zenlemek iÃ§in buraya daha fazla UI eklenebilir */}
        </div>
      )}

      <p className="feedback info">Åžimdilik, eÄŸitim varsayÄ±lan parametrelerle baÅŸlatÄ±lacaktÄ±r. Gelecekte bu parametreleri buradan dÃ¼zenleyebileceksiniz.</p>

      <button type="submit" disabled={isLoading} className="button-primary">
        {isLoading ? 'BaÅŸlatÄ±lÄ±yor...' : `"${selectedPipelineDetails?.name || 'SeÃ§ilen'}" EÄŸitimini BaÅŸlat`}
      </button>
      
      <Feedback message={feedback?.message} type={feedback?.type} />
    </form>
  );
}

NewExperiment.propTypes = {
  onExperimentStarted: PropTypes.func.isRequired,
};

export default NewExperiment;
========== FILE: dashboard/src/pages/DashboardOverview.jsx ==========
// ========== YENÄ° DOSYA: dashboard/src/pages/DashboardOverview.jsx ==========
import { useState, useEffect } from 'react';
import { fetchExperiments } from '../services/api';
import ExperimentCard from '../components/ExperimentCard';
import ExperimentsList from '../components/ExperimentsList'; // Tamamlanan/baÅŸarÄ±sÄ±z deneyler iÃ§in
import PropTypes from 'prop-types'; // PropTypes import edildi

function DashboardOverview({ onExperimentSelect, onNewExperimentClick }) {
  const [experiments, setExperiments] = useState([]);
  const [loading, setLoading] = useState(true);
  const [error, setError] = useState(null);

  useEffect(() => {
    const getExperiments = async () => {
      try {
        const response = await fetchExperiments();
        // API'den gelen veriye gÃ¶re sÄ±ralama: Ã–nce Ã§alÄ±ÅŸanlar, sonra en yeni tamamlananlar
        const sortedExperiments = response.data.sort((a, b) => {
          const statusOrder = { 'STARTED': 1, 'PROGRESS': 2, 'FAILURE': 3, 'SUCCESS': 4, 'UNKNOWN': 5, 'DISCONNECTED': 6 }; // DISCONNECTED'Ä± da ekleyelim
          const aStatus = statusOrder[a.status] || 7; // VarsayÄ±lan deÄŸer unknown/diÄŸer durumlar iÃ§in
          const bStatus = statusOrder[b.status] || 7;

          if (aStatus !== bStatus) {
            return aStatus - bStatus; // Duruma gÃ¶re sÄ±rala (STARTED en Ã¼stte)
          }

          // AynÄ± durumdaki deneyleri en yeni bitiÅŸ tarihine gÃ¶re sÄ±rala (varsa)
          // `completed_at` yoksa `started_at` veya `id` (timestamp iÃ§erdiÄŸi iÃ§in) kullanabiliriz
          const aDate = a.completed_at ? new Date(a.completed_at) : (a.started_at ? new Date(a.started_at) : new Date(0));
          const bDate = b.completed_at ? new Date(b.completed_at) : (b.started_at ? new Date(b.started_at) : new Date(0));
          return bDate.getTime() - aDate.getTime(); // En yeni tamamlanan Ã¼stte
        });

        setExperiments(sortedExperiments);
        setError(null);
      } catch (err) {
        setError('API sunucusuna baÄŸlanÄ±lamadÄ± veya veri Ã§ekilemedi. Servislerin Ã§alÄ±ÅŸtÄ±ÄŸÄ±ndan emin olun.');
        console.error("Error fetching experiments for overview:", err);
      } finally {
        setLoading(false);
      }
    };
    
    getExperiments();
    const intervalId = setInterval(getExperiments, 5000); // Deneyleri dÃ¼zenli olarak yenile (5 saniyede bir)
    
    return () => clearInterval(intervalId); // BileÅŸen kaldÄ±rÄ±ldÄ±ÄŸÄ±nda interval'i temizle
  }, []);

  const runningExperiments = experiments.filter(exp => 
    exp.status === 'STARTED' || exp.status === 'PROGRESS'
  );
  const completedOrFailedExperiments = experiments.filter(exp => 
    exp.status === 'SUCCESS' || exp.status === 'FAILURE' || exp.status === 'ERROR' || exp.status === 'DISCONNECTED' || exp.status === 'UNKNOWN'
  );

  return (
    <div className="dashboard-overview">
      <div className="page-header">
        <h1><span role="img" aria-label="dashboard">ðŸ“Š</span> Genel BakÄ±ÅŸ</h1>
        <p>TÃ¼m deneylerinizin durumunu ve son geliÅŸmelerini takip edin.</p>
      </div>

      {loading && <p className="feedback info">Veriler yÃ¼kleniyor...</p>}
      {error && <p className="feedback error">{error}</p>}

      {!loading && !error && (
        <>
          <h2 className="section-title">Ã‡alÄ±ÅŸan Deneyler ({runningExperiments.length})</h2>
          {runningExperiments.length === 0 ? (
            <p className="feedback info">Åžu anda Ã§alÄ±ÅŸan bir deney bulunmamaktadÄ±r. <button onClick={onNewExperimentClick} className="button-link">Yeni bir deney baÅŸlatmak</button> ister misiniz?</p>
          ) : (
            <div className="running-experiments-grid">
              {runningExperiments.map(exp => (
                <ExperimentCard key={exp.id} experiment={exp} onSelect={onExperimentSelect} />
              ))}
            </div>
          )}

          <h2 className="section-title">Son Tamamlanan/BaÅŸarÄ±sÄ±z Olan Deneyler ({completedOrFailedExperiments.length})</h2>
          {completedOrFailedExperiments.length === 0 ? (
            <p className="feedback info">HenÃ¼z tamamlanan veya baÅŸarÄ±sÄ±z olan bir deney bulunmamaktadÄ±r.</p>
          ) : (
            <ExperimentsList experiments={completedOrFailedExperiments} onExperimentSelect={onExperimentSelect} />
          )}
        </>
      )}
    </div>
  );
}

// PropTypes ekleyelim
DashboardOverview.propTypes = {
  onExperimentSelect: PropTypes.func.isRequired,
  onNewExperimentClick: PropTypes.func.isRequired,
};

export default DashboardOverview;
========== FILE: dashboard/src/services/api.js ==========
// ========== DOSYA: dashboard/src/services/api.js (DEÄžÄ°ÅžÄ°KLÄ°K YOK) ==========
import axios from 'axios';

const API_BASE_URL = 'http://localhost:8000/api/v1';

const apiClient = axios.create({
  baseURL: API_BASE_URL,
  headers: {
    'Content-Type': 'application/json',
  },
});

/**
 * TÃ¼m tamamlanmÄ±ÅŸ/Ã§alÄ±ÅŸan deney gÃ¶revlerini API'dan Ã§eker.
 * Åžu anda sahte veri dÃ¶ndÃ¼rÃ¼yor. GerÃ§ek veritabanÄ± eklendiÄŸinde gÃ¼ncellenecek.
 */
export const fetchExperiments = () => {
  return apiClient.get('/experiments');
};

/**
 * Yeni bir deneyi baÅŸlatmak iÃ§in API'a istek gÃ¶nderir.
 * @param {object} config - Deney konfigÃ¼rasyonu (pipeline_name, data_sourcing, training_params vb.)
 */
export const startNewExperiment = (config) => {
  return apiClient.post('/experiments', config);
};

/**
 * Platformda kurulu ve keÅŸfedilmiÅŸ tÃ¼m pipeline'larÄ± ve varsayÄ±lan 
 * konfigÃ¼rasyonlarÄ±nÄ± API'dan Ã§eker.
 */
export const fetchAvailablePipelines = () => {
  return apiClient.get('/pipelines'); 
};

/**
 * Belirli bir gÃ¶revin (task) anlÄ±k durumunu sorgular.
 * @param {string} taskId - Celery gÃ¶rev ID'si
 */
export const getTaskStatus = (taskId) => {
  return apiClient.get(`/experiments/${taskId}/status`);
};
========== FILE: docs/CONTRIBUTING.md ==========
# ðŸ¤ AzuraForge Platforma KatkÄ±da Bulunma Rehberi

AzuraForge projesine gÃ¶sterdiÄŸiniz ilgi ve katkÄ±larÄ±nÄ±z iÃ§in teÅŸekkÃ¼r ederiz! Bu rehber, kod tabanÄ±nÄ±n tutarlÄ±, okunabilir, sÃ¼rdÃ¼rÃ¼lebilir ve yÃ¼ksek kalitede kalmasÄ±nÄ± saÄŸlamak iÃ§in benimsediÄŸimiz Ã§alÄ±ÅŸma prensiplerini ve standartlarÄ±nÄ± aÃ§Ä±klamaktadÄ±r.

## ðŸš€ HÄ±zlÄ± BaÅŸlangÄ±Ã§

EÄŸer henÃ¼z geliÅŸtirme ortamÄ±nÄ±zÄ± kurmadÄ±ysanÄ±z, lÃ¼tfen platform repo'sunun ana `README.md` dosyasÄ±ndaki "GeliÅŸtirme OrtamÄ± Kurulumu" bÃ¶lÃ¼mÃ¼nÃ¼ takip edin.

## ðŸ› ï¸ Kodlama StandartlarÄ±

Projeye eklenen her kodun aÅŸaÄŸÄ±daki standartlarÄ± karÅŸÄ±lamasÄ± beklenmektedir:

1.  **Stil KÄ±lavuzu (PEP8 & Black):**
    *   TÃ¼m Python kodlarÄ±, PEP8 stil kurallarÄ±na uymalÄ±dÄ±r.
    *   Kodunuzu `black` ile otomatik formatlayÄ±n.
    *   **Kontrol:** DeÄŸiÅŸikliklerinizi gÃ¶ndermeden Ã¶nce `black <dosya_adÄ±>` veya `black .` komutunu Ã§alÄ±ÅŸtÄ±rÄ±n.
    *   **Otomasyon:** `pre-commit` hook'larÄ± otomatik formatlamayÄ± zorunlu kÄ±lar.

2.  **Linting (`flake8`):**
    *   TÃ¼m Python kodlarÄ±, `flake8` denetiminden hatasÄ±z geÃ§melidir.
    *   **Kontrol:** `flake8 <dosya_adÄ±>` veya `flake8 src` komutunu Ã§alÄ±ÅŸtÄ±rÄ±n.
    *   **Otomasyon:** `pre-commit` hook'larÄ± linting'i zorunlu kÄ±lar.

3.  **Tip Ä°puÃ§larÄ± (Type Hinting & Mypy):**
    *   TÃ¼m fonksiyon ve metod imzalarÄ±, parametreler ve dÃ¶nÃ¼ÅŸ deÄŸerleri iÃ§in tip ipuÃ§larÄ± (`typing` modÃ¼lÃ¼ kullanÄ±larak) iÃ§ermelidir.
    *   **Kontrol:** `mypy src` komutunu Ã§alÄ±ÅŸtÄ±rÄ±n.
    *   **Otomasyon:** `pre-commit` hook'larÄ± statik tip denetimini zorunlu kÄ±lar.

4.  **DokÃ¼mantasyon (Docstrings):**
    *   TÃ¼m modÃ¼ller, sÄ±nÄ±flar, fonksiyonlar ve metodlar, ne iÅŸe yaradÄ±klarÄ±nÄ±, aldÄ±klarÄ± argÃ¼manlarÄ± (`Args:`) ve ne dÃ¶ndÃ¼rdÃ¼klerini (`Returns:`) aÃ§Ä±klayan Google-style docstring'ler iÃ§ermelidir.
    *   ArayÃ¼z (API) repolarÄ± iÃ§in `FastAPI`'nin otomatik dokÃ¼mantasyonunu besleyecek docstring'ler kullanÄ±lmalÄ±dÄ±r.

5.  **Testler (`pytest`):**
    *   Eklenen her yeni Ã¶zellik veya fonksiyon iÃ§in ilgili birim testleri (`unit tests`) `tests/` klasÃ¶rÃ¼ne eklenmelidir.
    *   YapÄ±lan bir hata dÃ¼zeltmesi (bug fix) iÃ§in, o hatanÄ±n tekrar oluÅŸmasÄ±nÄ± engelleyecek bir regresyon testi yazÄ±lmalÄ±dÄ±r.
    *   **Kontrol:** Ä°lgili reponun kÃ¶k dizinindeyken `pytest` komutunu Ã§alÄ±ÅŸtÄ±rÄ±n.

## ðŸ“ Commit MesajlarÄ±

Commit mesajlarÄ±, yapÄ±lan deÄŸiÅŸikliÄŸi net bir ÅŸekilde aÃ§Ä±klamalÄ±dÄ±r ve [Conventional Commits](https://www.conventionalcommits.org/en/v1.0.0/) standardÄ±na uymalÄ±dÄ±r. Bu, otomatik versiyonlama ve deÄŸiÅŸiklik gÃ¼nlÃ¼ÄŸÃ¼ oluÅŸturmak iÃ§in hayati Ã¶nem taÅŸÄ±r.

**Format:**
```
<tip>(<kapsam>): <aÃ§Ä±klama>

[opsiyonel gÃ¶vde]
```

**Ã–rnek Tipler:**
*   `feat`: Yeni bir Ã¶zellik ekler (Minor versiyon artÄ±rÄ±mÄ±).
*   `fix`: Bir hata dÃ¼zeltmesi (Patch versiyon artÄ±rÄ±mÄ±).
*   `docs`: Sadece dokÃ¼mantasyon deÄŸiÅŸiklikleri (Versiyon artÄ±rÄ±mÄ± yok).
*   `style`: Kod formatÄ±, eksik noktalÄ± virgÃ¼l gibi stil dÃ¼zeltmeleri (Kod mantÄ±ÄŸÄ± deÄŸiÅŸmez, versiyon artÄ±rÄ±mÄ± yok).
*   `refactor`: Kodu yeniden yapÄ±landÄ±rma, davranÄ±ÅŸ deÄŸiÅŸikliÄŸi yok (Versiyon artÄ±rÄ±mÄ± yok).
*   `perf`: Performans iyileÅŸtirmesi yapan kod deÄŸiÅŸikliÄŸi (Versiyon artÄ±rÄ±mÄ± olabilir).
*   `test`: Eksik testlerin eklenmesi veya mevcut testlerin dÃ¼zeltilmesi (Versiyon artÄ±rÄ±mÄ± yok).
*   `build`: Build sistemi veya dÄ±ÅŸ baÄŸÄ±mlÄ±lÄ±k deÄŸiÅŸiklikleri (Versiyon artÄ±rÄ±mÄ± olabilir).
*   `ci`: CI/CD yapÄ±landÄ±rma dosyalarÄ± ve script'leri deÄŸiÅŸiklikleri (Versiyon artÄ±rÄ±mÄ± yok).

**Ã–rnekler:**
*   `feat(core): Add exponential function to Tensor`
*   `fix(api): Resolve 307 redirect issues for endpoints`
*   `docs(platform): Add initial development guide`
*   `refactor(learner): Separate Layer and Model definitions`

## ðŸ”„ Pull Request (PR) SÃ¼reci

1.  **Branch OluÅŸturma:** `main` branch'inden kendi feature branch'inizi (`feat/yeni-ozellik` veya `fix/hata-adi` gibi) oluÅŸturun.
2.  **DeÄŸiÅŸikliklerinizi YapÄ±n:** YukarÄ±daki standartlara uyduÄŸunuzdan emin olun.
3.  **Test Edin:** Yerel testlerinizi (`pytest`) Ã§alÄ±ÅŸtÄ±rÄ±n ve geÃ§tiÄŸinden emin olun.
4.  **Commit ve Push:** DeÄŸiÅŸikliklerinizi anlamlÄ± commit mesajlarÄ±yla branch'inize `push` edin.
5.  **Pull Request AÃ§Ä±n:** GitHub Ã¼zerinden `main` branch'ine bir "Pull Request" (PR) aÃ§Ä±n.
6.  **CI Kontrolleri:** PR'Ä±nÄ±zÄ±n CI kontrollerinden (testler, linting) baÅŸarÄ±yla geÃ§tiÄŸinden emin olun.
7.  **Kod Ä°ncelemesi:** Kodunuz incelenecek ve gerekli geri bildirimler saÄŸlanacaktÄ±r.

Bu standartlara uyarak, AzuraForge platformunun uzun vadede saÄŸlÄ±klÄ±, sÃ¼rdÃ¼rÃ¼lebilir ve yÃ¼ksek kalitede kalmasÄ±na yardÄ±mcÄ± olursunuz.

========== FILE: docs/DEVELOPMENT_GUIDE.md ==========
# ðŸ› ï¸ AzuraForge Platform GeliÅŸtirme Rehberi

Bu belge, AzuraForge platformunda geliÅŸtirme yapmak isteyenler iÃ§in adÄ±m adÄ±m kurulum, Ã§alÄ±ÅŸma prensipleri ve katkÄ±da bulunma yÃ¶nergelerini iÃ§erir.

## ðŸŽ¯ Temel Felsefemiz

Her repomuz, kendi baÅŸÄ±na yaÅŸayan, kurulabilir ve test edilebilir baÄŸÄ±msÄ±z bir Python/JavaScript paketidir. Repolar arasÄ± baÄŸÄ±mlÄ±lÄ±klar, Git adresleri (`@git+https://...`) Ã¼zerinden kurulur.

## ðŸ“¦ Proje RepolarÄ±na Genel BakÄ±ÅŸ

AzuraForge platformu, aÅŸaÄŸÄ±daki baÄŸÄ±msÄ±z GitHub depolarÄ±ndan oluÅŸur. GeliÅŸtirme yaparken bu repolarÄ±n bir kÄ±smÄ±nÄ± veya tamamÄ±nÄ± yerel makinenizde klonlamanÄ±z gerekecektir.

*   **`core`** ([link](https://github.com/AzuraForge/core)): Temel otomatik tÃ¼rev motoru.
*   **`learner`** ([link](https://github.com/AzuraForge/learner)): `core` Ã¼zerinde yÃ¼ksek seviyeli Ã¶ÄŸrenme kÃ¼tÃ¼phanesi.
*   **`app-stock-predictor`** ([link](https://github.com/AzuraForge/app-stock-predictor)): Bir uygulama eklentisi Ã¶rneÄŸi.
*   **`applications`** ([link](https://github.com/AzuraForge/applications)): Resmi uygulama katalogu (sadece JSON veri iÃ§erir).
*   **`api`** ([link](https://github.com/AzuraForge/api)): RESTful API ve WebSocket sunucusu.
*   **`worker`** ([link](https://github.com/AzuraForge/worker)): Arka plan gÃ¶revlerini (eÄŸitimleri) iÅŸleyen Celery worker.
*   **`dashboard`** ([link](https://github.com/AzuraForge/dashboard)): React tabanlÄ± web kullanÄ±cÄ± arayÃ¼zÃ¼.

## âš™ï¸ GeliÅŸtirme OrtamÄ± Kurulumu

Bu adÄ±mlar, platformun tÃ¼m parÃ§alarÄ±nÄ± yerel geliÅŸtirme iÃ§in hazÄ±r hale getirir.

1.  **Gerekli AraÃ§lar:**
    *   **Git:** RepolarÄ± klonlamak iÃ§in.
    *   **Python 3.8+:** TÃ¼m Python bileÅŸenleri iÃ§in.
    *   **Node.js & npm:** Frontend bileÅŸeni iÃ§in.
    *   **Docker Desktop:** Redis ve Dockerize edilmiÅŸ ortamda test iÃ§in (alternatifler belirtilecektir).

2.  **RepolarÄ± Klonlama:**
    Platformda geliÅŸtirmek iÃ§in tÃ¼m ilgili repolarÄ± aynÄ± seviyede bir klasÃ¶re klonlamanÄ±z Ã¶nerilir:
    ```bash
    mkdir azuraforge-dev
    cd azuraforge-dev

    git clone https://github.com/AzuraForge/core.git
    git clone https://github.com/AzuraForge/learner.git
    git clone https://github.com/AzuraForge/app-stock-predictor.git
    git clone https://github.com/AzuraForge/applications.git
    git clone https://github.com/AzuraForge/api.git
    git clone https://github.com/AzuraForge/worker.git
    git clone https://github.com/AzuraForge/dashboard.git
    git clone https://github.com/AzuraForge/platform.git # Orkestrasyon iÃ§in
    ```

3.  **Sanal Ortam Kurulumu (Python):**
    Her Python projesinin kendi sanal ortamÄ± olabilir veya merkezi bir tane kullanabiliriz. Yerel geliÅŸtirme iÃ§in, **`api` projesinin** kÃ¶k dizininde tek bir sanal ortam oluÅŸturmak ve tÃ¼m Python baÄŸÄ±mlÄ±lÄ±klarÄ±nÄ± oraya kurmak en pratik yoldur.

    ```bash
    cd api # `api` reposunun iÃ§ine gir
    python -m venv .venv
    .\.venv\Scripts\activate # Windows iÃ§in
    # source ./.venv/bin/activate # Linux/macOS iÃ§in
    ```

4.  **Python BaÄŸÄ±mlÄ±lÄ±klarÄ±nÄ± Kurma (TÃ¼m Python RepolarÄ± iÃ§in):**
    Sanal ortam aktifken, tÃ¼m Python repolarÄ±nÄ± "dÃ¼zenlenebilir" (editable) modda kurmalÄ±yÄ±z. Bu, kodda yaptÄ±ÄŸÄ±nÄ±z deÄŸiÅŸikliklerin anÄ±nda yansÄ±masÄ±nÄ± saÄŸlar. **`api` projesinin** kÃ¶k dizininde olduÄŸunuzdan emin olun.

    ```bash
    # Ã–nce en alt seviyeden baÅŸlayarak kÃ¼tÃ¼phaneleri kurun
    pip install -e ../core 
    pip install -e ../learner
    pip install -e ../app-stock-predictor # Ä°lk uygulama eklentisi
    pip install -e ../applications       # Uygulama katalogu
    
    # Sonra API ve Worker'Ä± kurun
    pip install -e .                     # `api` projesini kurar
    pip install -e ../worker             # `worker` projesini kurar
    ```
    Bu komutlar, her bir reponun `pyproject.toml` dosyasÄ±nÄ± okuyacak ve tÃ¼m baÄŸÄ±mlÄ±lÄ±k zincirini doÄŸru bir ÅŸekilde Ã§Ã¶zecektir.

5.  **JavaScript BaÄŸÄ±mlÄ±lÄ±klarÄ±nÄ± Kurma (Dashboard iÃ§in):**
    ```bash
    cd ../dashboard # `dashboard` reposunun iÃ§ine gir
    npm install
    ```

6.  **Redis Kurulumu:**
    Platform, bir Redis sunucusuna ihtiyaÃ§ duyar. En kolay yol Docker kullanmaktÄ±r:
    ```bash
    docker run -d -p 6379:6379 --name azuraforge_redis redis
    ```

## â–¶ï¸ Servisleri Ã‡alÄ±ÅŸtÄ±rma (Yerel GeliÅŸtirme)

Sanal ortamÄ±nÄ±z aktifken ve Redis Ã§alÄ±ÅŸÄ±rken, her servisi ayrÄ± bir terminalde baÅŸlatÄ±n.

1.  **API Sunucusu (`api` reposundan):**
    ```bash
    cd api
    .\.venv\Scripts\activate # Sanal ortam aktif deÄŸilse
    start-api
    ```
    (TarayÄ±cÄ±da `http://localhost:8000/api/v1/docs` adresini kontrol edin.)

2.  **Worker Servisi (`worker` reposundan):**
    ```bash
    cd worker
    .\.venv\Scripts\activate
    start-worker
    ```
    (Worker terminalinde "Discovered pipeline..." loglarÄ±nÄ± kontrol edin.)

3.  **Dashboard (`dashboard` reposundan):**
    ```bash
    cd dashboard
    npm run dev
    ```
    (TarayÄ±cÄ±da `http://localhost:5173` adresini aÃ§Ä±n.)

## ðŸ§ª Test Etme ve Hata AyÄ±klama

*   **UÃ§tan Uca AkÄ±ÅŸ:** Dashboard'dan yeni bir deney baÅŸlatarak tÃ¼m sistemin (`Dashboard -> API -> Worker -> Uygulama Eklentisi -> KÃ¼tÃ¼phane`) sorunsuz Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± doÄŸrulayÄ±n. CanlÄ± takip ekranÄ±nÄ± ve kayÄ±p grafiÄŸini izleyin.
*   **API Testleri:** `http://localhost:8000/api/v1/docs` adresinden API endpoint'lerini test edin.
*   **Birim Testleri:** Her bir repoda (Ã¶rn: `core`, `learner`, `app-stock-predictor`) kendi `pytest` testlerini Ã§alÄ±ÅŸtÄ±rÄ±n.
    ```bash
    cd core # veya learner, app-stock-predictor
    .\.venv\Scripts\activate
    pytest
    ```
    (Bu testleri koÅŸabilmek iÃ§in ilgili repoda `pip install -e ".[dev]"` yapmÄ±ÅŸ olmanÄ±z gerekir.)

## ðŸ”„ Ä°teratif GeliÅŸtirme AkÄ±ÅŸÄ±

Ã‡oÄŸu zaman, kodda kÃ¼Ã§Ã¼k deÄŸiÅŸiklikler yapÄ±p bunlarÄ± hÄ±zla test etmek istersiniz.

1.  **KÃ¼tÃ¼phanede DeÄŸiÅŸiklik (Ã¶rn: `core/src/azuraforge_core/tensor.py`):**
    *   DeÄŸiÅŸikliÄŸi yapÄ±n ve kaydedin.
    *   Bu deÄŸiÅŸikliÄŸin `learner` veya diÄŸer kÃ¼tÃ¼phanelerde anÄ±nda etkili olmasÄ± iÃ§in **ekstra bir `pip install` komutuna GEREK YOKTUR**, Ã§Ã¼nkÃ¼ `pip install -e` ile kurulduklarÄ± iÃ§in doÄŸrudan kaynak dosyayÄ± kullanÄ±rlar.
    *   `core` projesine geri dÃ¶nÃ¼p `pytest` ile kendi testlerini koÅŸun.
    *   DeÄŸiÅŸikliÄŸi `commit`'leyin ve `push`'layÄ±n.

2.  **Uygulama/Servis DeÄŸiÅŸikliÄŸi (Ã¶rn: `app-stock-predictor/src/azuraforge_stockapp/pipeline.py`):**
    *   DeÄŸiÅŸikliÄŸi yapÄ±n ve kaydedin.
    *   `api` veya `worker` servisleri otomatik olarak `reload` (yeniden yÃ¼kleme) yapacaktÄ±r (eÄŸer `uvicorn --reload` ile Ã§alÄ±ÅŸÄ±yorlarsa).
    *   `api` ve `worker`'Ä± yeniden baÅŸlatmak genellikle yeterlidir.
    *   DeÄŸiÅŸikliÄŸi `commit`'leyin ve `push`'layÄ±n.

3.  **Yeni Bir BaÄŸÄ±mlÄ±lÄ±k EklendiÄŸinde (`pyproject.toml` deÄŸiÅŸtiÄŸinde):**
    *   Ä°lgili reponun kÃ¶k dizinine gidin (Ã¶rn: `api`).
    *   Sanal ortamÄ±nÄ±zÄ± aktive edin.
    *   `pip install -e .` komutunu tekrar Ã§alÄ±ÅŸtÄ±rÄ±n. `pip`, sadece eksik olan yeni baÄŸÄ±mlÄ±lÄ±klarÄ± ekleyecektir.

## ðŸ¤ KatkÄ±da Bulunma

Bu proje bir aÃ§Ä±k kaynak projesi olarak geliÅŸtirilmektedir. KatkÄ±da bulunmak iÃ§in lÃ¼tfen `platform/docs/CONTRIBUTING.md` dosyasÄ±nÄ± inceleyin.

========== FILE: docs/PROJECT_JOURNEY.md ==========
# ðŸ—ºï¸ Proje YolculuÄŸu: AzuraForge'un GeliÅŸim Hikayesi ve Gelecek Vizyonu

Bu belge, AzuraForge platformunun baÅŸlangÄ±cÄ±ndan mevcut durumuna kadar olan geliÅŸim sÃ¼recini, karÅŸÄ±laÅŸÄ±lan zorluklarÄ±, bulunan Ã§Ã¶zÃ¼mleri ve projenin **modÃ¼ler, Ã¶lÃ§eklenebilir ve ihtiyaÃ§ odaklÄ± bir yapay zeka geliÅŸtirme platformuna** dÃ¶nÃ¼ÅŸme vizyonunu Ã¶zetlemektedir.

## ðŸŽ¯ Proje Felsefesi ve Ã‡Ä±kÄ±ÅŸ Hikayesi

AzuraForge'un her aÅŸamasÄ±nda, kalitesini ve sÃ¼rdÃ¼rÃ¼lebilirliÄŸini saÄŸlamak iÃ§in ÅŸu temel prensipleri benimsedik:

1.  **SÄ±fÄ±rdan Ä°nÅŸa ve Tam Kontrol:** Temel algoritmalarÄ± ve yapÄ±larÄ± (`Tensor` gibi) mÃ¼mkÃ¼n olduÄŸunca sÄ±fÄ±rdan implemente ederek, sistem Ã¼zerinde tam kontrol saÄŸlamak ve derinlemesine Ã¶ÄŸrenmek.
2.  **ModÃ¼lerlik ve Sorumluluk AyrÄ±mÄ± (Microservices):** Her bileÅŸenin (Ã§ekirdek kÃ¼tÃ¼phane, API, worker, uygulama eklentisi, UI) tek ve net bir gÃ¶revi vardÄ±r ve kendi baÄŸÄ±msÄ±z repo'sunda yaÅŸar.
3.  **Olay GÃ¼dÃ¼mlÃ¼ Mimari:** BileÅŸenler arasÄ± iletiÅŸim, baÄŸÄ±mlÄ±lÄ±klarÄ± azaltmak ve gerÃ§ek zamanlÄ± yetenekler saÄŸlamak iÃ§in olaylar (Celery, Redis Pub/Sub, WebSockets) Ã¼zerinden gerÃ§ekleÅŸir.
4.  **Eklenti TabanlÄ± (Plug-in Architecture):** Yeni Ã¶zellikler ve uygulamalar, mevcut platform koduna dokunmadan birer eklenti olarak kolayca eklenebilir.
5.  **KanÄ±t OdaklÄ± GeliÅŸtirme:** Her bÃ¼yÃ¼k Ã¶zellik veya yetenek, gerÃ§ek dÃ¼nya verisi Ã¼zerinde kabul edilebilir bir performansla kanÄ±tlanmalÄ±dÄ±r.
6.  **Otomatik Kalite KontrolÃ¼:** Kod kalitesi (linting, type checking, unit tests) ve versiyonlama sÃ¼reÃ§leri (CI/CD) otomatikleÅŸtirilmiÅŸtir.

## âœ… Tamamlanan Fazlar ve Elde Edilen BaÅŸarÄ±lar

### Faz 0: Fikir ve Ä°lk Denemeler (Monolitik YaklaÅŸÄ±m)

*   **DÃ¼ÅŸÃ¼nce:** Mevcut ML araÃ§larÄ±nÄ±n karmaÅŸÄ±klÄ±ÄŸÄ±na ve baÄŸÄ±mlÄ±lÄ±klarÄ±na bir tepki olarak, sÄ±fÄ±rdan bir derin Ã¶ÄŸrenme motoru (`mininn`) inÅŸa etme fikri doÄŸdu.
*   **Ä°lk Uygulama:** Hava durumu tahmini ve hisse senedi tahmini gibi basit uygulamalarla `mininn`'in yetenekleri test edildi.
*   **Ã–ÄŸrenilen Ders:** Monolitik bir yaklaÅŸÄ±mla (her ÅŸey tek bir repo'da) hÄ±zlÄ± prototipleme mÃ¼mkÃ¼n olsa da, Ã¶lÃ§eklenebilirlik ve yÃ¶netim zorluklarÄ± ortaya Ã§Ä±ktÄ±.

### Faz 1: Multi-Repo ve Mikroservis Mimarisine GeÃ§iÅŸ

*   **Karar:** Uzun vadeli sÃ¼rdÃ¼rÃ¼lebilirlik, Ã¶lÃ§eklenebilirlik ve profesyonellik iÃ§in, platformu baÄŸÄ±msÄ±z repolara sahip bir mikroservis mimarisine dÃ¶nÃ¼ÅŸtÃ¼rme kararÄ± alÄ±ndÄ±.
*   **Zorluk:** Python'da Ã§oklu repolar arasÄ± baÄŸÄ±mlÄ±lÄ±k yÃ¶netimi ve yol (path) sorunlarÄ±.
*   **Ã‡Ã¶zÃ¼m:** `pip`'in `editable` kurulumu (`-e`) ve `git+https` baÄŸÄ±mlÄ±lÄ±klarÄ±nÄ± kullanarak, her reponun kendi `pyproject.toml` ve `setup.py` dosyalarÄ±yla kurulabilir bir paket olmasÄ± saÄŸlandÄ±. `importlib.resources` ile paket iÃ§i dosya eriÅŸimi Ã§Ã¶zÃ¼ldÃ¼.

### Faz 2: Temel KÃ¼tÃ¼phanelerin Ä°nÅŸasÄ± ve KanÄ±tÄ±

*   **`AzuraForge/core` (Matematik Motoru):** `Tensor` objesi ve otomatik tÃ¼rev yetenekleri sÄ±fÄ±rdan inÅŸa edildi. `pytest` ile birim testleri (dot, sum, add, mul, relu backward pass) baÅŸarÄ±yla yazÄ±ldÄ± ve geÃ§ti. **`to_cpu` ve `_unbroadcast_to` hatalarÄ± bu fazda tespit edilip dÃ¼zeltildi.**
*   **`AzuraForge/learner` (Ã–ÄŸrenme KÃ¼tÃ¼phanesi):** `azuraforge-core`'a baÄŸÄ±mlÄ± olarak `Layer`, `Linear`, `Loss`, `MSELoss`, `Sequential`, `Optimizer`, `SGD` gibi temel Ã¶ÄŸrenme bileÅŸenleri inÅŸa edildi. `pytest` ile basit regresyon testi (`test_learner_fit_simple_regression`) baÅŸarÄ±yla geÃ§ti.

### Faz 3: DaÄŸÄ±tÄ±k Servisler ve Eklenti Mimarisi

*   **`AzuraForge/applications` (Katalog):** Uygulama eklentilerinin JSON kataloÄŸunu barÄ±ndÄ±ran basit bir Python paketi olarak yapÄ±landÄ±rÄ±ldÄ±.
*   **`AzuraForge/app-stock-predictor` (Ä°lk Eklenti):** `azuraforge-learner`'Ä± kullanan ve platforma `entry_points` (`azuraforge.pipelines`) ile kendini tanÄ±tan ilk uygulama eklentisi inÅŸa edildi.
*   **`AzuraForge/worker` (Ä°ÅŸÃ§i Servisi):** `celery[redis]` kullanarak arka plan gÃ¶revlerini iÅŸleyen ve `importlib.metadata` ile sisteme kurulu tÃ¼m `azuraforge.pipelines` eklentilerini **otomatik olarak keÅŸfeden** ve Ã§alÄ±ÅŸtÄ±ran worker servisi kuruldu.
*   **`AzuraForge/api` (API Servisi):** `FastAPI` ile RESTful API endpoint'leri (`/experiments`, `/pipelines`) sunan ve `worker`'a gÃ¶rev gÃ¶nderen iletiÅŸim katmanÄ± inÅŸa edildi. API rotalarÄ±nÄ±n `prefix` yÃ¶netimi ve `307 Redirect` sorunlarÄ± bu fazda Ã§Ã¶zÃ¼ldÃ¼.
*   **BaÅŸarÄ±:** `api` Ã¼zerinden gÃ¶nderilen bir "stock_predictor" gÃ¶revinin, `worker` tarafÄ±ndan alÄ±nÄ±p, `app-stock-predictor` eklentisinin keÅŸfedilip, `learner` kÃ¼tÃ¼phanesi kullanÄ±larak **gerÃ§ek bir model eÄŸitiminin baÅŸarÄ±yla tamamlandÄ±ÄŸÄ±** kanÄ±tlandÄ±.

### Faz 4: KullanÄ±cÄ± ArayÃ¼zÃ¼ ve CanlÄ± Takip

*   **`AzuraForge/dashboard` (Web UI):** React tabanlÄ±, `api` servisinden deney ve pipeline listelerini Ã§eken, yeni deneyler baÅŸlatmayÄ± saÄŸlayan temel bir web arayÃ¼zÃ¼ inÅŸa edildi.
*   **CanlÄ± Takip (WebSocket Entegrasyonu):**
    *   `worker`, eÄŸitim sÄ±rasÄ±nda `Celery task.update_state` ile ilerleme durumunu Redis'e raporladÄ±.
    *   `api`, `FastAPI WebSocket` endpoint'i Ã¼zerinden bu ilerlemeyi `dashboard`'a anlÄ±k olarak iletti.
    *   `dashboard`, gelen `PROGRESS` mesajlarÄ±yla bir **ilerleme Ã§ubuÄŸunu ve kayÄ±p grafiÄŸini canlÄ± olarak gÃ¼ncelledi.**

**An itibarÄ±yla AzuraForge Platform 1.0, tÃ¼m temel mimarisi ve uÃ§tan uca Ã§alÄ±ÅŸan canlÄ± takip yetenekleriyle TAMAMLANMIÅžTIR!**

## ðŸ—ºï¸ Gelecek Fazlar ve Yol HaritasÄ±

Bu saÄŸlam temel Ã¼zerine inÅŸa edilecek adÄ±mlar, AzuraForge'u daha da zenginleÅŸtirmeyi ve kapsamÄ±nÄ± geniÅŸletmeyi hedefleyecektir.

### Faz 5: Deney YÃ¶netimini DerinleÅŸtirme

*   **KalÄ±cÄ± SonuÃ§lar:** `worker`'Ä±n `results.json`'a kaydettiÄŸi tÃ¼m detaylÄ± veriyi (eÄŸitim geÃ§miÅŸi, metrikler, konfigÃ¼rasyon) `api` Ã¼zerinden okuyup Dashboard'da gÃ¶rselleÅŸtirme.
*   **Deney Detay SayfasÄ±:** Dashboard'da her deney iÃ§in ayrÄ± bir detay sayfasÄ± oluÅŸturma.
*   **Model YÃ¶netimi:** EÄŸitilen modellerin kaydedilmesi, listelenmesi ve daha sonra Ã§Ä±karÄ±m iÃ§in yÃ¼klenebilmesi.

### Faz 6: Yeni Veri Modalitelerine AÃ§Ä±lÄ±m (GÃ¶rÃ¼ntÃ¼ Ä°ÅŸleme)

*   **`core` GeniÅŸletme:** `Conv2D`, `MaxPool2D`, `Flatten` gibi CNN katmanlarÄ±nÄ± `core` kÃ¼tÃ¼phanesine ekleme.
*   **Yeni Uygulama Eklentisi:** `azuraforge-app-image-classifier` (Ã¶rn: MNIST iÃ§in) oluÅŸturma.

### Faz 7: Hiperparametre Optimizasyonu

*   **`azuraforge-hyper-tuner`:** FarklÄ± hiperparametre kombinasyonlarÄ±yla otomatik deneyler yapabilen yeni bir uygulama eklentisi.
*   **Dashboard Entegrasyonu:** Dashboard'dan hiperparametre optimizasyonu iÅŸleri baÅŸlatma.

### Faz 8: Ãœretim OrtamÄ± HazÄ±rlÄ±ÄŸÄ± (Deployment)

*   **`platform` Orkestrasyonu:** `docker-compose.yml`'Ä± daha saÄŸlam hale getirme (Nginx, HTTPS, Load Balancing).
*   **CI/CD Pipeline'larÄ±:** TÃ¼m repolar iÃ§in otomatik test, versiyonlama ve yayÄ±nlama (PyPI/GitHub Packages) pipeline'larÄ± kurma.

========== FILE: learner/pyproject.toml ==========
# ========== DOSYA: learner/pyproject.toml ==========
[build-system]
requires = ["setuptools>=61.0"]
build-backend = "setuptools.build_meta"

[project]
name = "azuraforge-learner"
version = "0.1.1"
authors = [{ name = "Azmi Sahin" }]
description = "High-level deep learning library for model training and management, using the AzuraForge Core engine."
readme = "README.md"
requires-python = ">=3.8"
license = { text = "MIT" }
dependencies = [
    # Ã‡ekirdek motorumuza olan baÄŸÄ±mlÄ±lÄ±ÄŸÄ±mÄ±z.
    "azuraforge-core @ git+https://github.com/AzuraForge/core.git@main",
    "scikit-learn",
    "numpy" # scikit-learn iÃ§in explicit belirtmek iyi bir pratik
]

[project.optional-dependencies]
dev = ["pytest"]

========== FILE: learner/README.md ==========
# AzuraForge Learner ðŸ§ 

**AzuraForge Learner**, `azuraforge-core` motorunu kullanarak modelleri kolayca oluÅŸturmak, eÄŸitmek ve yÃ¶netmek iÃ§in tasarlanmÄ±ÅŸ yÃ¼ksek seviyeli bir kÃ¼tÃ¼phanedir.

## Kurulum

```bash
pip install azuraforge-learner@git+https://github.com/AzuraForge/learner.git
```
========== FILE: learner/setup.py ==========
from setuptools import setup, find_packages
setup(
    package_dir={"": "src"},
    packages=find_packages(where="src"),
)
========== FILE: learner/src/azuraforge_learner/callbacks.py ==========
# ========== GÃœNCELLENECEK DOSYA: src/azuraforge_learner/callbacks.py ==========
import os
import numpy as np
from .events import Event

# 'Learner' sÄ±nÄ±fÄ± henÃ¼z tanÄ±mlanmadÄ±ÄŸÄ± iÃ§in ileriye dÃ¶nÃ¼k referans (forward reference) kullanÄ±yoruz
from typing import TYPE_CHECKING
if TYPE_CHECKING:
    from .learner import Learner

class Callback:
    """
    TÃ¼m callback'lerin temel sÄ±nÄ±fÄ±. OlaylarÄ± dinler ve ilgili metoda yÃ¶nlendirir.
    """
    def __call__(self, event: Event):
        method = getattr(self, f"on_{event.name}", None)
        if method:
            method(event)

    def on_train_begin(self, event: Event): pass
    def on_train_end(self, event: Event): pass
    def on_epoch_begin(self, event: Event): pass
    def on_epoch_end(self, event: Event): pass

class ModelCheckpoint(Callback):
    """Her epoch sonunda performansÄ± izler ve sadece en iyi modeli kaydeder."""
    def __init__(self, filepath: str, monitor: str = "val_loss", mode: str = "min", verbose: int = 1):
        self.filepath = filepath
        self.monitor = monitor
        self.mode = mode
        self.verbose = verbose
        self.best = np.inf if mode == "min" else -np.inf

        # DosyanÄ±n kaydedileceÄŸi dizini oluÅŸtur
        dir_path = os.path.dirname(self.filepath)
        if dir_path:
            os.makedirs(dir_path, exist_ok=True)

    def on_epoch_end(self, event: Event):
        current_val = event.payload.get(self.monitor)
        if current_val is None:
            if event.payload.get("epoch") == 0 and self.verbose > 0:
                print(f"ModelCheckpoint Warning: Can't find metric '{self.monitor}' to save model.")
            return

        is_better = (self.mode == "min" and current_val < self.best) or \
                    (self.mode == "max" and current_val > self.best)

        if is_better:
            if self.verbose > 0:
                print(f"ModelCheckpoint: {self.monitor} improved from {self.best:.6f} to {current_val:.6f}. Saving model to {self.filepath}")
            self.best = current_val
            event.learner.save(self.filepath)

class EarlyStopping(Callback):
    """Performans belirli bir epoch sayÄ±sÄ± boyunca iyileÅŸmediÄŸinde eÄŸitimi durdurur."""
    def __init__(self, monitor: str = "val_loss", patience: int = 10, mode: str = "min", verbose: int = 1):
        self.monitor = monitor
        self.patience = patience
        self.mode = mode
        self.verbose = verbose
        self.wait = 0
        self.best = np.inf if mode == "min" else -np.inf

    def on_train_begin(self, event: Event):
        # EÄŸitimin baÅŸÄ±nda sayaÃ§larÄ± sÄ±fÄ±rla
        self.wait = 0
        self.best = np.inf if self.mode == "min" else -np.inf

    def on_epoch_end(self, event: Event):
        current_val = event.payload.get(self.monitor)
        if current_val is None:
            return
            
        is_better = (self.mode == "min" and current_val < self.best) or \
                    (self.mode == "max" and current_val > self.best)

        if is_better:
            self.best = current_val
            self.wait = 0
        else:
            self.wait += 1
            if self.wait >= self.patience:
                if self.verbose > 0:
                    print(f"EarlyStopping: Stopping training. {self.monitor} did not improve for {self.patience} epochs.")
                event.learner.stop_training = True
========== FILE: learner/src/azuraforge_learner/events.py ==========
# ========== DOSYA: src/azuraforge_learner/events.py ==========
from dataclasses import dataclass, field
from typing import Dict, Any, Literal, TYPE_CHECKING

if TYPE_CHECKING:
    from .learner import Learner

EventName = Literal["train_begin", "train_end", "epoch_begin", "epoch_end"]

@dataclass
class Event:
    name: EventName
    learner: 'Learner'
    payload: Dict[str, Any] = field(default_factory=dict)
========== FILE: learner/src/azuraforge_learner/layers.py ==========
# ========== DOSYA: src/azuraforge_learner/layers.py ==========
from typing import List
import numpy as np
from azuraforge_core import Tensor, xp

class Layer:
    def forward(self, x: Tensor) -> Tensor: raise NotImplementedError
    def parameters(self) -> List[Tensor]: return []
    def __call__(self, x: Tensor) -> Tensor: return self.forward(x)

class Linear(Layer):
    def __init__(self, input_dim: int, output_dim: int):
        limit = np.sqrt(2.0 / input_dim)
        self.weights = Tensor(xp.random.randn(input_dim, output_dim) * limit, requires_grad=True)
        self.bias = Tensor(xp.zeros(output_dim), requires_grad=True)
    def forward(self, x: Tensor) -> Tensor:
        return x.dot(self.weights) + self.bias
    def parameters(self) -> List[Tensor]:
        return [self.weights, self.bias]

class ReLU(Layer):
    def forward(self, x: Tensor) -> Tensor:
        return x.relu()
========== FILE: learner/src/azuraforge_learner/learner.py ==========
# ========== GÃœNCELLENECEK DOSYA: src/azuraforge_learner/learner.py ==========
import pickle
from typing import Any, Dict, List, Optional
import numpy as np
from azuraforge_core import Tensor
from .events import Event
from .models import Sequential
from .losses import Loss
from .optimizers import Optimizer
from .callbacks import Callback

class Learner:
    def __init__(self, model: Sequential, criterion: Loss, optimizer: Optimizer, callbacks: Optional[List[Callback]] = None, current_task: Optional[Any] = None):
        self.model = model
        self.criterion = criterion
        self.optimizer = optimizer
        self.callbacks = callbacks or []
        self.history: Dict[str, List[float]] = {}
        self.stop_training: bool = False
        self.current_task = current_task # Celery Task referansÄ±

    def _publish(self, event_name: str, payload: Optional[Dict[str, Any]] = None):
        event = Event(name=event_name, learner=self, payload=payload or {})
        for cb in self.callbacks: cb(event)
        
        # --- KRÄ°TÄ°K DÃœZELTME: Celery Task durumunu gÃ¼ncelle ---
        if self.current_task and hasattr(self.current_task, 'update_state'):
            # Celery'ye PROGRESS durumu ve meta verileri gÃ¶nder
            # payload, epoch_logs'u iÃ§eriyor
            self.current_task.update_state(state='PROGRESS', meta=payload)

    def fit(self, X_train: np.ndarray, y_train: np.ndarray, epochs: int):
        self.history = {} # Her fit Ã§aÄŸrÄ±sÄ±nda geÃ§miÅŸi sÄ±fÄ±rla
        
        # History'yi baÅŸlat
        for key in ["loss", "val_loss", "val_r2"]: # EkleyeceÄŸimiz metrikler iÃ§in yer aÃ§alÄ±m
             self.history[key] = []

        X_train_t, y_train_t = Tensor(X_train), Tensor(y_train)
        
        self._publish("train_begin", payload={"total_epochs": epochs}) # Toplam epoch sayÄ±sÄ±nÄ± gÃ¶nder
        for epoch in range(epochs):
            if self.stop_training: break
            
            # Epoch baÅŸlangÄ±cÄ± olayÄ±nÄ± yayÄ±nla
            self._publish("epoch_begin", payload={"epoch": epoch, "total_epochs": epochs})
            
            # EÄŸitim adÄ±mÄ±
            y_pred = self.model(X_train_t)
            loss = self.criterion(y_pred, y_train_t)
            
            self.optimizer.zero_grad()
            loss.backward()
            self.optimizer.step()
            
            epoch_logs = {
                "epoch": epoch + 1, # Epoch sayÄ±sÄ±nÄ± 1'den baÅŸlatalÄ±m
                "total_epochs": epochs,
                "loss": loss.data.item(),
                "status_text": f"Epoch {epoch+1}/{epochs} completed..."
            }
            
            # History'ye ekle
            self.history["loss"].append(epoch_logs["loss"])
            
            # Epoch sonu olayÄ±nÄ± yayÄ±nla (payload olarak tÃ¼m epoch loglarÄ±nÄ± gÃ¶nder)
            self._publish("epoch_end", payload=epoch_logs)
        self._publish("train_end")
        return self.history

    def predict(self, X_test: np.ndarray) -> np.ndarray:
        return self.model(Tensor(X_test)).to_cpu()

    def evaluate(self, X_val: np.ndarray, y_val: np.ndarray) -> Dict[str, float]:
        from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
        y_val_t = Tensor(y_val)
        y_pred = self.model(Tensor(X_val))
        
        val_loss = self.criterion(y_pred, y_val_t).data.item()
        y_pred_np = y_pred.to_cpu()
        
        val_r2 = r2_score(y_val, y_pred_np)
        val_mae = mean_absolute_error(y_val, y_pred_np)
        val_rmse = np.sqrt(mean_squared_error(y_val, y_pred_np))

        return {"val_loss": val_loss, "val_r2": val_r2, "val_mae": val_mae, "val_rmse": val_rmse}
========== FILE: learner/src/azuraforge_learner/losses.py ==========
# ========== DOSYA: src/azuraforge_learner/losses.py ==========
from azuraforge_core import Tensor

class Loss:
    def __call__(self, y_pred: Tensor, y_true: Tensor) -> Tensor: raise NotImplementedError

class MSELoss(Loss):
    def __call__(self, y_pred: Tensor, y_true: Tensor) -> Tensor:
        return ((y_pred - y_true) ** 2).mean()
========== FILE: learner/src/azuraforge_learner/models.py ==========
# ========== DOSYA: src/azuraforge_learner/models.py ==========
from typing import List
from .layers import Layer
from azuraforge_core import Tensor

class Sequential(Layer):
    def __init__(self, *layers: Layer):
        self.layers = list(layers)
    def forward(self, x: Tensor) -> Tensor:
        for layer in self.layers:
            x = layer(x)
        return x
    def parameters(self) -> List[Tensor]:
        return [p for layer in self.layers for p in layer.parameters()]
========== FILE: learner/src/azuraforge_learner/optimizers.py ==========
# ========== DOSYA: src/azuraforge_learner/optimizers.py ==========
from typing import List
from azuraforge_core import Tensor

class Optimizer:
    def __init__(self, params: List[Tensor], lr: float):
        self.params = [p for p in params if p.requires_grad]
        self.lr = lr
    def step(self) -> None: raise NotImplementedError
    def zero_grad(self) -> None:
        for p in self.params:
            if p.grad is not None: p.grad.fill(0.0)

class SGD(Optimizer):
    def step(self) -> None:
        for p in self.params:
            if p.grad is not None: p.data -= self.lr * p.grad
========== FILE: learner/src/azuraforge_learner/__init__.py ==========
# ========== DOSYA: src/azuraforge_learner/__init__.py ==========
from .events import Event
from .callbacks import Callback, ModelCheckpoint, EarlyStopping
from .losses import Loss, MSELoss
from .layers import Layer, Linear, ReLU
from .models import Sequential
from .optimizers import Optimizer, SGD
from .learner import Learner

__all__ = [
    "Event", "Callback", "ModelCheckpoint", "EarlyStopping",
    "Loss", "MSELoss", "Layer", "Linear", "ReLU",
    "Sequential", "Optimizer", "SGD", "Learner",
]
========== FILE: learner/src/azuraforge_learner/utils/__init__.py ==========

========== FILE: learner/tests/azuraforge_learner/test_learner_components.py ==========
# ========== GÃœNCELLENECEK DOSYA: tests\azuraforge_learner\test_learner_components.py ==========
import pytest
import numpy as np

from azuraforge_learner import Learner, Sequential, Linear, ReLU, MSELoss, SGD

def test_learner_fit_simple_regression():
    X_train = np.array([[-1.0], [0.0], [1.0], [2.0]], dtype=np.float32)
    y_train = np.array([[-1.0], [1.0], [3.0], [5.0]], dtype=np.float32)
    
    model = Sequential(Linear(1, 1))
    criterion = MSELoss()
    optimizer = SGD(model.parameters(), lr=0.1)
    learner = Learner(model, criterion, optimizer)
    
    initial_loss = learner.evaluate(X_train, y_train)['val_loss']
    
    learner.fit(X_train, y_train, epochs=30)
    
    final_loss = learner.history['loss'][-1]
    
    print(f"Initial Loss: {initial_loss}, Final Loss: {final_loss}")
    assert final_loss < initial_loss / 5

def test_sequential_model_forward_pass():
    model = Sequential(Linear(2, 4), ReLU(), Linear(4, 1))
    from azuraforge_core import Tensor
    
    input_tensor = Tensor(np.random.randn(10, 2))
    output_tensor = model(input_tensor)
    
    assert output_tensor.data.shape == (10, 1)
========== FILE: tools/snapshot_generator.py ==========
# ========== GÃœNCELLENMÄ°Åž VE DÃœZELTÄ°LMÄ°Åž DOSYA: platform/tools/snapshot_generator.py ==========
import os
import sys
import json
import argparse
from typing import List, Dict, Any, Set, Optional, Tuple
import re

# Configuration for included/excluded paths and extensions
DEFAULT_INCLUDE_DIRS = ["."]
DEFAULT_INCLUDE_EXTENSIONS = [
    ".toml",
    ".py",
    ".yaml",
    ".yml",
    ".json",
    ".md",
    ".txt",
    "html",
    ".bat",
    ".sh",
    ".jsx",
    ".js",
    ".json",
    ".css"    
]
DEFAULT_EXCLUDE_PATTERNS = [
    "__pycache__",
    ".git",
    ".venv",
    ".vscode",
    ".idea",
    "build",
    "dist",
    "*.egg-info",
    "*.pyc",
    "*.so",
    "*.pyd",
    ".pytest_cache",
    ".mypy_cache",
    ".dataset",
    "dataset",
    ".logs",
    "logs",
    ".output",
    "output",
    "inputs",
    "outputs",
    ".tmp",
    "checkpoints",
    "reports",
    "docs/_build",
    "site",
    "node_modules",
    ".DS_Store",
    "Thumbs.db", # Windows thumbnail cache
    "*.lock", # npm lock dosyalarÄ± gibi
    "package-lock.json"
]

FILE_HEADER_TEMPLATE = "========== FILE: {file_path} =========="
SNAPSHOT_INFO_TEMPLATE = """PROJE KOD SNAPSHOT (TAM)
Toplam {total_files_placeholder} dosya bulundu ve eklendi.
Dahil Edilen Dizinler: {included_dirs_placeholder}
Dahil Edilen UzantÄ±lar: {included_extensions_placeholder}
HariÃ§ Tutulan Desenler/Yollar: {excluded_patterns_placeholder}
================================================================================
"""

def clean_code_comments(content: str, file_extension: str) -> str:
    """Removes most comments from code, attempting to preserve shebangs and type hints."""
    if file_extension not in [".py", ".sh", ".bat"]: return content
    lines = content.splitlines()
    cleaned_lines = []
    for line in lines:
        stripped_line = line.strip()
        if file_extension == ".py":
            # Preserve special comments like '# type:' and shebangs
            if stripped_line.startswith("# type:") or stripped_line.startswith("# noqa"): 
                cleaned_lines.append(line)
            elif stripped_line.startswith("#!/"): 
                cleaned_lines.append(line)
            # Remove inline comments
            elif "#" in line and not stripped_line.startswith("#"): 
                cleaned_lines.append(line.split("#", 1)[0].rstrip())
            # Remove full-line comments
            elif stripped_line.startswith("#"):
                continue # Skip full line comments
            else: 
                cleaned_lines.append(line)
        elif file_extension == ".sh":
            if stripped_line.startswith("#!/"): 
                cleaned_lines.append(line)
            elif not stripped_line.startswith("#"): 
                cleaned_lines.append(line)
        elif file_extension == ".bat":
            if not stripped_line.lower().startswith("rem "): 
                cleaned_lines.append(line)
        else: 
            cleaned_lines.append(line)
    return "\n".join(cleaned_lines)


def should_exclude(item_path: str, root_path: str, exclude_patterns: List[str]) -> bool:
    """Checks if a file or directory should be excluded based on the patterns."""
    normalized_item_path = os.path.normpath(item_path)
    normalized_root_path = os.path.normpath(os.path.abspath(root_path))
    
    try:
        relative_item_path = os.path.relpath(normalized_item_path, normalized_root_path)
    except ValueError:
        # If item_path is not relative to root_path (e.g., different drive on Windows)
        # or other path normalization issues, treat it as its own path.
        relative_item_path = normalized_item_path
    
    relative_item_path_slashes = relative_item_path.replace(os.sep, "/")

    for pattern in exclude_patterns:
        normalized_pattern = os.path.normpath(pattern)
        normalized_pattern_slashes = normalized_pattern.replace(os.sep, "/")

        # Wildcard extensions like "*.pyc"
        if pattern.startswith("*."):
            if relative_item_path_slashes.endswith(pattern[1:]): return True
        # Directory names or file names without path
        elif "/" not in pattern and "." not in pattern and not pattern.startswith("*"):
            path_segments = relative_item_path_slashes.split("/")
            if pattern in path_segments: return True
        # Exact file name match
        elif pattern == os.path.basename(normalized_item_path): return True
        # Full path prefix match or relative path match
        elif normalized_item_path.startswith(os.path.join(normalized_root_path, normalized_pattern)) or \
             relative_item_path_slashes.startswith(normalized_pattern_slashes): return True
        # Absolute path match
        elif os.path.isabs(normalized_pattern) and normalized_pattern == normalized_item_path: return True
    return False


def collect_project_files_full(
    output_file: str,
    include_dirs: Optional[List[str]] = None,
    include_extensions: Optional[List[str]] = None,
    exclude_patterns: Optional[List[str]] = None,
    base_dir: str = ".",
    clean_comments: bool = False,
) -> None:
    if include_dirs is None: include_dirs = DEFAULT_INCLUDE_DIRS
    if include_extensions is None: include_extensions = DEFAULT_INCLUDE_EXTENSIONS
    if exclude_patterns is None: exclude_patterns = DEFAULT_EXCLUDE_PATTERNS

    abs_base_dir = os.path.abspath(base_dir)
    
    snapshot_content_header = SNAPSHOT_INFO_TEMPLATE.format(
        total_files_placeholder="{total_files_counter}",
        included_dirs_placeholder=", ".join(include_dirs),
        included_extensions_placeholder=", ".join(include_extensions),
        excluded_patterns_placeholder=", ".join(exclude_patterns),
    )

    all_found_relative_paths: Set[str] = set() # This set stores relative paths to prevent duplicates
    content_parts: List[str] = [snapshot_content_header]
    processed_files_count = 0

    for inc_dir_pattern in include_dirs:
        current_scan_dir = os.path.abspath(os.path.join(abs_base_dir, inc_dir_pattern))
        if not os.path.exists(current_scan_dir):
            print(f"Warning: Include directory '{inc_dir_pattern}' (resolved to '{current_scan_dir}') does not exist. Skipping.")
            continue

        for root, dirs, files in os.walk(current_scan_dir, topdown=True):
            # Filter directories in-place to prevent os.walk from entering excluded ones
            dirs[:] = [
                d for d in dirs
                if not should_exclude(os.path.join(root, d), abs_base_dir, exclude_patterns)
            ]
            for file_name in files:
                file_path = os.path.join(root, file_name)

                relative_file_path = os.path.relpath(file_path, abs_base_dir)
                display_path = relative_file_path.replace(os.sep, "/")

                # Skip if already processed (e.g., if included by multiple patterns)
                if display_path in all_found_relative_paths:
                    continue 

                # Apply exclusion patterns to files
                if should_exclude(file_path, abs_base_dir, exclude_patterns):
                    continue

                _, file_extension = os.path.splitext(file_name)
                # For extension check, handle files without an explicit extension (like Dockerfile)
                name_part_for_ext_check = file_extension.lower() if file_extension else file_name.lower()

                # Check if file extension (or full name for extensionless files) is in include list
                if any(name_part_for_ext_check.endswith(ext.lower()) for ext in include_extensions) or \
                   (not file_extension and file_name.lower() in [ext.lower() for ext in include_extensions if not ext.startswith('.')]):
                    
                    all_found_relative_paths.add(display_path) # Add to set of found paths
                    try:
                        with open(file_path, "r", encoding="utf-8", errors="ignore") as f:
                            file_content = f.read()
                        
                        if clean_comments:
                            file_content = clean_code_comments(file_content, file_extension)
                        
                        # Add a leading newline for separator, then the header, then content.
                        # This creates the format: \n========== FILE:PATH==========\nCONTENT
                        content_parts.append(f"\n{FILE_HEADER_TEMPLATE.format(file_path=display_path)}\n")
                        content_parts.append(file_content)
                        processed_files_count += 1
                    except Exception as e:
                        print(f"Error reading file {relative_file_path}: {e}")
                        content_parts.append(f"\nError reading file {relative_file_path}: {e}\n")

    final_header_with_count = content_parts[0].replace("{total_files_counter}", str(processed_files_count))
    content_parts[0] = final_header_with_count

    with open(output_file, "w", encoding="utf-8") as f:
        f.write("".join(content_parts))

    print(f"Project snapshot (full) generated: {output_file}")
    print(f"Total {processed_files_count} files included.")


def restore_from_full_snapshot(
    snapshot_file: str,
    target_dir: str = ".",
    dry_run: bool = False,
    overwrite_existing: bool = False,
) -> None:
    print(f"Restoring project from snapshot: {snapshot_file}")
    if dry_run: print("DRY RUN: No files will be written.")

    try:
        with open(snapshot_file, "r", encoding="utf-8") as f:
            full_content = f.read()
    except FileNotFoundError:
        print(f"Error: Snapshot file '{snapshot_file}' not found.")
        return
    except Exception as e:
        print(f"Error reading snapshot file: {e}")
        return

    # Regex to find file blocks. It captures the file path (group 1) and its content (group 2).
    # The crucial point is that group(2) captures ALL characters (including newlines due to re.DOTALL)
    # after the header line's trailing newline, until the START of the next file header or end of string.
    # The lookahead `(?=...)` is non-consuming, so the content is captured completely.
    file_block_pattern = re.compile(
        r"^========== FILE: (.*?) ==========\n"  # Match header line and its trailing newline
        r"(.*?)"                                 # Capture content (non-greedy)
        r"(?=\n========== FILE: |\Z)",           # Lookahead: followed by newline then next header, OR end of string.
                                                # \Z matches only at the end of the string.
        re.MULTILINE | re.DOTALL
    )
    
    # Find the end of the initial info header to start parsing file blocks
    info_header_last_line = SNAPSHOT_INFO_TEMPLATE.splitlines()[-1]
    content_start_index = full_content.find(info_header_last_line)
    if content_start_index == -1:
        print("Error: Could not find the end of the snapshot info header.")
        return
    
    # Slice the content to start exactly after the info header,
    # and then lstrip any *leading* newlines that might be left before the first file block.
    # This ensures the regex for the first file block can match correctly.
    content_to_parse = full_content[content_start_index + len(info_header_last_line):].lstrip('\n')

    files_restored = 0
    files_skipped = 0
    files_overwritten = 0
    
    matches = file_block_pattern.finditer(content_to_parse)

    for match in matches:
        relative_file_path = match.group(1).strip()
        # KRÄ°TÄ°K DÃœZELTME: match.group(2) Ã¼zerinde .strip() metodunu kaldÄ±rdÄ±k.
        # Bu, tÃ¼m boÅŸluk karakterlerinin (yeni satÄ±rlar dahil) korunmasÄ±nÄ± saÄŸlar.
        content_part = match.group(2) 

        os_specific_relative_path = relative_file_path.replace("/", os.sep)
        target_file_path = os.path.join(target_dir, os_specific_relative_path)
        
        # DEBUG YARDIMI: YazÄ±lacak iÃ§eriÄŸin uzunluÄŸunu gÃ¶ster
        print(f"Processing file: {relative_file_path} (Content length: {len(content_part)}) -> {target_file_path}")

        if os.path.exists(target_file_path) and not overwrite_existing:
            print(f"  SKIPPED: File '{target_file_path}' already exists (overwrite_existing is False).")
            files_skipped += 1
            continue

        if os.path.exists(target_file_path) and overwrite_existing:
            print(f"  OVERWRITING: File '{target_file_path}'.")
            files_overwritten += 1

        if not dry_run:
            try:
                os.makedirs(os.path.dirname(target_file_path), exist_ok=True)
                with open(target_file_path, "w", encoding="utf-8") as f:
                    f.write(content_part)
                files_restored += 1
            except Exception as e:
                print(f"  ERROR: Could not write file '{target_file_path}': {e}")
        else:
            if not os.path.exists(os.path.dirname(target_file_path)):
                print(f"  DRY RUN: Would create directory {os.path.dirname(target_file_path)}")
            print(f"  DRY RUN: Would write {len(content_part)} bytes to {target_file_path}")
            files_restored += 1

    print("\n--- Restoration Summary ---")
    print(f"Files processed for restoration: {files_restored}")
    if not dry_run:
        print(f"Files actually written/overwritten: {files_restored - files_skipped}")
        print(f"Files overwritten: {files_overwritten}")
    print(f"Files skipped (already exist and overwrite=False): {files_skipped}")


def main():
    parser = argparse.ArgumentParser(description="Project Snapshot Tool (Full Version)")
    subparsers = parser.add_subparsers(dest="command", required=True)

    parser_collect = subparsers.add_parser(
        "collect", help="Collect project files into a single snapshot file."
    )
    parser_collect.add_argument(
        "output_file",
        type=str,
        default="project_snapshot_full.txt",
        nargs="?",
        help="Path to the output snapshot file (default: project_snapshot_full.txt)",
    )
    parser_collect.add_argument(
        "--include-dir",
        action="append",
        dest="include_dirs",
        help="Directory to include (relative to base_dir or absolute). Can be used multiple times. Defaults to ['.']",
    )
    parser_collect.add_argument(
        "--include-ext",
        action="append",
        dest="include_extensions",
        help="File extension to include (e.g., .py, .md). Can be used multiple times. Defaults to common code/config extensions.",
    )
    parser_collect.add_argument(
        "--exclude-pattern",
        action="append",
        dest="exclude_patterns",
        help="Pattern/path to exclude. Can be used multiple times. Defaults to common ignores.",
    )
    parser_collect.add_argument(
        "--base-dir",
        type=str,
        default=".",
        help="Base directory for the project (default: current directory). Relative paths are resolved against this.",
    )
    parser_collect.add_argument(
        "--clean-comments",
        action="store_true",
        help="Attempt to remove comments from collected code files (.py, .sh, .bat).",
    )

    parser_restore = subparsers.add_parser(
        "restore", help="Restore project files from a snapshot."
    )
    parser_restore.add_argument(
        "snapshot_file", type=str, help="Path to the snapshot file to restore from."
    )
    parser_restore.add_argument(
        "--target-dir",
        type=str,
        default=".",
        help="Directory where files will be restored (default: current directory).",
    )
    parser_restore.add_argument(
        "--dry-run",
        action="store_true",
        help="Simulate restoration without writing any files.",
    )
    parser_restore.add_argument(
        "--overwrite",
        action="store_true",
        dest="overwrite_existing",
        help="Overwrite files if they already exist in the target directory.",
    )

    args = parser.parse_args()

    if args.command == "collect":
        final_include_dirs = (
            args.include_dirs if args.include_dirs is not None else DEFAULT_INCLUDE_DIRS
        )
        final_include_extensions = (
            args.include_extensions
            if args.include_extensions is not None
            else DEFAULT_INCLUDE_EXTENSIONS
        )
        final_exclude_patterns = (
            args.exclude_patterns
            if args.exclude_patterns is not None
            else DEFAULT_EXCLUDE_PATTERNS
        )
        collect_project_files_full(
            output_file=args.output_file,
            include_dirs=final_include_dirs,
            include_extensions=final_include_extensions,
            exclude_patterns=final_exclude_patterns,
            base_dir=args.base_dir,
            clean_comments=args.clean_comments,
        )
    elif args.command == "restore":
        restore_from_full_snapshot(
            snapshot_file=args.snapshot_file,
            target_dir=args.target_dir,
            dry_run=args.dry_run,
            overwrite_existing=args.overwrite_existing,
        )


if __name__ == "__main__":
    # Example usage:
    # python tools/snapshot_generator.py collect project_full_snapshot.txt
    # python tools/snapshot_generator.py restore project_full_snapshot.txt --dry-run   
    # python tools/snapshot_generator.py restore project_full_snapshot.txt --overwrite
    print("Project Snapshot Tool (Full Version)")
    print("Collects project files into a single snapshot file or restores from a snapshot.")
    print("Use 'collect' to create a snapshot and 'restore' to restore files from it.")    
    main()
========== FILE: worker/pyproject.toml ==========
# ========== DOSYA: worker/pyproject.toml ==========
[build-system]
requires = ["setuptools>=61.0"]
build-backend = "setuptools.build_meta"

[project]
name = "azuraforge-worker"
version = "0.1.0"
description = "The Celery worker for the AzuraForge Platform. Discovers and runs pipeline plugins."
requires-python = ">=3.8"
dependencies = [
    # Worker'Ä±n kendisi doÄŸrudan Learner'a deÄŸil, eklentilere ihtiyaÃ§ duyar.
    # Eklentiler zaten Learner'a baÄŸÄ±mlÄ± olduÄŸu iÃ§in, pip bunu Ã§Ã¶zecektir.
    
    # GeliÅŸtirme ve test sÄ±rasÄ±nda bu eklentinin kurulu olmasÄ±nÄ± saÄŸlÄ±yoruz.
    # CanlÄ± bir ortamda, hangi eklentilerin kurulacaÄŸÄ± bir konfigÃ¼rasyon dosyasÄ± ile yÃ¶netilir.
    "azuraforge-app-stock-predictor @ git+https://github.com/AzuraForge/app-stock-predictor.git@main",
    
    "celery[redis]",
    "pyyaml",
]

[project.scripts]
start-worker = "azuraforge_worker.main:run_celery_worker"
========== FILE: worker/README.md ==========
# worker
========== FILE: worker/setup.py ==========
# ========== DOSYA: worker/setup.py ==========
from setuptools import setup, find_packages

setup(
    package_dir={"": "src"},
    packages=find_packages(where="src"),
)
========== FILE: worker/src/azuraforge_worker/celery_app.py ==========
# ========== DOSYA: src/azuraforge_worker/celery_app.py ==========
from celery import Celery
import os

REDIS_URL = os.getenv("REDIS_URL", "redis://localhost:6379/0")

celery_app = Celery(
    "azuraforge_worker",
    broker=REDIS_URL,
    backend=REDIS_URL,
    # Worker baÅŸladÄ±ÄŸÄ±nda gÃ¶revlerin nerede olduÄŸunu belirtir.
    include=["azuraforge_worker.tasks.training_tasks"]
)
========== FILE: worker/src/azuraforge_worker/main.py ==========
# ========== DOSYA: src/azuraforge_worker/main.py ==========
import subprocess
import sys

def run_celery_worker():
    """'start-worker' komutu iÃ§in giriÅŸ noktasÄ±."""
    print("ðŸ‘·â€â™‚ï¸ Starting AzuraForge Worker...")
    command = [
        sys.executable, "-m", "celery",
        "-A", "azuraforge_worker.celery_app:celery_app", # Celery app nesnesinin tam yolu
        "worker",
        "--pool=solo", # Windows uyumluluÄŸu Ã¼retim iÃ§in prefork kullanÄ±n
        "--loglevel=INFO"
    ]
    subprocess.run(command)
========== FILE: worker/src/azuraforge_worker/__init__.py ==========
# ========== DOSYA: worker/src/azuraforge_worker/__init__.py ==========
from .celery_app import celery_app

# Bu, diÄŸer projelerin 'from azuraforge_worker import celery_app' yapabilmesini saÄŸlar.
__all__ = ("celery_app",)
========== FILE: worker/src/azuraforge_worker/tasks/training_tasks.py ==========
# ========== DOSYA: worker/src/azuraforge_worker/tasks/training_tasks.py ==========
import logging
import os
import json
from datetime import datetime
from importlib.metadata import entry_points
from celery import current_task # GÃ¶revin durumunu gÃ¼ncellemek iÃ§in
import time # SimÃ¼lasyon iÃ§in
import traceback # Hata detaylarÄ±nÄ± yakalamak iÃ§in

from ..celery_app import celery_app
# applications reposundan pipeline'Ä± import etmek iÃ§in bu kodun olduÄŸu yerde deÄŸil,
# pip tarafÄ±ndan paket olarak kurulmuÅŸ azuraforge_stockapp'tan import edilecek.

# --- Eklenti KeÅŸfi ---
def discover_pipelines():
    """Sisteme kurulmuÅŸ tÃ¼m AzuraForge pipeline'larÄ±nÄ± keÅŸfeder."""
    logging.info("Worker: Discovering installed AzuraForge pipeline plugins...")
    discovered = {}
    try:
        eps = entry_points(group='azuraforge.pipelines')
        for ep in eps:
            logging.info(f"Worker: Found plugin: '{ep.name}' -> points to '{ep.value}'")
            discovered[ep.name] = ep.load() 
    except Exception as e:
        logging.error(f"Worker: Error discovering pipelines: {e}", exc_info=True)
    return discovered

AVAILABLE_PIPELINES = discover_pipelines()
if not AVAILABLE_PIPELINES:
    logging.warning("Worker: No AzuraForge pipelines found! Please install a pipeline plugin, e.g., 'azuraforge-app-stock-predictor'.")

REPORTS_BASE_DIR = os.path.abspath(os.getenv("REPORTS_DIR", "/app/reports"))
os.makedirs(REPORTS_BASE_DIR, exist_ok=True) # Dizinin var olduÄŸundan emin ol

@celery_app.task(bind=True, name="start_training_pipeline")
def start_training_pipeline(self, config: dict):
    pipeline_name = config.get("pipeline_name")
    if not pipeline_name or pipeline_name not in AVAILABLE_PIPELINES:
        raise ValueError(f"Pipeline '{pipeline_name}' not found or installed.")

    # --- Deney iÃ§in benzersiz bir klasÃ¶r ve ID oluÅŸtur ---
    run_timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    experiment_id = f"{pipeline_name}_{run_timestamp}_{self.request.id}" 
    
    pipeline_specific_report_dir = os.path.join(REPORTS_BASE_DIR, pipeline_name)
    os.makedirs(pipeline_specific_report_dir, exist_ok=True)
    experiment_dir = os.path.join(pipeline_specific_report_dir, experiment_id)
    os.makedirs(experiment_dir, exist_ok=True)
    
    config['experiment_id'] = experiment_id
    config['task_id'] = self.request.id
    config['experiment_dir'] = experiment_dir

    PipelineClass = AVAILABLE_PIPELINES[pipeline_name]
    logging.info(f"Worker: Instantiating pipeline '{PipelineClass.__name__}' for experiment {experiment_id}")
    
    initial_report_data = {
        "task_id": self.request.id, "experiment_id": experiment_id, "status": "STARTED", "config": config, "results": {}
    }
    with open(os.path.join(experiment_dir, "results.json"), 'w') as f:
        json.dump(initial_report_data, f, indent=4, default=str)

    try:
        # --- KRÄ°TÄ°K DÃœZELTME: Pipeline'a Celery Task objesini iletiyoruz ---
        # Bu, pipeline'Ä±n iÃ§indeki Learner'Ä±n Celery state'i gÃ¼ncelleyebilmesini saÄŸlar.
        pipeline_instance = PipelineClass(config, celery_task=self) # <- Yeni parametre
        results = pipeline_instance.run() 

        final_report_data = {
            "task_id": self.request.id, "experiment_id": experiment_id, "status": "SUCCESS", "config": config, "results": results, "completed_at": datetime.now().isoformat()
        }
        with open(os.path.join(experiment_dir, "results.json"), 'w') as f:
            json.dump(final_report_data, f, indent=4, default=str)
            
        logging.info(f"Worker: Task {self.request.id} for pipeline '{pipeline_name}' completed successfully. Results in {experiment_dir}")
        return final_report_data

    except Exception as e:
        error_traceback = traceback.format_exc()
        error_message = f"Pipeline execution failed for {pipeline_name}: {e}\n{error_traceback}"
        logging.error(error_message)
        
        self.update_state(state='FAILURE', meta={'error_message': str(e), 'traceback': error_traceback})
        
        error_report_data = {
            "task_id": self.request.id, "experiment_id": experiment_id, "status": "FAILURE", "config": config, "error": error_message, "failed_at": datetime.now().isoformat()
        }
        with open(os.path.join(experiment_dir, "results.json"), 'w') as f:
            json.dump(error_report_data, f, indent=4)
            
        raise e
========== FILE: worker/src/azuraforge_worker/tasks/__init__.py ==========
