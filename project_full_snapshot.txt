PROJE KOD SNAPSHOT (TAM)
Toplam 80 dosya bulundu ve eklendi.
Dahil Edilen Dizinler: .
Dahil Edilen Uzantılar: .toml, .py, .yaml, .yml, .json, .md, .txt, html, .bat, .sh, .jsx, .js, .json, .css
Hariç Tutulan Desenler/Yollar: __pycache__, .git, .venv, .vscode, .idea, build, dist, *.egg-info, *.pyc, *.so, *.pyd, .pytest_cache, .mypy_cache, .dataset, dataset, .logs, logs, .output, output, inputs, outputs, .tmp, checkpoints, reports, docs/_build, site, node_modules, .DS_Store, Thumbs.db, *.lock
================================================================================

========== FILE: docker-compose.yml ==========
services:
  # 1. Redis Servisi (Mesaj Kuyruğu ve Sonuç Deposu)
  redis:
    image: "redis:alpine"
    container_name: azuraforge_redis
    ports: ["6379:6379"]
    volumes: ["redis_data:/data"]

  # --- KÜTÜPHANE SERVİSLERİ (SADECE BUILD VE SAĞLIK KONTROLÜ İÇİN) ---
  # Bu servisler, ana uygulamaların (API, Worker) bağımlılıklarını kurabilmesi için önceden build edilir.
  # Bağımlılık zincirinde alt seviyede oldukları için 'depends_on' gerekmez,
  # API ve Worker Dockerfile'ları onları zaten pip ile çeker.
  # Buradaki tanımlar, onların da build edildiğini doğrulamak içindir.

  # 2. Core Kütüphanesi
  core_lib:
    container_name: azuraforge_core_lib_build_test
    build:
      context: ./core # 'core' reposunun bulunduğu klasörü göster
      dockerfile: Dockerfile # 'core' reposunun içindeki Dockerfile
    command: python -c "import azuraforge_core; print('AzuraForge Core built and imported successfully in Docker!')"
    # volumes: - ./core:/app # Geliştirme sırasında kodu anında yansıtmak için
    # Bu servis sadece build ediliyor, çalıştırılmıyor. Mount'a gerek yok.

  # 3. Learner Kütüphanesi
  learner_lib:
    container_name: azuraforge_learner_lib_build_test
    build:
      context: ./learner
      dockerfile: Dockerfile
    command: python -c "import azuraforge_learner; print('AzuraForge Learner built and imported successfully in Docker!')"
    # volumes: - ./learner:/app # Sadece build ediliyor.

  # 4. Applications Katalogu
  applications_catalog:
    container_name: azuraforge_applications_catalog_build_test
    build:
      context: ./applications
      dockerfile: Dockerfile
    command: python -c "import azuraforge_applications; print('AzuraForge Applications Catalog built and imported successfully in Docker!')"
    # volumes: - ./applications:/app # Sadece build ediliyor.

  # 5. App Stock Predictor (Uygulama Eklentisi)
  app_stock_predictor:
    container_name: azuraforge_app_stock_predictor_build_test
    build:
      context: ./app-stock-predictor
      dockerfile: Dockerfile
    command: python -c "import azuraforge_stockapp; print('AzuraForge App Stock Predictor built and imported successfully in Docker!')"
    # volumes: - ./app-stock-predictor:/app # Sadece build ediliyor.

  # --- ANA PLATFORM SERVİSLERİ ---
  # Bu servisler, tüm ekosistemin temelidir ve diğer kütüphanelere bağımlıdır.

  # 6. API Servisi
  api:
    container_name: azuraforge_api
    build:
      context: ./api # 'api' reposunun bulunduğu klasörü göster
      dockerfile: Dockerfile # 'api' reposunun içindeki Dockerfile
    command: start-api # 'api' reposundaki entrypoint script'i
    ports: ["8000:8000"]
    volumes:
      - ./api:/app # API'ın kendi kodu
      - ${REPORTS_DIR}:/app/reports # Ortak rapor dizini (Host makineden mount ediliyor)
    environment:
      - REDIS_URL=${REDIS_URL}
      - REPORTS_DIR=/app/reports
    depends_on: [redis] # Redis'e bağımlı

  # 7. Worker Servisi
  worker:
    container_name: azuraforge_worker
    build:
      context: ./worker
      dockerfile: Dockerfile
    command: start-worker
    volumes:
      - ./worker:/app # Worker'ın kendi kodu
      - ${REPORTS_DIR}:/app/reports # Raporlar için
    environment:
      - REDIS_URL=${REDIS_URL}
      - REPORTS_DIR=/app/reports
    depends_on: [redis]

  # 8. Dashboard Servisi
  dashboard:
    container_name: azuraforge_dashboard
    build:
      context: ./dashboard
      dockerfile: Dockerfile
    command: npm run dev -- --host 0.0.0.0
    ports: ["5173:5173"]
    volumes:
      - ./dashboard:/app
      - /app/node_modules
    depends_on: [api]

volumes:
  redis_data: # Redis verilerini kalıcı tutmak için volume

========== FILE: README.md ==========
# AzuraForge Platform 🚀

**AzuraForge Platform**, yapay zeka modellerini sıfırdan oluşturmak, eğitmek ve yönetmek için tasarlanmış modüler, dağıtık ve eklenti tabanlı bir MLOps platformudur. Modern mikroservis mimarisi prensipleriyle inşa edilmiştir.

Bu depo, AzuraForge ekosistemindeki tüm ana servisleri (API, Worker, Dashboard) ve kütüphaneleri (Core, Learner, Applications) bir araya getiren **orkestrasyon katmanıdır**.

## 🎯 Temel Amaçlar ve Felsefe

*   **Sıfırdan İnşa:** Derin öğrenme motoru ve temel bileşenler sıfırdan geliştirilmiştir.
*   **Modülerlik ve Bağımsızlık:** Her bileşen (kütüphane, API, worker, UI, uygulama) kendi bağımsız repo'sunda yaşar ve kendi sorumluluğuna sahiptir.
*   **Olay Güdümlü Mimari:** Servisler arası iletişim olay tabanlı (Celery, Redis, WebSockets) gerçekleşir.
*   **Eklenti Tabanlı:** Yeni yapay zeka modelleri ve uygulamaları, platformun çekirdek koduna dokunmadan birer eklenti (plugin) olarak eklenebilir.
*   **Ölçeklenebilirlik:** Dağıtık servisler sayesinde yatayda ölçeklenebilir.
*   **Profesyonel Geliştirici Deneyimi:** Otomatik kurulum, test ve dokümantasyon ile geliştirme sürecini kolaylaştırmak.

## 🏛️ Mimari Genel Bakış

AzuraForge platformu, aşağıdaki bağımsız GitHub depolarından oluşan bir mikroservis mimarisini benimser:

-   **`core`** (`azuraforge-core`): Otomatik türev yeteneklerine sahip temel matematik motoru (NumPy/CuPy).
-   **`learner`** (`azuraforge-learner`): `core` üzerinde geliştirilmiş yüksek seviyeli derin öğrenme kütüphanesi (Katmanlar, Optimizatörler, Kayıp Fonksiyonları, `Learner` sınıfı).
-   **`applications`** (`azuraforge-applications`): Platform için resmi uygulama eklentilerinin katalogu (JSON dosyası).
-   **`app-stock-predictor`** (`azuraforge-app-stock-predictor`): Gerçek bir uygulama eklentisi örneği (Hisse Senedi Tahmini).
-   **`api`** (`azuraforge-api`): RESTful API ve WebSocket endpoint'leri sunan iletişim katmanı.
-   **`worker`** (`azuraforge-worker`): Arka plan görevlerini işleyen ve uygulama eklentilerini çalıştıran işçi servisi.
-   **`dashboard`** (`azuraforge-dashboard`): Platform için web tabanlı kullanıcı arayüzü.

Bu repo, tüm bu servisleri tek bir `docker-compose` komutuyla ayağa kaldıran ana orkestrasyon katmanıdır.

## 🚀 Hızlı Başlangıç (Docker Compose ile)

Tüm platformu yerel makinenizde tek bir komutla başlatmak için:

1.  **Docker Desktop'ın yüklü ve çalıştığından emin olun.**
2.  **Bu repoyu klonlayın:**
    ```bash
    git clone https://github.com/AzuraForge/platform.git
    cd platform
    ```
3.  **.env dosyasını oluşturun:**
    Proje kök dizininde `.env` adında bir dosya oluşturun ve içine raporların kaydedileceği dizini belirtin.
    ```
    # .env
    REDIS_URL=redis://redis:6379/0
    # Rapor dizini: Worker'ın sonuçları yazacağı ve API'nin okuyacağı host makinedeki dizin
    # Windows için C:/azuraforge_platform_reports veya ./reports
    # Linux/macOS için: ./reports
    REPORTS_DIR=./reports 
    ```
    **ÖNEMLİ:** Docker Compose'u çalıştırmadan önce bu dizini host makinenizde oluşturduğunuzdan emin olun. Örneğin, Linux/macOS'ta:
    ```bash
    mkdir -p ./reports
    ```
    (Windows kullanıyorsanız `REPORTS_DIR`'i `C:/azuraforge_platform_reports` gibi bir mutlak yola ayarlamanız ve bu klasörü oluşturmanız daha güvenli olabilir).
4.  **Platformu başlatın:**
    ```bash
    docker-compose up --build -d
    ```
    (`-d` parametresi arka planda çalıştırmayı sağlar.)

5.  **Platforma erişin:**
    -   **Dashboard:** `http://localhost:5173`
    -   **API Dokümantasyonu:** `http://localhost:8000/api/v1/docs`

## 🛠️ Geliştirme Rehberi ve İç Detaylar

Bu rehber, platformun nasıl çalıştığını, nasıl katkıda bulunacağınızı ve geliştirme ortamınızı nasıl yöneteceğinizi detaylandırır.

**[Tam Geliştirme Rehberine Git](./docs/DEVELOPMENT_GUIDE.md)**

## 🤝 Katkıda Bulunma

Projenin gelişimine katkıda bulunmak için [CONTRIBUTING.md](./docs/CONTRIBUTING.md) dosyasını inceleyin.

## 🗺️ Yol Haritası ve Gelecek Vizyonu

Projenin tamamlanan aşamaları, mevcut durumu ve gelecek hedefleri hakkında bilgi almak için [PROJECT_JOURNEY.md](./docs/PROJECT_JOURNEY.md) dosyasını okuyun.

========== FILE: api/pyproject.toml ==========
[build-system]
requires = ["setuptools>=61.0"]
build-backend = "setuptools.build_meta"

[project]
name = "azuraforge-api"
version = "0.1.0"
description = "The API server for the AzuraForge Platform."
requires-python = ">=3.8"

dependencies = [
    "azuraforge-learner @ git+https://github.com/AzuraForge/learner.git@main",
    # Yeni önerilen: (PyPI'da olsaydı) ( Ancak şu an için henüz PyPI'da değil )
    # "azuraforge-learner==0.1.1", # Belirli bir sürümü hedefle
    # Veya hala yerel geliştirme için, ama geliştirme rehberindeki -e kurulumu öncelikli
    # "azuraforge-learner @ git+https://github.com/AzuraForge/learner.git@v0.1.1", # Eğer tag'ler kullanılıyorsa

    "azuraforge-worker @ git+https://github.com/AzuraForge/worker.git@main",
    # Yeni önerilen:
    # "azuraforge-worker==0.1.0", # Belirli bir sürümü hedefle

    "azuraforge-applications @ git+https://github.com/AzuraForge/applications.git@main",
    # Yeni önerilen:
    # "azuraforge-applications==0.1.0", # Belirli bir sürümü hedefle

    "fastapi", "uvicorn[standard]", "pydantic-settings", "python-dotenv", "pyyaml",
]

[project.scripts]
start-api = "azuraforge_api.main:run_server"
========== FILE: api/README.md ==========
# api

========== FILE: api/setup.py ==========
from setuptools import setup, find_packages

setup(
    # Bu satır, setuptools'a paketlerin 'src' klasörünün içinde
    # olduğunu söyler.
    package_dir={"": "src"},
    
    # Bu satır, 'src' klasörünün içindeki tüm Python paketlerini
    # (azuraforge_api ve altındakiler) otomatik olarak bulur.
    packages=find_packages(where="src"),
)

========== FILE: api/src/azuraforge_api/main.py ==========
import uvicorn
from fastapi import FastAPI, APIRouter # DÜZELTME: APIRouter'ı import et
from fastapi.middleware.cors import CORSMiddleware

from .core.config import settings
from .routes import experiments, pipelines, streaming

def create_app() -> FastAPI:
    app = FastAPI(title=settings.PROJECT_NAME, version="0.1.0")
    
    # CORS ayarlarını dinamik olarak belirle
    if settings.CORS_ORIGINS == "*":
        allowed_origins = ["*"]
    else:
        allowed_origins = [origin.strip() for origin in settings.CORS_ORIGINS.split(',')]

    app.add_middleware(
        CORSMiddleware,
        allow_origins=allowed_origins,
        allow_credentials=True,
        allow_methods=["*"],
        allow_headers=["*"],
    )

    # DÜZELTME: İç içe FastAPI uygulaması yerine tek bir APIRouter kullanıyoruz.
    # Bu, "AttributeError: 'FastAPI' object has no attribute 'default_response_class'"
    # hatasını çözer.
    api_router = APIRouter()
    api_router.include_router(experiments.router)
    api_router.include_router(pipelines.router)
    
    # Şimdi bu birleştirilmiş router'ı tek bir prefix ile ana uygulamaya ekliyoruz.
    app.include_router(api_router, prefix=settings.API_V1_PREFIX)
    
    # WebSocket router'ı prefix dışında, doğrudan ana uygulamaya ekleniyor.
    app.include_router(streaming.router)
    
    @app.get("/", tags=["Root"])
    def read_root():
        return {"message": f"Welcome to {settings.PROJECT_NAME}"}
        
    return app

app = create_app()

def run_server():
    print(f"🚀 Starting {settings.PROJECT_NAME}...")
    uvicorn.run("azuraforge_api.main:app", host="0.0.0.0", port=8000, reload=True)
========== FILE: api/src/azuraforge_api/__init__.py ==========

========== FILE: api/src/azuraforge_api/core/config.py ==========
from pydantic_settings import BaseSettings, SettingsConfigDict

class Settings(BaseSettings):
    PROJECT_NAME: str = "AzuraForge API"
    API_V1_PREFIX: str = "/api/v1"
    
    # Yeni CORS ayarı
    # Virgülle ayrılmış URL'ler veya tümüne izin vermek için "*"
    CORS_ORIGINS: str = "*" # Varsayılan olarak tümüne izin ver (geliştirme için)
    
    model_config = SettingsConfigDict(env_file=".env", env_file_encoding='utf-8')

settings = Settings()

========== FILE: api/src/azuraforge_api/core/__init__.py ==========

========== FILE: api/src/azuraforge_api/routes/experiments.py ==========
from fastapi import APIRouter, HTTPException
from typing import List, Dict, Any
from ..services import experiment_service

# DÜZELTME: tags'i buraya al, prefix'i ana dosyada bırak
router = APIRouter(tags=["Experiments"])

@router.get("/experiments", response_model=List[Dict[str, Any]])
def get_all_experiments():
    return experiment_service.list_experiments()

@router.post("/experiments", status_code=202, response_model=Dict[str, Any])
def create_new_experiment(config: Dict[str, Any]):
    return experiment_service.start_experiment(config)

@router.get("/experiments/{task_id}/status", response_model=Dict[str, Any])
def get_experiment_status(task_id: str):
    return experiment_service.get_task_status(task_id)
========== FILE: api/src/azuraforge_api/routes/pipelines.py ==========
from fastapi import APIRouter, HTTPException
from typing import List, Dict, Any
from ..services import experiment_service

router = APIRouter(tags=["Pipelines"])

@router.get("/pipelines", response_model=List[Dict[str, Any]])
def get_all_available_pipelines():
    return experiment_service.get_available_pipelines()

@router.get("/pipelines/{pipeline_id}/config", response_model=Dict[str, Any])
def get_pipeline_default_config(pipeline_id: str):
    try:
        return experiment_service.get_default_pipeline_config(pipeline_id)
    except ValueError as e:
        raise HTTPException(status_code=404, detail=str(e))
========== FILE: api/src/azuraforge_api/routes/streaming.py ==========
import asyncio
import logging
from fastapi import APIRouter, WebSocket, WebSocketDisconnect
from celery.result import AsyncResult

from azuraforge_worker import celery_app

router = APIRouter()

@router.websocket("/ws/task_status/{task_id}")
async def websocket_task_status(websocket: WebSocket, task_id: str):
    await websocket.accept()
    logging.info(f"WebSocket connection accepted for task: {task_id}")
    
    task_result = AsyncResult(task_id, app=celery_app)
    
    try:
        # DÜZELTME: Bağlantı kurulur kurulmaz ilk durumu gönder.
        # Bu, hızlı biten görevlerin son durumunun anında UI'a ulaşmasını sağlar.
        initial_status = {
            "state": task_result.state,
            "details": task_result.info if task_result.state == 'PROGRESS' else None,
            "result": task_result.result if task_result.ready() else None
        }
        await websocket.send_json(initial_status)

        # Görev tamamlanana kadar döngüde kal
        while not task_result.ready():
            if task_result.state == 'PROGRESS':
                await websocket.send_json({
                    "state": task_result.state,
                    "details": task_result.info,
                })
            await asyncio.sleep(1)
        
        # Döngü bittiğinde son durumu tekrar gönder (garanti amaçlı)
        await websocket.send_json({
            "state": task_result.state,
            "result": task_result.result,
        })

    except WebSocketDisconnect:
        logging.warning(f"WebSocket disconnected for task: {task_id}")
    except Exception as e:
        logging.error(f"An error occurred in WebSocket for task {task_id}: {e}")
        try:
            await websocket.send_json({
                "state": "ERROR",
                "details": {"message": str(e), "task_id": task_id}
            })
        except Exception:
            pass 
    finally:
        logging.info(f"Closing WebSocket for task {task_id}")
        await websocket.close()
========== FILE: api/src/azuraforge_api/routes/__init__.py ==========

========== FILE: api/src/azuraforge_api/services/experiment_service.py ==========
import json
import os
import glob
from importlib import resources
from importlib.metadata import entry_points
from typing import List, Dict, Any, Optional
from celery.result import AsyncResult 

from azuraforge_worker import celery_app
from azuraforge_worker.tasks.training_tasks import start_training_pipeline
from azuraforge_worker.tasks.training_tasks import AVAILABLE_PIPELINES_AND_CONFIGS

REPORTS_BASE_DIR = os.path.abspath(os.getenv("REPORTS_DIR", "/app/reports"))

def get_available_pipelines() -> List[Dict[str, Any]]:
    # Mevcut kodunuzu kullanarak resmi uygulamalar kataloğunu çekmeye devam edin
    # Bu, dashboard'daki "pipeline adı" ve "açıklama" gibi meta verileri sağlar.
    official_apps_data = []
    try:
        with resources.open_text("azuraforge_applications", "official_apps.json") as f:
            official_apps_data = json.load(f)
    except (FileNotFoundError, ModuleNotFoundError) as e:
        print(f"ERROR: Could not find or read the official apps catalog. {e}")
        # Hata durumunda boş liste döndürmek yerine hata fırlatılabilir veya varsayılan bir şey sağlanabilir.

    # Şimdi worker'dan keşfedilen pipeline'lar ile bu meta veriyi birleştir.
    # Sadece worker'ın gerçekten keşfettiği pipeline'ları sun.
    available_pipelines_with_configs = []
    for app_meta in official_apps_data:
        app_id = app_meta.get("id")
        if app_id in AVAILABLE_PIPELINES_AND_CONFIGS:
            # Sadece keşfedilenleri ekle
            available_pipelines_with_configs.append(app_meta)
    
    return available_pipelines_with_configs

# Yeni fonksiyon: Belirli bir pipeline'ın varsayılan konfigürasyonunu döndürür
def get_default_pipeline_config(pipeline_id: str) -> Dict[str, Any]:
    """Belirli bir pipeline'ın varsayılan konfigürasyonunu döndürür."""
    pipeline_info = AVAILABLE_PIPELINES_AND_CONFIGS.get(pipeline_id)
    if not pipeline_info:
        raise ValueError(f"Pipeline '{pipeline_id}' not found or its config function is missing.")
    
    get_config_func = pipeline_info.get('get_config_func')
    if not get_config_func:
        return {"message": "No specific default configuration available for this pipeline. Worker will use its internal defaults.", "pipeline_name": pipeline_id}

    return get_config_func()


def list_experiments() -> List[Dict[str, Any]]:
    """
    DÜZELTME: Artık her deney için results.json dosyasının tamamını döndürüyor.
    Bu, UI'ın genişletilebilir satırlarda tüm detayları göstermesini sağlar.
    """
    experiment_files = glob.glob(f"{REPORTS_BASE_DIR}/**/results.json", recursive=True)
    experiments = []
    for f_path in experiment_files:
        try:
            with open(f_path, 'r') as f:
                data = json.load(f)
                # Direkt olarak dosyanın içeriğini listeye ekle
                experiments.append(data)
        except Exception as e:
            print(f"Warning: Could not read results.json from {f_path}: {e}")
            continue
    
    # Sıralama: Önce çalışanlar, sonra en yeni tamamlananlar
    def sort_key(exp):
        status_order = {'STARTED': 1, 'PROGRESS': 2, 'PENDING': 3, 'UNKNOWN': 4, 'DISCONNECTED': 5, 'FAILURE': 6, 'ERROR': 7, 'SUCCESS': 8}
        status = exp.get('status', 'UNKNOWN')
        # Eğer canlı bir görevse, Celery'den anlık durumunu al. Bu, PENDING'den STARTED'a geçişi yakalar.
        if status in ['STARTED', 'PROGRESS', 'PENDING']:
             task = AsyncResult(exp.get('task_id'), app=celery_app)
             status = task.state
             exp['status'] = status # Deney objesini de anlık durumla güncelle
        
        timestamp = exp.get('completed_at') or exp.get('failed_at') or exp.get('config', {}).get('start_time', '1970-01-01T00:00:00')
        return (status_order.get(status, 99), timestamp)

    experiments.sort(key=sort_key, reverse=False) # Status'e göre artan, tarihe göre azalan sıralama için
    # reverse=False olacak ama sıralama anahtarını (timestamp) negatif yapmak aynı etkiyi verir.
    # En basit yol:
    experiments.sort(key=lambda x: x.get('config', {}).get('start_time', ''), reverse=True)
    
    return experiments


def start_experiment(config: Dict[str, Any]) -> Dict[str, Any]:
    pipeline_name = config.get("pipeline_name", "unknown")
    print(f"Service: Sending task for pipeline '{pipeline_name}' to Celery with config: {config}") # Logu güncellendi
    task = start_training_pipeline.delay(config) 
    return {"message": "Experiment submitted to worker.", "task_id": task.id}

def get_task_status(task_id: str) -> Dict[str, Any]:
    # Artık /experiments endpoint'i tüm veriyi döndürdüğü için bu endpoint'e olan ihtiyaç azalıyor.
    # Ama WebSocket'in ilk veri çekişi için hala değerli olabilir.
    task_result = AsyncResult(task_id, app=celery_app)
    status = task_result.state
    
    details = task_result.info 
    
    # Başarı durumunda, Celery result.result'ı doğrudan alıp gönder
    if status == 'SUCCESS':
        # Başarılı biten görevlerin rapor dosyasından okunmasını sağla
        # Bu, sayfa yenilense bile tüm verinin (özellikle loss geçmişinin) görünmesini garanti eder.
        matching_experiments = list_experiments()
        for exp in matching_experiments:
            if exp.get('task_id') == task_id: # task_id'yi de almanız gerekebilir list_experiments içinde
                return exp # Zaten gerekli tüm verileri içeren objeyi döndür

        # Eğer rapor dosyasından bulunamazsa, Celery sonucunu döndür
        return {"task_id": task_id, "status": status, "result": task_result.result}
    
    elif status == 'FAILURE':
        error_message = details.get('error_message', 'Bilinmeyen bir hata oluştu.')
        traceback_info = details.get('traceback', 'Detaylı hata izleme bilgisi yok.')
        
        # Kullanıcı dostu hata mesajı üretimi (örnek)
        user_friendly_message = "Deney eğitimi sırasında bir hata oluştu. Lütfen yapılandırmanızı kontrol edin veya AI modelinde bir sorun olabilir."
        if "yfinance.download" in error_message or "No data downloaded" in error_message:
            user_friendly_message = "Veri çekilirken bir sorun oluştu. Ticker sembolünü veya başlangıç tarihini kontrol edin."
        elif "Not enough data" in error_message:
            user_friendly_message = "Eğitim için yeterli veri bulunamadı. Lütfen daha uzun bir tarih aralığı seçin."
        elif "Pipeline execution failed" in error_message:
            user_friendly_message = "Pipeline'ın kendisi çalışırken bir hata ile karşılaştı. Detaylar için aşağıdaki teknik hata mesajını inceleyin."


        # Eğer rapor dosyasından bulunursa, hata bilgilerini oradan al.
        # Bu bölüm, önceki get_task_status'taki mantıkla çakışmaması için biraz daha dikkatli ele alınmalı.
        # En iyisi, task_id'ye göre rapor dosyasından full veriyi çekip, Celery'den sadece canlı durumu almak.
        # Şimdilik direkt Celery sonucunu zenginleştirelim.
        
        # Buradaki return, direkt Celery'den alınan 'FAILURE' state'indeki veriyi döndürür.
        # Rapor dosyasındaki "error" alanını burada "user_friendly_error" olarak ekleyebiliriz.
        return {
            "task_id": task_id, 
            "status": status, 
            "result": details, # Celery meta verisi (error_message, traceback içerir)
            "user_friendly_error": user_friendly_message
        }
    
    # PROGRESS, PENDING, STARTED gibi durumlar için
    return {"task_id": task_id, "status": status, "details": details}
========== FILE: api/src/azuraforge_api/services/__init__.py ==========

========== FILE: api/src/azuraforge_api/tasks/training_tasks.py ==========

========== FILE: api/src/azuraforge_api/tasks/__init__.py ==========

========== FILE: app-stock-predictor/pyproject.toml ==========
[build-system]
requires = ["setuptools>=61.0"]
build-backend = "setuptools.build_meta"

[project]
name = "azuraforge-app-stock-predictor"
version = "0.1.0"
description = "A stock prediction pipeline application for the AzuraForge platform."
requires-python = ">=3.8"
dependencies = [
    "azuraforge-learner @ git+https://github.com/AzuraForge/learner.git@main",
    "yfinance",
    "pandas",
    "scikit-learn",
    "PyYAML", # <-- YENİ BAĞIMLILIK
]

[project.entry-points]
# Var olan giriş noktası
"azuraforge.pipelines" = { stock_predictor = "azuraforge_stockapp.pipeline:StockPredictionPipeline" }

# --- YENİ GİRİŞ NOKTASI GRUBU ---
"azuraforge.configs" = { stock_predictor = "azuraforge_stockapp.pipeline:get_default_config" }

========== FILE: app-stock-predictor/README.md ==========
# app-stock-predictor

========== FILE: app-stock-predictor/setup.py ==========
from setuptools import setup, find_packages
setup(
    package_dir={"": "src"},
    packages=find_packages(where="src"),
    # DÜZELTME: Paket kurulduğunda .yml gibi Python dışı dosyaların da
    # kopyalanmasını sağlar. Bu, API ve Worker loglarındaki hatayı çözer.
    include_package_data=True, 
    package_data={
        # "azuraforge_stockapp" paketi içindeki tüm .yml dosyalarını dahil et.
        "azuraforge_stockapp": ["config/*.yml"], 
    },
)
========== FILE: app-stock-predictor/src/azuraforge_stockapp/pipeline.py ==========
import logging
import yfinance as yf
import numpy as np
from sklearn.preprocessing import MinMaxScaler
import os 
from typing import Any
import yaml
from importlib import resources # YENİ: Paket içi kaynak okumak için en güvenilir yol

from azuraforge_learner import Learner, Sequential, Linear, MSELoss, SGD, ReLU

def get_default_config():
    """
    Bu pipeline'ın varsayılan konfigürasyonunu bir Python sözlüğü olarak döndürür.
    DÜZELTME: importlib.resources kullanarak dosya okuma hatasını giderir.
    """
    try:
        # "azuraforge_stockapp.config" modülü içindeki dosyayı güvenli bir şekilde açar
        with resources.open_text("azuraforge_stockapp.config", "stock_predictor_config.yml") as f:
            config = yaml.safe_load(f)
        return config
    except (FileNotFoundError, ModuleNotFoundError, Exception) as e:
        logging.error(f"Error loading default config for stock_predictor: {e}", exc_info=True)
        return {"error": f"Could not load default config: {e}"}

class StockPredictionPipeline:
    def __init__(self, config: dict, celery_task: Any = None):
        self.celery_task = celery_task
        self.logger = logging.getLogger(self.__class__.__name__)
        logging.basicConfig(level="INFO", format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')

        # Gelen konfigürasyonu varsayılanın üzerine yazarak tam bir config oluştur
        default_config = get_default_config()
        if "error" in default_config:
            self.logger.error("Could not load default config. Using only provided config.")
            self.config = config
        else:
            # Derin birleştirme (nested dict'ler için)
            def deep_merge(source, destination):
                for key, value in source.items():
                    if isinstance(value, dict):
                        node = destination.setdefault(key, {})
                        deep_merge(value, node)
                    else:
                        destination[key] = value
                return destination
            
            # Önce varsayılanı al, sonra gelen config ile üzerine yaz
            merged_config = default_config.copy()
            self.config = deep_merge(config, merged_config)

    def run(self):
        data_sourcing_config = self.config.get("data_sourcing", {})
        training_params_config = self.config.get("training_params", {})
        
        ticker = data_sourcing_config.get("ticker", "MSFT")
        start_date = data_sourcing_config.get("start_date", "2021-01-01")
        epochs = int(training_params_config.get("epochs", 10)) # UI'dan string gelebilir, int'e çevir
        lr = float(training_params_config.get("lr", 0.01)) # UI'dan string gelebilir, float'a çevir

        self.logger.info(f"--- Running Stock Prediction Pipeline for {ticker} ({epochs} epochs, lr={lr}) ---")
        
        try:
            data = yf.download(ticker, start=start_date, progress=False, actions=False, auto_adjust=True)
            if data.empty:
                raise ValueError(f"No data downloaded for ticker: {ticker} from {start_date}")
            self.logger.info(f"Downloaded {len(data)} rows of data.")
            close_prices = data[['Close']].values.astype(np.float32)
        except Exception as e:
            self.logger.error(f"Data download failed for {ticker}: {e}")
            raise 

        scaler = MinMaxScaler(feature_range=(-1, 1))
        scaled_prices = scaler.fit_transform(close_prices)
        
        if len(scaled_prices) < 2:
            self.logger.warning("Not enough data to create sequences for training.")
            return {"status": "completed", "ticker": ticker, "final_loss": float('inf'), "message": "Not enough data for training"}

        X, y = scaled_prices[:-1], scaled_prices[1:]
        
        model = Sequential(Linear(1, 64), ReLU(), Linear(64, 1))
        criterion = MSELoss()
        optimizer = SGD(model.parameters(), lr=lr)
        
        learner = Learner(model, criterion, optimizer, current_task=self.celery_task)

        self.logger.info(f"Starting training for {epochs} epochs...")
        history = learner.fit(X, y, epochs=epochs)
        
        final_loss = history['loss'][-1]
        self.logger.info(f"Training complete. Final loss: {final_loss:.6f}")
        
        return {"status": "completed", "ticker": ticker, "final_loss": final_loss, "loss": history['loss']}
========== FILE: app-stock-predictor/src/azuraforge_stockapp/__init__.py ==========

========== FILE: app-stock-predictor/src/azuraforge_stockapp/config/stock_predictor_config.yml ==========
pipeline_name: "stock_predictor"

data_sourcing:
  ticker: "MSFT" # Microsoft
  start_date: "2021-01-01"

training_params:
  epochs: 10 # Test için kısa tutalım
  lr: 0.01

========== FILE: app-stock-predictor/src/azuraforge_stockapp/config/__init__.py ==========

========== FILE: applications/pyproject.toml ==========
[build-system]
requires = ["setuptools>=61.0"]
build-backend = "setuptools.build_meta"

[project]
name = "azuraforge-applications"
version = "0.1.0"
description = "A catalog of official applications for the AzuraForge platform."

========== FILE: applications/README.md ==========
# applications

========== FILE: applications/setup.py ==========
from setuptools import setup, find_packages

setup(
    package_dir={"": "src"},
    packages=find_packages(where="src"),
    # EN ÖNEMLİ KISIM: Paket kurulduğunda .json dosyasının da kopyalanmasını sağlar
    include_package_data=True, 
    package_data={
        "azuraforge_applications": ["*.json"], # "azuraforge_apps_catalog" -> "azuraforge_applications"
    },
)


========== FILE: applications/src/azuraforge_applications/official_apps.json ==========
[
  {
    "id": "stock_predictor",
    "name": "Hisse Senedi Fiyat Tahmini",
    "repository": "https://github.com/AzuraForge/app-stock-predictor",
    "description": "LSTM tabanlı hisse senedi fiyat tahmini yapar."
  },
  {
    "id": "weather_forecaster",
    "name": "Hava Durumu Tahmini",
    "repository": "https://github.com/AzuraForge/app-weather-forecaster",
    "description": "Gelecekteki hava durumunu tahmin eder (Henüz Geliştirilmedi)."
  }
]

========== FILE: applications/src/azuraforge_applications/__init__.py ==========


========== FILE: core/pyproject.toml ==========
[build-system]
requires = ["setuptools>=61.0"]
build-backend = "setuptools.build_meta"

[project]
name = "azuraforge-core"
version = "0.1.2"
authors = [{ name = "Azmi Sahin" }]
description = "The core automatic differentiation engine (Tensor object) for the AzuraForge ecosystem."
readme = "README.md"
requires-python = ">=3.8"
license = { text = "MIT" }
classifiers = ["Programming Language :: Python :: 3"]
dependencies = ["numpy"]

# --- YENİ BÖLÜM ---
[project.optional-dependencies]
dev = ["pytest"]

========== FILE: core/README.md ==========
# core

========== FILE: core/setup.py ==========
from setuptools import setup, find_packages
setup(
    package_dir={"": "src"},
    packages=find_packages(where="src"),
)

========== FILE: core/src/azuraforge_core/tensor.py ==========
import os
from typing import Callable, List, Optional, Set, Tuple, Union, Any, cast
import numpy as np

DEVICE = os.environ.get("AZURAFORGE_DEVICE", "cpu").lower()

xp: Any
if DEVICE == "gpu":
    try:
        import cupy
        xp = cupy
    except ImportError:
        import numpy
        xp = numpy
        DEVICE = "cpu"
else:
    import numpy
    xp = numpy

ArrayType = Any
ScalarType = Union[int, float, bool, np.number, xp.number]

def _empty_backward_op() -> None: pass

class Tensor:
    def __init__(self, data: Any, _children: Tuple["Tensor", ...] = (), _op: str = "", requires_grad: bool = False):
        if isinstance(data, Tensor): self.data = data.data.copy()
        else: self.data = xp.array(data, dtype=np.float64)
        
        self.requires_grad = requires_grad
        self.grad: Optional[ArrayType] = xp.zeros_like(self.data) if requires_grad else None
        self._backward: Callable[[], None] = _empty_backward_op
        self._prev: Set["Tensor"] = set(_children)
        self._op: str = _op

    def backward(self, grad_output: Optional[ArrayType] = None) -> None:
        if not self.requires_grad: return
        topo: List[Tensor] = []
        visited: Set[Tensor] = set()
        def build_topo(v):
            if v not in visited:
                visited.add(v); [build_topo(child) for child in v._prev]; topo.append(v)
        build_topo(self)
        for t in topo:
            if t.grad is not None: t.grad.fill(0.0)
        self.grad = xp.ones_like(self.data) if grad_output is None else xp.asarray(grad_output, dtype=np.float64).reshape(self.data.shape)
        for v in reversed(topo): v._backward()

    def to_cpu(self) -> np.ndarray:
        if hasattr(self.data, 'get'): return self.data.get()
        return np.array(self.data, copy=True)

    def __add__(self, other: Any) -> "Tensor":
        other = _ensure_tensor(other)
        out = Tensor(self.data + other.data, (self, other), "+", self.requires_grad or other.requires_grad)
        def _backward():
            if self.requires_grad: self.grad += _unbroadcast_to(self.data.shape, out.grad)
            if other.requires_grad: other.grad += _unbroadcast_to(other.data.shape, out.grad)
        out._backward = _backward
        return out

    def __mul__(self, other: Any) -> "Tensor":
        other = _ensure_tensor(other)
        out = Tensor(self.data * other.data, (self, other), "*", self.requires_grad or other.requires_grad)
        def _backward():
            if self.requires_grad: self.grad += _unbroadcast_to(self.data.shape, other.data * out.grad)
            if other.requires_grad: other.grad += _unbroadcast_to(other.data.shape, self.data * out.grad)
        out._backward = _backward
        return out

    def __pow__(self, power: float) -> "Tensor":
        out = Tensor(self.data ** power, (self,), f"**{power}", self.requires_grad)
        def _backward():
            if self.requires_grad: self.grad += (power * (self.data ** (power - 1))) * out.grad
        out._backward = _backward
        return out

    def dot(self, other: "Tensor") -> "Tensor":
        out = Tensor(self.data @ other.data, (self, other), "@", self.requires_grad or other.requires_grad)
        def _backward():
            if self.requires_grad: self.grad += out.grad @ other.data.T
            if other.requires_grad: other.grad += self.data.T @ out.grad
        out._backward = _backward
        return out

    def sum(self, axis=None, keepdims=False) -> "Tensor":
        out = Tensor(xp.sum(self.data, axis=axis, keepdims=keepdims), (self,), "sum", self.requires_grad)
        def _backward(_axis=axis, _keepdims=keepdims):
            if self.requires_grad and self.grad is not None:
                grad_val = out.grad
                if _axis is not None and not _keepdims:
                    grad_val = xp.expand_dims(grad_val, axis=_axis)
                self.grad += grad_val
        out._backward = _backward
        return out

    def mean(self, axis=None, keepdims=False) -> "Tensor":
        sum_val = self.sum(axis=axis, keepdims=keepdims)
        num_elements = float(np.prod(self.data.shape) / np.prod(sum_val.data.shape))
        return sum_val * (1.0 / num_elements)
    
    def relu(self) -> "Tensor":
        out = Tensor(xp.maximum(0, self.data), (self,), "ReLU", self.requires_grad)
        def _backward():
            if self.requires_grad: self.grad += (self.data > 0) * out.grad
        out._backward = _backward
        return out

    # YENİ: Sigmoid aktivasyon fonksiyonu
    def sigmoid(self) -> "Tensor":
        s = 1 / (1 + xp.exp(-self.data))
        out = Tensor(s, (self,), "Sigmoid", self.requires_grad)
        def _backward():
            if self.requires_grad: self.grad += out.data * (1 - out.data) * out.grad
        out._backward = _backward
        return out
        
    def __repr__(self): return f"Tensor(data={self.data}, requires_grad={self.requires_grad})"
    def __neg__(self): return self * -1
    def __sub__(self, other): return self + (-other)
    def __truediv__(self, other): return self * (_ensure_tensor(other) ** -1)
    __radd__ = __add__
    def __rmul__(self, other): return self * other
    def __rsub__(self, other): return _ensure_tensor(other) - self
    def __rtruediv__(self, other): return _ensure_tensor(other) / self

def _ensure_tensor(val: Any) -> "Tensor":
    return val if isinstance(val, Tensor) else Tensor(val)

def _unbroadcast_to(target_shape: Tuple[int, ...], grad: ArrayType) -> ArrayType:
    """Bir gradyanı, orijinal tensörün (yayınlamadan önceki) şekline geri küçültür."""
    if target_shape == grad.shape:
        return grad
    
    # Boyut sayısını eşitle
    ndim_diff = grad.ndim - len(target_shape)
    if ndim_diff > 0:
        grad = grad.sum(axis=tuple(range(ndim_diff)))

    # Boyutu 1 olan eksenler boyunca topla
    axes_to_sum = []
    for i, dim in enumerate(target_shape):
        if dim == 1:
            axes_to_sum.append(i)
    
    if axes_to_sum:
        grad = grad.sum(axis=tuple(axes_to_sum), keepdims=True)
        
    return grad
========== FILE: core/src/azuraforge_core/__init__.py ==========
from .tensor import Tensor, xp, DEVICE, ArrayType, ScalarType, _unbroadcast_to

__all__ = ["Tensor", "xp", "DEVICE", "ArrayType", "ScalarType", "_unbroadcast_to"]

========== FILE: core/tests/azuraforge_core/test_tensor.py ==========
import pytest
import numpy as np

# Test edilecek paketi import et
from azuraforge_core import Tensor

def test_tensor_creation_and_defaults():
    """Tensor nesnesinin doğru şekilde ve varsayılan değerlerle oluşturulduğunu test eder."""
    t = Tensor([1, 2, 3])
    assert isinstance(t.data, np.ndarray)
    assert t.requires_grad is False
    assert t.grad is None

def test_tensor_requires_grad():
    """`requires_grad=True` olduğunda gradyan dizisinin oluşturulduğunu test eder."""
    t = Tensor([1, 2], requires_grad=True)
    assert t.requires_grad is True
    assert isinstance(t.grad, np.ndarray)
    assert np.array_equal(t.grad, np.array([0.0, 0.0]))

def test_addition_backward():
    """Basit toplama işlemi için geri yayılımın doğru çalıştığını test eder."""
    a = Tensor([1, 2, 3], requires_grad=True)
    b = Tensor(5, requires_grad=True)
    
    # c = a.sum() + b  ->  dc/da = [1, 1, 1], dc/db = 1
    c = a.sum() + b
    
    c.backward()

    assert a.grad is not None
    assert b.grad is not None
    assert np.array_equal(a.grad, [1, 1, 1])
    assert b.grad == 1.0

def test_multiplication_backward():
    """Basit çarpma işlemi için geri yayılımın doğru çalıştığını test eder."""
    x = Tensor(2.0, requires_grad=True)
    y = Tensor(3.0, requires_grad=True)
    
    z = x * y
    
    z.backward() # dz/dx = y = 3,  dz/dy = x = 2

    assert x.grad == 3.0
    assert y.grad == 2.0

def test_chained_rule_backward():
    """Zincir kuralının birden çok işlemde doğru çalıştığını test eder."""
    x = Tensor(2.0, requires_grad=True)
    y = Tensor(3.0, requires_grad=True)

    z = x * y  # dz/dx = y, dz/dy = x
    q = z + x  # dq/dz = 1, dq/dx = 1
    
    # Zincir Kuralı:
    # dq/dx = (dq/dz * dz/dx) + dq/dx = (1 * y) + 1 = 3 + 1 = 4
    # dq/dy = (dq/dz * dz/dy) = 1 * x = 2
    q.backward()

    assert x.grad == 4.0
    assert y.grad == 2.0

def test_dot_product_backward():
    """Matris çarpımı için geri yayılımı test eder."""
    a_data = np.random.randn(2, 3)
    b_data = np.random.randn(3, 4)
    a = Tensor(a_data, requires_grad=True)
    b = Tensor(b_data, requires_grad=True)
    
    c = a.dot(b)
    
    # Gradyanı 1'lerden oluşan bir matrisle başlat
    c.backward(np.ones_like(c.data))
    
    # Manuel olarak hesaplanan gradyanlar
    grad_a_manual = np.ones_like(c.data) @ b_data.T
    grad_b_manual = a_data.T @ np.ones_like(c.data)
    
    assert np.allclose(a.grad, grad_a_manual)
    assert np.allclose(b.grad, grad_b_manual)


def test_relu_backward():
    """ReLU aktivasyonu için geri yayılımı test eder."""
    a = Tensor([-1, 0, 5], requires_grad=True)
    r = a.relu()
    r.backward(np.array([10, 20, 30]))

    # Gradyan sadece pozitif değerler için akar (self.data > 0)
    assert np.array_equal(a.grad, [0, 0, 30])

========== FILE: dashboard/eslint.config.js ==========
import js from '@eslint/js'
import globals from 'globals'
import reactHooks from 'eslint-plugin-react-hooks'
import reactRefresh from 'eslint-plugin-react-refresh'
import { defineConfig, globalIgnores } from 'eslint/config'

export default defineConfig([
  globalIgnores(['dist']),
  {
    files: ['**/*.{js,jsx}'],
    extends: [
      js.configs.recommended,
      reactHooks.configs['recommended-latest'],
      reactRefresh.configs.vite,
    ],
    languageOptions: {
      ecmaVersion: 2020,
      globals: globals.browser,
      parserOptions: {
        ecmaVersion: 'latest',
        ecmaFeatures: { jsx: true },
        sourceType: 'module',
      },
    },
    rules: {
      'no-unused-vars': ['error', { varsIgnorePattern: '^[A-Z_]' }],
    },
  },
])

========== FILE: dashboard/index.html ==========
<!doctype html>
<html lang="tr">
  <head>
    <meta charset="UTF-8" />
    <link rel="icon" type="image/svg+xml" href="/favicon.svg" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>AzuraForge | MLOps Dashboard</title>
  </head>
  <body>
    <div id="root"></div>
    <script type="module" src="/src/main.jsx"></script>
  </body>
</html>
========== FILE: dashboard/package.json ==========
{
  "name": "dashboard",
  "private": true,
  "version": "0.0.0",
  "type": "module",
  "scripts": {
    "dev": "vite",
    "build": "vite build",
    "lint": "eslint .",
    "preview": "vite preview"
  },
  "dependencies": {
    "@fontsource/inter": "^5.2.6",
    "axios": "^1.10.0",
    "chart.js": "^4.5.0",
    "chartjs-plugin-annotation": "^3.1.0",
    "chartjs-plugin-zoom": "^2.2.0",
    "prop-types": "^15.8.1",
    "react": "^19.1.0",
    "react-chartjs-2": "^5.3.0",
    "react-dom": "^19.1.0",
    "react-router-dom": "^7.6.3",
    "react-toastify": "^11.0.5"
  },
  "devDependencies": {
    "@eslint/js": "^9.30.0",
    "@types/react": "^19.1.8",
    "@types/react-dom": "^19.1.6",
    "@vitejs/plugin-react": "^4.6.0",
    "eslint": "^9.30.0",
    "eslint-plugin-react-hooks": "^5.2.0",
    "eslint-plugin-react-refresh": "^0.4.20",
    "globals": "^16.2.0",
    "npm-check-updates": "^18.0.1",
    "vite": "^7.0.0"
  }
}

========== FILE: dashboard/README.md ==========
# React + Vite

This template provides a minimal setup to get React working in Vite with HMR and some ESLint rules.

Currently, two official plugins are available:

- [@vitejs/plugin-react](https://github.com/vitejs/vite-plugin-react/blob/main/packages/plugin-react) uses [Babel](https://babeljs.io/) for Fast Refresh
- [@vitejs/plugin-react-swc](https://github.com/vitejs/vite-plugin-react/blob/main/packages/plugin-react-swc) uses [SWC](https://swc.rs/) for Fast Refresh

## Expanding the ESLint configuration

If you are developing a production application, we recommend using TypeScript with type-aware lint rules enabled. Check out the [TS template](https://github.com/vitejs/vite/tree/main/packages/create-vite/template-react-ts) for information on how to integrate TypeScript and [`typescript-eslint`](https://typescript-eslint.io) in your project.

========== FILE: dashboard/vite.config.js ==========
import { defineConfig } from 'vite'
import react from '@vitejs/plugin-react'

// https://vite.dev/config/
export default defineConfig({
  plugins: [react()],
})

========== FILE: dashboard/src/App.css ==========
/* ==========================================================================
   1. KÖK DEĞİŞKENLER (Tasarım Sistemi)
   ========================================================================== */
:root {
  /* Koyu Tema (Varsayılan) */
  --primary-color: #42b983; --primary-color-dark: #369c70; --secondary-color: #3b82f6;
  --text-color: #e2e8f0; --text-color-darker: #94a3b8; --text-inverse: #ffffff;
  --bg-color: #0f172a; --content-bg: #1e293b; --border-color: #334155; --hover-bg: #2a3a52;
  --success-color: #22c55e; --error-color: #ef4444; --warning-color: #f59e0b; --info-color: #3b82f6;
  --font-sans: 'Inter', system-ui, sans-serif; --font-mono: ui-monospace, Menlo, monospace;
  --shadow-md: 0 4px 6px -1px rgb(0 0 0 / 0.1), 0 2px 4px -2px rgb(0 0 0 / 0.1);
  --shadow-lg: 0 10px 15px -3px rgb(0 0 0 / 0.1), 0 4px 6px -2px rgb(0 0 0 / 0.1);
  --border-radius: 12px;
}
body.light-theme {
  /* Açık Tema */
  --text-color: #1e293b; --text-color-darker: #475569; --bg-color: #f8fafc;
  --content-bg: #ffffff; --border-color: #e2e8f0; --hover-bg: #f1f5f9;
  --success-color: #16a34a; --error-color: #dc2626; --warning-color: #d97706; --info-color: #2563eb;
}
/* ==========================================================================
   2. TEMEL RESET VE GLOBAL STİLLER
   ========================================================================== */
*, *::before, *::after { box-sizing: border-box; }
body {
  margin: 0; font-family: var(--font-sans); background-color: var(--bg-color); color: var(--text-color);
  font-synthesis: none; text-rendering: optimizeLegibility; -webkit-font-smoothing: antialiased;
  transition: background-color 0.3s, color 0.3s;
}
#root, .app-layout { display: flex; width: 100vw; height: 100vh; overflow: hidden; }
/* ==========================================================================
   3. ANA YAPI (Layout)
   ========================================================================== */
.sidebar {
  width: 260px; background-color: var(--content-bg); border-right: 1px solid var(--border-color);
  padding: 20px; display: flex; flex-direction: column; flex-shrink: 0;
  transition: background-color 0.3s, border-color 0.3s, width 0.3s ease; z-index: 2000;
}
.sidebar nav ul { list-style: none; padding: 0; margin: 0; }
.sidebar nav a {
  display: flex; align-items: center; gap: 15px; padding: 12px 15px; text-decoration: none;
  color: var(--text-color-darker); border-radius: 8px; margin-bottom: 8px;
  transition: background-color 0.2s ease, color 0.2s ease; font-weight: 500;
}
.sidebar nav a:hover { background-color: var(--hover-bg); color: var(--text-color); }
.sidebar nav a.active { background-color: var(--primary-color); color: var(--text-inverse); font-weight: 600; }
.main-content { flex-grow: 1; padding: 30px; overflow-y: auto; position: relative; }
.page-header { margin-bottom: 30px; }
.page-header h1 {
  font-size: 2.2em; font-weight: 700; color: var(--text-color); margin: 0 0 5px 0;
  display: flex; align-items: center; gap: 15px; transition: color 0.3s;
}
.page-header p { color: var(--text-color-darker); font-size: 1.1em; margin: 0; }
/* ==========================================================================
   4. LOGO VE TEMA DEĞİŞTİRME
   ========================================================================== */
.logo-container {
  display: flex; align-items: center; justify-content: flex-start; gap: 12px;
  margin-bottom: 40px; padding: 0 10px;
}
.logo-container h1 {
  color: var(--text-color); font-size: 1.6em; font-weight: 600; margin: 0;
  letter-spacing: 0.5px; transition: color 0.3s;
}
.theme-toggle-button {
  background-color: var(--bg-color); color: var(--text-color-darker); border: 1px solid var(--border-color);
  border-radius: 8px; padding: 8px; cursor: pointer; display: flex; align-items: center;
  justify-content: center; margin-top: 20px; transition: all 0.2s ease;
}
.theme-toggle-button:hover { border-color: var(--primary-color); color: var(--primary-color); }
/* ==========================================================================
   5. BİLEŞENLER (Components)
   ========================================================================== */
.card, .table-container, .form-container, .pipeline-details {
  background-color: var(--content-bg); border: 1px solid var(--border-color);
  border-radius: var(--border-radius); box-shadow: var(--shadow-md);
  transition: background-color 0.3s, border-color 0.3s;
}
.table-container { padding: 0; }
.card { padding: 25px; }
.button-primary {
  background-color: var(--primary-color); color: var(--text-inverse); padding: 10px 20px; border: none;
  border-radius: 8px; cursor: pointer; font-size: 1em; font-weight: 600;
  transition: background-color 0.2s ease, transform 0.2s ease; display: inline-flex;
  align-items: center; gap: 8px;
}
.button-primary:hover:not(:disabled) { background-color: var(--primary-color-dark); transform: translateY(-2px); }
.button-primary:disabled { background-color: var(--border-color); cursor: not-allowed; opacity: 0.6; transform: none; }
.status-badge {
  display: inline-flex; align-items: center; gap: 6px; padding: 4px 12px; border-radius: 9999px;
  font-size: 0.8em; font-weight: 600; text-transform: uppercase; justify-content: center;
}
.status-badge::before { content: ''; display: inline-block; width: 8px; height: 8px; border-radius: 50%; }
.status-badge.status-started, .status-badge.status-progress, .status-badge.status-connecting { background-color: rgba(59, 130, 246, 0.2); color: #60a5fa; }
.status-badge.status-started::before, .status-badge.status-progress::before, .status-badge.status-connecting::before { background-color: var(--info-color); animation: pulse 2s infinite; }
@keyframes pulse { 0%, 100% { opacity: 1; } 50% { opacity: 0.5; } }
.status-badge.status-success { background-color: rgba(34, 197, 94, 0.2); color: #4ade80; }
.status-badge.status-success::before { background-color: var(--success-color); }
.status-badge.status-failure, .status-badge.status-error { background-color: rgba(239, 68, 68, 0.2); color: #f87171; }
.status-badge.status-failure::before, .status-badge.status-error::before { background-color: var(--error-color); }
.status-badge.status-pending, .status-badge.status-unknown, .status-badge.status-disconnected { background-color: rgba(148, 163, 184, 0.2); color: var(--text-color-darker); }
.status-badge.status-pending::before, .status-badge.status-unknown::before, .status-badge.status-disconnected::before { background-color: var(--text-color-darker); }
.form-group { margin-bottom: 20px; }
.form-group label { display: block; margin-bottom: 8px; font-weight: 500; color: var(--text-color-darker); }
.form-group input, .form-group select {
  width: 100%; padding: 12px; background-color: var(--bg-color); border: 1px solid var(--border-color);
  border-radius: 8px; color: var(--text-color); font-size: 1em; font-family: var(--font-sans);
  transition: background-color 0.3s, border-color 0.3s, color 0.3s;
}
.form-group input:focus, .form-group select:focus {
  outline: none; border-color: var(--primary-color); box-shadow: 0 0 0 2px color-mix(in srgb, var(--primary-color) 30%, transparent);
}
table { width: 100%; border-collapse: collapse; }
table th, table td { padding: 12px 20px; text-align: left; border-bottom: 1px solid var(--border-color); vertical-align: middle; transition: border-color 0.3s; }
table th {
  background-color: var(--bg-color); color: var(--text-color-darker); font-weight: 600;
  text-transform: uppercase; font-size: 0.8em; letter-spacing: 0.5px;
  transition: background-color 0.3s, color 0.3s;
}
table tbody tr:hover { background-color: var(--hover-bg); }
table tbody tr.selected-row { background-color: color-mix(in srgb, var(--primary-color) 10%, transparent); border-left: 3px solid var(--primary-color); }
.actions-cell { position: relative; text-align: right !important; }
.actions-button {
  background: none; border: none; font-size: 24px; line-height: 1; color: var(--text-color-darker);
  cursor: pointer; border-radius: 4px; padding: 0 8px;
}
.actions-button:hover { background-color: var(--border-color); color: var(--text-color); }
.actions-menu {
  position: absolute; right: 20px; top: 50px; background-color: var(--hover-bg); border: 1px solid var(--border-color);
  border-radius: 8px; box-shadow: var(--shadow-lg); z-index: 100; display: flex;
  flex-direction: column; padding: 8px; min-width: 180px;
}
.actions-menu button {
  background: none; border: none; color: var(--text-color); padding: 10px 15px; text-align: left;
  cursor: pointer; border-radius: 6px; display: flex; align-items: center; gap: 10px; font-size: 0.9em;
}
.actions-menu button:hover { background-color: var(--secondary-color); color: var(--text-inverse); }
/* ==========================================================================
   6. ÖZEL PANELLER VE MODALLAR
   ========================================================================== */
.live-tracker-pane {
  position: sticky; top: -30px; z-index: 1000; margin: -30px -30px 30px -30px;
  padding: 20px 30px; background: color-mix(in srgb, var(--content-bg) 70%, transparent);
  backdrop-filter: blur(10px); -webkit-backdrop-filter: blur(10px);
  border-bottom: 1px solid var(--border-color); box-shadow: var(--shadow-lg);
}
.comparison-modal-overlay {
  position: fixed; top: 0; left: 0; right: 0; bottom: 0;
  background-color: color-mix(in srgb, var(--bg-color) 70%, transparent); backdrop-filter: blur(8px);
  z-index: 5000; display: flex; align-items: center; justify-content: center;
}
.comparison-modal-content {
  background-color: var(--bg-color); border: 1px solid var(--border-color); border-radius: 16px;
  width: 90%; max-width: 1200px; height: 90vh; box-shadow: var(--shadow-lg);
  display: flex; flex-direction: column;
}
.comparison-header {
  display: flex; justify-content: space-between; align-items: center; padding: 20px 30px;
  border-bottom: 1px solid var(--border-color); flex-shrink: 0;
}
.comparison-header h2 { margin: 0; font-size: 1.5em; }
.close-button {
  background: none; border: none; font-size: 24px; color: var(--text-color-darker);
  cursor: pointer; transition: color 0.2s;
}
.close-button:hover { color: var(--text-color); }
.comparison-body {
  padding: 30px; flex-grow: 1; overflow-y: auto; display: flex;
  flex-direction: column; gap: 30px;
}
.comparison-chart-container { height: 400px; min-height: 300px; width: 100%; position: relative; }
.chart-instructions {
  position: absolute; bottom: 5px; right: 10px; font-size: 0.75em;
  color: var(--text-color-darker); background-color: color-mix(in srgb, var(--content-bg) 80%, transparent);
  padding: 2px 8px; border-radius: 4px; opacity: 0.7;
}
.color-indicator {
  display: inline-block; width: 12px; height: 12px; border-radius: 50%;
  margin-right: 10px; vertical-align: middle;
}
/* ==========================================================================
   7. ÜÇÜNCÜ PARTİ KÜTÜPHANE STİLLERİ
   ========================================================================== */
.Toastify__toast {
  background-color: var(--content-bg) !important; color: var(--text-color) !important;
  border: 1px solid var(--border-color) !important; border-radius: 8px !important;
  font-family: var(--font-sans) !important;
}
.Toastify__progress-bar { background: var(--primary-color) !important; }
.Toastify__close-button { color: var(--text-color) !important; }

/* ==========================================================================
   8. YENİ DENEY SAYFASI ÖZEL STİLLERİ
   ========================================================================== */

.new-experiment-layout {
  display: flex;
  flex-direction: column;
  height: 100%; /* Ana konteynerin tüm yüksekliği kaplaması için */
}

.new-experiment-form {
  flex-grow: 1; /* Kalan tüm alanı kapla */
  display: flex;
  flex-direction: column;
  overflow: hidden; /* İçerik taşmasını engelle */
  border-radius: var(--border-radius);
  background-color: var(--content-bg);
  border: 1px solid var(--border-color);
}

.form-main-content {
  flex-grow: 1;
  overflow-y: auto; /* Sadece bu alan kaydırılabilir olacak */
  padding: 25px;
  display: flex;
  flex-direction: column;
  gap: 25px;
}

.form-action-bar {
  flex-shrink: 0; /* Bu panelin küçülmesini engelle */
  padding: 15px 25px;
  background-color: var(--bg-color);
  border-top: 1px solid var(--border-color);
  display: flex;
  justify-content: space-between;
  align-items: center;
  transition: background-color 0.3s, border-color 0.3s;
}

.pipeline-info {
  display: flex;
  align-items: center;
  gap: 10px;
  color: var(--text-color-darker);
}
.pipeline-info span {
  font-weight: 600;
  color: var(--text-color);
}

/* Form içindeki iç içe gruplar için daha iyi stiller */
.form-fieldset {
  border: 1px solid var(--border-color);
  border-radius: 8px;
  padding: 20px;
  margin: 0 0 20px 0;
}
.form-fieldset legend {
  padding: 0 10px;
  font-weight: 600;
  color: var(--text-color);
}
========== FILE: dashboard/src/App.jsx ==========
import { useState, useContext } from 'react';
import { Routes, Route, Link, useNavigate, useLocation } from 'react-router-dom';
import { ToastContainer } from 'react-toastify';
import 'react-toastify/dist/ReactToastify.css';

import './App.css'; 
import { ThemeContext } from './context/ThemeContext';
import NewExperiment from './pages/NewExperiment';
import DashboardOverview from './pages/DashboardOverview';
import LiveTrackerPane from './components/LiveTrackerPane';
import Logo from './components/Logo';
import ThemeToggle from './components/ThemeToggle';

function App() {
  const [trackingTaskId, setTrackingTaskId] = useState(null);
  const navigate = useNavigate();
  const location = useLocation();
  const { theme } = useContext(ThemeContext);

  const handleExperimentStarted = (taskId) => {
    if (taskId) setTrackingTaskId(taskId);
  };
  
  const handleCloseTracker = () => {
    setTrackingTaskId(null);
  };

  const isActive = (path) => {
    if (path === '/' && (location.pathname === '/' || location.pathname.startsWith('/experiments'))) return true;
    return location.pathname === path;
  };

  return (
    <div className="app-layout">
      <ToastContainer position="bottom-right" autoClose={5000} theme={theme} />
      <aside className="sidebar">
        <Logo />
        <nav style={{ flexGrow: 1 }}>
          <ul>
            <li><Link to="/" className={isActive('/') ? 'active' : ''}><span role="img" aria-label="dashboard">📊</span><span>Genel Bakış</span></Link></li>
            <li><Link to="/new-experiment" className={isActive('/new-experiment') ? 'active' : ''}><span role="img" aria-label="rocket">🚀</span><span>Yeni Deney</span></Link></li>
          </ul>
        </nav>
        <ThemeToggle />
      </aside>
      <main className="main-content">
        {trackingTaskId && <LiveTrackerPane taskId={trackingTaskId} onClose={handleCloseTracker} />}
        <Routes>
          <Route path="/" element={<DashboardOverview onNewExperimentClick={() => navigate('/new-experiment')} setTrackingTaskId={setTrackingTaskId} />} />
          <Route path="/new-experiment" element={<NewExperiment onExperimentStarted={handleExperimentStarted} />} />
        </Routes>
      </main>
    </div>
  );
}

export default App;
========== FILE: dashboard/src/index.css ==========
/*
  Bu dosya, gelecekte çok temel, uygulama geneli reset kuralları için kullanılabilir.
  Şimdilik, projenin tüm özel stil mantığı App.css dosyasında merkezileştirilmiştir.
*/
========== FILE: dashboard/src/main.jsx ==========
import React from 'react';
import { createRoot } from 'react-dom/client';
import { BrowserRouter } from 'react-router-dom';
import { ThemeProvider } from './context/ThemeContext';

// Fontsource
import '@fontsource/inter/400.css';
import '@fontsource/inter/500.css';
import '@fontsource/inter/600.css';
import '@fontsource/inter/700.css';

// Stil dosyaları
import './index.css'; 
import './App.css';
import App from './App.jsx';

createRoot(document.getElementById('root')).render(
  // StrictMode'u bilinçli olarak kapalı tutuyoruz
  // <React.StrictMode>
    <ThemeProvider>
      <BrowserRouter> 
        <App />
      </BrowserRouter>
    </ThemeProvider>
  // </React.StrictMode>
);
========== FILE: dashboard/src/components/ComparisonView.jsx ==========
// Bu dosyanın içeriği önceki cevaptaki ile aynı, tam halini tekrar veriyorum
import PropTypes from 'prop-types';
import { Line } from 'react-chartjs-2';
import { Chart as ChartJS, CategoryScale, LinearScale, PointElement, LineElement, Title, Tooltip, Legend } from 'chart.js';
import zoomPlugin from 'chartjs-plugin-zoom';

ChartJS.register(CategoryScale, LinearScale, PointElement, LineElement, Title, Tooltip, Legend, zoomPlugin);

const chartColors = ['#42b983', '#3b82f6', '#ef4444', '#f59e0b', '#8b5cf6', '#ec4899'];

function ComparisonView({ experiments, onClose }) {
  const chartData = {
    labels: Array.from({ length: Math.max(...experiments.map(e => e.results?.loss?.length || 0)) }, (_, i) => `E${i + 1}`),
    datasets: experiments.map((exp, i) => ({
      label: `${exp.config.data_sourcing.ticker} (${exp.experiment_id.slice(-6)})`,
      data: exp.results?.loss || [],
      borderColor: chartColors[i % chartColors.length],
      backgroundColor: `${chartColors[i % chartColors.length]}33`,
      tension: 0.1, fill: false, borderWidth: 2, pointRadius: 1, pointHoverRadius: 5,
    })),
  };

  const chartOptions = {
      responsive: true, maintainAspectRatio: false,
      interaction: { mode: 'index', intersect: false, },
      plugins: { 
        legend: { position: 'top', labels: { font: { size: 14 } } },
        tooltip: {
          backgroundColor: 'var(--content-bg)',
          borderColor: 'var(--border-color)',
          borderWidth: 1,
        },
        zoom: {
          pan: { enabled: true, mode: 'xy', modifierKey: 'alt', },
          zoom: { wheel: { enabled: true }, pinch: { enabled: true }, mode: 'xy' }
        }
      },
      scales: {
          y: { title: { display: true, text: 'Kayıp Değeri (Loss)' }, beginAtZero: false, }, 
          x: { title: { display: true, text: 'Epoch' }, grid: { display: false } } 
      }
  };

  return (
    <div className="comparison-modal-overlay" onClick={onClose}>
      <div className="comparison-modal-content" onClick={e => e.stopPropagation()}>
        <div className="comparison-header">
          <h2>Deney Karşılaştırması ({experiments.length} adet)</h2>
          <button className="close-button" onClick={onClose}>×</button>
        </div>
        <div className="comparison-body">
          <div className="comparison-chart-container">
            <Line data={chartData} options={chartOptions} />
            <p className="chart-instructions">Yakınlaştırmak için fare tekerleğini kullanın. Sıfırlamak için çift tıklayın. Kaydırmak için <strong>Alt + Sürükle</strong>.</p>
          </div>
          <h4 className="section-title" style={{ marginTop: 0 }}>Özet Tablosu</h4>
          <div className="table-container">
            <table>
              <thead><tr><th>Deney ID</th><th>Ticker</th><th>Epochs</th><th>LR</th><th>Final Kayıp</th></tr></thead>
              <tbody>
                {experiments.map((exp, i) => (
                  <tr key={exp.experiment_id}>
                    <td><span className="color-indicator" style={{backgroundColor: chartColors[i % chartColors.length]}}></span>{exp.experiment_id.slice(0, 18)}...</td>
                    <td>{exp.config.data_sourcing.ticker}</td>
                    <td>{exp.config.training_params.epochs}</td>
                    <td>{exp.config.training_params.lr}</td>
                    <td>{exp.results.final_loss?.toFixed(6) ?? 'N/A'}</td>
                  </tr>
                ))}
              </tbody>
            </table>
          </div>
        </div>
      </div>
    </div>
  );
}
ComparisonView.propTypes = { experiments: PropTypes.array.isRequired, onClose: PropTypes.func.isRequired, };
export default ComparisonView;
========== FILE: dashboard/src/components/ExperimentRow.jsx ==========
// Bu dosyanın içeriği de önceki cevaptaki ile aynı, tam halini tekrar veriyorum
import { useState } from 'react';
import PropTypes from 'prop-types';
import { toast } from 'react-toastify';

const Icon = ({ path }) => <svg width="16" height="16" viewBox="0 0 24 24" fill="currentColor" xmlns="http://www.w3.org/2000/svg"><path d={path} /></svg>;
Icon.propTypes = { path: PropTypes.string.isRequired };

const ICONS = {
  rerun: "M12 4V1L8 5l4 4V6c3.31 0 6 2.69 6 6s-2.69 6-6 6-6-2.69-6-6H4c0 4.42 3.58 8 8 8s8-3.58 8-8-3.58-8-8-8z",
  copy: "M16 1H4c-1.1 0-2 .9-2 2v14h2V3h12V1zm3 4H8c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h11c1.1 0 2-.9 2-2V7c0-1.1-.9-2-2-2zm0 16H8V7h11v14z",
  satellite: "M6.34 5.34L4.93 3.93l-1.41 1.41 1.41 1.41C3.89 7.79 3.5 9.05 3.5 10.41c0 .46.06.91.16 1.34l-2.48 1.43c-.22.13-.34.38-.34.65v1.14c0 .27.11.52.34.65l2.48 1.43c-.1.43-.16.88-.16 1.34 0 2.21 1.79 4 4 4s4-1.79 4-4c0-1.37-.69-2.63-1.76-3.34l1.41-1.41-1.41-1.41-1.41 1.41C9.11 6.1 9.5 4.95 9.5 3.59c0-.46-.06-.91-.16-1.34l2.48-1.43c.22-.13.34-.38.34-.65V-.98c0-.27-.11-.52-.34-.65L9.34.8c.1-.43.16-.88.16-1.34 0-2.21-1.79-4-4-4s-4 1.79-4 4c0 1.37.69 2.63 1.76 3.34zm.24 9.35l-1.24-.71c.12-.52.19-1.06.19-1.61s-.07-1.09-.19-1.61l1.24-.71C7.58 10.9 8.5 12.05 8.5 13.41s-.92 2.51-1.92 3.28zM12 17.5c-2.21 0-4-1.79-4-4s1.79-4 4-4 4 1.79 4 4-1.79 4-4 4z",
};

function ExperimentRow({ experiment, isSelected, onSelect, onReRun, setTrackingTaskId }) {
  const [actionsOpen, setActionsOpen] = useState(false);
  const { experiment_id, status, config, results, completed_at, failed_at, task_id } = experiment;

  const handleCopyConfig = () => {
    navigator.clipboard.writeText(JSON.stringify(config, null, 2));
    toast.success('Konfigürasyon panoya kopyalandı!');
    setActionsOpen(false);
  };
  const isRunning = ['STARTED', 'PROGRESS', 'PENDING'].includes(status);
  return (
    <tr className={isSelected ? 'selected-row' : ''}>
      <td><input type="checkbox" checked={isSelected} onChange={onSelect} title="Karşılaştırmak için seç"/></td>
      <td><span className={`status-badge status-${status?.toLowerCase() || 'unknown'}`}>{status || 'Bilinmiyor'}</span></td>
      <td><div className="detail-cell"><strong>{config?.pipeline_name || 'N/A'}</strong><span className="exp-id">{experiment_id}</span></div></td>
      <td><div className="detail-cell"><span>Ticker: <strong>{config?.data_sourcing?.ticker || 'N/A'}</strong></span><span>Epochs: <strong>{config?.training_params?.epochs || 'N/A'}</strong>, LR: <strong>{config?.training_params?.lr || 'N/A'}</strong></span></div></td>
      <td><div className="detail-cell"><span>Final Kayıp: <strong>{results?.final_loss !== undefined ? results.final_loss.toFixed(6) : 'N/A'}</strong></span></div></td>
      <td><div className="detail-cell"><span>Başlangıç: {new Date(config.start_time).toLocaleString()}</span><span>Bitiş: {completed_at || failed_at ? new Date(completed_at || failed_at).toLocaleString() : 'N/A'}</span></div></td>
      <td className="actions-cell">
        <button className="actions-button" onClick={() => setActionsOpen(!actionsOpen)}>⋮</button>
        {actionsOpen && (
          <div className="actions-menu" onMouseLeave={() => setActionsOpen(false)}>
            {isRunning && <button onClick={() => { setTrackingTaskId(task_id); setActionsOpen(false); }}><Icon path={ICONS.satellite} /> Canlı İzle</button>}
            <button onClick={() => { onReRun(); setActionsOpen(false); }}><Icon path={ICONS.rerun} /> Yeniden Çalıştır</button>
            <button onClick={handleCopyConfig}><Icon path={ICONS.copy} /> Config'i Kopyala</button>
          </div>
        )}
      </td>
    </tr>
  );
}
ExperimentRow.propTypes = { experiment: PropTypes.object.isRequired, isSelected: PropTypes.bool.isRequired, onSelect: PropTypes.func.isRequired, onReRun: PropTypes.func.isRequired, setTrackingTaskId: PropTypes.func.isRequired, };
export default ExperimentRow;
========== FILE: dashboard/src/components/ExperimentsList.jsx ==========
import PropTypes from 'prop-types';
import ExperimentRow from './ExperimentRow';

function ExperimentsList({ experiments, selectedIds, onSelect, onReRun, setTrackingTaskId }) {
  if (!experiments || experiments.length === 0) {
    return <p style={{textAlign: 'center', padding: '20px'}}>Filtrelerinize uyan bir deney bulunamadı.</p>;
  }
  return (
    <div className="table-container">
      <table>
        <thead>
          <tr>
            <th style={{width: '40px'}}></th>
            <th>Durum</th>
            <th>Deney Detayları</th>
            <th>Parametreler</th>
            <th>Sonuçlar</th>
            <th>Zamanlama</th>
            <th style={{width: '50px'}}>Aksiyon</th>
          </tr>
        </thead>
        <tbody>
          {experiments.map((exp) => (
            <ExperimentRow 
              key={exp.experiment_id} 
              experiment={exp} 
              isSelected={selectedIds.has(exp.experiment_id)}
              onSelect={() => onSelect(exp.experiment_id)}
              onReRun={() => onReRun(exp.config)}
              setTrackingTaskId={setTrackingTaskId}
            />
          ))}
        </tbody>
      </table>
    </div>
  );
}
ExperimentsList.propTypes = { experiments: PropTypes.array.isRequired, selectedIds: PropTypes.object.isRequired, onSelect: PropTypes.func.isRequired, onReRun: PropTypes.func.isRequired, setTrackingTaskId: PropTypes.func.isRequired, };
export default ExperimentsList;
========== FILE: dashboard/src/components/LiveTrackerPane.jsx ==========
import { useState, useEffect, useRef, useMemo } from 'react';
import PropTypes from 'prop-types';
import { Line } from 'react-chartjs-2';
import { Chart } from 'chart.js';
import 'chart.js/auto';
import { getCssVar } from '../utils/cssUtils';

// Sabit başlangıç durumları
const initialStatus = { 
  state: 'CONNECTING', 
  details: { status_text: 'Worker\'a bağlanılıyor...' }
};

function LiveTrackerPane({ taskId, onClose }) {
  // Tek bir state objesi
  const [liveData, setLiveData] = useState({ 
    status: initialStatus,
    chart: { labels: [], datasets: [{ data: [] }] } // Başlangıçta boş
  });
  
  const socketRef = useRef(null);
  
  const chartOptions = useMemo(() => {
    return {
      responsive: true, maintainAspectRatio: false,
      animation: { duration: 300, easing: 'linear' },
      plugins: { 
        legend: { display: false }, 
        tooltip: {
          enabled: true, backgroundColor: getCssVar('--content-bg'),
          titleColor: getCssVar('--text-color'), bodyColor: getCssVar('--text-color'),
          borderColor: getCssVar('--border-color'), borderWidth: 1, padding: 10,
          displayColors: false,
          callbacks: {
            title: (ctx) => ctx[0].label,
            label: (ctx) => `Kayıp: ${ctx.parsed.y.toFixed(6)}`,
          }
        },
      },
      scales: { 
        y: { 
          grid: { color: getCssVar('--border-color'), borderDash: [2, 4], drawTicks: false },
          ticks: { padding: 10, maxTicksLimit: 5, font: { size: 12 }, color: getCssVar('--text-color-darker') },
        }, 
        x: {
          grid: { display: false },
          ticks: { padding: 10, maxRotation: 0, autoSkip: true, maxTicksLimit: 7, font: { size: 12 }, color: getCssVar('--text-color-darker') },
        } 
      }
    };
  }, []);

  useEffect(() => {
    if (!taskId) return;

    // YENİ: Başlangıç chart state'ini renklerle birlikte burada ayarla
    const initialChartWithColors = {
      labels: [],
      datasets: [{
        label: 'Eğitim Kaybı', data: [], fill: true,
        borderColor: getCssVar('--primary-color'),
        backgroundColor: `color-mix(in srgb, ${getCssVar('--primary-color')} 20%, transparent)`,
        tension: 0.4, borderWidth: 2,
        pointRadius: (ctx) => ctx.dataIndex === ctx.dataset.data.length - 1 ? 6 : 0,
        pointBorderColor: getCssVar('--text-inverse'),
        pointBackgroundColor: getCssVar('--primary-color'),
        pointHoverRadius: 8,
      }]
    };
    
    setLiveData({ status: initialStatus, chart: initialChartWithColors });

    const newSocket = new WebSocket(`ws://localhost:8000/ws/task_status/${taskId}`);
    socketRef.current = newSocket;
    
    newSocket.onmessage = (event) => {
      const data = JSON.parse(event.data);
      
      setLiveData(prev => {
        let newChart = prev.chart;
        if (data.state === 'PROGRESS' && data.details?.loss !== undefined) {
          const epochLabel = `E${data.details.epoch}`;
          if (!prev.chart.labels.includes(epochLabel)) {
            const newLabels = [...prev.chart.labels, epochLabel].slice(-30);
            const newLossData = [...prev.chart.datasets[0].data, data.details.loss].slice(-30);
            newChart = { ...prev.chart, labels: newLabels, datasets: [{ ...prev.chart.datasets[0], data: newLossData }] };
          }
        } else if (data.result?.results?.loss) {
          const finalLossHistory = data.result.results.loss;
          newChart = {
            ...prev.chart,
            labels: Array.from({ length: finalLossHistory.length }, (_, i) => `E${i + 1}`),
            datasets: [{ ...prev.chart.datasets[0], data: finalLossHistory }]
          };
        }
        return { status: data, chart: newChart };
      });
    };
    
    newSocket.onerror = () => setLiveData(prev => ({ ...prev, status: { state: 'ERROR', details: { status_text: 'WebSocket bağlantı hatası!' } }}));
    newSocket.onclose = () => setLiveData(prev => (['SUCCESS', 'FAILURE', 'ERROR'].includes(prev.status.state)) ? prev : { ...prev, status: { ...prev.status, state: 'DISCONNECTED' }});
    
    return () => { newSocket.close(1000, "Component unmounting"); };
  }, [taskId]);
  
  const { state, details, result } = liveData.status;
  const { pipeline_name, data_sourcing } = details?.config || result?.config || {};
  const { total_epochs, epoch, status_text } = details || {};
  const progressPercent = state === 'SUCCESS' ? 100 : (total_epochs ? (epoch / total_epochs) * 100 : 0);
  
  return (
    <div className="live-tracker-pane">
      <button className="close-button" onClick={onClose}>×</button>
      <div style={{display: 'flex', justifyContent: 'space-between', alignItems: 'center', marginBottom: '15px'}}>
        <h4><span role="img" aria-label="satellite">🛰️</span> Canlı Takip: {pipeline_name || "..."} {data_sourcing?.ticker && `(${data_sourcing.ticker})`}</h4>
        <div><span className="exp-id">ID: {taskId}</span><span className={`status-badge status-${state?.toLowerCase()}`}>{state}</span></div>
      </div>
      <div style={{display: 'flex', gap: '20px', alignItems: 'center'}}>
        <div style={{flex: 1}}><p>{status_text || state}</p><progress value={progressPercent} max="100" style={{width: '100%'}}></progress></div>
        <div style={{flex: 2, height: '100px'}}>
          {liveData.chart.labels.length > 0 && <Line data={liveData.chart} options={chartOptions} />}
        </div>
      </div>
      {state === 'FAILURE' && result?.error && <p className="feedback error" style={{marginTop: '15px', whiteSpace: 'pre-wrap', maxHeight: '100px', overflowY: 'auto'}}>{result.error}</p>}
    </div>
  );
}

LiveTrackerPane.propTypes = { 
  taskId: PropTypes.string.isRequired, 
  onClose: PropTypes.func.isRequired, 
};

export default LiveTrackerPane;
========== FILE: dashboard/src/components/Logo.jsx ==========
import PropTypes from 'prop-types';

function Logo({ size = 36 }) {
  return (
    <div className="logo-container">
      <svg width={size} height={size} viewBox="0 0 100 100" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" style={{ flexShrink: 0 }}>
        <defs>
          <linearGradient id="azura-stream-gradient-component" x1="15" y1="50" x2="85" y2="50" gradientUnits="userSpaceOnUse">
            <stop offset="0%" stopColor="var(--secondary-color)"/>
            <stop offset="100%" stopColor="var(--primary-color)"/>
          </linearGradient>
        </defs>
        <path d="M50 10 L10 90 H32 L42 70 H58 L68 90 H90 Z" fill="var(--content-bg)" stroke="var(--text-color-darker)" strokeWidth="4" strokeLinejoin="round"/>
        <path d="M15 55 C 35 45, 65 45, 85 55" stroke="url(#azura-stream-gradient-component)" strokeWidth="8" strokeLinecap="round" fill="none"/>
      </svg>
      <h1>AzuraForge</h1>
    </div>
  );
}
Logo.propTypes = { size: PropTypes.number, };
export default Logo;
========== FILE: dashboard/src/components/ThemeToggle.jsx ==========
import { useContext } from 'react';
import { ThemeContext } from '../context/ThemeContext';

const SunIcon = () => <svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2" strokeLinecap="round" strokeLinejoin="round"><circle cx="12" cy="12" r="5"></circle><line x1="12" y1="1" x2="12" y2="3"></line><line x1="12" y1="21" x2="12" y2="23"></line><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line><line x1="1" y1="12" x2="3" y2="12"></line><line x1="21" y1="12" x2="23" y2="12"></line><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line></svg>;
const MoonIcon = () => <svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2" strokeLinecap="round" strokeLinejoin="round"><path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path></svg>;

function ThemeToggle() {
  const { theme, toggleTheme } = useContext(ThemeContext);

  return (
    <button onClick={toggleTheme} className="theme-toggle-button" title="Temayı Değiştir">
      {theme === 'light' ? <MoonIcon /> : <SunIcon />}
    </button>
  );
}

// DÜZELTME: Eksik olan 'export default' satırı eklendi.
export default ThemeToggle;
========== FILE: dashboard/src/context/ThemeContext.jsx ==========
import { createContext, useState, useEffect, useMemo } from 'react';
import PropTypes from 'prop-types';

export const ThemeContext = createContext();

export function ThemeProvider({ children }) {
  const [theme, setTheme] = useState(() => {
    const savedTheme = localStorage.getItem('theme');
    const prefersDark = window.matchMedia('(prefers-color-scheme: dark)').matches;
    return savedTheme || (prefersDark ? 'dark' : 'light');
  });

  useEffect(() => {
    const body = document.body;
    // body'nin class'ını mevcut temaya göre ayarla
    body.classList.toggle('light-theme', theme === 'light');
    // Seçimi tarayıcı hafızasına kaydet
    localStorage.setItem('theme', theme);
  }, [theme]);

  const toggleTheme = () => {
    setTheme(prevTheme => (prevTheme === 'light' ? 'dark' : 'light'));
  };

  // Sadece theme ve toggleTheme'i dışarıya veriyoruz.
  const value = useMemo(() => ({ theme, toggleTheme }), [theme]);

  return (
    <ThemeContext.Provider value={value}>
      {children}
    </ThemeContext.Provider>
  );
}

ThemeProvider.propTypes = {
  children: PropTypes.node.isRequired,
};
========== FILE: dashboard/src/pages/DashboardOverview.jsx ==========
import { useState, useEffect, useMemo } from 'react';
import { toast } from 'react-toastify';
import PropTypes from 'prop-types';
import ExperimentsList from '../components/ExperimentsList';
import ComparisonView from '../components/ComparisonView';
import { fetchExperiments, startNewExperiment } from '../services/api';

function DashboardOverview({ onNewExperimentClick, setTrackingTaskId }) {
  const [experiments, setExperiments] = useState([]);
  const [loading, setLoading] = useState(true);
  const [error, setError] = useState(null);
  
  // Filtreleme ve Arama State'leri
  const [searchTerm, setSearchTerm] = useState('');
  const [filterStatus, setFilterStatus] = useState('ALL');
  
  // Karşılaştırma State'leri
  const [selectedForComparison, setSelectedForComparison] = useState(new Set());
  const [comparisonData, setComparisonData] = useState(null);

  const getExperiments = async (showLoadingIndicator = false) => {
    if (showLoadingIndicator) setLoading(true);
    try {
      const response = await fetchExperiments();
      // Gelen veriyi başlangıç zamanına göre sırala (en yeni en üstte)
      const sortedData = response.data.sort((a, b) => new Date(b.config.start_time) - new Date(a.config.start_time));
      setExperiments(sortedData);
      setError(null);
    } catch (err) {
      setError('API sunucusuna bağlanılamadı veya veri çekilemedi. Servislerin çalıştığından emin olun.');
    } finally {
      if (showLoadingIndicator) setLoading(false);
    }
  };

  useEffect(() => {
    getExperiments(true); // Sayfa ilk yüklendiğinde loading göstergesiyle veri çek
    const intervalId = setInterval(() => getExperiments(false), 5000); // Arka planda sessizce güncelle
    return () => clearInterval(intervalId); // Component unmount olduğunda interval'ı temizle
  }, []);

  // Mevcut deneylerden dinamik olarak durum listesi oluşturur
  const allStatuses = useMemo(() => {
    const statuses = new Set(experiments.map(exp => exp.status));
    return ['ALL', ...Array.from(statuses).sort()];
  }, [experiments]);

  // Filtrelenmiş deneyleri hesaplar
  const filteredExperiments = useMemo(() => {
    return experiments.filter(exp => {
      // Durum filtresi
      const statusMatch = filterStatus === 'ALL' || exp.status === filterStatus;
      if (!statusMatch) return false;

      // Arama terimi filtresi (ID, pipeline adı veya ticker sembolü)
      if (searchTerm) {
        const lowerCaseSearchTerm = searchTerm.toLowerCase();
        const searchFields = [
          exp.experiment_id,
          exp.config?.pipeline_name,
          exp.config?.data_sourcing?.ticker
        ];
        return searchFields.some(field => field?.toLowerCase().includes(lowerCaseSearchTerm));
      }

      return true;
    });
  }, [experiments, filterStatus, searchTerm]);
  
  // Karşılaştırma için deney seçme/kaldırma fonksiyonu
  const handleComparisonSelect = (experimentId) => {
    setSelectedForComparison(prev => {
      const newSelection = new Set(prev);
      if (newSelection.has(experimentId)) {
        newSelection.delete(experimentId);
      } else {
        newSelection.add(experimentId);
      }
      return newSelection;
    });
  };

  // Bir deneyi konfigürasyonuyla yeniden çalıştırma fonksiyonu
  const handleReRun = async (experimentConfig) => {
    // Yeniden çalıştırmadan önce eski ID ve zaman bilgilerini temizle
    const { experiment_id, task_id, start_time, ...configToReRun } = experimentConfig;
    toast.info(`"${configToReRun.pipeline_name}" deneyi yeniden başlatılıyor...`);
    try {
      const response = await startNewExperiment(configToReRun);
      toast.success(`Deney başarıyla gönderildi! ID: ${response.data.task_id}`);
      setTrackingTaskId(response.data.task_id); // Yeniden çalıştırılan deneyi canlı izlemeye başla
    } catch (err) {
      toast.error('Deney yeniden başlatılamadı.');
    }
  };

  // Karşılaştırma modalını açar
  const handleStartComparison = () => {
    const dataToCompare = experiments.filter(exp => selectedForComparison.has(exp.experiment_id));
    if (dataToCompare.length > 1) {
      setComparisonData(dataToCompare);
    }
  };

  // Yükleme ve Hata durumları için gösterilecek arayüz
  if (loading) return <p style={{textAlign: 'center', padding: '40px'}}>Deney verileri yükleniyor...</p>;
  if (error) return <p style={{textAlign: 'center', padding: '40px', color: 'var(--error-color)'}}>{error}</p>;

  return (
    <div className="dashboard-overview">
      {/* Karşılaştırma modalı, sadece data varsa render edilir */}
      {comparisonData && <ComparisonView experiments={comparisonData} onClose={() => setComparisonData(null)}/>}
      
      <div className="page-header">
        <h1>Genel Bakış</h1>
        <p>Tüm deneylerinizi tek bir yerden yönetin, takip edin ve karşılaştırın.</p>
      </div>
      
      {/* Filtreleme ve Aksiyonlar Paneli */}
      <div className="card" style={{ marginBottom: '25px' }}>
        <div style={{ display: 'flex', justifyContent: 'space-between', alignItems: 'center', flexWrap: 'wrap', gap: '20px' }}>
          <div style={{ display: 'flex', gap: '20px', flexWrap: 'wrap', alignItems: 'flex-end' }}>
            <div className="form-group" style={{ marginBottom: 0 }}>
              <label htmlFor="search-term">Arama</label>
              <input type="text" id="search-term" placeholder="ID, Pipeline, Sembol ara..." value={searchTerm} onChange={(e) => setSearchTerm(e.target.value)} />
            </div>
            <div className="form-group" style={{ marginBottom: 0 }}>
              <label htmlFor="filter-status">Durum</label>
              <select id="filter-status" value={filterStatus} onChange={(e) => setFilterStatus(e.target.value)}>
                {allStatuses.map(s => <option key={s} value={s}>{s === 'ALL' ? 'Tümü' : s}</option>)}
              </select>
            </div>
          </div>
          <button 
            className="button-primary" 
            onClick={handleStartComparison} 
            disabled={selectedForComparison.size < 2} 
            title={selectedForComparison.size < 2 ? 'Karşılaştırmak için en az 2 deney seçin' : ''}
          >
            <span role="img" aria-label="scales">⚖️</span> Seçilenleri Karşılaştır ({selectedForComparison.size})
          </button>
        </div>
      </div>
      
      {/* Deney Tablosu */}
      <ExperimentsList 
        experiments={filteredExperiments} 
        selectedIds={selectedForComparison} 
        onSelect={handleComparisonSelect} 
        onReRun={handleReRun} 
        setTrackingTaskId={setTrackingTaskId} 
      />
    </div>
  );
}
DashboardOverview.propTypes = { 
  onNewExperimentClick: PropTypes.func.isRequired, 
  setTrackingTaskId: PropTypes.func.isRequired, 
};
export default DashboardOverview;
========== FILE: dashboard/src/pages/NewExperiment.jsx ==========
import { useState, useEffect } from 'react';
import { useNavigate } from 'react-router-dom';
import PropTypes from 'prop-types';
import { toast } from 'react-toastify';
import { startNewExperiment, fetchAvailablePipelines, fetchPipelineDefaultConfig } from '../services/api';

// Bu bileşen artık bu dosyanın içinde yerel olarak kalabilir.
const renderConfigForm = (config, setConfig) => {
  const handleChange = (e, keyPath) => {
    const { value, type } = e.target;
    const newConfig = JSON.parse(JSON.stringify(config));
    let current = newConfig;
    for (let i = 0; i < keyPath.length - 1; i++) {
      current = current[keyPath[i]] = current[keyPath[i]] || {};
    }
    current[keyPath[keyPath.length - 1]] = type === 'number' ? parseFloat(value) : value;
    setConfig(newConfig);
  };

  const traverseConfig = (obj, path = []) => Object.entries(obj).map(([key, value]) => {
    const currentPath = [...path, key];
    const fieldId = currentPath.join('-');
    const labelText = key.replace(/_/g, ' ').replace(/\b\w/g, l => l.toUpperCase());

    if (typeof value === 'object' && value !== null && !Array.isArray(value)) {
      return (
        <fieldset key={fieldId} className="form-fieldset">
          <legend>{labelText}</legend>
          {traverseConfig(value, currentPath)}
        </fieldset>
      );
    }
    const inputType = typeof value === 'number' ? 'number' : 'text';
    return (
      <div key={fieldId} className="form-group">
        <label htmlFor={fieldId}>{labelText}:</label>
        <input type={inputType} id={fieldId} value={value ?? ''} onChange={(e) => handleChange(e, currentPath)} step={inputType === 'number' ? 'any' : undefined} />
      </div>
    );
  });

  return traverseConfig(config);
};

function NewExperiment({ onExperimentStarted }) {
  const [pipelines, setPipelines] = useState([]);
  const [selectedPipelineId, setSelectedPipelineId] = useState('');
  const [currentConfig, setCurrentConfig] = useState(null);
  const [isLoading, setIsLoading] = useState(true);
  const [isSubmitting, setIsSubmitting] = useState(false);
  const navigate = useNavigate();

  useEffect(() => {
    const loadPipelines = async () => {
      setIsLoading(true);
      try {
        const response = await fetchAvailablePipelines();
        if (response.data && response.data.length > 0) {
          setPipelines(response.data);
          setSelectedPipelineId(response.data[0].id);
        }
      } catch (error) { toast.error('Pipeline listesi yüklenemedi.'); } 
      finally { setIsLoading(false); }
    };
    loadPipelines();
  }, []);

  useEffect(() => {
    const loadPipelineConfig = async (pipelineId) => {
      if (!pipelineId) return;
      setIsLoading(true);
      setCurrentConfig(null);
      try {
        const { data } = await fetchPipelineDefaultConfig(pipelineId);
        if (data && !data.error) setCurrentConfig(data);
      } catch (error) { toast.error(`Konfigürasyon yüklenemedi: ${error.message}`); } 
      finally { setIsLoading(false); }
    };
    loadPipelineConfig(selectedPipelineId);
  }, [selectedPipelineId]);

  const handleSubmit = async (e) => {
    e.preventDefault();
    setIsSubmitting(true);
    const configToSend = { ...currentConfig, pipeline_name: selectedPipelineId };
    try {
      const { data } = await startNewExperiment(configToSend);
      toast.success(`Görev başarıyla gönderildi! ID: ${data.task_id}`);
      if (onExperimentStarted) onExperimentStarted(data.task_id);
      navigate('/');
    } catch (err) {
      toast.error('Deney başlatılamadı. API/Worker loglarını kontrol edin.');
    } finally {
      setIsSubmitting(false);
    }
  };
  
  const selectedPipelineDetails = pipelines.find(p => p.id === selectedPipelineId);

  return (
    // YENİ YAPI: Form, başlık ve aksiyon paneli olarak ayrıldı
    <div className="new-experiment-layout">
      <div className="page-header">
        <h1>Yeni Deney Başlat</h1>
        <p>Mevcut bir AI pipeline'ı seçerek yeni bir eğitim süreci başlatın.</p>
      </div>
      
      <form onSubmit={handleSubmit} className="new-experiment-form">
        <div className="form-main-content"> {/* Kaydırılabilir alan */}
          <div className="card">
            <div className="form-group">
              <label htmlFor="pipeline-select">Çalıştırılacak Pipeline Eklentisi</label>
              <select id="pipeline-select" value={selectedPipelineId} onChange={(e) => setSelectedPipelineId(e.target.value)} disabled={isLoading || isSubmitting}>
                {pipelines.map(p => <option key={p.id} value={p.id}>{p.name} ({p.id})</option>)}
              </select>
            </div>
          </div>
          
          <div className="card">
            <h3>Deney Parametreleri</h3>
            {isLoading ? <p>Parametreler yükleniyor...</p> : (
              currentConfig ? renderConfigForm(currentConfig, setCurrentConfig) : <p>Bu pipeline için düzenlenebilir konfigürasyon bulunamadı.</p>
            )}
          </div>
        </div>

        {/* YENİ YAPI: Yapışkan Aksiyon Paneli */}
        <div className="form-action-bar">
          <div className="pipeline-info">
            <strong>Pipeline:</strong>
            <span>{selectedPipelineDetails?.name || '...'}</span>
          </div>
          <button type="submit" disabled={isLoading || isSubmitting} className="button-primary">
            {isSubmitting ? 'Başlatılıyor...' : 'Eğitimi Başlat'}
          </button>
        </div>
      </form>
    </div>
  );
}

NewExperiment.propTypes = { onExperimentStarted: PropTypes.func.isRequired };
export default NewExperiment;
========== FILE: dashboard/src/services/api.js ==========
import axios from 'axios';

const API_BASE_URL = 'http://localhost:8000/api/v1';

const apiClient = axios.create({
  baseURL: API_BASE_URL,
  headers: { 'Content-Type': 'application/json' },
});

export const fetchExperiments = () => apiClient.get('/experiments');
export const startNewExperiment = (config) => apiClient.post('/experiments', config);
export const fetchAvailablePipelines = () => apiClient.get('/pipelines'); 
export const fetchPipelineDefaultConfig = (pipelineId) => apiClient.get(`/pipelines/${pipelineId}/config`);
========== FILE: dashboard/src/utils/cssUtils.js ==========
/**
 * Belirtilen CSS değişkeninin hesaplanmış değerini döndürür.
 * @param {string} varName - '--primary-color' gibi CSS değişken adı.
 * @returns {string} - Değişkenin renk değeri (örn. '#42b983').
 */
export const getCssVar = (varName) => {
  if (typeof window === 'undefined') return '';
  return getComputedStyle(document.documentElement).getPropertyValue(varName).trim();
};
========== FILE: docs/CONTRIBUTING.md ==========
# 🤝 AzuraForge Platforma Katkıda Bulunma Rehberi

AzuraForge projesine gösterdiğiniz ilgi ve katkılarınız için teşekkür ederiz! Bu rehber, kod tabanının tutarlı, okunabilir, sürdürülebilir ve yüksek kalitede kalmasını sağlamak için benimsediğimiz çalışma prensiplerini ve standartlarını açıklamaktadır.

## 🚀 Hızlı Başlangıç

Eğer henüz geliştirme ortamınızı kurmadıysanız, lütfen platform repo'sunun ana `README.md` dosyasındaki "Geliştirme Ortamı Kurulumu" bölümünü takip edin.

## 🛠️ Kodlama Standartları

Projeye eklenen her kodun aşağıdaki standartları karşılaması beklenmektedir:

1.  **Stil Kılavuzu (PEP8 & Black):**
    *   Tüm Python kodları, PEP8 stil kurallarına uymalıdır.
    *   Kodunuzu `black` ile otomatik formatlayın.
    *   **Kontrol:** Değişikliklerinizi göndermeden önce `black <dosya_adı>` veya `black .` komutunu çalıştırın.
    *   **Otomasyon:** `pre-commit` hook'ları otomatik formatlamayı zorunlu kılar.

2.  **Linting (`flake8`):**
    *   Tüm Python kodları, `flake8` denetiminden hatasız geçmelidir.
    *   **Kontrol:** `flake8 <dosya_adı>` veya `flake8 src` komutunu çalıştırın.
    *   **Otomasyon:** `pre-commit` hook'ları linting'i zorunlu kılar.

3.  **Tip İpuçları (Type Hinting & Mypy):**
    *   Tüm fonksiyon ve metod imzaları, parametreler ve dönüş değerleri için tip ipuçları (`typing` modülü kullanılarak) içermelidir.
    *   **Kontrol:** `mypy src` komutunu çalıştırın.
    *   **Otomasyon:** `pre-commit` hook'ları statik tip denetimini zorunlu kılar.

4.  **Dokümantasyon (Docstrings):**
    *   Tüm modüller, sınıflar, fonksiyonlar ve metodlar, ne işe yaradıklarını, aldıkları argümanları (`Args:`) ve ne döndürdüklerini (`Returns:`) açıklayan Google-style docstring'ler içermelidir.
    *   Arayüz (API) repoları için `FastAPI`'nin otomatik dokümantasyonunu besleyecek docstring'ler kullanılmalıdır.

5.  **Testler (`pytest`):**
    *   Eklenen her yeni özellik veya fonksiyon için ilgili birim testleri (`unit tests`) `tests/` klasörüne eklenmelidir.
    *   Yapılan bir hata düzeltmesi (bug fix) için, o hatanın tekrar oluşmasını engelleyecek bir regresyon testi yazılmalıdır.
    *   **Kontrol:** İlgili reponun kök dizinindeyken `pytest` komutunu çalıştırın.

## 📝 Commit Mesajları

Commit mesajları, yapılan değişikliği net bir şekilde açıklamalıdır ve [Conventional Commits](https://www.conventionalcommits.org/en/v1.0.0/) standardına uymalıdır. Bu, otomatik versiyonlama ve değişiklik günlüğü oluşturmak için hayati önem taşır.

**Format:**
```
<tip>(<kapsam>): <açıklama>

[opsiyonel gövde]
```

**Örnek Tipler:**
*   `feat`: Yeni bir özellik ekler (Minor versiyon artırımı).
*   `fix`: Bir hata düzeltmesi (Patch versiyon artırımı).
*   `docs`: Sadece dokümantasyon değişiklikleri (Versiyon artırımı yok).
*   `style`: Kod formatı, eksik noktalı virgül gibi stil düzeltmeleri (Kod mantığı değişmez, versiyon artırımı yok).
*   `refactor`: Kodu yeniden yapılandırma, davranış değişikliği yok (Versiyon artırımı yok).
*   `perf`: Performans iyileştirmesi yapan kod değişikliği (Versiyon artırımı olabilir).
*   `test`: Eksik testlerin eklenmesi veya mevcut testlerin düzeltilmesi (Versiyon artırımı yok).
*   `build`: Build sistemi veya dış bağımlılık değişiklikleri (Versiyon artırımı olabilir).
*   `ci`: CI/CD yapılandırma dosyaları ve script'leri değişiklikleri (Versiyon artırımı yok).

**Örnekler:**
*   `feat(core): Add exponential function to Tensor`
*   `fix(api): Resolve 307 redirect issues for endpoints`
*   `docs(platform): Add initial development guide`
*   `refactor(learner): Separate Layer and Model definitions`

## 🔄 Pull Request (PR) Süreci

1.  **Branch Oluşturma:** `main` branch'inden kendi feature branch'inizi (`feat/yeni-ozellik` veya `fix/hata-adi` gibi) oluşturun.
2.  **Değişikliklerinizi Yapın:** Yukarıdaki standartlara uyduğunuzdan emin olun.
3.  **Test Edin:** Yerel testlerinizi (`pytest`) çalıştırın ve geçtiğinden emin olun.
4.  **Commit ve Push:** Değişikliklerinizi anlamlı commit mesajlarıyla branch'inize `push` edin.
5.  **Pull Request Açın:** GitHub üzerinden `main` branch'ine bir "Pull Request" (PR) açın.
6.  **CI Kontrolleri:** PR'ınızın CI kontrollerinden (testler, linting) başarıyla geçtiğinden emin olun.
7.  **Kod İncelemesi:** Kodunuz incelenecek ve gerekli geri bildirimler sağlanacaktır.

Bu standartlara uyarak, AzuraForge platformunun uzun vadede sağlıklı, sürdürülebilir ve yüksek kalitede kalmasına yardımcı olursunuz.

========== FILE: docs/DEVELOPMENT_GUIDE.md ==========
# 🛠️ AzuraForge Platform Geliştirme Rehberi

Bu belge, AzuraForge platformunda geliştirme yapmak isteyenler için adım adım kurulum, çalışma prensipleri ve katkıda bulunma yönergelerini içerir.

## 🎯 Temel Felsefemiz

Her repomuz, kendi başına yaşayan, kurulabilir ve test edilebilir bağımsız bir Python/JavaScript paketidir. Repolar arası bağımlılıklar, Git adresleri (`@git+https://...`) üzerinden kurulur.

## 📦 Proje Repolarına Genel Bakış

AzuraForge platformu, aşağıdaki bağımsız GitHub depolarından oluşur. Geliştirme yaparken bu repoların bir kısmını veya tamamını yerel makinenizde klonlamanız gerekecektir.

*   **`core`** ([link](https://github.com/AzuraForge/core)): Temel otomatik türev motoru.
*   **`learner`** ([link](https://github.com/AzuraForge/learner)): `core` üzerinde yüksek seviyeli öğrenme kütüphanesi.
*   **`app-stock-predictor`** ([link](https://github.com/AzuraForge/app-stock-predictor)): Bir uygulama eklentisi örneği.
*   **`applications`** ([link](https://github.com/AzuraForge/applications)): Resmi uygulama katalogu (sadece JSON veri içerir).
*   **`api`** ([link](https://github.com/AzuraForge/api)): RESTful API ve WebSocket sunucusu.
*   **`worker`** ([link](https://github.com/AzuraForge/worker)): Arka plan görevlerini (eğitimleri) işleyen Celery worker.
*   **`dashboard`** ([link](https://github.com/AzuraForge/dashboard)): React tabanlı web kullanıcı arayüzü.

## ⚙️ Geliştirme Ortamı Kurulumu

Bu adımlar, platformun tüm parçalarını yerel geliştirme için hazır hale getirir.

1.  **Gerekli Araçlar:**
    *   **Git:** Repoları klonlamak için.
    *   **Python 3.8+:** Tüm Python bileşenleri için.
    *   **Node.js & npm:** Frontend bileşeni için.
    *   **Docker Desktop:** Redis ve Dockerize edilmiş ortamda test için (alternatifler belirtilecektir).

2.  **Repoları Klonlama:**
    Platformda geliştirmek için tüm ilgili repoları aynı seviyede bir klasöre klonlamanız önerilir:
    ```bash
    mkdir azuraforge-dev
    cd azuraforge-dev

    git clone https://github.com/AzuraForge/core.git
    git clone https://github.com/AzuraForge/learner.git
    git clone https://github.com/AzuraForge/app-stock-predictor.git
    git clone https://github.com/AzuraForge/applications.git
    git clone https://github.com/AzuraForge/api.git
    git clone https://github.com/AzuraForge/worker.git
    git clone https://github.com/AzuraForge/dashboard.git
    git clone https://github.com/AzuraForge/platform.git # Orkestrasyon için
    ```

3.  **Sanal Ortam Kurulumu (Python):**
    Her Python projesinin kendi sanal ortamı olabilir veya merkezi bir tane kullanabiliriz. Yerel geliştirme için, **`api` projesinin** kök dizininde tek bir sanal ortam oluşturmak ve tüm Python bağımlılıklarını oraya kurmak en pratik yoldur.

    ```bash
    cd api # `api` reposunun içine gir
    python -m venv .venv
    .\.venv\Scripts\activate # Windows için
    # source ./.venv/bin/activate # Linux/macOS için
    ```

4.  **Python Bağımlılıklarını Kurma (Tüm Python Repoları için):**
    Sanal ortam aktifken, tüm Python repolarını "düzenlenebilir" (editable) modda kurmalıyız. Bu, kodda yaptığınız değişikliklerin anında yansımasını sağlar. **`api` projesinin** kök dizininde olduğunuzdan emin olun.

    ```bash
    # Önce en alt seviyeden başlayarak kütüphaneleri kurun
    pip install -e ../core 
    pip install -e ../learner
    pip install -e ../app-stock-predictor # İlk uygulama eklentisi
    pip install -e ../applications       # Uygulama katalogu
    
    # Sonra API ve Worker'ı kurun
    pip install -e .                     # `api` projesini kurar
    pip install -e ../worker             # `worker` projesini kurar
    ```
    Bu komutlar, her bir reponun `pyproject.toml` dosyasını okuyacak ve tüm bağımlılık zincirini doğru bir şekilde çözecektir.

5.  **JavaScript Bağımlılıklarını Kurma (Dashboard için):**
    ```bash
    cd ../dashboard # `dashboard` reposunun içine gir
    npm install
    ```

6.  **Redis Kurulumu:**
    Platform, bir Redis sunucusuna ihtiyaç duyar. En kolay yol Docker kullanmaktır:
    ```bash
    docker run -d -p 6379:6379 --name azuraforge_redis redis
    ```

## ▶️ Servisleri Çalıştırma (Yerel Geliştirme)

Sanal ortamınız aktifken ve Redis çalışırken, her servisi ayrı bir terminalde başlatın.

1.  **API Sunucusu (`api` reposundan):**
    ```bash
    cd api
    .\.venv\Scripts\activate # Sanal ortam aktif değilse
    start-api
    ```
    (Tarayıcıda `http://localhost:8000/api/v1/docs` adresini kontrol edin.)

2.  **Worker Servisi (`worker` reposundan):**
    ```bash
    cd worker
    .\.venv\Scripts\activate
    start-worker
    ```
    (Worker terminalinde "Discovered pipeline..." loglarını kontrol edin.)

3.  **Dashboard (`dashboard` reposundan):**
    ```bash
    cd dashboard
    npm run dev
    ```
    (Tarayıcıda `http://localhost:5173` adresini açın.)

## 🧪 Test Etme ve Hata Ayıklama

*   **Uçtan Uca Akış:** Dashboard'dan yeni bir deney başlatarak tüm sistemin (`Dashboard -> API -> Worker -> Uygulama Eklentisi -> Kütüphane`) sorunsuz çalıştığını doğrulayın. Canlı takip ekranını ve kayıp grafiğini izleyin.
*   **API Testleri:** `http://localhost:8000/api/v1/docs` adresinden API endpoint'lerini test edin.
*   **Birim Testleri:** Her bir repoda (örn: `core`, `learner`, `app-stock-predictor`) kendi `pytest` testlerini çalıştırın.
    ```bash
    cd core # veya learner, app-stock-predictor
    .\.venv\Scripts\activate
    pytest
    ```
    (Bu testleri koşabilmek için ilgili repoda `pip install -e ".[dev]"` yapmış olmanız gerekir.)

## 🔄 İteratif Geliştirme Akışı

Çoğu zaman, kodda küçük değişiklikler yapıp bunları hızla test etmek istersiniz.

1.  **Kütüphanede Değişiklik (örn: `core/src/azuraforge_core/tensor.py`):**
    *   Değişikliği yapın ve kaydedin.
    *   Bu değişikliğin `learner` veya diğer kütüphanelerde anında etkili olması için **ekstra bir `pip install` komutuna GEREK YOKTUR**, çünkü `pip install -e` ile kuruldukları için doğrudan kaynak dosyayı kullanırlar.
    *   `core` projesine geri dönüp `pytest` ile kendi testlerini koşun.
    *   Değişikliği `commit`'leyin ve `push`'layın.

2.  **Uygulama/Servis Değişikliği (örn: `app-stock-predictor/src/azuraforge_stockapp/pipeline.py`):**
    *   Değişikliği yapın ve kaydedin.
    *   `api` veya `worker` servisleri otomatik olarak `reload` (yeniden yükleme) yapacaktır (eğer `uvicorn --reload` ile çalışıyorlarsa).
    *   `api` ve `worker`'ı yeniden başlatmak genellikle yeterlidir.
    *   Değişikliği `commit`'leyin ve `push`'layın.

3.  **Yeni Bir Bağımlılık Eklendiğinde (`pyproject.toml` değiştiğinde):**
    *   İlgili reponun kök dizinine gidin (örn: `api`).
    *   Sanal ortamınızı aktive edin.
    *   `pip install -e .` komutunu tekrar çalıştırın. `pip`, sadece eksik olan yeni bağımlılıkları ekleyecektir.

## 🤝 Katkıda Bulunma

Bu proje bir açık kaynak projesi olarak geliştirilmektedir. Katkıda bulunmak için lütfen `platform/docs/CONTRIBUTING.md` dosyasını inceleyin.

========== FILE: docs/PROJECT_JOURNEY.md ==========
# 🗺️ Proje Yolculuğu: AzuraForge'un Gelişim Hikayesi ve Gelecek Vizyonu

Bu belge, AzuraForge platformunun başlangıcından mevcut durumuna kadar olan gelişim sürecini, karşılaşılan zorlukları, bulunan çözümleri ve projenin **modüler, ölçeklenebilir ve ihtiyaç odaklı bir yapay zeka geliştirme platformuna** dönüşme vizyonunu özetlemektedir.

## 🎯 Proje Felsefesi ve Çıkış Hikayesi

AzuraForge'un her aşamasında, kalitesini ve sürdürülebilirliğini sağlamak için şu temel prensipleri benimsedik:

1.  **Sıfırdan İnşa ve Tam Kontrol:** Temel algoritmaları ve yapıları (`Tensor` gibi) mümkün olduğunca sıfırdan implemente ederek, sistem üzerinde tam kontrol sağlamak ve derinlemesine öğrenmek.
2.  **Modülerlik ve Sorumluluk Ayrımı (Microservices):** Her bileşenin (çekirdek kütüphane, API, worker, uygulama eklentisi, UI) tek ve net bir görevi vardır ve kendi bağımsız repo'sunda yaşar.
3.  **Olay Güdümlü Mimari:** Bileşenler arası iletişim, bağımlılıkları azaltmak ve gerçek zamanlı yetenekler sağlamak için olaylar (Celery, Redis Pub/Sub, WebSockets) üzerinden gerçekleşir.
4.  **Eklenti Tabanlı (Plug-in Architecture):** Yeni özellikler ve uygulamalar, mevcut platform koduna dokunmadan birer eklenti olarak kolayca eklenebilir.
5.  **Kanıt Odaklı Geliştirme:** Her büyük özellik veya yetenek, gerçek dünya verisi üzerinde kabul edilebilir bir performansla kanıtlanmalıdır.
6.  **Otomatik Kalite Kontrolü:** Kod kalitesi (linting, type checking, unit tests) ve versiyonlama süreçleri (CI/CD) otomatikleştirilmiştir.

## ✅ Tamamlanan Fazlar ve Elde Edilen Başarılar

### Faz 0: Fikir ve İlk Denemeler (Monolitik Yaklaşım)

*   **Düşünce:** Mevcut ML araçlarının karmaşıklığına ve bağımlılıklarına bir tepki olarak, sıfırdan bir derin öğrenme motoru (`mininn`) inşa etme fikri doğdu.
*   **İlk Uygulama:** Hava durumu tahmini ve hisse senedi tahmini gibi basit uygulamalarla `mininn`'in yetenekleri test edildi.
*   **Öğrenilen Ders:** Monolitik bir yaklaşımla (her şey tek bir repo'da) hızlı prototipleme mümkün olsa da, ölçeklenebilirlik ve yönetim zorlukları ortaya çıktı.

### Faz 1: Multi-Repo ve Mikroservis Mimarisine Geçiş

*   **Karar:** Uzun vadeli sürdürülebilirlik, ölçeklenebilirlik ve profesyonellik için, platformu bağımsız repolara sahip bir mikroservis mimarisine dönüştürme kararı alındı.
*   **Zorluk:** Python'da çoklu repolar arası bağımlılık yönetimi ve yol (path) sorunları.
*   **Çözüm:** `pip`'in `editable` kurulumu (`-e`) ve `git+https` bağımlılıklarını kullanarak, her reponun kendi `pyproject.toml` ve `setup.py` dosyalarıyla kurulabilir bir paket olması sağlandı. `importlib.resources` ile paket içi dosya erişimi çözüldü.

### Faz 2: Temel Kütüphanelerin İnşası ve Kanıtı

*   **`AzuraForge/core` (Matematik Motoru):** `Tensor` objesi ve otomatik türev yetenekleri sıfırdan inşa edildi. `pytest` ile birim testleri (dot, sum, add, mul, relu backward pass) başarıyla yazıldı ve geçti. **`to_cpu` ve `_unbroadcast_to` hataları bu fazda tespit edilip düzeltildi.**
*   **`AzuraForge/learner` (Öğrenme Kütüphanesi):** `azuraforge-core`'a bağımlı olarak `Layer`, `Linear`, `Loss`, `MSELoss`, `Sequential`, `Optimizer`, `SGD` gibi temel öğrenme bileşenleri inşa edildi. `pytest` ile basit regresyon testi (`test_learner_fit_simple_regression`) başarıyla geçti.

### Faz 3: Dağıtık Servisler ve Eklenti Mimarisi

*   **`AzuraForge/applications` (Katalog):** Uygulama eklentilerinin JSON kataloğunu barındıran basit bir Python paketi olarak yapılandırıldı.
*   **`AzuraForge/app-stock-predictor` (İlk Eklenti):** `azuraforge-learner`'ı kullanan ve platforma `entry_points` (`azuraforge.pipelines`) ile kendini tanıtan ilk uygulama eklentisi inşa edildi.
*   **`AzuraForge/worker` (İşçi Servisi):** `celery[redis]` kullanarak arka plan görevlerini işleyen ve `importlib.metadata` ile sisteme kurulu tüm `azuraforge.pipelines` eklentilerini **otomatik olarak keşfeden** ve çalıştıran worker servisi kuruldu.
*   **`AzuraForge/api` (API Servisi):** `FastAPI` ile RESTful API endpoint'leri (`/experiments`, `/pipelines`) sunan ve `worker`'a görev gönderen iletişim katmanı inşa edildi. API rotalarının `prefix` yönetimi ve `307 Redirect` sorunları bu fazda çözüldü.
*   **Başarı:** `api` üzerinden gönderilen bir "stock_predictor" görevinin, `worker` tarafından alınıp, `app-stock-predictor` eklentisinin keşfedilip, `learner` kütüphanesi kullanılarak **gerçek bir model eğitiminin başarıyla tamamlandığı** kanıtlandı.

### Faz 4: Kullanıcı Arayüzü ve Canlı Takip

*   **`AzuraForge/dashboard` (Web UI):** React tabanlı, `api` servisinden deney ve pipeline listelerini çeken, yeni deneyler başlatmayı sağlayan temel bir web arayüzü inşa edildi.
*   **Canlı Takip (WebSocket Entegrasyonu):**
    *   `worker`, eğitim sırasında `Celery task.update_state` ile ilerleme durumunu Redis'e raporladı.
    *   `api`, `FastAPI WebSocket` endpoint'i üzerinden bu ilerlemeyi `dashboard`'a anlık olarak iletti.
    *   `dashboard`, gelen `PROGRESS` mesajlarıyla bir **ilerleme çubuğunu ve kayıp grafiğini canlı olarak güncelledi.**

**An itibarıyla AzuraForge Platform 1.0, tüm temel mimarisi ve uçtan uca çalışan canlı takip yetenekleriyle TAMAMLANMIŞTIR!**

## 🗺️ Gelecek Fazlar ve Yol Haritası

Bu sağlam temel üzerine inşa edilecek adımlar, AzuraForge'u daha da zenginleştirmeyi ve kapsamını genişletmeyi hedefleyecektir.

### Faz 5: Deney Yönetimini Derinleştirme

*   **Kalıcı Sonuçlar:** `worker`'ın `results.json`'a kaydettiği tüm detaylı veriyi (eğitim geçmişi, metrikler, konfigürasyon) `api` üzerinden okuyup Dashboard'da görselleştirme.
*   **Deney Detay Sayfası:** Dashboard'da her deney için ayrı bir detay sayfası oluşturma.
*   **Model Yönetimi:** Eğitilen modellerin kaydedilmesi, listelenmesi ve daha sonra çıkarım için yüklenebilmesi.

### Faz 6: Yeni Veri Modalitelerine Açılım (Görüntü İşleme)

*   **`core` Genişletme:** `Conv2D`, `MaxPool2D`, `Flatten` gibi CNN katmanlarını `core` kütüphanesine ekleme.
*   **Yeni Uygulama Eklentisi:** `azuraforge-app-image-classifier` (örn: MNIST için) oluşturma.

### Faz 7: Hiperparametre Optimizasyonu

*   **`azuraforge-hyper-tuner`:** Farklı hiperparametre kombinasyonlarıyla otomatik deneyler yapabilen yeni bir uygulama eklentisi.
*   **Dashboard Entegrasyonu:** Dashboard'dan hiperparametre optimizasyonu işleri başlatma.

### Faz 8: Üretim Ortamı Hazırlığı (Deployment)

*   **`platform` Orkestrasyonu:** `docker-compose.yml`'ı daha sağlam hale getirme (Nginx, HTTPS, Load Balancing).
*   **CI/CD Pipeline'ları:** Tüm repolar için otomatik test, versiyonlama ve yayınlama (PyPI/GitHub Packages) pipeline'ları kurma.

========== FILE: learner/pyproject.toml ==========
[build-system]
requires = ["setuptools>=61.0"]
build-backend = "setuptools.build_meta"

[project]
name = "azuraforge-learner"
version = "0.1.1"
authors = [{ name = "Azmi Sahin" }]
description = "High-level deep learning library for model training and management, using the AzuraForge Core engine."
readme = "README.md"
requires-python = ">=3.8"
license = { text = "MIT" }
dependencies = [
    # Çekirdek motorumuza olan bağımlılığımız.
    "azuraforge-core @ git+https://github.com/AzuraForge/core.git@main",
    "scikit-learn",
    "numpy" # scikit-learn için explicit belirtmek iyi bir pratik
]

[project.optional-dependencies]
dev = ["pytest"]

========== FILE: learner/README.md ==========
# AzuraForge Learner 🧠

**AzuraForge Learner**, `azuraforge-core` motorunu kullanarak modelleri kolayca oluşturmak, eğitmek ve yönetmek için tasarlanmış yüksek seviyeli bir kütüphanedir.

## Kurulum

```bash
pip install azuraforge-learner@git+https://github.com/AzuraForge/learner.git
```

========== FILE: learner/setup.py ==========
from setuptools import setup, find_packages
setup(
    package_dir={"": "src"},
    packages=find_packages(where="src"),
)

========== FILE: learner/src/azuraforge_learner/callbacks.py ==========
import os
import numpy as np
from .events import Event

# 'Learner' sınıfı henüz tanımlanmadığı için ileriye dönük referans (forward reference) kullanıyoruz
from typing import TYPE_CHECKING
if TYPE_CHECKING:
    from .learner import Learner

class Callback:
    """
    Tüm callback'lerin temel sınıfı. Olayları dinler ve ilgili metoda yönlendirir.
    """
    def __call__(self, event: Event):
        method = getattr(self, f"on_{event.name}", None)
        if method:
            method(event)

    def on_train_begin(self, event: Event): pass
    def on_train_end(self, event: Event): pass
    def on_epoch_begin(self, event: Event): pass
    def on_epoch_end(self, event: Event): pass

class ModelCheckpoint(Callback):
    """Her epoch sonunda performansı izler ve sadece en iyi modeli kaydeder."""
    def __init__(self, filepath: str, monitor: str = "val_loss", mode: str = "min", verbose: int = 1):
        self.filepath = filepath
        self.monitor = monitor
        self.mode = mode
        self.verbose = verbose
        self.best = np.inf if mode == "min" else -np.inf

        # Dosyanın kaydedileceği dizini oluştur
        dir_path = os.path.dirname(self.filepath)
        if dir_path:
            os.makedirs(dir_path, exist_ok=True)

    def on_epoch_end(self, event: Event):
        current_val = event.payload.get(self.monitor)
        if current_val is None:
            if event.payload.get("epoch") == 0 and self.verbose > 0:
                print(f"ModelCheckpoint Warning: Can't find metric '{self.monitor}' to save model.")
            return

        is_better = (self.mode == "min" and current_val < self.best) or \
                    (self.mode == "max" and current_val > self.best)

        if is_better:
            if self.verbose > 0:
                print(f"ModelCheckpoint: {self.monitor} improved from {self.best:.6f} to {current_val:.6f}. Saving model to {self.filepath}")
            self.best = current_val
            event.learner.save(self.filepath)

class EarlyStopping(Callback):
    """Performans belirli bir epoch sayısı boyunca iyileşmediğinde eğitimi durdurur."""
    def __init__(self, monitor: str = "val_loss", patience: int = 10, mode: str = "min", verbose: int = 1):
        self.monitor = monitor
        self.patience = patience
        self.mode = mode
        self.verbose = verbose
        self.wait = 0
        self.best = np.inf if mode == "min" else -np.inf

    def on_train_begin(self, event: Event):
        # Eğitimin başında sayaçları sıfırla
        self.wait = 0
        self.best = np.inf if self.mode == "min" else -np.inf

    def on_epoch_end(self, event: Event):
        current_val = event.payload.get(self.monitor)
        if current_val is None:
            return
            
        is_better = (self.mode == "min" and current_val < self.best) or \
                    (self.mode == "max" and current_val > self.best)

        if is_better:
            self.best = current_val
            self.wait = 0
        else:
            self.wait += 1
            if self.wait >= self.patience:
                if self.verbose > 0:
                    print(f"EarlyStopping: Stopping training. {self.monitor} did not improve for {self.patience} epochs.")
                event.learner.stop_training = True

========== FILE: learner/src/azuraforge_learner/events.py ==========
from dataclasses import dataclass, field
from typing import Dict, Any, Literal, TYPE_CHECKING

if TYPE_CHECKING:
    from .learner import Learner

EventName = Literal["train_begin", "train_end", "epoch_begin", "epoch_end"]

@dataclass
class Event:
    name: EventName
    learner: 'Learner'
    payload: Dict[str, Any] = field(default_factory=dict)

========== FILE: learner/src/azuraforge_learner/layers.py ==========
from typing import List
import numpy as np
from azuraforge_core import Tensor, xp

class Layer:
    def forward(self, x: Tensor) -> Tensor: raise NotImplementedError
    def parameters(self) -> List[Tensor]: return []
    def __call__(self, x: Tensor) -> Tensor: return self.forward(x)

class Linear(Layer):
    def __init__(self, input_dim: int, output_dim: int):
        limit = np.sqrt(2.0 / input_dim)
        self.weights = Tensor(xp.random.randn(input_dim, output_dim) * limit, requires_grad=True)
        self.bias = Tensor(xp.zeros(output_dim), requires_grad=True)
    def forward(self, x: Tensor) -> Tensor:
        return x.dot(self.weights) + self.bias
    def parameters(self) -> List[Tensor]:
        return [self.weights, self.bias]

class ReLU(Layer):
    def forward(self, x: Tensor) -> Tensor:
        return x.relu()

# YENİ: Sigmoid Katmanı
class Sigmoid(Layer):
    def forward(self, x: Tensor) -> Tensor:
        return x.sigmoid()
========== FILE: learner/src/azuraforge_learner/learner.py ==========
import pickle
from typing import Any, Dict, List, Optional
import numpy as np
from azuraforge_core import Tensor
from .events import Event
from .models import Sequential
from .losses import Loss
from .optimizers import Optimizer
from .callbacks import Callback

class Learner:
    def __init__(self, model: Sequential, criterion: Loss, optimizer: Optimizer, callbacks: Optional[List[Callback]] = None, current_task: Optional[Any] = None):
        self.model = model
        self.criterion = criterion
        self.optimizer = optimizer
        self.callbacks = callbacks or []
        self.history: Dict[str, List[float]] = {}
        self.stop_training: bool = False
        self.current_task = current_task # Celery Task referansı

    def _publish(self, event_name: str, payload: Optional[Dict[str, Any]] = None):
        event = Event(name=event_name, learner=self, payload=payload or {})
        for cb in self.callbacks: cb(event)
        
        # --- KRİTİK DÜZELTME: Celery Task durumunu güncelle ---
        if self.current_task and hasattr(self.current_task, 'update_state'):
            # Celery'ye PROGRESS durumu ve meta verileri gönder
            # payload, epoch_logs'u içeriyor
            self.current_task.update_state(state='PROGRESS', meta=payload)

    def fit(self, X_train: np.ndarray, y_train: np.ndarray, epochs: int):
        self.history = {} # Her fit çağrısında geçmişi sıfırla
        
        # History'yi başlat
        for key in ["loss", "val_loss", "val_r2"]: # Ekleyeceğimiz metrikler için yer açalım
             self.history[key] = []

        X_train_t, y_train_t = Tensor(X_train), Tensor(y_train)
        
        self._publish("train_begin", payload={"total_epochs": epochs}) # Toplam epoch sayısını gönder
        for epoch in range(epochs):
            if self.stop_training: break
            
            # Epoch başlangıcı olayını yayınla
            self._publish("epoch_begin", payload={"epoch": epoch, "total_epochs": epochs})
            
            # Eğitim adımı
            y_pred = self.model(X_train_t)
            loss = self.criterion(y_pred, y_train_t)
            
            self.optimizer.zero_grad()
            loss.backward()
            self.optimizer.step()
            
            epoch_logs = {
                "epoch": epoch + 1, # Epoch sayısını 1'den başlatalım
                "total_epochs": epochs,
                "loss": loss.data.item(),
                "status_text": f"Epoch {epoch+1}/{epochs} completed..."
            }
            
            # History'ye ekle
            self.history["loss"].append(epoch_logs["loss"])
            
            # Epoch sonu olayını yayınla (payload olarak tüm epoch loglarını gönder)
            self._publish("epoch_end", payload=epoch_logs)
        self._publish("train_end")
        return self.history

    def predict(self, X_test: np.ndarray) -> np.ndarray:
        return self.model(Tensor(X_test)).to_cpu()

    def evaluate(self, X_val: np.ndarray, y_val: np.ndarray) -> Dict[str, float]:
        from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
        y_val_t = Tensor(y_val)
        y_pred = self.model(Tensor(X_val))
        
        val_loss = self.criterion(y_pred, y_val_t).data.item()
        y_pred_np = y_pred.to_cpu()
        
        val_r2 = r2_score(y_val, y_pred_np)
        val_mae = mean_absolute_error(y_val, y_pred_np)
        val_rmse = np.sqrt(mean_squared_error(y_val, y_pred_np))

        return {"val_loss": val_loss, "val_r2": val_r2, "val_mae": val_mae, "val_rmse": val_rmse}

========== FILE: learner/src/azuraforge_learner/losses.py ==========
from azuraforge_core import Tensor

class Loss:
    def __call__(self, y_pred: Tensor, y_true: Tensor) -> Tensor: raise NotImplementedError

class MSELoss(Loss):
    def __call__(self, y_pred: Tensor, y_true: Tensor) -> Tensor:
        return ((y_pred - y_true) ** 2).mean()

========== FILE: learner/src/azuraforge_learner/models.py ==========
from typing import List
from .layers import Layer
from azuraforge_core import Tensor

class Sequential(Layer):
    def __init__(self, *layers: Layer):
        self.layers = list(layers)
    def forward(self, x: Tensor) -> Tensor:
        for layer in self.layers:
            x = layer(x)
        return x
    def parameters(self) -> List[Tensor]:
        return [p for layer in self.layers for p in layer.parameters()]

========== FILE: learner/src/azuraforge_learner/optimizers.py ==========
from typing import List
from azuraforge_core import Tensor

class Optimizer:
    def __init__(self, params: List[Tensor], lr: float):
        self.params = [p for p in params if p.requires_grad]
        self.lr = lr
    def step(self) -> None: raise NotImplementedError
    def zero_grad(self) -> None:
        for p in self.params:
            if p.grad is not None: p.grad.fill(0.0)

class SGD(Optimizer):
    def step(self) -> None:
        for p in self.params:
            if p.grad is not None: p.data -= self.lr * p.grad

========== FILE: learner/src/azuraforge_learner/__init__.py ==========
from .events import Event
from .callbacks import Callback, ModelCheckpoint, EarlyStopping
from .losses import Loss, MSELoss
from .layers import Layer, Linear, ReLU, Sigmoid # Sigmoid eklendi
from .models import Sequential
from .optimizers import Optimizer, SGD
from .learner import Learner

__all__ = [
    "Event", "Callback", "ModelCheckpoint", "EarlyStopping",
    "Loss", "MSELoss", "Layer", "Linear", "ReLU", "Sigmoid", # Sigmoid eklendi
    "Sequential", "Optimizer", "SGD", "Learner",
]
========== FILE: learner/src/azuraforge_learner/utils/__init__.py ==========

========== FILE: learner/tests/azuraforge_learner/test_learner_components.py ==========
import pytest
import numpy as np

from azuraforge_learner import Learner, Sequential, Linear, ReLU, MSELoss, SGD

def test_learner_fit_simple_regression():
    X_train = np.array([[-1.0], [0.0], [1.0], [2.0]], dtype=np.float32)
    y_train = np.array([[-1.0], [1.0], [3.0], [5.0]], dtype=np.float32)
    
    model = Sequential(Linear(1, 1))
    criterion = MSELoss()
    optimizer = SGD(model.parameters(), lr=0.1)
    learner = Learner(model, criterion, optimizer)
    
    initial_loss = learner.evaluate(X_train, y_train)['val_loss']
    
    learner.fit(X_train, y_train, epochs=30)
    
    final_loss = learner.history['loss'][-1]
    
    print(f"Initial Loss: {initial_loss}, Final Loss: {final_loss}")
    assert final_loss < initial_loss / 5

def test_sequential_model_forward_pass():
    model = Sequential(Linear(2, 4), ReLU(), Linear(4, 1))
    from azuraforge_core import Tensor
    
    input_tensor = Tensor(np.random.randn(10, 2))
    output_tensor = model(input_tensor)
    
    assert output_tensor.data.shape == (10, 1)

========== FILE: tools/snapshot_generator.py ==========
import os
import sys
import json
import argparse
from typing import List, Dict, Any, Set, Optional, Tuple
import re

# Configuration for included/excluded paths and extensions
DEFAULT_INCLUDE_DIRS = ["."]
DEFAULT_INCLUDE_EXTENSIONS = [
    ".toml",
    ".py",
    ".yaml",
    ".yml",
    ".json",
    ".md",
    ".txt",
    "html",
    ".bat",
    ".sh",
    ".jsx",
    ".js",
    ".json",
    ".css"    
]
DEFAULT_EXCLUDE_PATTERNS = [
    "__pycache__",
    ".git",
    ".venv",
    ".vscode",
    ".idea",
    "build",
    "dist",
    "*.egg-info",
    "*.pyc",
    "*.so",
    "*.pyd",
    ".pytest_cache",
    ".mypy_cache",
    ".dataset",
    "dataset",
    ".logs",
    "logs",
    ".output",
    "output",
    "inputs",
    "outputs",
    ".tmp",
    "checkpoints",
    "reports",
    "docs/_build",
    "site",
    "node_modules",
    ".DS_Store",
    "Thumbs.db", # Windows thumbnail cache
    "*.lock", # npm lock dosyaları gibi
]

FILE_HEADER_TEMPLATE = "========== FILE: {file_path} =========="
SNAPSHOT_INFO_TEMPLATE = """PROJE KOD SNAPSHOT (TAM)
Toplam {total_files_placeholder} dosya bulundu ve eklendi.
Dahil Edilen Dizinler: {included_dirs_placeholder}
Dahil Edilen Uzantılar: {included_extensions_placeholder}
Hariç Tutulan Desenler/Yollar: {excluded_patterns_placeholder}
================================================================================
"""

def clean_code_comments(content: str, file_extension: str) -> str:
    """Removes most comments from code, attempting to preserve shebangs and type hints."""
    if file_extension not in [".py", ".sh", ".bat"]: return content
    lines = content.splitlines()
    cleaned_lines = []
    for line in lines:
        stripped_line = line.strip()
        if file_extension == ".py":
            # Preserve special comments like '# type:' and shebangs
            if stripped_line.startswith("# type:") or stripped_line.startswith("# noqa"): 
                cleaned_lines.append(line)
            elif stripped_line.startswith("#!/"): 
                cleaned_lines.append(line)
            # Remove inline comments
            elif "#" in line and not stripped_line.startswith("#"): 
                cleaned_lines.append(line.split("#", 1)[0].rstrip())
            # Remove full-line comments
            elif stripped_line.startswith("#"):
                continue # Skip full line comments
            else: 
                cleaned_lines.append(line)
        elif file_extension == ".sh":
            if stripped_line.startswith("#!/"): 
                cleaned_lines.append(line)
            elif not stripped_line.startswith("#"): 
                cleaned_lines.append(line)
        elif file_extension == ".bat":
            if not stripped_line.lower().startswith("rem "): 
                cleaned_lines.append(line)
        else: 
            cleaned_lines.append(line)
    return "\n".join(cleaned_lines)


def should_exclude(item_path: str, root_path: str, exclude_patterns: List[str]) -> bool:
    """Checks if a file or directory should be excluded based on the patterns."""
    normalized_item_path = os.path.normpath(item_path)
    normalized_root_path = os.path.normpath(os.path.abspath(root_path))
    
    try:
        relative_item_path = os.path.relpath(normalized_item_path, normalized_root_path)
    except ValueError:
        # If item_path is not relative to root_path (e.g., different drive on Windows)
        # or other path normalization issues, treat it as its own path.
        relative_item_path = normalized_item_path
    
    relative_item_path_slashes = relative_item_path.replace(os.sep, "/")

    for pattern in exclude_patterns:
        normalized_pattern = os.path.normpath(pattern)
        normalized_pattern_slashes = normalized_pattern.replace(os.sep, "/")

        # Wildcard extensions like "*.pyc"
        if pattern.startswith("*."):
            if relative_item_path_slashes.endswith(pattern[1:]): return True
        # Directory names or file names without path
        elif "/" not in pattern and "." not in pattern and not pattern.startswith("*"):
            path_segments = relative_item_path_slashes.split("/")
            if pattern in path_segments: return True
        # Exact file name match
        elif pattern == os.path.basename(normalized_item_path): return True
        # Full path prefix match or relative path match
        elif normalized_item_path.startswith(os.path.join(normalized_root_path, normalized_pattern)) or \
             relative_item_path_slashes.startswith(normalized_pattern_slashes): return True
        # Absolute path match
        elif os.path.isabs(normalized_pattern) and normalized_pattern == normalized_item_path: return True
    return False


def collect_project_files_full(
    output_file: str,
    include_dirs: Optional[List[str]] = None,
    include_extensions: Optional[List[str]] = None,
    exclude_patterns: Optional[List[str]] = None,
    base_dir: str = ".",
    clean_comments: bool = False,
) -> None:
    if include_dirs is None: include_dirs = DEFAULT_INCLUDE_DIRS
    if include_extensions is None: include_extensions = DEFAULT_INCLUDE_EXTENSIONS
    if exclude_patterns is None: exclude_patterns = DEFAULT_EXCLUDE_PATTERNS

    abs_base_dir = os.path.abspath(base_dir)
    
    snapshot_content_header = SNAPSHOT_INFO_TEMPLATE.format(
        total_files_placeholder="{total_files_counter}",
        included_dirs_placeholder=", ".join(include_dirs),
        included_extensions_placeholder=", ".join(include_extensions),
        excluded_patterns_placeholder=", ".join(exclude_patterns),
    )

    all_found_relative_paths: Set[str] = set() # This set stores relative paths to prevent duplicates
    content_parts: List[str] = [snapshot_content_header]
    processed_files_count = 0

    for inc_dir_pattern in include_dirs:
        current_scan_dir = os.path.abspath(os.path.join(abs_base_dir, inc_dir_pattern))
        if not os.path.exists(current_scan_dir):
            print(f"Warning: Include directory '{inc_dir_pattern}' (resolved to '{current_scan_dir}') does not exist. Skipping.")
            continue

        for root, dirs, files in os.walk(current_scan_dir, topdown=True):
            # Filter directories in-place to prevent os.walk from entering excluded ones
            dirs[:] = [
                d for d in dirs
                if not should_exclude(os.path.join(root, d), abs_base_dir, exclude_patterns)
            ]
            for file_name in files:
                file_path = os.path.join(root, file_name)

                relative_file_path = os.path.relpath(file_path, abs_base_dir)
                display_path = relative_file_path.replace(os.sep, "/")

                # Skip if already processed (e.g., if included by multiple patterns)
                if display_path in all_found_relative_paths:
                    continue 

                # Apply exclusion patterns to files
                if should_exclude(file_path, abs_base_dir, exclude_patterns):
                    continue

                _, file_extension = os.path.splitext(file_name)
                # For extension check, handle files without an explicit extension (like Dockerfile)
                name_part_for_ext_check = file_extension.lower() if file_extension else file_name.lower()

                # Check if file extension (or full name for extensionless files) is in include list
                if any(name_part_for_ext_check.endswith(ext.lower()) for ext in include_extensions) or \
                   (not file_extension and file_name.lower() in [ext.lower() for ext in include_extensions if not ext.startswith('.')]):
                    
                    all_found_relative_paths.add(display_path) # Add to set of found paths
                    try:
                        with open(file_path, "r", encoding="utf-8", errors="ignore") as f:
                            file_content = f.read()
                        
                        if clean_comments:
                            file_content = clean_code_comments(file_content, file_extension)
                        
                        # Add a leading newline for separator, then the header, then content.
                        # This creates the format: \n========== FILE:PATH==========\nCONTENT
                        content_parts.append(f"\n{FILE_HEADER_TEMPLATE.format(file_path=display_path)}\n")
                        content_parts.append(file_content)
                        processed_files_count += 1
                    except Exception as e:
                        print(f"Error reading file {relative_file_path}: {e}")
                        content_parts.append(f"\nError reading file {relative_file_path}: {e}\n")

    final_header_with_count = content_parts[0].replace("{total_files_counter}", str(processed_files_count))
    content_parts[0] = final_header_with_count

    with open(output_file, "w", encoding="utf-8") as f:
        f.write("".join(content_parts))

    print(f"Project snapshot (full) generated: {output_file}")
    print(f"Total {processed_files_count} files included.")


def restore_from_full_snapshot(
    snapshot_file: str,
    target_dir: str = ".",
    dry_run: bool = False,
    overwrite_existing: bool = False,
) -> None:
    print(f"Restoring project from snapshot: {snapshot_file}")
    if dry_run: print("DRY RUN: No files will be written.")

    try:
        with open(snapshot_file, "r", encoding="utf-8") as f:
            full_content = f.read()
    except FileNotFoundError:
        print(f"Error: Snapshot file '{snapshot_file}' not found.")
        return
    except Exception as e:
        print(f"Error reading snapshot file: {e}")
        return

    # Regex to find file blocks. It captures the file path (group 1) and its content (group 2).
    # The crucial point is that group(2) captures ALL characters (including newlines due to re.DOTALL)
    # after the header line's trailing newline, until the START of the next file header or end of string.
    # The lookahead `(?=...)` is non-consuming, so the content is captured completely.
    file_block_pattern = re.compile(
        r"^========== FILE: (.*?) ==========\n"  # Match header line and its trailing newline
        r"(.*?)"                                 # Capture content (non-greedy)
        r"(?=\n========== FILE: |\Z)",           # Lookahead: followed by newline then next header, OR end of string.
                                                # \Z matches only at the end of the string.
        re.MULTILINE | re.DOTALL
    )
    
    # Find the end of the initial info header to start parsing file blocks
    info_header_last_line = SNAPSHOT_INFO_TEMPLATE.splitlines()[-1]
    content_start_index = full_content.find(info_header_last_line)
    if content_start_index == -1:
        print("Error: Could not find the end of the snapshot info header.")
        return
    
    # Slice the content to start exactly after the info header,
    # and then lstrip any *leading* newlines that might be left before the first file block.
    # This ensures the regex for the first file block can match correctly.
    content_to_parse = full_content[content_start_index + len(info_header_last_line):].lstrip('\n')

    files_restored = 0
    files_skipped = 0
    files_overwritten = 0
    
    matches = file_block_pattern.finditer(content_to_parse)

    for match in matches:
        relative_file_path = match.group(1).strip()
        # KRİTİK DÜZELTME: match.group(2) üzerinde .strip() metodunu kaldırdık.
        # Bu, tüm boşluk karakterlerinin (yeni satırlar dahil) korunmasını sağlar.
        content_part = match.group(2) 

        os_specific_relative_path = relative_file_path.replace("/", os.sep)
        target_file_path = os.path.join(target_dir, os_specific_relative_path)
        
        # DEBUG YARDIMI: Yazılacak içeriğin uzunluğunu göster
        print(f"Processing file: {relative_file_path} (Content length: {len(content_part)}) -> {target_file_path}")

        if os.path.exists(target_file_path) and not overwrite_existing:
            print(f"  SKIPPED: File '{target_file_path}' already exists (overwrite_existing is False).")
            files_skipped += 1
            continue

        if os.path.exists(target_file_path) and overwrite_existing:
            print(f"  OVERWRITING: File '{target_file_path}'.")
            files_overwritten += 1

        if not dry_run:
            try:
                os.makedirs(os.path.dirname(target_file_path), exist_ok=True)
                with open(target_file_path, "w", encoding="utf-8") as f:
                    f.write(content_part)
                files_restored += 1
            except Exception as e:
                print(f"  ERROR: Could not write file '{target_file_path}': {e}")
        else:
            if not os.path.exists(os.path.dirname(target_file_path)):
                print(f"  DRY RUN: Would create directory {os.path.dirname(target_file_path)}")
            print(f"  DRY RUN: Would write {len(content_part)} bytes to {target_file_path}")
            files_restored += 1

    print("\n--- Restoration Summary ---")
    print(f"Files processed for restoration: {files_restored}")
    if not dry_run:
        print(f"Files actually written/overwritten: {files_restored - files_skipped}")
        print(f"Files overwritten: {files_overwritten}")
    print(f"Files skipped (already exist and overwrite=False): {files_skipped}")


def main():
    parser = argparse.ArgumentParser(description="Project Snapshot Tool (Full Version)")
    subparsers = parser.add_subparsers(dest="command", required=True)

    parser_collect = subparsers.add_parser(
        "collect", help="Collect project files into a single snapshot file."
    )
    parser_collect.add_argument(
        "output_file",
        type=str,
        default="project_snapshot_full.txt",
        nargs="?",
        help="Path to the output snapshot file (default: project_snapshot_full.txt)",
    )
    parser_collect.add_argument(
        "--include-dir",
        action="append",
        dest="include_dirs",
        help="Directory to include (relative to base_dir or absolute). Can be used multiple times. Defaults to ['.']",
    )
    parser_collect.add_argument(
        "--include-ext",
        action="append",
        dest="include_extensions",
        help="File extension to include (e.g., .py, .md). Can be used multiple times. Defaults to common code/config extensions.",
    )
    parser_collect.add_argument(
        "--exclude-pattern",
        action="append",
        dest="exclude_patterns",
        help="Pattern/path to exclude. Can be used multiple times. Defaults to common ignores.",
    )
    parser_collect.add_argument(
        "--base-dir",
        type=str,
        default=".",
        help="Base directory for the project (default: current directory). Relative paths are resolved against this.",
    )
    parser_collect.add_argument(
        "--clean-comments",
        action="store_true",
        help="Attempt to remove comments from collected code files (.py, .sh, .bat).",
    )

    parser_restore = subparsers.add_parser(
        "restore", help="Restore project files from a snapshot."
    )
    parser_restore.add_argument(
        "snapshot_file", type=str, help="Path to the snapshot file to restore from."
    )
    parser_restore.add_argument(
        "--target-dir",
        type=str,
        default=".",
        help="Directory where files will be restored (default: current directory).",
    )
    parser_restore.add_argument(
        "--dry-run",
        action="store_true",
        help="Simulate restoration without writing any files.",
    )
    parser_restore.add_argument(
        "--overwrite",
        action="store_true",
        dest="overwrite_existing",
        help="Overwrite files if they already exist in the target directory.",
    )

    args = parser.parse_args()

    if args.command == "collect":
        final_include_dirs = (
            args.include_dirs if args.include_dirs is not None else DEFAULT_INCLUDE_DIRS
        )
        final_include_extensions = (
            args.include_extensions
            if args.include_extensions is not None
            else DEFAULT_INCLUDE_EXTENSIONS
        )
        final_exclude_patterns = (
            args.exclude_patterns
            if args.exclude_patterns is not None
            else DEFAULT_EXCLUDE_PATTERNS
        )
        collect_project_files_full(
            output_file=args.output_file,
            include_dirs=final_include_dirs,
            include_extensions=final_include_extensions,
            exclude_patterns=final_exclude_patterns,
            base_dir=args.base_dir,
            clean_comments=args.clean_comments,
        )
    elif args.command == "restore":
        restore_from_full_snapshot(
            snapshot_file=args.snapshot_file,
            target_dir=args.target_dir,
            dry_run=args.dry_run,
            overwrite_existing=args.overwrite_existing,
        )


if __name__ == "__main__":
    # Example usage:
    # python tools/snapshot_generator.py collect project_full_snapshot.txt
    # python tools/snapshot_generator.py restore project_full_snapshot.txt --dry-run   
    # python tools/snapshot_generator.py restore project_full_snapshot.txt --overwrite
    print("Project Snapshot Tool (Full Version)")
    print("Collects project files into a single snapshot file or restores from a snapshot.")
    print("Use 'collect' to create a snapshot and 'restore' to restore files from it.")    
    main()

========== FILE: worker/pyproject.toml ==========
[build-system]
requires = ["setuptools>=61.0"]
build-backend = "setuptools.build_meta"

[project]
name = "azuraforge-worker"
version = "0.1.0"
description = "The Celery worker for the AzuraForge Platform. Discovers and runs pipeline plugins."
requires-python = ">=3.8"
dependencies = [
    # Worker'ın kendisi doğrudan Learner'a değil, eklentilere ihtiyaç duyar.
    # Eklentiler zaten Learner'a bağımlı olduğu için, pip bunu çözecektir.
    
    # Geliştirme ve test sırasında bu eklentinin kurulu olmasını sağlıyoruz.
    # Canlı bir ortamda, hangi eklentilerin kurulacağı bir konfigürasyon dosyası ile yönetilir.
    "azuraforge-app-stock-predictor @ git+https://github.com/AzuraForge/app-stock-predictor.git@main",
    
    "celery[redis]",
    "pyyaml",
]

[project.scripts]
start-worker = "azuraforge_worker.main:run_celery_worker"

========== FILE: worker/README.md ==========
# worker

========== FILE: worker/setup.py ==========
from setuptools import setup, find_packages

setup(
    package_dir={"": "src"},
    packages=find_packages(where="src"),
)

========== FILE: worker/src/azuraforge_worker/celery_app.py ==========
from celery import Celery
import os

REDIS_URL = os.getenv("REDIS_URL", "redis://localhost:6379/0")

celery_app = Celery(
    "azuraforge_worker",
    broker=REDIS_URL,
    backend=REDIS_URL,
    # Worker başladığında görevlerin nerede olduğunu belirtir.
    include=["azuraforge_worker.tasks.training_tasks"]
)

========== FILE: worker/src/azuraforge_worker/main.py ==========
import subprocess
import sys

def run_celery_worker():
    """'start-worker' komutu için giriş noktası."""
    print("👷‍♂️ Starting AzuraForge Worker...")
    command = [
        sys.executable, "-m", "celery",
        "-A", "azuraforge_worker.celery_app:celery_app", # Celery app nesnesinin tam yolu
        "worker",
        "--pool=solo", # Windows uyumluluğu üretim için prefork kullanın
        "--loglevel=INFO"
    ]
    subprocess.run(command)

========== FILE: worker/src/azuraforge_worker/__init__.py ==========
from .celery_app import celery_app

# Bu, diğer projelerin 'from azuraforge_worker import celery_app' yapabilmesini sağlar.
__all__ = ("celery_app",)

========== FILE: worker/src/azuraforge_worker/tasks/training_tasks.py ==========
import logging
import os
import json
from datetime import datetime
from importlib.metadata import entry_points
from celery import current_task # Görevin durumunu güncellemek için
import time # Simülasyon için
import traceback # Hata detaylarını yakalamak için

from ..celery_app import celery_app
# applications reposundan pipeline'ı import etmek için bu kodun olduğu yerde değil,
# pip tarafından paket olarak kurulmuş azuraforge_stockapp'tan import edilecek.

# --- Eklenti Keşfi ---
def discover_pipelines():
    """
    Sisteme kurulmuş tüm AzuraForge pipeline'larını ve varsa varsayılan konfigürasyon
    fonksiyonlarını keşfeder.
    Dönüş değeri: { 'pipeline_id': { 'pipeline_class': Class, 'get_config_func': Function | None } }
    """
    logging.info("Worker: Discovering installed AzuraForge pipeline plugins and configurations...")
    discovered = {}
    try:
        # Pipeline sınıflarını keşfet
        pipeline_entry_points = entry_points(group='azuraforge.pipelines')
        for ep in pipeline_entry_points:
            logging.info(f"Worker: Found pipeline plugin: '{ep.name}' -> points to '{ep.value}'")
            discovered[ep.name] = {'pipeline_class': ep.load()} 
        
        # Konfigürasyon fonksiyonlarını keşfet (aynı isimle eşleşmeli)
        config_entry_points = entry_points(group='azuraforge.configs')
        for ep in config_entry_points:
            logging.info(f"Worker: Found config entry point: '{ep.name}' -> points to '{ep.value}'")
            if ep.name in discovered:
                discovered[ep.name]['get_config_func'] = ep.load()
            else:
                logging.warning(f"Worker: Found config for '{ep.name}' but no corresponding pipeline. Skipping config.")
                
    except Exception as e:
        logging.error(f"Worker: Error discovering pipelines or configs: {e}", exc_info=True)
    
    # Debug için keşfedilenleri logla
    for p_id, p_info in discovered.items():
        logging.info(f"Worker: Discovered pipeline '{p_id}' (Config available: {'get_config_func' in p_info})")

    return discovered

AVAILABLE_PIPELINES_AND_CONFIGS = discover_pipelines() # Değiştirildi
if not AVAILABLE_PIPELINES_AND_CONFIGS: # Değiştirildi
    logging.warning("Worker: No AzuraForge pipelines found! Please install a pipeline plugin, e.g., 'azuraforge-app-stock-predictor'.")

REPORTS_BASE_DIR = os.path.abspath(os.getenv("REPORTS_DIR", "/app/reports"))
os.makedirs(REPORTS_BASE_DIR, exist_ok=True) # Dizinin var olduğundan emin ol

@celery_app.task(bind=True, name="start_training_pipeline")
def start_training_pipeline(self, config: dict):
    pipeline_name = config.get("pipeline_name")
    
    # Değiştirildi: AVAILABLE_PIPELINES_AND_CONFIGS kullan
    if not pipeline_name or pipeline_name not in AVAILABLE_PIPELINES_AND_CONFIGS:
        raise ValueError(f"Pipeline '{pipeline_name}' not found or installed.")

    PipelineInfo = AVAILABLE_PIPELINES_AND_CONFIGS[pipeline_name]
    PipelineClass = PipelineInfo['pipeline_class']

    # --- Deney için benzersiz bir klasör ve ID oluştur ---
    run_timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    experiment_id = f"{pipeline_name}_{run_timestamp}_{self.request.id}" 
    
    pipeline_specific_report_dir = os.path.join(REPORTS_BASE_DIR, pipeline_name)
    os.makedirs(pipeline_specific_report_dir, exist_ok=True)
    experiment_dir = os.path.join(pipeline_specific_report_dir, experiment_id)
    os.makedirs(experiment_dir, exist_ok=True)
    
    config['experiment_id'] = experiment_id
    config['task_id'] = self.request.id
    config['experiment_dir'] = experiment_dir
    config['start_time'] = datetime.now().isoformat() # Yeni: Başlangıç zamanını ekle

    logging.info(f"Worker: Instantiating pipeline '{PipelineClass.__name__}' for experiment {experiment_id}")
    
    initial_report_data = {
        "task_id": self.request.id, "experiment_id": experiment_id, "status": "STARTED", "config": config, "results": {}
    }
    with open(os.path.join(experiment_dir, "results.json"), 'w') as f:
        json.dump(initial_report_data, f, indent=4, default=str)

    try:
        # --- KRİTİK DÜZELTME: Pipeline'a Celery Task objesini iletiyoruz ---
        # Bu, pipeline'ın içindeki Learner'ın Celery state'i güncelleyebilmesini sağlar.
        pipeline_instance = PipelineClass(config, celery_task=self) # <- Yeni parametre
        results = pipeline_instance.run() 

        final_report_data = {
            "task_id": self.request.id, "experiment_id": experiment_id, "status": "SUCCESS", "config": config, "results": results, "completed_at": datetime.now().isoformat()
        }
        with open(os.path.join(experiment_dir, "results.json"), 'w') as f:
            json.dump(final_report_data, f, indent=4, default=str)
            
        logging.info(f"Worker: Task {self.request.id} for pipeline '{pipeline_name}' completed successfully. Results in {experiment_dir}")
        return final_report_data

    except Exception as e:
        error_traceback = traceback.format_exc()
        error_message = f"Pipeline execution failed for {pipeline_name}: {e}\n{error_traceback}"
        logging.error(error_message)
        
        self.update_state(state='FAILURE', meta={'error_message': str(e), 'traceback': error_traceback})
        
        error_report_data = {
            "task_id": self.request.id, "experiment_id": experiment_id, "status": "FAILURE", "config": config, "error": error_message, "failed_at": datetime.now().isoformat()
        }
        with open(os.path.join(experiment_dir, "results.json"), 'w') as f:
            json.dump(error_report_data, f, indent=4)
            
        raise e
========== FILE: worker/src/azuraforge_worker/tasks/__init__.py ==========
