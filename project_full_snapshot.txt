PROJE KOD SNAPSHOT (TAM)
Toplam 76 dosya bulundu ve eklendi.
Dahil Edilen Dizinler: .
Dahil Edilen Uzantılar: .toml, .py, .yaml, .yml, .json, .md, .txt, html, .bat, .sh, .jsx, .js, .json, .css
Hariç Tutulan Desenler/Yollar: __pycache__, .git, .venv, .vscode, .idea, build, dist, *.egg-info, *.pyc, *.so, *.pyd, .pytest_cache, .mypy_cache, .dataset, dataset, .logs, logs, .output, output, inputs, outputs, .tmp, checkpoints, reports, docs/_build, site, node_modules, .DS_Store, Thumbs.db, *.lock, package-lock.json
================================================================================

========== FILE: docker-compose.yml ==========
services:
  # 1. Redis Servisi (Mesaj Kuyruğu ve Sonuç Deposu)
  redis:
    image: "redis:alpine"
    container_name: azuraforge_redis
    ports: ["6379:6379"]
    volumes: ["redis_data:/data"]

  # --- KÜTÜPHANE SERVİSLERİ (SADECE BUILD VE SAĞLIK KONTROLÜ İÇİN) ---
  # Bu servisler, ana uygulamaların (API, Worker) bağımlılıklarını kurabilmesi için önceden build edilir.
  # Bağımlılık zincirinde alt seviyede oldukları için 'depends_on' gerekmez,
  # API ve Worker Dockerfile'ları onları zaten pip ile çeker.
  # Buradaki tanımlar, onların da build edildiğini doğrulamak içindir.

  # 2. Core Kütüphanesi
  core_lib:
    container_name: azuraforge_core_lib_build_test
    build:
      context: ./core # 'core' reposunun bulunduğu klasörü göster
      dockerfile: Dockerfile # 'core' reposunun içindeki Dockerfile
    command: python -c "import azuraforge_core; print('AzuraForge Core built and imported successfully in Docker!')"
    # volumes: - ./core:/app # Geliştirme sırasında kodu anında yansıtmak için
    # Bu servis sadece build ediliyor, çalıştırılmıyor. Mount'a gerek yok.

  # 3. Learner Kütüphanesi
  learner_lib:
    container_name: azuraforge_learner_lib_build_test
    build:
      context: ./learner
      dockerfile: Dockerfile
    command: python -c "import azuraforge_learner; print('AzuraForge Learner built and imported successfully in Docker!')"
    # volumes: - ./learner:/app # Sadece build ediliyor.

  # 4. Applications Katalogu
  applications_catalog:
    container_name: azuraforge_applications_catalog_build_test
    build:
      context: ./applications
      dockerfile: Dockerfile
    command: python -c "import azuraforge_applications; print('AzuraForge Applications Catalog built and imported successfully in Docker!')"
    # volumes: - ./applications:/app # Sadece build ediliyor.

  # 5. App Stock Predictor (Uygulama Eklentisi)
  app_stock_predictor:
    container_name: azuraforge_app_stock_predictor_build_test
    build:
      context: ./app-stock-predictor
      dockerfile: Dockerfile
    command: python -c "import azuraforge_stockapp; print('AzuraForge App Stock Predictor built and imported successfully in Docker!')"
    # volumes: - ./app-stock-predictor:/app # Sadece build ediliyor.

  # --- ANA PLATFORM SERVİSLERİ ---
  # Bu servisler, tüm ekosistemin temelidir ve diğer kütüphanelere bağımlıdır.

  # 6. API Servisi
  api:
    container_name: azuraforge_api
    build:
      context: ./api # 'api' reposunun bulunduğu klasörü göster
      dockerfile: Dockerfile # 'api' reposunun içindeki Dockerfile
    command: start-api # 'api' reposundaki entrypoint script'i
    ports: ["8000:8000"]
    volumes:
      - ./api:/app # API'ın kendi kodu
      - ${REPORTS_DIR}:/app/reports # Ortak rapor dizini (Host makineden mount ediliyor)
    environment:
      - REDIS_URL=${REDIS_URL}
      - REPORTS_DIR=/app/reports
    depends_on: [redis] # Redis'e bağımlı

  # 7. Worker Servisi
  worker:
    container_name: azuraforge_worker
    build:
      context: ./worker
      dockerfile: Dockerfile
    command: start-worker
    volumes:
      - ./worker:/app # Worker'ın kendi kodu
      - ${REPORTS_DIR}:/app/reports # Raporlar için
    environment:
      - REDIS_URL=${REDIS_URL}
      - REPORTS_DIR=/app/reports
    depends_on: [redis]

  # 8. Dashboard Servisi
  dashboard:
    container_name: azuraforge_dashboard
    build:
      context: ./dashboard
      dockerfile: Dockerfile
    command: npm run dev -- --host 0.0.0.0
    ports: ["5173:5173"]
    volumes:
      - ./dashboard:/app
      - /app/node_modules
    depends_on: [api]

volumes:
  redis_data: # Redis verilerini kalıcı tutmak için volume

========== FILE: README.md ==========
# AzuraForge Platform 🚀

**AzuraForge Platform**, yapay zeka modellerini sıfırdan oluşturmak, eğitmek ve yönetmek için tasarlanmış modüler, dağıtık ve eklenti tabanlı bir MLOps platformudur. Modern mikroservis mimarisi prensipleriyle inşa edilmiştir.

Bu depo, AzuraForge ekosistemindeki tüm ana servisleri (API, Worker, Dashboard) ve kütüphaneleri (Core, Learner, Applications) bir araya getiren **orkestrasyon katmanıdır**.

## 🎯 Temel Amaçlar ve Felsefe

*   **Sıfırdan İnşa:** Derin öğrenme motoru ve temel bileşenler sıfırdan geliştirilmiştir.
*   **Modülerlik ve Bağımsızlık:** Her bileşen (kütüphane, API, worker, UI, uygulama) kendi bağımsız repo'sunda yaşar ve kendi sorumluluğuna sahiptir.
*   **Olay Güdümlü Mimari:** Servisler arası iletişim olay tabanlı (Celery, Redis, WebSockets) gerçekleşir.
*   **Eklenti Tabanlı:** Yeni yapay zeka modelleri ve uygulamaları, platformun çekirdek koduna dokunmadan birer eklenti (plugin) olarak eklenebilir.
*   **Ölçeklenebilirlik:** Dağıtık servisler sayesinde yatayda ölçeklenebilir.
*   **Profesyonel Geliştirici Deneyimi:** Otomatik kurulum, test ve dokümantasyon ile geliştirme sürecini kolaylaştırmak.

## 🏛️ Mimari Genel Bakış

AzuraForge platformu, aşağıdaki bağımsız GitHub depolarından oluşan bir mikroservis mimarisini benimser:

-   **`core`** (`azuraforge-core`): Otomatik türev yeteneklerine sahip temel matematik motoru (NumPy/CuPy).
-   **`learner`** (`azuraforge-learner`): `core` üzerinde geliştirilmiş yüksek seviyeli derin öğrenme kütüphanesi (Katmanlar, Optimizatörler, Kayıp Fonksiyonları, `Learner` sınıfı).
-   **`applications`** (`azuraforge-applications`): Platform için resmi uygulama eklentilerinin katalogu (JSON dosyası).
-   **`app-stock-predictor`** (`azuraforge-app-stock-predictor`): Gerçek bir uygulama eklentisi örneği (Hisse Senedi Tahmini).
-   **`api`** (`azuraforge-api`): RESTful API ve WebSocket endpoint'leri sunan iletişim katmanı.
-   **`worker`** (`azuraforge-worker`): Arka plan görevlerini işleyen ve uygulama eklentilerini çalıştıran işçi servisi.
-   **`dashboard`** (`azuraforge-dashboard`): Platform için web tabanlı kullanıcı arayüzü.

Bu repo, tüm bu servisleri tek bir `docker-compose` komutuyla ayağa kaldıran ana orkestrasyon katmanıdır.

## 🚀 Hızlı Başlangıç (Docker Compose ile)

Tüm platformu yerel makinenizde tek bir komutla başlatmak için:

1.  **Docker Desktop'ın yüklü ve çalıştığından emin olun.**
2.  **Bu repoyu klonlayın:**
    ```bash
    git clone https://github.com/AzuraForge/platform.git
    cd platform
    ```
3.  **.env dosyasını oluşturun:**
    Proje kök dizininde `.env` adında bir dosya oluşturun ve içine raporların kaydedileceği dizini belirtin.
    ```
    # .env
    REDIS_URL=redis://redis:6379/0
    # Rapor dizini: Worker'ın sonuçları yazacağı ve API'nin okuyacağı host makinedeki dizin
    # Windows için C:/azuraforge_platform_reports veya ./reports
    # Linux/macOS için: ./reports
    REPORTS_DIR=./reports 
    ```
    (Windows kullanıyorsanız `REPORTS_DIR`'i `C:/azuraforge_platform_reports` gibi bir mutlak yola ayarlamanız daha güvenli olabilir).
4.  **Platformu başlatın:**
    ```bash
    docker-compose up --build -d
    ```
    (`-d` parametresi arka planda çalıştırmayı sağlar.)

5.  **Platforma erişin:**
    -   **Dashboard:** `http://localhost:5173`
    -   **API Dokümantasyonu:** `http://localhost:8000/api/v1/docs`

## 🛠️ Geliştirme Rehberi ve İç Detaylar

Bu rehber, platformun nasıl çalıştığını, nasıl katkıda bulunacağınızı ve geliştirme ortamınızı nasıl yöneteceğinizi detaylandırır.

**[Tam Geliştirme Rehberine Git](./docs/DEVELOPMENT_GUIDE.md)**

## 🤝 Katkıda Bulunma

Projenin gelişimine katkıda bulunmak için [CONTRIBUTING.md](./docs/CONTRIBUTING.md) dosyasını inceleyin.

## 🗺️ Yol Haritası ve Gelecek Vizyonu

Projenin tamamlanan aşamaları, mevcut durumu ve gelecek hedefleri hakkında bilgi almak için [PROJECT_JOURNEY.md](./docs/PROJECT_JOURNEY.md) dosyasını okuyun.

========== FILE: api/pyproject.toml ==========
[build-system]
requires = ["setuptools>=61.0"]
build-backend = "setuptools.build_meta"

[project]
name = "azuraforge-api"
version = "0.1.0"
description = "The API server for the AzuraForge Platform."
requires-python = ">=3.8"

dependencies = [
    "azuraforge-learner @ git+https://github.com/AzuraForge/learner.git@main",
    "azuraforge-worker @ git+https://github.com/AzuraForge/worker.git@main", # Worker bağımlılığı, streaming için şart
    "azuraforge-applications @ git+https://github.com/AzuraForge/applications.git@main",
    "fastapi", "uvicorn[standard]", "pydantic-settings", "python-dotenv", "pyyaml",

]

[project.scripts]
start-api = "azuraforge_api.main:run_server"

========== FILE: api/README.md ==========
# api

========== FILE: api/setup.py ==========
from setuptools import setup, find_packages

setup(
    # Bu satır, setuptools'a paketlerin 'src' klasörünün içinde
    # olduğunu söyler.
    package_dir={"": "src"},
    
    # Bu satır, 'src' klasörünün içindeki tüm Python paketlerini
    # (azuraforge_api ve altındakiler) otomatik olarak bulur.
    packages=find_packages(where="src"),
)

========== FILE: api/src/azuraforge_api/main.py ==========
import uvicorn
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware

from .core.config import settings
from .routes import experiments, pipelines, streaming

def create_app() -> FastAPI:
    app = FastAPI(title=settings.PROJECT_NAME, version="0.1.0")
    
    # CORS ayarlarını dinamik olarak belirle
    if settings.CORS_ORIGINS == "*":
        allowed_origins = ["*"]
    else:
        allowed_origins = [origin.strip() for origin in settings.CORS_ORIGINS.split(',')]

    app.add_middleware(
        CORSMiddleware,
        allow_origins=allowed_origins, # <-- Burası değişti
        allow_credentials=True,
        allow_methods=["*"],
        allow_headers=["*"],
    )

    # --- KRİTİK DÜZELTME: Prefix'i geri ekliyoruz ---
    app.include_router(experiments.router, prefix=settings.API_V1_PREFIX)
    app.include_router(pipelines.router, prefix=settings.API_V1_PREFIX)
    app.include_router(streaming.router) # WebSocket router'ı eklendi
    
    @app.get("/", tags=["Root"])
    def read_root():
        return {"message": f"Welcome to {settings.PROJECT_NAME}"}
        
    return app

app = create_app()

def run_server():
    print(f"🚀 Starting {settings.PROJECT_NAME}...")
    uvicorn.run("azuraforge_api.main:app", host="0.0.0.0", port=8000, reload=True)

========== FILE: api/src/azuraforge_api/__init__.py ==========

========== FILE: api/src/azuraforge_api/core/config.py ==========
from pydantic_settings import BaseSettings, SettingsConfigDict

class Settings(BaseSettings):
    PROJECT_NAME: str = "AzuraForge API"
    API_V1_PREFIX: str = "/api/v1"
    
    # Yeni CORS ayarı
    # Virgülle ayrılmış URL'ler veya tümüne izin vermek için "*"
    CORS_ORIGINS: str = "*" # Varsayılan olarak tümüne izin ver (geliştirme için)
    
    model_config = SettingsConfigDict(env_file=".env", env_file_encoding='utf-8')

settings = Settings()

========== FILE: api/src/azuraforge_api/core/__init__.py ==========

========== FILE: api/src/azuraforge_api/routes/experiments.py ==========
from fastapi import APIRouter, HTTPException
from typing import List, Dict, Any
from ..services import experiment_service

router = APIRouter(prefix="/experiments", tags=["Experiments"])

@router.get("/", response_model=List[Dict[str, Any]])
def get_all_experiments():
    return experiment_service.list_experiments()

@router.post("/", status_code=202, response_model=Dict[str, Any])
def create_new_experiment(config: Dict[str, Any]):
    return experiment_service.start_experiment(config)

@router.get("/{task_id}/status", response_model=Dict[str, Any])
def get_experiment_status(task_id: str):
    return experiment_service.get_task_status(task_id)

========== FILE: api/src/azuraforge_api/routes/pipelines.py ==========
from fastapi import APIRouter, HTTPException
from typing import List, Dict, Any
from ..services import experiment_service

router = APIRouter(prefix="/pipelines", tags=["Pipelines"])

@router.get("/", response_model=List[Dict[str, Any]])
def get_all_available_pipelines():
    return experiment_service.get_available_pipelines()

========== FILE: api/src/azuraforge_api/routes/streaming.py ==========
import asyncio
import logging
from fastapi import APIRouter, WebSocket, WebSocketDisconnect
from celery.result import AsyncResult

# Worker projesinden celery_app'i import etmemiz gerekiyor.
# Bu, api projesinin worker'a bağımlı olmasını gerektirir.
from azuraforge_worker import celery_app

router = APIRouter()

@router.websocket("/ws/task_status/{task_id}")
async def websocket_task_status(websocket: WebSocket, task_id: str):
    """
    Bir Celery görevinin durumunu bir WebSocket üzerinden anlık olarak yayınlar.
    """
    await websocket.accept()
    logging.info(f"WebSocket connection accepted for task: {task_id}")
    
    task_result = AsyncResult(task_id, app=celery_app)
    
    try:
        # Görev tamamlanana kadar döngüde kal
        while not task_result.ready():
            # Sadece PROGRESS durumundaki ara bilgileri gönder
            if task_result.state == 'PROGRESS':
                await websocket.send_json({
                    "state": task_result.state,
                    "details": task_result.info, # .info, update_state ile gönderilen meta verisini içerir
                })
            # Çok sık kontrol etmemek için kısa bir bekleme
            await asyncio.sleep(1)
        
        # Görev bittiğinde (SUCCESS, FAILURE vb.) son durumu ve sonucu gönder
        await websocket.send_json({
            "state": task_result.state,
            "details": task_result.result, # Başarı durumunda sonuç, hata durumunda hata detayları
        })

    except WebSocketDisconnect:
        logging.warning(f"WebSocket disconnected for task: {task_id}")
    except Exception as e:
        logging.error(f"An error occurred in WebSocket for task {task_id}: {e}")
        # Hata durumunda da istemciye bildirim gönder
        try:
            await websocket.send_json({
                "state": "ERROR",
                "details": {"message": str(e), "task_id": task_id}
            })
        except Exception:
            pass # Eğer gönderilemezse, bağlantı zaten kapanmıştır.
    finally:
        logging.info(f"Closing WebSocket for task {task_id}")
        # Bağlantıyı her durumda kapat
        await websocket.close()

========== FILE: api/src/azuraforge_api/routes/__init__.py ==========

========== FILE: api/src/azuraforge_api/services/experiment_service.py ==========
import json
import os
import glob
from importlib import resources
from typing import List, Dict, Any, Optional
from celery.result import AsyncResult 

from azuraforge_worker import celery_app
from azuraforge_worker.tasks.training_tasks import start_training_pipeline # Görevi import et

REPORTS_BASE_DIR = os.path.abspath(os.getenv("REPORTS_DIR", "/app/reports"))

def get_available_pipelines() -> List[Dict[str, Any]]:
    try:
        with resources.open_text("azuraforge_applications", "official_apps.json") as f:
            return json.load(f)
    except (FileNotFoundError, ModuleNotFoundError) as e:
        print(f"ERROR: Could not find or read the official apps catalog. {e}")
        return []

def list_experiments() -> List[Dict[str, Any]]:
    # **GÜNCELLENDİ:** completed_at bilgisi de results.json'dan okunacak.
    experiment_files = glob.glob(f"{REPORTS_BASE_DIR}/**/results.json", recursive=True)
    experiments = []
    for f_path in experiment_files:
        try:
            with open(f_path, 'r') as f:
                data = json.load(f)
                experiments.append({
                    "id": data.get("experiment_id", os.path.basename(os.path.dirname(f_path))),
                    "status": data.get("status", "UNKNOWN"),
                    "pipeline_name": data.get("config", {}).get("pipeline_name", "N/A"),
                    "ticker": data.get("config", {}).get("data_sourcing", {}).get("ticker", "N/A"),
                    "final_loss": data.get("results", {}).get("final_loss"),
                    "completed_at": data.get("completed_at"), # Yeni eklendi
                    "started_at": data.get("config", {}).get("start_time"), # Eğer config'de varsa
                })
        except Exception as e:
            print(f"Warning: Could not read results.json from {f_path}: {e}")
            continue
    experiments.sort(key=lambda x: x.get('id', ''), reverse=True)
    return experiments

def start_experiment(config: Dict[str, Any]) -> Dict[str, Any]:
    pipeline_name = config.get("pipeline_name", "unknown")
    print(f"Service: Sending task for pipeline '{pipeline_name}' to Celery.")
    task = start_training_pipeline.delay(config) 
    return {"message": "Experiment submitted to worker.", "task_id": task.id}

def get_task_status(task_id: str) -> Dict[str, Any]:
    task_result = AsyncResult(task_id, app=celery_app)
    status = task_result.state
    
    # --- KRİTİK DÜZELTME: Exception objesini string'e çevir ---
    details = task_result.info 
    if isinstance(details, Exception): # Eğer gelen bir hata objesiyse
        details = str(details) # Onu string'e çevirerek JSON serileştirme hatasını önle
    
    # Başarı durumunda, Celery result.result'ı doğrudan alıp gönder
    if status == 'SUCCESS' or status == 'FAILURE':
        return {"task_id": task_id, "status": status, "result": task_result.result}
    
    return {"task_id": task_id, "status": status, "details": details}

========== FILE: api/src/azuraforge_api/services/__init__.py ==========

========== FILE: api/src/azuraforge_api/tasks/training_tasks.py ==========

========== FILE: api/src/azuraforge_api/tasks/__init__.py ==========

========== FILE: app-stock-predictor/pyproject.toml ==========
[build-system]
requires = ["setuptools>=61.0"]
build-backend = "setuptools.build_meta"

[project]
name = "azuraforge-app-stock-predictor"
version = "0.1.0"
description = "A stock prediction pipeline application for the AzuraForge platform."
requires-python = ">=3.8"
dependencies = [
    "azuraforge-learner @ git+https://github.com/AzuraForge/learner.git@main",
    "yfinance",
    "pandas",
    "scikit-learn",
]

[project.entry-points]
# Var olan giriş noktası
"azuraforge.pipelines" = { stock_predictor = "azuraforge_stockapp.pipeline:StockPredictionPipeline" }

# --- YENİ GİRİŞ NOKTASI GRUBU ---
"azuraforge.configs" = { stock_predictor = "azuraforge_stockapp.pipeline:get_default_config" }

========== FILE: app-stock-predictor/README.md ==========
# app-stock-predictor

========== FILE: app-stock-predictor/setup.py ==========
from setuptools import setup, find_packages
setup(
    package_dir={"": "src"},
    packages=find_packages(where="src"),
)

========== FILE: app-stock-predictor/src/azuraforge_stockapp/pipeline.py ==========
import logging
import yfinance as yf
import numpy as np
from sklearn.preprocessing import MinMaxScaler
import os 
from typing import Any # <<<< KRİTİK DÜZELTME

from azuraforge_learner import Learner, Sequential, Linear, MSELoss, SGD, ReLU

class StockPredictionPipeline:
    def __init__(self, config: dict, celery_task: Any = None):
        self.config = config
        self.logger = logging.getLogger(self.__class__.__name__)
        logging.basicConfig(level="INFO", format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        self.celery_task = celery_task # Celery Task objesi buraya iletilir

    def run(self):
        data_sourcing_config = self.config.get("data_sourcing", {})
        training_params_config = self.config.get("training_params", {})
        
        ticker = data_sourcing_config.get("ticker", "MSFT")
        start_date = data_sourcing_config.get("start_date", "2021-01-01")
        epochs = training_params_config.get("epochs", 10)
        lr = training_params_config.get("lr", 0.01)

        self.logger.info(f"--- Running Stock Prediction Pipeline for {ticker} ({epochs} epochs) ---")
        
        try:
            data = yf.download(ticker, start=start_date, progress=False, actions=False, auto_adjust=True)
            if data.empty:
                raise ValueError(f"No data downloaded for ticker: {ticker} from {start_date}")
            self.logger.info(f"Downloaded {len(data)} rows of data.")
            close_prices = data[['Close']].values.astype(np.float32)
        except Exception as e:
            self.logger.error(f"Data download failed for {ticker}: {e}")
            raise 

        scaler = MinMaxScaler(feature_range=(-1, 1))
        scaled_prices = scaler.fit_transform(close_prices)
        
        if len(scaled_prices) < 2:
            self.logger.warning("Not enough data to create sequences for training.")
            return {"status": "completed", "ticker": ticker, "final_loss": float('inf'), "message": "Not enough data for training"}

        X, y = scaled_prices[:-1], scaled_prices[1:]
        
        model = Sequential(Linear(1, 64), ReLU(), Linear(64, 1))
        criterion = MSELoss()
        optimizer = SGD(model.parameters(), lr=lr)
        
        # --- KRİTİK DÜZELTME: Learner'a Celery Task objesini iletiyoruz ---
        learner = Learner(model, criterion, optimizer, current_task=self.celery_task)

        self.logger.info(f"Starting training for {epochs} epochs...")
        history = learner.fit(X, y, epochs=epochs)
        
        final_loss = history['loss'][-1]
        self.logger.info(f"Training complete. Final loss: {final_loss:.6f}")
        
        return {"status": "completed", "ticker": ticker, "final_loss": final_loss, "loss": history['loss']}

========== FILE: app-stock-predictor/src/azuraforge_stockapp/__init__.py ==========

========== FILE: app-stock-predictor/src/azuraforge_stockapp/config/stock_predictor_config.yml ==========
pipeline_name: "stock_predictor"

data_sourcing:
  ticker: "MSFT" # Microsoft
  start_date: "2021-01-01"

training_params:
  epochs: 10 # Test için kısa tutalım
  lr: 0.01

========== FILE: app-stock-predictor/src/azuraforge_stockapp/config/__init__.py ==========

========== FILE: applications/pyproject.toml ==========
[build-system]
requires = ["setuptools>=61.0"]
build-backend = "setuptools.build_meta"

[project]
name = "azuraforge-applications"
version = "0.1.0"
description = "A catalog of official applications for the AzuraForge platform."

========== FILE: applications/README.md ==========
# applications

========== FILE: applications/setup.py ==========
from setuptools import setup, find_packages

setup(
    package_dir={"": "src"},
    packages=find_packages(where="src"),
    # EN ÖNEMLİ KISIM: Paket kurulduğunda .json dosyasının da kopyalanmasını sağlar
    include_package_data=True, 
    package_data={
        "azuraforge_applications": ["*.json"], # "azuraforge_apps_catalog" -> "azuraforge_applications"
    },
)


========== FILE: applications/src/azuraforge_applications/official_apps.json ==========
[
  {
    "id": "stock_predictor",
    "name": "Hisse Senedi Fiyat Tahmini",
    "repository": "https://github.com/AzuraForge/app-stock-predictor",
    "description": "LSTM tabanlı hisse senedi fiyat tahmini yapar."
  },
  {
    "id": "weather_forecaster",
    "name": "Hava Durumu Tahmini",
    "repository": "https://github.com/AzuraForge/app-weather-forecaster",
    "description": "Gelecekteki hava durumunu tahmin eder (Henüz Geliştirilmedi)."
  }
]

========== FILE: applications/src/azuraforge_applications/__init__.py ==========


========== FILE: core/pyproject.toml ==========
[build-system]
requires = ["setuptools>=61.0"]
build-backend = "setuptools.build_meta"

[project]
name = "azuraforge-core"
version = "0.1.2"
authors = [{ name = "Azmi Sahin" }]
description = "The core automatic differentiation engine (Tensor object) for the AzuraForge ecosystem."
readme = "README.md"
requires-python = ">=3.8"
license = { text = "MIT" }
classifiers = ["Programming Language :: Python :: 3"]
dependencies = ["numpy"]

# --- YENİ BÖLÜM ---
[project.optional-dependencies]
dev = ["pytest"]

========== FILE: core/README.md ==========
# core

========== FILE: core/setup.py ==========
from setuptools import setup, find_packages
setup(
    package_dir={"": "src"},
    packages=find_packages(where="src"),
)

========== FILE: core/src/azuraforge_core/tensor.py ==========
import os
from typing import Callable, List, Optional, Set, Tuple, Union, Any, cast
import numpy as np

DEVICE = os.environ.get("AZURAFORGE_DEVICE", "cpu").lower()

xp: Any
if DEVICE == "gpu":
    try:
        import cupy
        xp = cupy
    except ImportError:
        import numpy
        xp = numpy
        DEVICE = "cpu"
else:
    import numpy
    xp = numpy

ArrayType = Any
ScalarType = Union[int, float, bool, np.number, xp.number]

def _empty_backward_op() -> None: pass

class Tensor:
    def __init__(self, data: Any, _children: Tuple["Tensor", ...] = (), _op: str = "", requires_grad: bool = False):
        if isinstance(data, Tensor): self.data = data.data.copy()
        else: self.data = xp.array(data, dtype=np.float64)
        
        self.requires_grad = requires_grad
        self.grad: Optional[ArrayType] = xp.zeros_like(self.data) if requires_grad else None
        self._backward: Callable[[], None] = _empty_backward_op
        self._prev: Set["Tensor"] = set(_children)
        self._op: str = _op

    def backward(self, grad_output: Optional[ArrayType] = None) -> None:
        if not self.requires_grad: return
        topo: List[Tensor] = []
        visited: Set[Tensor] = set()
        def build_topo(v):
            if v not in visited:
                visited.add(v); [build_topo(child) for child in v._prev]; topo.append(v)
        build_topo(self)
        for t in topo:
            if t.grad is not None: t.grad.fill(0.0)
        self.grad = xp.ones_like(self.data) if grad_output is None else xp.asarray(grad_output, dtype=np.float64).reshape(self.data.shape)
        for v in reversed(topo): v._backward()

    def to_cpu(self) -> np.ndarray:
        if hasattr(self.data, 'get'): return self.data.get()
        return np.array(self.data, copy=True)

    def __add__(self, other: Any) -> "Tensor":
        other = _ensure_tensor(other)
        out = Tensor(self.data + other.data, (self, other), "+", self.requires_grad or other.requires_grad)
        def _backward():
            if self.requires_grad: self.grad += _unbroadcast_to(self.data.shape, out.grad)
            if other.requires_grad: other.grad += _unbroadcast_to(other.data.shape, out.grad)
        out._backward = _backward
        return out

    def __mul__(self, other: Any) -> "Tensor":
        other = _ensure_tensor(other)
        out = Tensor(self.data * other.data, (self, other), "*", self.requires_grad or other.requires_grad)
        def _backward():
            if self.requires_grad: self.grad += _unbroadcast_to(self.data.shape, other.data * out.grad)
            if other.requires_grad: other.grad += _unbroadcast_to(other.data.shape, self.data * out.grad)
        out._backward = _backward
        return out

    # ... (Diğer tüm metodlar aynı kalabilir, sadece __add__ ve __mul__ _unbroadcast_to kullanacak şekilde güncellendi)
    def __pow__(self, power: float) -> "Tensor":
        out = Tensor(self.data ** power, (self,), f"**{power}", self.requires_grad)
        def _backward():
            if self.requires_grad: self.grad += (power * (self.data ** (power - 1))) * out.grad
        out._backward = _backward
        return out

    def dot(self, other: "Tensor") -> "Tensor":
        out = Tensor(self.data @ other.data, (self, other), "@", self.requires_grad or other.requires_grad)
        def _backward():
            if self.requires_grad: self.grad += out.grad @ other.data.T
            if other.requires_grad: other.grad += self.data.T @ out.grad
        out._backward = _backward
        return out

    def sum(self, axis=None, keepdims=False) -> "Tensor":
        out = Tensor(xp.sum(self.data, axis=axis, keepdims=keepdims), (self,), "sum", self.requires_grad)
        def _backward(_axis=axis, _keepdims=keepdims):
            if self.requires_grad and self.grad is not None:
                grad_val = out.grad
                if _axis is not None and not _keepdims:
                    grad_val = xp.expand_dims(grad_val, axis=_axis)
                self.grad += grad_val
        out._backward = _backward
        return out

    def mean(self, axis=None, keepdims=False) -> "Tensor":
        sum_val = self.sum(axis=axis, keepdims=keepdims)
        num_elements = float(np.prod(self.data.shape) / np.prod(sum_val.data.shape))
        return sum_val * (1.0 / num_elements)
    
    def relu(self) -> "Tensor":
        out = Tensor(xp.maximum(0, self.data), (self,), "ReLU", self.requires_grad)
        def _backward():
            if self.requires_grad: self.grad += (self.data > 0) * out.grad
        out._backward = _backward
        return out
        
    def __repr__(self): return f"Tensor(data={self.data}, requires_grad={self.requires_grad})"
    def __neg__(self): return self * -1
    def __sub__(self, other): return self + (-other)
    def __truediv__(self, other): return self * (_ensure_tensor(other) ** -1)
    __radd__ = __add__
    def __rmul__(self, other): return self * other
    def __rsub__(self, other): return _ensure_tensor(other) - self
    def __rtruediv__(self, other): return _ensure_tensor(other) / self

def _ensure_tensor(val: Any) -> "Tensor":
    return val if isinstance(val, Tensor) else Tensor(val)

# --- YENİ VE SAĞLAM _unbroadcast_to FONKSİYONU ---
def _unbroadcast_to(target_shape: Tuple[int, ...], grad: ArrayType) -> ArrayType:
    """Bir gradyanı, orijinal tensörün (yayınlamadan önceki) şekline geri küçültür."""
    if target_shape == grad.shape:
        return grad
    
    # Boyut sayısını eşitle
    ndim_diff = grad.ndim - len(target_shape)
    if ndim_diff > 0:
        grad = grad.sum(axis=tuple(range(ndim_diff)))

    # Boyutu 1 olan eksenler boyunca topla
    axes_to_sum = []
    for i, dim in enumerate(target_shape):
        if dim == 1:
            axes_to_sum.append(i)
    
    if axes_to_sum:
        grad = grad.sum(axis=tuple(axes_to_sum), keepdims=True)
        
    return grad

========== FILE: core/src/azuraforge_core/__init__.py ==========
from .tensor import Tensor, xp, DEVICE, ArrayType, ScalarType, _unbroadcast_to

__all__ = ["Tensor", "xp", "DEVICE", "ArrayType", "ScalarType", "_unbroadcast_to"]

========== FILE: core/tests/azuraforge_core/test_tensor.py ==========
import pytest
import numpy as np

# Test edilecek paketi import et
from azuraforge_core import Tensor

def test_tensor_creation_and_defaults():
    """Tensor nesnesinin doğru şekilde ve varsayılan değerlerle oluşturulduğunu test eder."""
    t = Tensor([1, 2, 3])
    assert isinstance(t.data, np.ndarray)
    assert t.requires_grad is False
    assert t.grad is None

def test_tensor_requires_grad():
    """`requires_grad=True` olduğunda gradyan dizisinin oluşturulduğunu test eder."""
    t = Tensor([1, 2], requires_grad=True)
    assert t.requires_grad is True
    assert isinstance(t.grad, np.ndarray)
    assert np.array_equal(t.grad, np.array([0.0, 0.0]))

def test_addition_backward():
    """Basit toplama işlemi için geri yayılımın doğru çalıştığını test eder."""
    a = Tensor([1, 2, 3], requires_grad=True)
    b = Tensor(5, requires_grad=True)
    
    # c = a.sum() + b  ->  dc/da = [1, 1, 1], dc/db = 1
    c = a.sum() + b
    
    c.backward()

    assert a.grad is not None
    assert b.grad is not None
    assert np.array_equal(a.grad, [1, 1, 1])
    assert b.grad == 1.0

def test_multiplication_backward():
    """Basit çarpma işlemi için geri yayılımın doğru çalıştığını test eder."""
    x = Tensor(2.0, requires_grad=True)
    y = Tensor(3.0, requires_grad=True)
    
    z = x * y
    
    z.backward() # dz/dx = y = 3,  dz/dy = x = 2

    assert x.grad == 3.0
    assert y.grad == 2.0

def test_chained_rule_backward():
    """Zincir kuralının birden çok işlemde doğru çalıştığını test eder."""
    x = Tensor(2.0, requires_grad=True)
    y = Tensor(3.0, requires_grad=True)

    z = x * y  # dz/dx = y, dz/dy = x
    q = z + x  # dq/dz = 1, dq/dx = 1
    
    # Zincir Kuralı:
    # dq/dx = (dq/dz * dz/dx) + dq/dx = (1 * y) + 1 = 3 + 1 = 4
    # dq/dy = (dq/dz * dz/dy) = 1 * x = 2
    q.backward()

    assert x.grad == 4.0
    assert y.grad == 2.0

def test_dot_product_backward():
    """Matris çarpımı için geri yayılımı test eder."""
    a_data = np.random.randn(2, 3)
    b_data = np.random.randn(3, 4)
    a = Tensor(a_data, requires_grad=True)
    b = Tensor(b_data, requires_grad=True)
    
    c = a.dot(b)
    
    # Gradyanı 1'lerden oluşan bir matrisle başlat
    c.backward(np.ones_like(c.data))
    
    # Manuel olarak hesaplanan gradyanlar
    grad_a_manual = np.ones_like(c.data) @ b_data.T
    grad_b_manual = a_data.T @ np.ones_like(c.data)
    
    assert np.allclose(a.grad, grad_a_manual)
    assert np.allclose(b.grad, grad_b_manual)


def test_relu_backward():
    """ReLU aktivasyonu için geri yayılımı test eder."""
    a = Tensor([-1, 0, 5], requires_grad=True)
    r = a.relu()
    r.backward(np.array([10, 20, 30]))

    # Gradyan sadece pozitif değerler için akar (self.data > 0)
    assert np.array_equal(a.grad, [0, 0, 30])

========== FILE: dashboard/eslint.config.js ==========
import js from '@eslint/js'
import globals from 'globals'
import reactHooks from 'eslint-plugin-react-hooks'
import reactRefresh from 'eslint-plugin-react-refresh'
import { defineConfig, globalIgnores } from 'eslint/config'

export default defineConfig([
  globalIgnores(['dist']),
  {
    files: ['**/*.{js,jsx}'],
    extends: [
      js.configs.recommended,
      reactHooks.configs['recommended-latest'],
      reactRefresh.configs.vite,
    ],
    languageOptions: {
      ecmaVersion: 2020,
      globals: globals.browser,
      parserOptions: {
        ecmaVersion: 'latest',
        ecmaFeatures: { jsx: true },
        sourceType: 'module',
      },
    },
    rules: {
      'no-unused-vars': ['error', { varsIgnorePattern: '^[A-Z_]' }],
    },
  },
])

========== FILE: dashboard/index.html ==========
<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <link rel="icon" type="image/svg+xml" href="/vite.svg" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Vite + React</title>
  </head>
  <body>
    <div id="root"></div>
    <script type="module" src="/src/main.jsx"></script>
  </body>
</html>

========== FILE: dashboard/package.json ==========
{
  "name": "dashboard",
  "private": true,
  "version": "0.0.0",
  "type": "module",
  "scripts": {
    "dev": "vite",
    "build": "vite build",
    "lint": "eslint .",
    "preview": "vite preview"
  },
  "dependencies": {
    "axios": "^1.10.0",
    "chart.js": "^4.5.0",
    "react": "^19.1.0",
    "react-chartjs-2": "^5.3.0",
    "react-dom": "^19.1.0",
    "prop-types": "^15.8.1",  
    "react-router-dom": "^6.25.1"
  },
  "devDependencies": {
    "@eslint/js": "^9.29.0",
    "@types/react": "^19.1.8",
    "@types/react-dom": "^19.1.6",
    "@vitejs/plugin-react": "^4.5.2",
    "eslint": "^9.29.0",
    "eslint-plugin-react-hooks": "^5.2.0",
    "eslint-plugin-react-refresh": "^0.4.20",
    "globals": "^16.2.0",
    "vite": "^7.0.0"
  }
}

========== FILE: dashboard/README.md ==========
# React + Vite

This template provides a minimal setup to get React working in Vite with HMR and some ESLint rules.

Currently, two official plugins are available:

- [@vitejs/plugin-react](https://github.com/vitejs/vite-plugin-react/blob/main/packages/plugin-react) uses [Babel](https://babeljs.io/) for Fast Refresh
- [@vitejs/plugin-react-swc](https://github.com/vitejs/vite-plugin-react/blob/main/packages/plugin-react-swc) uses [SWC](https://swc.rs/) for Fast Refresh

## Expanding the ESLint configuration

If you are developing a production application, we recommend using TypeScript with type-aware lint rules enabled. Check out the [TS template](https://github.com/vitejs/vite/tree/main/packages/create-vite/template-react-ts) for information on how to integrate TypeScript and [`typescript-eslint`](https://typescript-eslint.io) in your project.

========== FILE: dashboard/vite.config.js ==========
import { defineConfig } from 'vite'
import react from '@vitejs/plugin-react'

// https://vite.dev/config/
export default defineConfig({
  plugins: [react()],
})

========== FILE: dashboard/src/App.css ==========
/* ========== YENİ/GÜNCELLENECEK DOSYA: dashboard/src/App.css (Kapsamlı Stil Dosyası) ========== */

/* Temel Reset ve Genel Stiller */
:root {
  font-family: 'Inter', system-ui, Avenir, Helvetica, Arial, sans-serif;
  line-height: 1.5;
  font-weight: 400;

  color-scheme: light dark;
  color: #333; /* Varsayılan metin rengi */
  background-color: #f0f2f5; /* Genel arkaplan */

  font-synthesis: none;
  text-rendering: optimizeLegibility;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}

body {
  margin: 0;
  display: flex;
  min-height: 100vh;
  width: 100vw;
  font-size: 16px;
  overflow: hidden; /* Dikey kaydırmayı body'den kaldır, main-content'e bırak */
}

#root {
  display: flex; /* Sidebar ve ana içeriği yan yana koymak için */
  flex-grow: 1; /* Tüm alanı kapla */
  width: 100%;
}

/* Ana Uygulama Düzeni */
.app-layout {
  display: flex;
  flex-grow: 1;
}

/* Sidebar Stilleri */
.sidebar {
  width: 250px;
  background-color: #2c3e50; /* Koyu gri */
  color: white;
  padding: 20px;
  box-shadow: 2px 0 5px rgba(0, 0, 0, 0.2);
  display: flex;
  flex-direction: column;
  flex-shrink: 0; /* Küçülmesini engelle */
}

.sidebar h2 {
  text-align: center;
  color: #42b983; /* AzuraForge yeşili */
  margin-bottom: 30px;
  font-size: 1.5em;
  font-weight: bold;
}

.sidebar nav ul {
  list-style: none;
  padding: 0;
  margin: 0;
}

.sidebar nav ul li {
  margin-bottom: 10px;
}

.sidebar nav a {
  display: block;
  padding: 12px 15px;
  color: white;
  text-decoration: none;
  border-radius: 8px; /* Daha modern bir yuvarlaklık */
  transition: background-color 0.3s ease, color 0.3s ease;
  display: flex;
  align-items: center;
  gap: 12px; /* İkon ve yazı arası boşluk */
  font-size: 1.05em;
}

.sidebar nav a:hover {
  background-color: #4a6680; /* Daha açık bir hover rengi */
}

.sidebar nav a.active {
  background-color: #42b983; /* Aktif menü rengi */
  font-weight: bold;
}

/* Main Content Area */
.main-content {
  flex-grow: 1;
  padding: 30px;
  background-color: #f0f2f5; /* Açık gri arkaplan */
  overflow-y: auto; /* Dikey kaydırma çubuğu */
}

/* Header/Title */
.page-header {
  margin-bottom: 30px;
  color: #2c3e50;
  border-bottom: 1px solid #e0e0e0; /* Daha açık çizgi */
  padding-bottom: 15px;
  display: flex;
  flex-direction: column;
}

.page-header h1 {
  font-size: 2.5em; /* Daha büyük başlık */
  margin: 0;
  display: flex;
  align-items: center;
  gap: 15px;
}

.page-header p {
  color: #777;
  margin-top: 8px;
  font-size: 1.1em;
}

/* Genel Bileşen Stilleri */
.card {
  background-color: white;
  border-radius: 10px; /* Daha belirgin yuvarlak köşeler */
  box-shadow: 0 5px 15px rgba(0, 0, 0, 0.1); /* Daha belirgin gölge */
  padding: 25px;
  margin-bottom: 25px;
  transition: transform 0.2s ease-in-out; /* Hover efekti için */
}

.card.clickable:hover { /* Sadece tıklanabilir kartlara hover efekti */
  transform: translateY(-5px); /* Hafif yukarı kayma efekti */
}


.section-title {
  font-size: 2em;
  color: #2c3e50;
  margin-bottom: 25px;
  border-bottom: 1px solid #e0e0e0;
  padding-bottom: 10px;
}

/* Form Stilleri */
.form-container {
  max-width: 700px; /* Daha geniş form */
  margin: 0 auto;
  padding: 40px;
  background-color: white;
  border-radius: 10px;
  box-shadow: 0 5px 15px rgba(0, 0, 0, 0.1);
}

.form-group {
  margin-bottom: 25px;
}

.form-group label {
  display: block;
  margin-bottom: 10px;
  font-weight: bold;
  color: #555;
  font-size: 1.1em;
}

.form-group input[type="text"],
.form-group input[type="number"],
.form-group select,
.form-group textarea {
  width: calc(100% - 24px); /* Padding'i hesaba kat */
  padding: 12px;
  border: 1px solid #ccc;
  border-radius: 6px;
  font-size: 1em;
  box-sizing: border-box; /* Padding ve border genişliğe dahil */
}

.form-group textarea {
  min-height: 150px; /* Daha uzun textarea */
  resize: vertical;
}

.button-primary {
  background-color: #42b983;
  color: white;
  padding: 15px 30px;
  border: none;
  border-radius: 8px;
  cursor: pointer;
  font-size: 1.1em;
  font-weight: bold;
  transition: background-color 0.3s ease, transform 0.2s ease;
  width: auto; /* Genişliği içeriğe göre ayarla */
}

.button-primary:hover:not(:disabled) {
  background-color: #369c70;
  transform: translateY(-2px);
}

.button-primary:disabled {
  background-color: #cccccc;
  cursor: not-allowed;
  opacity: 0.7;
}

.button-link { /* İç metinlerde buton gibi görünen linkler için */
  background: none;
  border: none;
  color: #007bff;
  text-decoration: underline;
  cursor: pointer;
  font-size: 1em;
  padding: 0;
  font-family: inherit; /* Yazı tipini koru */
}
.button-link:hover {
  color: #0056b3;
}

/* Status Badges */
.status-badge {
  display: inline-block;
  padding: 6px 12px;
  border-radius: 20px;
  font-size: 0.85em;
  font-weight: bold;
  color: white;
  text-transform: uppercase;
  min-width: 90px;
  text-align: center;
  margin-left: 10px;
}

.status-badge.status-started, .status-badge.status-progress, .status-badge.status-connecting {
  background-color: #007bff; /* Mavi */
}

.status-badge.status-success {
  background-color: #28a745; /* Yeşil */
}

.status-badge.status-failure, .status-badge.status-error, .status-badge.status-disconnected {
  background-color: #dc3545; /* Kırmızı */
}

.status-badge.status-pending, .status-badge.status-unknown, .status-badge.status-no_task {
  background-color: #6c757d; /* Gri */
}

/* Feedback Messages */
.feedback {
  padding: 12px 20px;
  border-radius: 8px;
  margin-top: 20px;
  font-weight: bold;
  display: flex;
  align-items: center;
  gap: 10px;
}

.feedback.success {
  background-color: #d4edda;
  color: #155724;
  border: 1px solid #c3e6cb;
}

.feedback.error {
  background-color: #f8d7da;
  color: #721c24;
  border: 1px solid #f5c6cb;
}
.feedback.info {
  background-color: #d1ecf1;
  color: #0c5460;
  border: 1px solid #bee5eb;
}

/* Tablo Stilleri (ExperimentsList için) */
.table-container {
  overflow-x: auto;
  border-radius: 10px;
  box-shadow: 0 5px 15px rgba(0, 0, 0, 0.1);
  background-color: white;
  margin-bottom: 25px;
}

table {
  width: 100%;
  border-collapse: collapse;
  min-width: 700px; /* Küçük ekranlarda kaydırma çubuğu çıksın */
}

table th, table td {
  padding: 15px 20px;
  text-align: left;
  border-bottom: 1px solid #eee;
}

table th {
  background-color: #e9ecef;
  color: #495057;
  font-weight: bold;
  text-transform: uppercase;
  font-size: 0.9em;
}

table tbody tr:hover {
  background-color: #f5f5f5;
}

.exp-id {
  font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, Courier, monospace;
}

.clickable-cell {
  cursor: pointer;
}

.clickable-cell a {
  text-decoration: none;
  color: #007bff;
  font-weight: bold;
  transition: color 0.2s ease;
}

.clickable-cell a:hover {
  color: #0056b3;
  text-decoration: underline;
}

/* JSON / Code Block */
.code-block {
  background-color: #eef1f5; /* Hafif daha açık gri */
  border: 1px solid #dcdcdc;
  padding: 20px;
  border-radius: 8px;
  overflow-x: auto;
  font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, Courier, monospace;
  font-size: 0.95em;
  color: #444;
  white-space: pre-wrap;
  word-break: break-all;
  margin-top: 15px;
  margin-bottom: 20px;
}

/* Chart Container */
.chart-container {
  position: relative;
  height: 450px; /* Grafiğin yüksekliğini artır */
  width: 100%;
  margin-top: 25px;
  background-color: white; /* Grafik arkaplanı beyaz */
  padding: 20px;
  border-radius: 10px;
  box-shadow: 0 4px 10px rgba(0, 0, 0, 0.08);
}
.chart-container h4 {
  margin-top: 0;
  color: #2c3e50;
  margin-bottom: 15px;
  font-size: 1.3em;
}

/* Progress Bar (HTML native) */
progress {
  width: 100%;
  height: 22px; /* Daha belirgin */
  -webkit-appearance: none;
  appearance: none;
  border-radius: 12px;
  overflow: hidden; /* For Safari */
  border: none;
}

progress::-webkit-progress-bar {
  background-color: #e0e0e0;
  border-radius: 12px;
}

progress::-webkit-progress-value {
  background-color: #42b983; /* Yeşilimsi */
  border-radius: 12px;
  transition: width 0.5s ease;
}

progress::-moz-progress-bar {
  background-color: #42b983;
  border-radius: 12px;
}

.progress-section {
  padding: 15px;
  background-color: #e7f3ff; /* Açık mavi arkaplan */
  border: 1px solid #b3d9ff;
  border-radius: 8px;
  margin-top: 15px;
  margin-bottom: 15px;
}
.progress-section p {
  margin: 5px 0;
  color: #333;
}

/* Running Experiments Grid */
.running-experiments-grid {
  display: grid;
  grid-template-columns: repeat(auto-fill, minmax(320px, 1fr)); /* Daha büyük kartlar */
  gap: 25px;
  margin-bottom: 30px;
}
.experiment-card {
  cursor: pointer;
}
.experiment-card h3 {
  font-size: 1.4em;
  margin-top: 0;
  margin-bottom: 10px;
  color: #2c3e50;
}
.experiment-card p {
  margin-bottom: 5px;
  font-size: 0.95em;
}

/* Responsive Ayarlar */
@media (max-width: 992px) {
  .sidebar {
    width: 200px;
  }
  .sidebar h2 {
    font-size: 1.3em;
  }
  .sidebar nav a {
    font-size: 0.95em;
  }
  .main-content {
    padding: 20px;
  }
  .page-header h1 {
    font-size: 2em;
  }
  .section-title {
    font-size: 1.8em;
  }
  .running-experiments-grid {
    grid-template-columns: repeat(auto-fill, minmax(280px, 1fr));
    gap: 20px;
  }
}

@media (max-width: 768px) {
  .app-layout {
    flex-direction: column; /* Küçük ekranlarda sidebar üstte */
  }
  .sidebar {
    width: 100%;
    height: auto;
    flex-direction: row;
    justify-content: center;
    padding: 15px;
    box-shadow: 0 2px 5px rgba(0, 0, 0, 0.2);
  }
  .sidebar h2 {
    display: none; /* Küçük ekranlarda başlığı gizle */
  }
  .sidebar nav {
    width: 100%;
  }
  .sidebar nav ul {
    display: flex;
    justify-content: space-around;
    flex-wrap: wrap;
  }
  .sidebar nav ul li {
    margin: 5px;
  }
  .sidebar nav a {
    padding: 10px 15px;
    font-size: 0.9em;
    gap: 8px;
  }
  .main-content {
    padding: 15px;
  }
  .form-container {
    padding: 25px;
  }
  .page-header h1 {
    font-size: 1.8em;
  }
  .section-title {
    font-size: 1.6em;
  }
  table {
    font-size: 0.9em;
  }
  table th, table td {
    padding: 10px 12px;
  }
}

@media (max-width: 480px) {
  .sidebar nav a {
    padding: 8px 10px;
    font-size: 0.85em;
    gap: 5px;
  }
  .running-experiments-grid {
    grid-template-columns: 1fr; /* Çok küçük ekranlarda tek sütun */
  }
  .chart-container {
    height: 300px; /* Daha küçük grafik */
    padding: 15px;
  }
  .form-container {
    padding: 20px;
  }
}
========== FILE: dashboard/src/App.jsx ==========
// ========== GÜNCELLENECEK DOSYA: dashboard/src/App.jsx (Yeni Ana Layout ve Router) ==========
import { useState } from 'react';
import { Routes, Route, Link, useNavigate, useLocation } from 'react-router-dom';
import './App.css'; // Yeni stil dosyasını import et

// Bileşenleri import et
import ExperimentsList from './components/ExperimentsList'; // Halen kullanılacak (sadece tablo gösterimi için)
import NewExperiment from './components/NewExperiment';
import ExperimentTracker from './components/ExperimentTracker';
import ExperimentDetailPage from './components/ExperimentDetailPage'; 
import DashboardOverview from './pages/DashboardOverview'; // Yeni Genel Bakış Sayfası

function App() {
  const [trackingTaskId, setTrackingTaskId] = useState(null); // Canlı takip edilen görev ID'si
  const navigate = useNavigate();
  const location = useLocation();

  // Yeni bir deney başlatıldığında çağrılacak callback
  const handleExperimentStarted = (taskId) => {
    // Yeni deney başladığında direkt Tracker sayfasına yönlendirme yapabiliriz.
    // Ancak ana Dashboard'un otomatik yenilemesi de bu görevi yakalayacaktır.
    // Şimdilik Tracker sayfasına yönlendirme mantığını koruyalım,
    // ancak DashboardOverview'da anlık listeleme zaten yapılacağı için
    // bu navigasyonun zorunlu olmadığını unutmayalım.
    if (taskId) {
        setTrackingTaskId(taskId); // Takip edilecek görevi ayarla
        navigate(`/tracker/${taskId}`); // Canlı takip sayfasına yönlendir
    }
  };

  // Aktif link stilini belirlemek için yardımcı fonksiyon
  const isActive = (path) => {
    if (path === '/') return location.pathname === '/' || location.pathname === '/experiments';
    if (path === '/tracker' && location.pathname.startsWith('/tracker/')) return true;
    if (path === '/experiments' && location.pathname.startsWith('/experiments/')) return true;
    return location.pathname === path;
  };

  return (
    <div className="app-layout"> {/* Yeni ana layout div'i */}
      {/* Sidebar */}
      <aside className="sidebar">
        <h2>AzuraForge</h2>
        <nav>
          <ul>
            <li>
              <Link to="/experiments" className={isActive('/experiments') ? 'active' : ''}>
                <span role="img" aria-label="dashboard">📊</span> Genel Bakış
              </Link>
            </li>
            <li>
              <Link to="/new-experiment" className={isActive('/new-experiment') ? 'active' : ''}>
                <span role="img" aria-label="rocket">🚀</span> Yeni Deney Başlat
              </Link>
            </li>
            {/* Eğer bir görev takip ediliyorsa veya tracker sayfasındaysak canlı takip sekmesini göster */}
            {trackingTaskId && (
              <li>
                <Link to={`/tracker/${trackingTaskId}`} className={isActive('/tracker') ? 'active' : ''}>
                  <span role="img" aria-label="satellite">🛰️</span> Canlı Takip
                </Link>
              </li>
            )}
            {/* Diğer menü öğeleri (Uygulama Kataloğu, Model Kaydı vb.) buraya eklenebilir */}
          </ul>
        </nav>
      </aside>

      {/* Ana İçerik */}
      <main className="main-content">
        <Routes>
          {/* Ana sayfa "/experiments" ile aynı içeriği göstersin */}
          <Route path="/" element={<DashboardOverview 
            onExperimentSelect={(id) => navigate(`/experiments/${id}`)} 
            onNewExperimentClick={() => navigate('/new-experiment')}
          />} />
          <Route path="/experiments" element={<DashboardOverview 
            onExperimentSelect={(id) => navigate(`/experiments/${id}`)} 
            onNewExperimentClick={() => navigate('/new-experiment')}
          />} />
          <Route path="/new-experiment" element={<NewExperiment onExperimentStarted={handleExperimentStarted} />} />
          <Route path="/tracker/:taskId" element={<ExperimentTracker />} />
          <Route path="/experiments/:experimentId" element={<ExperimentDetailPage />} />
        </Routes>
      </main>
    </div>
  );
}

export default App;
========== FILE: dashboard/src/index.css ==========
:root {
  font-family: system-ui, Avenir, Helvetica, Arial, sans-serif;
  line-height: 1.5;
  font-weight: 400;

  color-scheme: light dark;
  color: rgba(255, 255, 255, 0.87);
  background-color: #242424;

  font-synthesis: none;
  text-rendering: optimizeLegibility;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}

a {
  font-weight: 500;
  color: #646cff;
  text-decoration: inherit;
}
a:hover {
  color: #535bf2;
}

body {
  margin: 0;
  display: flex;
  place-items: center;
  min-width: 320px;
  min-height: 100vh;
}

h1 {
  font-size: 3.2em;
  line-height: 1.1;
}

button {
  border-radius: 8px;
  border: 1px solid transparent;
  padding: 0.6em 1.2em;
  font-size: 1em;
  font-weight: 500;
  font-family: inherit;
  background-color: #1a1a1a;
  cursor: pointer;
  transition: border-color 0.25s;
}
button:hover {
  border-color: #646cff;
}
button:focus,
button:focus-visible {
  outline: 4px auto -webkit-focus-ring-color;
}

@media (prefers-color-scheme: light) {
  :root {
    color: #213547;
    background-color: #ffffff;
  }
  a:hover {
    color: #747bff;
  }
  button {
    background-color: #f9f9f9;
  }
}

========== FILE: dashboard/src/main.jsx ==========
// ========== GÜNCELLENECEK DOSYA: dashboard/src/main.jsx ==========
import { StrictMode } from 'react';
import { createRoot } from 'react-dom/client';
import './index.css'; // Global stil dosyanız (varsa)
import App from './App.jsx';
import { BrowserRouter } from 'react-router-dom'; // BrowserRouter import edildi

createRoot(document.getElementById('root')).render(
  <StrictMode>
    {/* Uygulamayı BrowserRouter ile sarmala */}
    <BrowserRouter> 
      <App />
    </BrowserRouter>
  </StrictMode>,
);
========== FILE: dashboard/src/components/ExperimentCard.jsx ==========
// ========== YENİ DOSYA: dashboard/src/components/ExperimentCard.jsx ==========
import { useState, useEffect, useRef } from 'react';
import { useNavigate } from 'react-router-dom';
import PropTypes from 'prop-types';
import { Line } from 'react-chartjs-2'; // Grafik bileşeni

// Chart.js bileşenlerini kaydet
import {
  Chart as ChartJS, CategoryScale, LinearScale, PointElement, LineElement, Title, Tooltip, Legend
} from 'chart.js';
ChartJS.register(CategoryScale, LinearScale, PointElement, LineElement, Title, Tooltip, Legend);

function ExperimentCard({ experiment, onSelect }) {
  const navigate = useNavigate();
  // Kartın kendi internal state'i, WebSocket'ten gelen canlı verilerle güncellenecek
  const [currentStatus, setCurrentStatus] = useState(experiment.status);
  const [currentLoss, setCurrentLoss] = useState(experiment.final_loss);
  const [progress, setProgress] = useState(0);
  const [statusText, setStatusText] = useState(experiment.status || "Bilgi bekleniyor...");
  const [chartData, setChartData] = useState({ labels: [], datasets: [] });
  const ws = useRef(null); // WebSocket bağlantısını tutmak için ref

  useEffect(() => {
    // Sadece çalışan veya henüz başlamış deneyler için WebSocket bağlantısı kur
    const isLiveStatus = (status) => status === 'STARTED' || status === 'PROGRESS';
    let cleanupNeeded = false;

    // İlk yüklemede ve experiment.id değiştiğinde sıfırlama yap
    setCurrentStatus(experiment.status);
    setCurrentLoss(experiment.final_loss);
    setProgress(experiment.status === 'SUCCESS' ? 100 : 0);
    setStatusText(experiment.status || "Bilgi bekleniyor...");
    setChartData({ // Grafiği sıfırla
        labels: [], 
        datasets: [{ 
            label: 'Eğitim Kaybı', 
            data: [], 
            borderColor: 'rgb(75, 192, 192)', 
            backgroundColor: 'rgba(75, 192, 192, 0.5)',
            tension: 0.1, 
            fill: false 
        }] 
    });


    if (isLiveStatus(experiment.status)) { // İlk render'da statüye göre karar ver
      cleanupNeeded = true;
      const wsUrl = `ws://localhost:8000/ws/task_status/${experiment.id}`;
      
      // Önceki bağlantıyı temizle (varsa)
      if (ws.current) { ws.current.close(); }
      ws.current = new WebSocket(wsUrl);

      ws.current.onopen = () => {
        console.log(`WebSocket connected for card (Task: ${experiment.id})`);
        setStatusText("Bağlantı kuruldu, veri bekleniyor...");
      };

      ws.current.onmessage = (event) => {
        const data = JSON.parse(event.data);
        setCurrentStatus(data.state);
        
        if (data.state === 'PROGRESS') {
          setCurrentLoss(data.details?.loss);
          if (data.details?.total_epochs) {
            setProgress(((data.details.epoch || 0) / data.details.total_epochs) * 100);
          }
          setStatusText(data.details?.status_text || `Epoch ${data.details?.epoch}/${data.details?.total_epochs}`);
          
          setChartData(prevData => {
            const epoch = data.details.epoch;
            const loss = data.details.loss;

            if (loss !== undefined && epoch !== undefined) {
                // Sadece yeni bir epoch kaydı geldiyse ekle
                if (!prevData.labels.includes(`Epoch ${epoch}`)) {
                    return {
                        labels: [...prevData.labels, `Epoch ${epoch}`],
                        datasets: [{
                            ...prevData.datasets[0], 
                            data: [...(prevData.datasets[0]?.data || []), loss]
                        }]
                    };
                }
            }
            return prevData;
        });

        } else if (data.state === 'SUCCESS' || data.state === 'FAILURE') {
          // Görev bittiğinde (SUCCESS, FAILURE vb.) son durumu ve sonucu al
          if (data.result?.final_loss !== undefined) {
             setCurrentLoss(data.result.final_loss);
          } else if (data.result?.loss && Array.isArray(data.result.loss)) { // Eğitim geçmişindeki son kayıp
             setCurrentLoss(data.result.loss[data.result.loss.length - 1]);
             setChartData(prevData => { // Tüm geçmişi grafik için yükle
                const losses = data.result.loss;
                const labels = Array.from({ length: losses.length }, (_, i) => `Epoch ${i + 1}`);
                return {
                    labels: labels,
                    datasets: [{
                        ...prevData.datasets[0], 
                        data: losses
                    }]
                };
             });
          }
          
          if (data.state === 'SUCCESS') setProgress(100);
          else setProgress(0); // Başarısız ise ilerleme 0
          setStatusText(data.result?.error_message || data.state); // Hata mesajı varsa onu göster
          
          // Görev bittiğinde WebSocket bağlantısını kapat
          if (ws.current) {
            ws.current.close();
          }
        }
      };

      ws.current.onerror = (error) => {
        console.error(`WebSocket Error for card (Task: ${experiment.id}):`, error);
        setCurrentStatus("ERROR");
        setStatusText("WebSocket bağlantı hatası!");
        if (ws.current) ws.current.close(); // Hata durumunda da kapat
      };

      ws.current.onclose = () => {
        console.log(`WebSocket disconnected for card (Task: ${experiment.id})`);
        setCurrentStatus(prevStatus => {
          // Eğer başarı veya hata ile kapanmadıysa DISCONNECTED yap
          if (prevStatus === 'SUCCESS' || prevStatus === 'FAILURE' || prevStatus === 'ERROR') {
            return prevStatus;
          }
          return 'DISCONNECTED';
        });
        setStatusText(prevStatusText => {
            if (prevStatusText.startsWith("WebSocket")) return prevStatusText;
            return `Bağlantı kesildi. Son durum: ${currentStatus}`;
        });
      };
    } else {
        // Eğer deney başlangıçta tamamlanmış veya başarısız durumdaysa, WebSocket kurmaya gerek yok
        // Ve tamamlannış veriyi yükle
        setCurrentStatus(experiment.status);
        setCurrentLoss(experiment.final_loss);
        setProgress(experiment.status === 'SUCCESS' ? 100 : 0);
        setStatusText(experiment.status);
        if (experiment.results?.loss && Array.isArray(experiment.results.loss)) {
            const losses = experiment.results.loss;
            const labels = Array.from({ length: losses.length }, (_, i) => `Epoch ${i + 1}`);
            setChartData({
                labels: labels,
                datasets: [{
                    label: 'Eğitim Kaybı',
                    data: losses,
                    borderColor: 'rgb(75, 192, 192)',
                    backgroundColor: 'rgba(75, 192, 192, 0.5)',
                    tension: 0.1,
                    fill: false
                }]
            });
        }
    }

    // Bileşen DOM'dan kaldırıldığında WebSocket bağlantısını temizle
    return () => {
      if (cleanupNeeded && ws.current) {
        ws.current.close();
        ws.current = null;
      }
    };
  }, [experiment.id, experiment.status, experiment.final_loss, experiment.results]); // Deney verileri değiştiğinde yeniden bağlan

  const handleCardClick = () => {
    navigate(`/experiments/${experiment.id}`); // Doğrudan yönlendir
    if (onSelect) { // onSelect prop'u varsa (eski kullanım için)
      onSelect(experiment.id);
    }
  };

  return (
    <div className="card experiment-card clickable" onClick={handleCardClick}>
      <h3>
        {experiment.pipeline_name || 'Bilinmeyen Pipeline'} 
        {experiment.ticker && <span className="exp-id"> ({experiment.ticker})</span>}
      </h3>
      <p><strong>ID:</strong> <span className="exp-id">{experiment.id}</span></p>
      <p><strong>Durum:</strong> 
        <span className={`status-badge status-${currentStatus?.toLowerCase()}`}>{currentStatus || 'Bilinmiyor'}</span>
      </p>
      
      {(currentStatus === 'STARTED' || currentStatus === 'PROGRESS' || currentStatus === 'CONNECTED') && (
        <div className="progress-section">
          <p>{statusText}</p>
          <progress value={progress} max="100"></progress>
          <p>Mevcut Kayıp: <strong>{currentLoss !== undefined && currentLoss !== null ? currentLoss.toFixed(6) : 'N/A'}</strong></p>
        </div>
      )}
      {(currentStatus === 'SUCCESS' || currentStatus === 'FAILURE' || currentStatus === 'ERROR' || currentStatus === 'DISCONNECTED') && (
        <p>Son Kayıp: <strong>{currentLoss !== undefined && currentLoss !== null ? currentLoss.toFixed(6) : 'N/A'}</strong></p>
      )}

      {/* Mini Grafik */}
      {chartData.labels.length > 0 && (
          <div className="mini-chart-container" style={{ height: '150px', width: '100%', marginTop: '15px' }}>
              <Line data={chartData} options={{
                  responsive: true,
                  maintainAspectRatio: false,
                  plugins: { legend: { display: false }, title: { display: false }, tooltip: { enabled: false } },
                  scales: {
                      x: { display: false },
                      y: { display: false, beginAtZero: false }
                  },
                  animation: false, // Canlı grafik için animasyonu kapat
                  elements: { point: { radius: 0 } } // Noktaları gizle
              }} />
          </div>
      )}
    </div>
  );
}

ExperimentCard.propTypes = {
  experiment: PropTypes.object.isRequired,
  onSelect: PropTypes.func, // Optional callback for parent component
};

export default ExperimentCard;
========== FILE: dashboard/src/components/ExperimentDetailPage.jsx ==========
// ========== YENİ DOSYA: dashboard/src/components/ExperimentDetailPage.jsx ==========
import { useState, useEffect } from 'react';
import { useParams } from 'react-router-dom';
import { getTaskStatus } from '../services/api';
import { Line } from 'react-chartjs-2';
import PropTypes from 'prop-types';

// Chart.js bileşenlerini kaydet
import {
  Chart as ChartJS, CategoryScale, LinearScale, PointElement, LineElement, Title, Tooltip, Legend
} from 'chart.js';
ChartJS.register(CategoryScale, LinearScale, PointElement, LineElement, Title, Tooltip, Legend);


function ExperimentDetailPage() {
  const { experimentId } = useParams(); // URL'den experimentId'yi alıyoruz
  const [experimentData, setExperimentData] = useState(null);
  const [loading, setLoading] = useState(true);
  const [error, setError] = useState(null);
  const [lossChartData, setLossChartData] = useState({ labels: [], datasets: [] });


  useEffect(() => {
    const fetchExperimentDetails = async () => {
      try {
        setLoading(true);
        const response = await getTaskStatus(experimentId);
        setExperimentData(response.data);
        setError(null);

        // Kayıp grafiği için veriyi hazırla
        // Result objesi içinde loss array'i varsa grafik oluştur
        if (response.data.status === 'SUCCESS' && response.data.result?.loss && Array.isArray(response.data.result.loss)) {
            const losses = response.data.result.loss;
            const labels = Array.from({ length: losses.length }, (_, i) => `Epoch ${i + 1}`);
            setLossChartData({
                labels: labels,
                datasets: [{
                    label: 'Eğitim Kaybı (Loss)',
                    data: losses,
                    borderColor: 'rgb(75, 192, 192)',
                    backgroundColor: 'rgba(75, 192, 192, 0.5)',
                    tension: 0.1,
                    fill: false
                }]
            });
        }

      } catch (err) {
        setError(`Deney detayları yüklenemedi: ${err.message || 'Bilinmeyen Hata'}. API'nizin çalıştığından emin olun.`);
        console.error("Error fetching experiment details:", err);
      } finally {
        setLoading(false);
      }
    };

    fetchExperimentDetails();
  }, [experimentId]); // experimentId değiştiğinde yeniden veri çek

  if (loading) return <p className="feedback info">Deney detayları yükleniyor...</p>;
  if (error) return <p className="feedback error">{error}</p>;
  if (!experimentData) return <p className="feedback info">Deney bulunamadı veya henüz tamamlanmadı.</p>;

  // API'dan gelen 'result' objesi, worker'dan dönen nihai veriyi içerir (SUCCESS/FAILURE)
  // 'config' objesi ise doğrudan celery task'ına gönderilen config'tir.
  const { status, config, result } = experimentData;

  // Hata mesajı ayrı bir alan olarak gelebilir veya result içinde olabilir
  const displayError = status === 'FAILURE' ? (result?.error_message || result || 'Bilinmeyen Hata') : null;
  const displayTraceback = status === 'FAILURE' ? result?.traceback : null;

  return (
    <div className="experiment-detail-page card"> {/* Card stilini uyguladık */}
      <div className="page-header">
        <h1><span role="img" aria-label="magnifying glass">🔍</span> Deney Detayları</h1>
        <p>Seçilen deneyin tüm detaylarını, konfigürasyonunu ve sonuçlarını inceleyin.</p>
      </div>

      <h3>Genel Bilgiler</h3>
      <p><strong>Deney ID:</strong> <span className="exp-id">{experimentId}</span></p>
      <p><strong>Durum:</strong> <span className={`status-badge status-${status?.toLowerCase()}`}>{status || 'Bilinmiyor'}</span></p>
      <p><strong>Pipeline Adı:</strong> {config?.pipeline_name || 'N/A'}</p>
      <p><strong>Sembol:</strong> {config?.data_sourcing?.ticker || 'N/A'}</p>
      <p><strong>Başlangıç Zamanı:</strong> {config?.start_time ? new Date(config.start_time).toLocaleString() : 'N/A'}</p> {/* Eğer config içinde start_time varsa */}
      <p><strong>Bitiş Zamanı:</strong> {experimentData.completed_at ? new Date(experimentData.completed_at).toLocaleString() : 'N/A'}</p>
      

      {displayError && <p className="feedback error">Deney Hatası: {displayError}</p>}

      <h3>Konfigürasyon</h3>
      <pre className="code-block">{JSON.stringify(config, null, 2)}</pre>

      {status === 'SUCCESS' && (
        <>
          <h3>Sonuçlar</h3>
          <pre className="code-block">{JSON.stringify(result, null, 2)}</pre>

          {lossChartData.labels.length > 0 && (
            <div className="chart-container">
              <h4>Eğitim Kaybı Geçmişi</h4>
              <Line data={lossChartData} options={{ 
                responsive: true, 
                maintainAspectRatio: false, 
                scales: { y: { beginAtZero: false }}
              }} />
            </div>
          )}
        </>
      )}

      {displayTraceback && (
        <>
          <h3>Detaylı Hata İzleme (Traceback)</h3>
          <pre className="code-block">{displayTraceback}</pre>
        </>
      )}

    </div>
  );
}

// PropTypes ekleyelim
ExperimentDetailPage.propTypes = {
  // experimentId URL parametresinden geldiği için burada propType tanımlamıyoruz
};

export default ExperimentDetailPage;
========== FILE: dashboard/src/components/ExperimentsList.jsx ==========
// ========== GÜNCELLENECEK DOSYA: dashboard/src/components/ExperimentsList.jsx (Prop Tabanlı) ==========
import { Link } from 'react-router-dom';
import PropTypes from 'prop-types';

function ExperimentsList({ experiments }) { // Sadece experiments prop'unu alıyoruz
  if (!experiments || experiments.length === 0) return <p className="feedback info">Henüz gösterilecek bir deney bulunamadı.</p>;

  return (
    <div className="table-container">
      <table>
        <thead>
          <tr>
            <th>Deney ID</th>
            <th>Durum</th>
            <th>Pipeline</th>
            <th>Sembol</th>
            <th>Kayıp</th>
            <th>Bitiş Tarihi</th> {/* Yeni sütun */}
          </tr>
        </thead>
        <tbody>
          {experiments.map((exp) => (
            <tr key={exp.id}>
              <td className="exp-id clickable-cell">
                <Link to={`/experiments/${exp.id}`}>
                  {exp.id}
                </Link>
              </td>
              <td><span className={`status-badge status-${exp.status?.toLowerCase() || 'unknown'}`}>{exp.status || 'Bilinmiyor'}</span></td>
              <td>{exp.config?.pipeline_name || exp.pipeline_name || 'N/A'}</td>
              <td>{exp.config?.data_sourcing?.ticker || exp.ticker || 'N/A'}</td>
              <td>{exp.final_loss !== undefined && exp.final_loss !== null ? exp.final_loss.toFixed(6) : 'N/A'}</td>
              <td>{exp.completed_at ? new Date(exp.completed_at).toLocaleString() : 'N/A'}</td> {/* Tarih formatlama */}
            </tr>
          ))}
        </tbody>
      </table>
    </div>
  );
}

// Prop tiplerini belirleyelim
ExperimentsList.propTypes = {
  experiments: PropTypes.array.isRequired,
};

export default ExperimentsList;
========== FILE: dashboard/src/components/ExperimentTracker.jsx ==========
// ========== GÜNCELLENECEK DOSYA: dashboard/src/components/ExperimentTracker.jsx (URL'den taskId Okuma ve Başlık) ==========
import { useState, useEffect, useRef } from 'react';
import { useParams } from 'react-router-dom';
import { Line } from 'react-chartjs-2';
import {
  Chart as ChartJS, CategoryScale, LinearScale, PointElement, LineElement, Title, Tooltip, Legend
} from 'chart.js';

ChartJS.register(CategoryScale, LinearScale, PointElement, LineElement, Title, Tooltip, Legend);

function ExperimentTracker() { 
  const { taskId } = useParams(); // URL'den taskId'yi al
  const [status, setStatus] = useState(null); 
  const [chartData, setChartData] = useState({ 
    labels: [], 
    datasets: [{ 
      label: 'Eğitim Kaybı', data: [], 
      borderColor: 'rgb(75, 192, 192)', backgroundColor: 'rgba(75, 192, 192, 0.5)',
      tension: 0.1, fill: false
    }] 
  }); 
  const ws = useRef(null); 
  const [currentLoss, setCurrentLoss] = useState('N/A'); // Canlı kayıp için state

  useEffect(() => {
    if (!taskId) {
      setStatus({ state: 'NO_TASK', details: { status_text: 'Takip edilecek görev ID\'si bulunamadı.' } });
      return;
    }

    // Önceki bağlantıyı temizle (varsa)
    if (ws.current) { ws.current.close(); }
    
    // Geçmiş verilerini ve durumu sıfırla
    setChartData({ labels: [], datasets: [{ 
        label: 'Eğitim Kaybı', data: [], 
        borderColor: 'rgb(75, 192, 192)', backgroundColor: 'rgba(75, 192, 192, 0.5)',
        tension: 0.1, fill: false
    }]});
    setStatus({ state: 'CONNECTING', details: { status_text: 'Worker\'a bağlanılıyor...' } });
    setCurrentLoss('N/A');


    const wsUrl = `ws://localhost:8000/ws/task_status/${taskId}`;
    ws.current = new WebSocket(wsUrl);

    ws.current.onopen = () => {
        console.log(`WebSocket connected for task ${taskId}`);
        setStatus({ state: 'CONNECTED', details: { status_text: 'Bağlantı kuruldu, veri bekleniyor...' } });
    };

    ws.current.onmessage = (event) => {
      const data = JSON.parse(event.data);
      console.log("Received data from WebSocket:", data);
      setStatus(data); // Genel durumu güncelle
      
      if(data.state === 'PROGRESS' && data.details?.loss !== undefined) {
        setCurrentLoss(data.details.loss.toFixed(6)); // Canlı kayıp
        setChartData(prevData => {
          const epoch = data.details.epoch;
          const loss = data.details.loss;

          // Eğer veri gelmişse ve epoch daha önce eklenmemişse ekle
          if (!prevData.labels.includes(`Epoch ${epoch}`)) {
            return {
              labels: [...prevData.labels, `Epoch ${epoch}`],
              datasets: [{
                ...prevData.datasets[0], 
                data: [...prevData.datasets[0].data, loss]
              }]
            };
          }
          return prevData;
        });
      } else if (data.state === 'SUCCESS' || data.state === 'FAILURE') {
        // Görev tamamlandığında veya başarısız olduğunda son durumu ve sonucu al
        const finalLoss = data.result?.final_loss || (data.result?.loss && Array.isArray(data.result.loss) ? data.result.loss[data.result.loss.length - 1] : undefined);
        if (finalLoss !== undefined) {
          setCurrentLoss(finalLoss.toFixed(6));
        } else if (data.state === 'FAILURE' && data.result?.error_message) {
            setCurrentLoss('Hata!');
        } else {
            setCurrentLoss('N/A');
        }

        // Eğer başarılı olduysa ve tam loss history varsa grafiği onunla güncelle
        if (data.state === 'SUCCESS' && data.result?.loss && Array.isArray(data.result.loss)) {
            const losses = data.result.loss;
            const labels = Array.from({ length: losses.length }, (_, i) => `Epoch ${i + 1}`);
            setChartData({
                labels: labels,
                datasets: [{
                    label: 'Eğitim Kaybı',
                    data: losses,
                    borderColor: 'rgb(75, 192, 192)',
                    backgroundColor: 'rgba(75, 192, 192, 0.5)',
                    tension: 0.1,
                    fill: false
                }]
            });
        }
      }
    };
    
    ws.current.onerror = (error) => {
      console.error("WebSocket Error:", error);
      setStatus({ state: 'ERROR', details: { status_text: 'WebSocket bağlantı hatası veya sunucuya erişilemiyor!' } });
      setCurrentLoss('Hata!');
    };

    ws.current.onclose = () => {
      console.log(`WebSocket disconnected for task ${taskId}`);
      setStatus(prevStatus => {
        if (prevStatus?.state === 'SUCCESS' || prevStatus?.state === 'FAILURE' || prevStatus?.state === 'ERROR') {
          return prevStatus;
        }
        return { 
          ...prevStatus, 
          state: 'DISCONNECTED',
          details: { status_text: `Bağlantı kesildi. Son durum: ${prevStatus?.state}` }
        };
      });
    };

    return () => {
      if (ws.current) {
        ws.current.close();
        ws.current = null;
      }
    };
  }, [taskId]); // taskId değiştiğinde yeniden bağlan

  const progressPercent = status?.details?.total_epochs 
    ? ((status.details.epoch || 0) / status.details.total_epochs) * 100
    : 0;

  return (
    <div className="tracker-container card"> {/* Card stilini uyguladık */}
      <div className="page-header">
        <h1><span role="img" aria-label="satellite">🛰️</span> Canlı Deney Takibi</h1>
        <p>Seçilen deneyin gerçek zamanlı ilerlemesini ve metriklerini izleyin.</p>
      </div>

      <h3>Görev Bilgileri</h3>
      <p><strong>Görev ID:</strong> <span className="exp-id">{taskId}</span></p>
      <p><strong>Durum:</strong> <span className={`status-badge status-${status?.state?.toLowerCase()}`}>{status?.state || 'Bilinmiyor'}</span></p>
      
      {(status?.state === 'STARTED' || status?.state === 'PROGRESS' || status?.state === 'CONNECTED') && (
        <div className="progress-section">
          <p>{status.details?.status_text || 'İlerleme bilgisi bekleniyor...'}</p>
          <progress value={progressPercent} max="100"></progress>
          <p>Mevcut Kayıp (Loss): <strong>{currentLoss}</strong></p>
        </div>
      )}

      {status?.state === 'SUCCESS' && <p className="feedback success">Eğitim başarıyla tamamlandı! Final Kayıp: {currentLoss}</p>}
      {status?.state === 'FAILURE' && <p className="feedback error">Eğitimde bir hata oluştu! Detaylar için aşağıdaki bölüme bakın veya deney detay sayfasına gidin.</p>}
      {status?.state === 'ERROR' && <p className="feedback error">{status.details.status_text}</p>}
      {status?.state === 'NO_TASK' && <p className="feedback info">{status.details.status_text}</p>}
      {status?.state === 'DISCONNECTED' && <p className="feedback info">Canlı takip bağlantısı kesildi. Görev tamamlanmış veya bir hata oluşmuş olabilir. Deney listesinden kontrol edin. Son Kayıp: {currentLoss}</p>}

      {chartData.labels.length > 0 && (
        <div className="chart-container">
          <h4>Canlı Kayıp Grafiği</h4>
          <Line data={chartData} options={{ 
            animation: false, 
            responsive: true, 
            maintainAspectRatio: false, 
            scales: { y: { beginAtZero: false }}
          }} />
        </div>
      )}
      {chartData.labels.length === 0 && (status?.state === 'PROGRESS' || status?.state === 'CONNECTING' || status?.state === 'CONNECTED' || status?.state === 'STARTED') && <p className="feedback info">Grafik verisi bekleniyor (ilk epoch tamamlandığında veya sonuç raporu hazırlandığında görünecektir)...</p>}
      
      {/* Hata durumunda detaylar */}
      {status?.state === 'FAILURE' && status.details?.traceback && (
        <>
          <h3>Detaylı Hata Mesajı</h3>
          <pre className="code-block">{status.details.traceback}</pre>
        </>
      )}
    </div>
  );
}

export default ExperimentTracker;
========== FILE: dashboard/src/components/NewExperiment.jsx ==========
// ========== GÜNCELLENECEK DOSYA: dashboard/src/components/NewExperiment.jsx (PropTypes Eklendi) ==========
import { useState, useEffect } from 'react';
import { startNewExperiment, fetchAvailablePipelines } from '../services/api';
import PropTypes from 'prop-types'; // PropTypes import edildi

// Kullanıcıya daha iyi geri bildirim vermek için bir bileşen
const Feedback = ({ message, type }) => {
  if (!message) return null;
  return <p className={`feedback ${type}`}>{message}</p>;
};

Feedback.propTypes = {
  message: PropTypes.string,
  type: PropTypes.string.isRequired,
};


function NewExperiment({ onExperimentStarted }) {
  // State tanımlamaları
  const [pipelines, setPipelines] = useState([]); // API'dan gelen tüm pipeline'lar
  const [selectedPipelineId, setSelectedPipelineId] = useState(''); // Seçili pipeline'ın ID'si
  const [selectedPipelineDetails, setSelectedPipelineDetails] = useState(null); // Seçili pipeline'ın tam detayları
  const [isLoading, setIsLoading] = useState(true); // Yüklenme durumu
  const [feedback, setFeedback] = useState(null); // Kullanıcı geri bildirimi

  // --- Pipeline listesini API'dan çek ---
  // Bileşen ilk yüklendiğinde, mevcut tüm pipeline'ları ve konfigürasyonlarını API'dan çek
  useEffect(() => {
    const loadPipelines = async () => {
      try {
        const response = await fetchAvailablePipelines();
        setPipelines(response.data);
        // Eğer pipeline varsa, ilkini varsayılan olarak seç
        if (response.data.length > 0) {
          const firstPipeline = response.data[0];
          setSelectedPipelineId(firstPipeline.id);
          setSelectedPipelineDetails(firstPipeline);
        }
      } catch (error) {
        setFeedback({ type: 'error', message: 'Pipeline listesi yüklenemedi. API\'nizin /api/v1/pipelines endpoint\'ini kontrol edin.' });
        console.error("Error fetching pipelines:", error);
      } finally {
        setIsLoading(false);
      }
    };
    loadPipelines();
  }, []); // Boş dizi, bu etkinin sadece bir kez çalışmasını sağlar

  // --- Form Gönderimi ---
  const handleSubmit = async (e) => {
    e.preventDefault();
    if (!selectedPipelineId) {
      setFeedback({ type: 'error', message: 'Lütfen bir pipeline seçin.' });
      return;
    }

    setIsLoading(true);
    setFeedback(null);
    
    // Sadece pipeline_name'i gönderiyoruz. Diğer konfigürasyonlar Worker'daki varsayılanlardan alınacak.
    const configToSend = {
      pipeline_name: selectedPipelineId,
      // Dashboard'dan ek parametre göndermek istersek buraya ekleyeceğiz:
      // data_sourcing: { ticker: "MSFT" },
      // training_params: { epochs: 10 }
    };
    
    try {
      const response = await startNewExperiment(configToSend);
      const taskId = response.data.task_id;
      setFeedback({ type: 'success', message: `Görev başarıyla gönderildi! ID: ${taskId}` });
      
      // Görev başladıktan sonra canlı takip ekranına geç
      if (onExperimentStarted && taskId) {
        onExperimentStarted(taskId);
      }
      
    } catch (err) {
      setFeedback({ type: 'error', message: 'Deney başlatılamadı. API ve Worker loglarını kontrol edin.' });
      console.error("Error starting experiment:", err);
    } finally {
      setIsLoading(false);
    }
  };

  // --- Render (Görünüm) ---
  if (isLoading) return <p className="feedback info">Pipeline'lar yükleniyor...</p>;
  if (pipelines.length === 0) return <p className="feedback error">Platforma kurulu ve keşfedilmiş pipeline eklentisi bulunamadı.</p>;

  return (
    <form onSubmit={handleSubmit} className="form-container card"> {/* Card stilini uyguladık */}
      <div className="page-header">
        <h1><span role="img" aria-label="rocket">🚀</span> Yeni Deney Başlat</h1>
        <p>Platformda kurulu mevcut yapay zeka pipeline'larından birini seçerek yeni bir deney başlatın.</p>
      </div>

      <div className="form-group">
        <label htmlFor="pipeline-select">Çalıştırılacak Pipeline Eklentisi</label>
        <select id="pipeline-select" value={selectedPipelineId} onChange={(e) => {
          const newId = e.target.value;
          setSelectedPipelineId(newId);
          setSelectedPipelineDetails(pipelines.find(p => p.id === newId));
        }}>
          {pipelines.map(p => (
            <option key={p.id} value={p.id}>{p.name} ({p.id})</option>
          ))}
        </select>
      </div>
      
      {selectedPipelineDetails && (
        <div className="pipeline-details card">
          <h3>{selectedPipelineDetails.name} Detayları</h3>
          <p><strong>Açıklama:</strong> <i>{selectedPipelineDetails.description || 'Açıklama bulunmuyor.'}</i></p>
          <p><strong>Repository:</strong> <a href={selectedPipelineDetails.repository} target="_blank" rel="noopener noreferrer">{selectedPipelineDetails.repository}</a></p>
          {/* Gelecekte varsayılan konfigürasyon JSON'unu göstermek/düzenlemek için buraya daha fazla UI eklenebilir */}
        </div>
      )}

      <p className="feedback info">Şimdilik, eğitim varsayılan parametrelerle başlatılacaktır. Gelecekte bu parametreleri buradan düzenleyebileceksiniz.</p>

      <button type="submit" disabled={isLoading} className="button-primary">
        {isLoading ? 'Başlatılıyor...' : `"${selectedPipelineDetails?.name || 'Seçilen'}" Eğitimini Başlat`}
      </button>
      
      <Feedback message={feedback?.message} type={feedback?.type} />
    </form>
  );
}

NewExperiment.propTypes = {
  onExperimentStarted: PropTypes.func.isRequired,
};

export default NewExperiment;
========== FILE: dashboard/src/pages/DashboardOverview.jsx ==========
// ========== YENİ DOSYA: dashboard/src/pages/DashboardOverview.jsx ==========
import { useState, useEffect } from 'react';
import { fetchExperiments } from '../services/api';
import ExperimentCard from '../components/ExperimentCard';
import ExperimentsList from '../components/ExperimentsList'; // Tamamlanan/başarısız deneyler için
import PropTypes from 'prop-types'; // PropTypes import edildi

function DashboardOverview({ onExperimentSelect, onNewExperimentClick }) {
  const [experiments, setExperiments] = useState([]);
  const [loading, setLoading] = useState(true);
  const [error, setError] = useState(null);

  useEffect(() => {
    const getExperiments = async () => {
      try {
        const response = await fetchExperiments();
        // API'den gelen veriye göre sıralama: Önce çalışanlar, sonra en yeni tamamlananlar
        const sortedExperiments = response.data.sort((a, b) => {
          const statusOrder = { 'STARTED': 1, 'PROGRESS': 2, 'FAILURE': 3, 'SUCCESS': 4, 'UNKNOWN': 5, 'DISCONNECTED': 6 }; // DISCONNECTED'ı da ekleyelim
          const aStatus = statusOrder[a.status] || 7; // Varsayılan değer unknown/diğer durumlar için
          const bStatus = statusOrder[b.status] || 7;

          if (aStatus !== bStatus) {
            return aStatus - bStatus; // Duruma göre sırala (STARTED en üstte)
          }

          // Aynı durumdaki deneyleri en yeni bitiş tarihine göre sırala (varsa)
          // `completed_at` yoksa `started_at` veya `id` (timestamp içerdiği için) kullanabiliriz
          const aDate = a.completed_at ? new Date(a.completed_at) : (a.started_at ? new Date(a.started_at) : new Date(0));
          const bDate = b.completed_at ? new Date(b.completed_at) : (b.started_at ? new Date(b.started_at) : new Date(0));
          return bDate.getTime() - aDate.getTime(); // En yeni tamamlanan üstte
        });

        setExperiments(sortedExperiments);
        setError(null);
      } catch (err) {
        setError('API sunucusuna bağlanılamadı veya veri çekilemedi. Servislerin çalıştığından emin olun.');
        console.error("Error fetching experiments for overview:", err);
      } finally {
        setLoading(false);
      }
    };
    
    getExperiments();
    const intervalId = setInterval(getExperiments, 5000); // Deneyleri düzenli olarak yenile (5 saniyede bir)
    
    return () => clearInterval(intervalId); // Bileşen kaldırıldığında interval'i temizle
  }, []);

  const runningExperiments = experiments.filter(exp => 
    exp.status === 'STARTED' || exp.status === 'PROGRESS'
  );
  const completedOrFailedExperiments = experiments.filter(exp => 
    exp.status === 'SUCCESS' || exp.status === 'FAILURE' || exp.status === 'ERROR' || exp.status === 'DISCONNECTED' || exp.status === 'UNKNOWN'
  );

  return (
    <div className="dashboard-overview">
      <div className="page-header">
        <h1><span role="img" aria-label="dashboard">📊</span> Genel Bakış</h1>
        <p>Tüm deneylerinizin durumunu ve son gelişmelerini takip edin.</p>
      </div>

      {loading && <p className="feedback info">Veriler yükleniyor...</p>}
      {error && <p className="feedback error">{error}</p>}

      {!loading && !error && (
        <>
          <h2 className="section-title">Çalışan Deneyler ({runningExperiments.length})</h2>
          {runningExperiments.length === 0 ? (
            <p className="feedback info">Şu anda çalışan bir deney bulunmamaktadır. <button onClick={onNewExperimentClick} className="button-link">Yeni bir deney başlatmak</button> ister misiniz?</p>
          ) : (
            <div className="running-experiments-grid">
              {runningExperiments.map(exp => (
                <ExperimentCard key={exp.id} experiment={exp} onSelect={onExperimentSelect} />
              ))}
            </div>
          )}

          <h2 className="section-title">Son Tamamlanan/Başarısız Olan Deneyler ({completedOrFailedExperiments.length})</h2>
          {completedOrFailedExperiments.length === 0 ? (
            <p className="feedback info">Henüz tamamlanan veya başarısız olan bir deney bulunmamaktadır.</p>
          ) : (
            <ExperimentsList experiments={completedOrFailedExperiments} onExperimentSelect={onExperimentSelect} />
          )}
        </>
      )}
    </div>
  );
}

// PropTypes ekleyelim
DashboardOverview.propTypes = {
  onExperimentSelect: PropTypes.func.isRequired,
  onNewExperimentClick: PropTypes.func.isRequired,
};

export default DashboardOverview;
========== FILE: dashboard/src/services/api.js ==========
// ========== DOSYA: dashboard/src/services/api.js (DEĞİŞİKLİK YOK) ==========
import axios from 'axios';

const API_BASE_URL = 'http://localhost:8000/api/v1';

const apiClient = axios.create({
  baseURL: API_BASE_URL,
  headers: {
    'Content-Type': 'application/json',
  },
});

/**
 * Tüm tamamlanmış/çalışan deney görevlerini API'dan çeker.
 * Şu anda sahte veri döndürüyor. Gerçek veritabanı eklendiğinde güncellenecek.
 */
export const fetchExperiments = () => {
  return apiClient.get('/experiments');
};

/**
 * Yeni bir deneyi başlatmak için API'a istek gönderir.
 * @param {object} config - Deney konfigürasyonu (pipeline_name, data_sourcing, training_params vb.)
 */
export const startNewExperiment = (config) => {
  return apiClient.post('/experiments', config);
};

/**
 * Platformda kurulu ve keşfedilmiş tüm pipeline'ları ve varsayılan 
 * konfigürasyonlarını API'dan çeker.
 */
export const fetchAvailablePipelines = () => {
  return apiClient.get('/pipelines'); 
};

/**
 * Belirli bir görevin (task) anlık durumunu sorgular.
 * @param {string} taskId - Celery görev ID'si
 */
export const getTaskStatus = (taskId) => {
  return apiClient.get(`/experiments/${taskId}/status`);
};
========== FILE: docs/CONTRIBUTING.md ==========
# 🤝 AzuraForge Platforma Katkıda Bulunma Rehberi

AzuraForge projesine gösterdiğiniz ilgi ve katkılarınız için teşekkür ederiz! Bu rehber, kod tabanının tutarlı, okunabilir, sürdürülebilir ve yüksek kalitede kalmasını sağlamak için benimsediğimiz çalışma prensiplerini ve standartlarını açıklamaktadır.

## 🚀 Hızlı Başlangıç

Eğer henüz geliştirme ortamınızı kurmadıysanız, lütfen platform repo'sunun ana `README.md` dosyasındaki "Geliştirme Ortamı Kurulumu" bölümünü takip edin.

## 🛠️ Kodlama Standartları

Projeye eklenen her kodun aşağıdaki standartları karşılaması beklenmektedir:

1.  **Stil Kılavuzu (PEP8 & Black):**
    *   Tüm Python kodları, PEP8 stil kurallarına uymalıdır.
    *   Kodunuzu `black` ile otomatik formatlayın.
    *   **Kontrol:** Değişikliklerinizi göndermeden önce `black <dosya_adı>` veya `black .` komutunu çalıştırın.
    *   **Otomasyon:** `pre-commit` hook'ları otomatik formatlamayı zorunlu kılar.

2.  **Linting (`flake8`):**
    *   Tüm Python kodları, `flake8` denetiminden hatasız geçmelidir.
    *   **Kontrol:** `flake8 <dosya_adı>` veya `flake8 src` komutunu çalıştırın.
    *   **Otomasyon:** `pre-commit` hook'ları linting'i zorunlu kılar.

3.  **Tip İpuçları (Type Hinting & Mypy):**
    *   Tüm fonksiyon ve metod imzaları, parametreler ve dönüş değerleri için tip ipuçları (`typing` modülü kullanılarak) içermelidir.
    *   **Kontrol:** `mypy src` komutunu çalıştırın.
    *   **Otomasyon:** `pre-commit` hook'ları statik tip denetimini zorunlu kılar.

4.  **Dokümantasyon (Docstrings):**
    *   Tüm modüller, sınıflar, fonksiyonlar ve metodlar, ne işe yaradıklarını, aldıkları argümanları (`Args:`) ve ne döndürdüklerini (`Returns:`) açıklayan Google-style docstring'ler içermelidir.
    *   Arayüz (API) repoları için `FastAPI`'nin otomatik dokümantasyonunu besleyecek docstring'ler kullanılmalıdır.

5.  **Testler (`pytest`):**
    *   Eklenen her yeni özellik veya fonksiyon için ilgili birim testleri (`unit tests`) `tests/` klasörüne eklenmelidir.
    *   Yapılan bir hata düzeltmesi (bug fix) için, o hatanın tekrar oluşmasını engelleyecek bir regresyon testi yazılmalıdır.
    *   **Kontrol:** İlgili reponun kök dizinindeyken `pytest` komutunu çalıştırın.

## 📝 Commit Mesajları

Commit mesajları, yapılan değişikliği net bir şekilde açıklamalıdır ve [Conventional Commits](https://www.conventionalcommits.org/en/v1.0.0/) standardına uymalıdır. Bu, otomatik versiyonlama ve değişiklik günlüğü oluşturmak için hayati önem taşır.

**Format:**
```
<tip>(<kapsam>): <açıklama>

[opsiyonel gövde]
```

**Örnek Tipler:**
*   `feat`: Yeni bir özellik ekler (Minor versiyon artırımı).
*   `fix`: Bir hata düzeltmesi (Patch versiyon artırımı).
*   `docs`: Sadece dokümantasyon değişiklikleri (Versiyon artırımı yok).
*   `style`: Kod formatı, eksik noktalı virgül gibi stil düzeltmeleri (Kod mantığı değişmez, versiyon artırımı yok).
*   `refactor`: Kodu yeniden yapılandırma, davranış değişikliği yok (Versiyon artırımı yok).
*   `perf`: Performans iyileştirmesi yapan kod değişikliği (Versiyon artırımı olabilir).
*   `test`: Eksik testlerin eklenmesi veya mevcut testlerin düzeltilmesi (Versiyon artırımı yok).
*   `build`: Build sistemi veya dış bağımlılık değişiklikleri (Versiyon artırımı olabilir).
*   `ci`: CI/CD yapılandırma dosyaları ve script'leri değişiklikleri (Versiyon artırımı yok).

**Örnekler:**
*   `feat(core): Add exponential function to Tensor`
*   `fix(api): Resolve 307 redirect issues for endpoints`
*   `docs(platform): Add initial development guide`
*   `refactor(learner): Separate Layer and Model definitions`

## 🔄 Pull Request (PR) Süreci

1.  **Branch Oluşturma:** `main` branch'inden kendi feature branch'inizi (`feat/yeni-ozellik` veya `fix/hata-adi` gibi) oluşturun.
2.  **Değişikliklerinizi Yapın:** Yukarıdaki standartlara uyduğunuzdan emin olun.
3.  **Test Edin:** Yerel testlerinizi (`pytest`) çalıştırın ve geçtiğinden emin olun.
4.  **Commit ve Push:** Değişikliklerinizi anlamlı commit mesajlarıyla branch'inize `push` edin.
5.  **Pull Request Açın:** GitHub üzerinden `main` branch'ine bir "Pull Request" (PR) açın.
6.  **CI Kontrolleri:** PR'ınızın CI kontrollerinden (testler, linting) başarıyla geçtiğinden emin olun.
7.  **Kod İncelemesi:** Kodunuz incelenecek ve gerekli geri bildirimler sağlanacaktır.

Bu standartlara uyarak, AzuraForge platformunun uzun vadede sağlıklı, sürdürülebilir ve yüksek kalitede kalmasına yardımcı olursunuz.

========== FILE: docs/DEVELOPMENT_GUIDE.md ==========
# 🛠️ AzuraForge Platform Geliştirme Rehberi

Bu belge, AzuraForge platformunda geliştirme yapmak isteyenler için adım adım kurulum, çalışma prensipleri ve katkıda bulunma yönergelerini içerir.

## 🎯 Temel Felsefemiz

Her repomuz, kendi başına yaşayan, kurulabilir ve test edilebilir bağımsız bir Python/JavaScript paketidir. Repolar arası bağımlılıklar, Git adresleri (`@git+https://...`) üzerinden kurulur.

## 📦 Proje Repolarına Genel Bakış

AzuraForge platformu, aşağıdaki bağımsız GitHub depolarından oluşur. Geliştirme yaparken bu repoların bir kısmını veya tamamını yerel makinenizde klonlamanız gerekecektir.

*   **`core`** ([link](https://github.com/AzuraForge/core)): Temel otomatik türev motoru.
*   **`learner`** ([link](https://github.com/AzuraForge/learner)): `core` üzerinde yüksek seviyeli öğrenme kütüphanesi.
*   **`app-stock-predictor`** ([link](https://github.com/AzuraForge/app-stock-predictor)): Bir uygulama eklentisi örneği.
*   **`applications`** ([link](https://github.com/AzuraForge/applications)): Resmi uygulama katalogu (sadece JSON veri içerir).
*   **`api`** ([link](https://github.com/AzuraForge/api)): RESTful API ve WebSocket sunucusu.
*   **`worker`** ([link](https://github.com/AzuraForge/worker)): Arka plan görevlerini (eğitimleri) işleyen Celery worker.
*   **`dashboard`** ([link](https://github.com/AzuraForge/dashboard)): React tabanlı web kullanıcı arayüzü.

## ⚙️ Geliştirme Ortamı Kurulumu

Bu adımlar, platformun tüm parçalarını yerel geliştirme için hazır hale getirir.

1.  **Gerekli Araçlar:**
    *   **Git:** Repoları klonlamak için.
    *   **Python 3.8+:** Tüm Python bileşenleri için.
    *   **Node.js & npm:** Frontend bileşeni için.
    *   **Docker Desktop:** Redis ve Dockerize edilmiş ortamda test için (alternatifler belirtilecektir).

2.  **Repoları Klonlama:**
    Platformda geliştirmek için tüm ilgili repoları aynı seviyede bir klasöre klonlamanız önerilir:
    ```bash
    mkdir azuraforge-dev
    cd azuraforge-dev

    git clone https://github.com/AzuraForge/core.git
    git clone https://github.com/AzuraForge/learner.git
    git clone https://github.com/AzuraForge/app-stock-predictor.git
    git clone https://github.com/AzuraForge/applications.git
    git clone https://github.com/AzuraForge/api.git
    git clone https://github.com/AzuraForge/worker.git
    git clone https://github.com/AzuraForge/dashboard.git
    git clone https://github.com/AzuraForge/platform.git # Orkestrasyon için
    ```

3.  **Sanal Ortam Kurulumu (Python):**
    Her Python projesinin kendi sanal ortamı olabilir veya merkezi bir tane kullanabiliriz. Yerel geliştirme için, **`api` projesinin** kök dizininde tek bir sanal ortam oluşturmak ve tüm Python bağımlılıklarını oraya kurmak en pratik yoldur.

    ```bash
    cd api # `api` reposunun içine gir
    python -m venv .venv
    .\.venv\Scripts\activate # Windows için
    # source ./.venv/bin/activate # Linux/macOS için
    ```

4.  **Python Bağımlılıklarını Kurma (Tüm Python Repoları için):**
    Sanal ortam aktifken, tüm Python repolarını "düzenlenebilir" (editable) modda kurmalıyız. Bu, kodda yaptığınız değişikliklerin anında yansımasını sağlar. **`api` projesinin** kök dizininde olduğunuzdan emin olun.

    ```bash
    # Önce en alt seviyeden başlayarak kütüphaneleri kurun
    pip install -e ../core 
    pip install -e ../learner
    pip install -e ../app-stock-predictor # İlk uygulama eklentisi
    pip install -e ../applications       # Uygulama katalogu
    
    # Sonra API ve Worker'ı kurun
    pip install -e .                     # `api` projesini kurar
    pip install -e ../worker             # `worker` projesini kurar
    ```
    Bu komutlar, her bir reponun `pyproject.toml` dosyasını okuyacak ve tüm bağımlılık zincirini doğru bir şekilde çözecektir.

5.  **JavaScript Bağımlılıklarını Kurma (Dashboard için):**
    ```bash
    cd ../dashboard # `dashboard` reposunun içine gir
    npm install
    ```

6.  **Redis Kurulumu:**
    Platform, bir Redis sunucusuna ihtiyaç duyar. En kolay yol Docker kullanmaktır:
    ```bash
    docker run -d -p 6379:6379 --name azuraforge_redis redis
    ```

## ▶️ Servisleri Çalıştırma (Yerel Geliştirme)

Sanal ortamınız aktifken ve Redis çalışırken, her servisi ayrı bir terminalde başlatın.

1.  **API Sunucusu (`api` reposundan):**
    ```bash
    cd api
    .\.venv\Scripts\activate # Sanal ortam aktif değilse
    start-api
    ```
    (Tarayıcıda `http://localhost:8000/api/v1/docs` adresini kontrol edin.)

2.  **Worker Servisi (`worker` reposundan):**
    ```bash
    cd worker
    .\.venv\Scripts\activate
    start-worker
    ```
    (Worker terminalinde "Discovered pipeline..." loglarını kontrol edin.)

3.  **Dashboard (`dashboard` reposundan):**
    ```bash
    cd dashboard
    npm run dev
    ```
    (Tarayıcıda `http://localhost:5173` adresini açın.)

## 🧪 Test Etme ve Hata Ayıklama

*   **Uçtan Uca Akış:** Dashboard'dan yeni bir deney başlatarak tüm sistemin (`Dashboard -> API -> Worker -> Uygulama Eklentisi -> Kütüphane`) sorunsuz çalıştığını doğrulayın. Canlı takip ekranını ve kayıp grafiğini izleyin.
*   **API Testleri:** `http://localhost:8000/api/v1/docs` adresinden API endpoint'lerini test edin.
*   **Birim Testleri:** Her bir repoda (örn: `core`, `learner`, `app-stock-predictor`) kendi `pytest` testlerini çalıştırın.
    ```bash
    cd core # veya learner, app-stock-predictor
    .\.venv\Scripts\activate
    pytest
    ```
    (Bu testleri koşabilmek için ilgili repoda `pip install -e ".[dev]"` yapmış olmanız gerekir.)

## 🔄 İteratif Geliştirme Akışı

Çoğu zaman, kodda küçük değişiklikler yapıp bunları hızla test etmek istersiniz.

1.  **Kütüphanede Değişiklik (örn: `core/src/azuraforge_core/tensor.py`):**
    *   Değişikliği yapın ve kaydedin.
    *   Bu değişikliğin `learner` veya diğer kütüphanelerde anında etkili olması için **ekstra bir `pip install` komutuna GEREK YOKTUR**, çünkü `pip install -e` ile kuruldukları için doğrudan kaynak dosyayı kullanırlar.
    *   `core` projesine geri dönüp `pytest` ile kendi testlerini koşun.
    *   Değişikliği `commit`'leyin ve `push`'layın.

2.  **Uygulama/Servis Değişikliği (örn: `app-stock-predictor/src/azuraforge_stockapp/pipeline.py`):**
    *   Değişikliği yapın ve kaydedin.
    *   `api` veya `worker` servisleri otomatik olarak `reload` (yeniden yükleme) yapacaktır (eğer `uvicorn --reload` ile çalışıyorlarsa).
    *   `api` ve `worker`'ı yeniden başlatmak genellikle yeterlidir.
    *   Değişikliği `commit`'leyin ve `push`'layın.

3.  **Yeni Bir Bağımlılık Eklendiğinde (`pyproject.toml` değiştiğinde):**
    *   İlgili reponun kök dizinine gidin (örn: `api`).
    *   Sanal ortamınızı aktive edin.
    *   `pip install -e .` komutunu tekrar çalıştırın. `pip`, sadece eksik olan yeni bağımlılıkları ekleyecektir.

## 🤝 Katkıda Bulunma

Bu proje bir açık kaynak projesi olarak geliştirilmektedir. Katkıda bulunmak için lütfen `platform/docs/CONTRIBUTING.md` dosyasını inceleyin.

========== FILE: docs/PROJECT_JOURNEY.md ==========
# 🗺️ Proje Yolculuğu: AzuraForge'un Gelişim Hikayesi ve Gelecek Vizyonu

Bu belge, AzuraForge platformunun başlangıcından mevcut durumuna kadar olan gelişim sürecini, karşılaşılan zorlukları, bulunan çözümleri ve projenin **modüler, ölçeklenebilir ve ihtiyaç odaklı bir yapay zeka geliştirme platformuna** dönüşme vizyonunu özetlemektedir.

## 🎯 Proje Felsefesi ve Çıkış Hikayesi

AzuraForge'un her aşamasında, kalitesini ve sürdürülebilirliğini sağlamak için şu temel prensipleri benimsedik:

1.  **Sıfırdan İnşa ve Tam Kontrol:** Temel algoritmaları ve yapıları (`Tensor` gibi) mümkün olduğunca sıfırdan implemente ederek, sistem üzerinde tam kontrol sağlamak ve derinlemesine öğrenmek.
2.  **Modülerlik ve Sorumluluk Ayrımı (Microservices):** Her bileşenin (çekirdek kütüphane, API, worker, uygulama eklentisi, UI) tek ve net bir görevi vardır ve kendi bağımsız repo'sunda yaşar.
3.  **Olay Güdümlü Mimari:** Bileşenler arası iletişim, bağımlılıkları azaltmak ve gerçek zamanlı yetenekler sağlamak için olaylar (Celery, Redis Pub/Sub, WebSockets) üzerinden gerçekleşir.
4.  **Eklenti Tabanlı (Plug-in Architecture):** Yeni özellikler ve uygulamalar, mevcut platform koduna dokunmadan birer eklenti olarak kolayca eklenebilir.
5.  **Kanıt Odaklı Geliştirme:** Her büyük özellik veya yetenek, gerçek dünya verisi üzerinde kabul edilebilir bir performansla kanıtlanmalıdır.
6.  **Otomatik Kalite Kontrolü:** Kod kalitesi (linting, type checking, unit tests) ve versiyonlama süreçleri (CI/CD) otomatikleştirilmiştir.

## ✅ Tamamlanan Fazlar ve Elde Edilen Başarılar

### Faz 0: Fikir ve İlk Denemeler (Monolitik Yaklaşım)

*   **Düşünce:** Mevcut ML araçlarının karmaşıklığına ve bağımlılıklarına bir tepki olarak, sıfırdan bir derin öğrenme motoru (`mininn`) inşa etme fikri doğdu.
*   **İlk Uygulama:** Hava durumu tahmini ve hisse senedi tahmini gibi basit uygulamalarla `mininn`'in yetenekleri test edildi.
*   **Öğrenilen Ders:** Monolitik bir yaklaşımla (her şey tek bir repo'da) hızlı prototipleme mümkün olsa da, ölçeklenebilirlik ve yönetim zorlukları ortaya çıktı.

### Faz 1: Multi-Repo ve Mikroservis Mimarisine Geçiş

*   **Karar:** Uzun vadeli sürdürülebilirlik, ölçeklenebilirlik ve profesyonellik için, platformu bağımsız repolara sahip bir mikroservis mimarisine dönüştürme kararı alındı.
*   **Zorluk:** Python'da çoklu repolar arası bağımlılık yönetimi ve yol (path) sorunları.
*   **Çözüm:** `pip`'in `editable` kurulumu (`-e`) ve `git+https` bağımlılıklarını kullanarak, her reponun kendi `pyproject.toml` ve `setup.py` dosyalarıyla kurulabilir bir paket olması sağlandı. `importlib.resources` ile paket içi dosya erişimi çözüldü.

### Faz 2: Temel Kütüphanelerin İnşası ve Kanıtı

*   **`AzuraForge/core` (Matematik Motoru):** `Tensor` objesi ve otomatik türev yetenekleri sıfırdan inşa edildi. `pytest` ile birim testleri (dot, sum, add, mul, relu backward pass) başarıyla yazıldı ve geçti. **`to_cpu` ve `_unbroadcast_to` hataları bu fazda tespit edilip düzeltildi.**
*   **`AzuraForge/learner` (Öğrenme Kütüphanesi):** `azuraforge-core`'a bağımlı olarak `Layer`, `Linear`, `Loss`, `MSELoss`, `Sequential`, `Optimizer`, `SGD` gibi temel öğrenme bileşenleri inşa edildi. `pytest` ile basit regresyon testi (`test_learner_fit_simple_regression`) başarıyla geçti.

### Faz 3: Dağıtık Servisler ve Eklenti Mimarisi

*   **`AzuraForge/applications` (Katalog):** Uygulama eklentilerinin JSON kataloğunu barındıran basit bir Python paketi olarak yapılandırıldı.
*   **`AzuraForge/app-stock-predictor` (İlk Eklenti):** `azuraforge-learner`'ı kullanan ve platforma `entry_points` (`azuraforge.pipelines`) ile kendini tanıtan ilk uygulama eklentisi inşa edildi.
*   **`AzuraForge/worker` (İşçi Servisi):** `celery[redis]` kullanarak arka plan görevlerini işleyen ve `importlib.metadata` ile sisteme kurulu tüm `azuraforge.pipelines` eklentilerini **otomatik olarak keşfeden** ve çalıştıran worker servisi kuruldu.
*   **`AzuraForge/api` (API Servisi):** `FastAPI` ile RESTful API endpoint'leri (`/experiments`, `/pipelines`) sunan ve `worker`'a görev gönderen iletişim katmanı inşa edildi. API rotalarının `prefix` yönetimi ve `307 Redirect` sorunları bu fazda çözüldü.
*   **Başarı:** `api` üzerinden gönderilen bir "stock_predictor" görevinin, `worker` tarafından alınıp, `app-stock-predictor` eklentisinin keşfedilip, `learner` kütüphanesi kullanılarak **gerçek bir model eğitiminin başarıyla tamamlandığı** kanıtlandı.

### Faz 4: Kullanıcı Arayüzü ve Canlı Takip

*   **`AzuraForge/dashboard` (Web UI):** React tabanlı, `api` servisinden deney ve pipeline listelerini çeken, yeni deneyler başlatmayı sağlayan temel bir web arayüzü inşa edildi.
*   **Canlı Takip (WebSocket Entegrasyonu):**
    *   `worker`, eğitim sırasında `Celery task.update_state` ile ilerleme durumunu Redis'e raporladı.
    *   `api`, `FastAPI WebSocket` endpoint'i üzerinden bu ilerlemeyi `dashboard`'a anlık olarak iletti.
    *   `dashboard`, gelen `PROGRESS` mesajlarıyla bir **ilerleme çubuğunu ve kayıp grafiğini canlı olarak güncelledi.**

**An itibarıyla AzuraForge Platform 1.0, tüm temel mimarisi ve uçtan uca çalışan canlı takip yetenekleriyle TAMAMLANMIŞTIR!**

## 🗺️ Gelecek Fazlar ve Yol Haritası

Bu sağlam temel üzerine inşa edilecek adımlar, AzuraForge'u daha da zenginleştirmeyi ve kapsamını genişletmeyi hedefleyecektir.

### Faz 5: Deney Yönetimini Derinleştirme

*   **Kalıcı Sonuçlar:** `worker`'ın `results.json`'a kaydettiği tüm detaylı veriyi (eğitim geçmişi, metrikler, konfigürasyon) `api` üzerinden okuyup Dashboard'da görselleştirme.
*   **Deney Detay Sayfası:** Dashboard'da her deney için ayrı bir detay sayfası oluşturma.
*   **Model Yönetimi:** Eğitilen modellerin kaydedilmesi, listelenmesi ve daha sonra çıkarım için yüklenebilmesi.

### Faz 6: Yeni Veri Modalitelerine Açılım (Görüntü İşleme)

*   **`core` Genişletme:** `Conv2D`, `MaxPool2D`, `Flatten` gibi CNN katmanlarını `core` kütüphanesine ekleme.
*   **Yeni Uygulama Eklentisi:** `azuraforge-app-image-classifier` (örn: MNIST için) oluşturma.

### Faz 7: Hiperparametre Optimizasyonu

*   **`azuraforge-hyper-tuner`:** Farklı hiperparametre kombinasyonlarıyla otomatik deneyler yapabilen yeni bir uygulama eklentisi.
*   **Dashboard Entegrasyonu:** Dashboard'dan hiperparametre optimizasyonu işleri başlatma.

### Faz 8: Üretim Ortamı Hazırlığı (Deployment)

*   **`platform` Orkestrasyonu:** `docker-compose.yml`'ı daha sağlam hale getirme (Nginx, HTTPS, Load Balancing).
*   **CI/CD Pipeline'ları:** Tüm repolar için otomatik test, versiyonlama ve yayınlama (PyPI/GitHub Packages) pipeline'ları kurma.

========== FILE: learner/pyproject.toml ==========
# ========== DOSYA: learner/pyproject.toml ==========
[build-system]
requires = ["setuptools>=61.0"]
build-backend = "setuptools.build_meta"

[project]
name = "azuraforge-learner"
version = "0.1.1"
authors = [{ name = "Azmi Sahin" }]
description = "High-level deep learning library for model training and management, using the AzuraForge Core engine."
readme = "README.md"
requires-python = ">=3.8"
license = { text = "MIT" }
dependencies = [
    # Çekirdek motorumuza olan bağımlılığımız.
    "azuraforge-core @ git+https://github.com/AzuraForge/core.git@main",
    "scikit-learn",
    "numpy" # scikit-learn için explicit belirtmek iyi bir pratik
]

[project.optional-dependencies]
dev = ["pytest"]

========== FILE: learner/README.md ==========
# AzuraForge Learner 🧠

**AzuraForge Learner**, `azuraforge-core` motorunu kullanarak modelleri kolayca oluşturmak, eğitmek ve yönetmek için tasarlanmış yüksek seviyeli bir kütüphanedir.

## Kurulum

```bash
pip install azuraforge-learner@git+https://github.com/AzuraForge/learner.git
```
========== FILE: learner/setup.py ==========
from setuptools import setup, find_packages
setup(
    package_dir={"": "src"},
    packages=find_packages(where="src"),
)
========== FILE: learner/src/azuraforge_learner/callbacks.py ==========
# ========== GÜNCELLENECEK DOSYA: src/azuraforge_learner/callbacks.py ==========
import os
import numpy as np
from .events import Event

# 'Learner' sınıfı henüz tanımlanmadığı için ileriye dönük referans (forward reference) kullanıyoruz
from typing import TYPE_CHECKING
if TYPE_CHECKING:
    from .learner import Learner

class Callback:
    """
    Tüm callback'lerin temel sınıfı. Olayları dinler ve ilgili metoda yönlendirir.
    """
    def __call__(self, event: Event):
        method = getattr(self, f"on_{event.name}", None)
        if method:
            method(event)

    def on_train_begin(self, event: Event): pass
    def on_train_end(self, event: Event): pass
    def on_epoch_begin(self, event: Event): pass
    def on_epoch_end(self, event: Event): pass

class ModelCheckpoint(Callback):
    """Her epoch sonunda performansı izler ve sadece en iyi modeli kaydeder."""
    def __init__(self, filepath: str, monitor: str = "val_loss", mode: str = "min", verbose: int = 1):
        self.filepath = filepath
        self.monitor = monitor
        self.mode = mode
        self.verbose = verbose
        self.best = np.inf if mode == "min" else -np.inf

        # Dosyanın kaydedileceği dizini oluştur
        dir_path = os.path.dirname(self.filepath)
        if dir_path:
            os.makedirs(dir_path, exist_ok=True)

    def on_epoch_end(self, event: Event):
        current_val = event.payload.get(self.monitor)
        if current_val is None:
            if event.payload.get("epoch") == 0 and self.verbose > 0:
                print(f"ModelCheckpoint Warning: Can't find metric '{self.monitor}' to save model.")
            return

        is_better = (self.mode == "min" and current_val < self.best) or \
                    (self.mode == "max" and current_val > self.best)

        if is_better:
            if self.verbose > 0:
                print(f"ModelCheckpoint: {self.monitor} improved from {self.best:.6f} to {current_val:.6f}. Saving model to {self.filepath}")
            self.best = current_val
            event.learner.save(self.filepath)

class EarlyStopping(Callback):
    """Performans belirli bir epoch sayısı boyunca iyileşmediğinde eğitimi durdurur."""
    def __init__(self, monitor: str = "val_loss", patience: int = 10, mode: str = "min", verbose: int = 1):
        self.monitor = monitor
        self.patience = patience
        self.mode = mode
        self.verbose = verbose
        self.wait = 0
        self.best = np.inf if mode == "min" else -np.inf

    def on_train_begin(self, event: Event):
        # Eğitimin başında sayaçları sıfırla
        self.wait = 0
        self.best = np.inf if self.mode == "min" else -np.inf

    def on_epoch_end(self, event: Event):
        current_val = event.payload.get(self.monitor)
        if current_val is None:
            return
            
        is_better = (self.mode == "min" and current_val < self.best) or \
                    (self.mode == "max" and current_val > self.best)

        if is_better:
            self.best = current_val
            self.wait = 0
        else:
            self.wait += 1
            if self.wait >= self.patience:
                if self.verbose > 0:
                    print(f"EarlyStopping: Stopping training. {self.monitor} did not improve for {self.patience} epochs.")
                event.learner.stop_training = True
========== FILE: learner/src/azuraforge_learner/events.py ==========
# ========== DOSYA: src/azuraforge_learner/events.py ==========
from dataclasses import dataclass, field
from typing import Dict, Any, Literal, TYPE_CHECKING

if TYPE_CHECKING:
    from .learner import Learner

EventName = Literal["train_begin", "train_end", "epoch_begin", "epoch_end"]

@dataclass
class Event:
    name: EventName
    learner: 'Learner'
    payload: Dict[str, Any] = field(default_factory=dict)
========== FILE: learner/src/azuraforge_learner/layers.py ==========
# ========== DOSYA: src/azuraforge_learner/layers.py ==========
from typing import List
import numpy as np
from azuraforge_core import Tensor, xp

class Layer:
    def forward(self, x: Tensor) -> Tensor: raise NotImplementedError
    def parameters(self) -> List[Tensor]: return []
    def __call__(self, x: Tensor) -> Tensor: return self.forward(x)

class Linear(Layer):
    def __init__(self, input_dim: int, output_dim: int):
        limit = np.sqrt(2.0 / input_dim)
        self.weights = Tensor(xp.random.randn(input_dim, output_dim) * limit, requires_grad=True)
        self.bias = Tensor(xp.zeros(output_dim), requires_grad=True)
    def forward(self, x: Tensor) -> Tensor:
        return x.dot(self.weights) + self.bias
    def parameters(self) -> List[Tensor]:
        return [self.weights, self.bias]

class ReLU(Layer):
    def forward(self, x: Tensor) -> Tensor:
        return x.relu()
========== FILE: learner/src/azuraforge_learner/learner.py ==========
# ========== GÜNCELLENECEK DOSYA: src/azuraforge_learner/learner.py ==========
import pickle
from typing import Any, Dict, List, Optional
import numpy as np
from azuraforge_core import Tensor
from .events import Event
from .models import Sequential
from .losses import Loss
from .optimizers import Optimizer
from .callbacks import Callback

class Learner:
    def __init__(self, model: Sequential, criterion: Loss, optimizer: Optimizer, callbacks: Optional[List[Callback]] = None, current_task: Optional[Any] = None):
        self.model = model
        self.criterion = criterion
        self.optimizer = optimizer
        self.callbacks = callbacks or []
        self.history: Dict[str, List[float]] = {}
        self.stop_training: bool = False
        self.current_task = current_task # Celery Task referansı

    def _publish(self, event_name: str, payload: Optional[Dict[str, Any]] = None):
        event = Event(name=event_name, learner=self, payload=payload or {})
        for cb in self.callbacks: cb(event)
        
        # --- KRİTİK DÜZELTME: Celery Task durumunu güncelle ---
        if self.current_task and hasattr(self.current_task, 'update_state'):
            # Celery'ye PROGRESS durumu ve meta verileri gönder
            # payload, epoch_logs'u içeriyor
            self.current_task.update_state(state='PROGRESS', meta=payload)

    def fit(self, X_train: np.ndarray, y_train: np.ndarray, epochs: int):
        self.history = {} # Her fit çağrısında geçmişi sıfırla
        
        # History'yi başlat
        for key in ["loss", "val_loss", "val_r2"]: # Ekleyeceğimiz metrikler için yer açalım
             self.history[key] = []

        X_train_t, y_train_t = Tensor(X_train), Tensor(y_train)
        
        self._publish("train_begin", payload={"total_epochs": epochs}) # Toplam epoch sayısını gönder
        for epoch in range(epochs):
            if self.stop_training: break
            
            # Epoch başlangıcı olayını yayınla
            self._publish("epoch_begin", payload={"epoch": epoch, "total_epochs": epochs})
            
            # Eğitim adımı
            y_pred = self.model(X_train_t)
            loss = self.criterion(y_pred, y_train_t)
            
            self.optimizer.zero_grad()
            loss.backward()
            self.optimizer.step()
            
            epoch_logs = {
                "epoch": epoch + 1, # Epoch sayısını 1'den başlatalım
                "total_epochs": epochs,
                "loss": loss.data.item(),
                "status_text": f"Epoch {epoch+1}/{epochs} completed..."
            }
            
            # History'ye ekle
            self.history["loss"].append(epoch_logs["loss"])
            
            # Epoch sonu olayını yayınla (payload olarak tüm epoch loglarını gönder)
            self._publish("epoch_end", payload=epoch_logs)
        self._publish("train_end")
        return self.history

    def predict(self, X_test: np.ndarray) -> np.ndarray:
        return self.model(Tensor(X_test)).to_cpu()

    def evaluate(self, X_val: np.ndarray, y_val: np.ndarray) -> Dict[str, float]:
        from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
        y_val_t = Tensor(y_val)
        y_pred = self.model(Tensor(X_val))
        
        val_loss = self.criterion(y_pred, y_val_t).data.item()
        y_pred_np = y_pred.to_cpu()
        
        val_r2 = r2_score(y_val, y_pred_np)
        val_mae = mean_absolute_error(y_val, y_pred_np)
        val_rmse = np.sqrt(mean_squared_error(y_val, y_pred_np))

        return {"val_loss": val_loss, "val_r2": val_r2, "val_mae": val_mae, "val_rmse": val_rmse}
========== FILE: learner/src/azuraforge_learner/losses.py ==========
# ========== DOSYA: src/azuraforge_learner/losses.py ==========
from azuraforge_core import Tensor

class Loss:
    def __call__(self, y_pred: Tensor, y_true: Tensor) -> Tensor: raise NotImplementedError

class MSELoss(Loss):
    def __call__(self, y_pred: Tensor, y_true: Tensor) -> Tensor:
        return ((y_pred - y_true) ** 2).mean()
========== FILE: learner/src/azuraforge_learner/models.py ==========
# ========== DOSYA: src/azuraforge_learner/models.py ==========
from typing import List
from .layers import Layer
from azuraforge_core import Tensor

class Sequential(Layer):
    def __init__(self, *layers: Layer):
        self.layers = list(layers)
    def forward(self, x: Tensor) -> Tensor:
        for layer in self.layers:
            x = layer(x)
        return x
    def parameters(self) -> List[Tensor]:
        return [p for layer in self.layers for p in layer.parameters()]
========== FILE: learner/src/azuraforge_learner/optimizers.py ==========
# ========== DOSYA: src/azuraforge_learner/optimizers.py ==========
from typing import List
from azuraforge_core import Tensor

class Optimizer:
    def __init__(self, params: List[Tensor], lr: float):
        self.params = [p for p in params if p.requires_grad]
        self.lr = lr
    def step(self) -> None: raise NotImplementedError
    def zero_grad(self) -> None:
        for p in self.params:
            if p.grad is not None: p.grad.fill(0.0)

class SGD(Optimizer):
    def step(self) -> None:
        for p in self.params:
            if p.grad is not None: p.data -= self.lr * p.grad
========== FILE: learner/src/azuraforge_learner/__init__.py ==========
# ========== DOSYA: src/azuraforge_learner/__init__.py ==========
from .events import Event
from .callbacks import Callback, ModelCheckpoint, EarlyStopping
from .losses import Loss, MSELoss
from .layers import Layer, Linear, ReLU
from .models import Sequential
from .optimizers import Optimizer, SGD
from .learner import Learner

__all__ = [
    "Event", "Callback", "ModelCheckpoint", "EarlyStopping",
    "Loss", "MSELoss", "Layer", "Linear", "ReLU",
    "Sequential", "Optimizer", "SGD", "Learner",
]
========== FILE: learner/src/azuraforge_learner/utils/__init__.py ==========

========== FILE: learner/tests/azuraforge_learner/test_learner_components.py ==========
# ========== GÜNCELLENECEK DOSYA: tests\azuraforge_learner\test_learner_components.py ==========
import pytest
import numpy as np

from azuraforge_learner import Learner, Sequential, Linear, ReLU, MSELoss, SGD

def test_learner_fit_simple_regression():
    X_train = np.array([[-1.0], [0.0], [1.0], [2.0]], dtype=np.float32)
    y_train = np.array([[-1.0], [1.0], [3.0], [5.0]], dtype=np.float32)
    
    model = Sequential(Linear(1, 1))
    criterion = MSELoss()
    optimizer = SGD(model.parameters(), lr=0.1)
    learner = Learner(model, criterion, optimizer)
    
    initial_loss = learner.evaluate(X_train, y_train)['val_loss']
    
    learner.fit(X_train, y_train, epochs=30)
    
    final_loss = learner.history['loss'][-1]
    
    print(f"Initial Loss: {initial_loss}, Final Loss: {final_loss}")
    assert final_loss < initial_loss / 5

def test_sequential_model_forward_pass():
    model = Sequential(Linear(2, 4), ReLU(), Linear(4, 1))
    from azuraforge_core import Tensor
    
    input_tensor = Tensor(np.random.randn(10, 2))
    output_tensor = model(input_tensor)
    
    assert output_tensor.data.shape == (10, 1)
========== FILE: tools/snapshot_generator.py ==========
# ========== GÜNCELLENMİŞ VE DÜZELTİLMİŞ DOSYA: platform/tools/snapshot_generator.py ==========
import os
import sys
import json
import argparse
from typing import List, Dict, Any, Set, Optional, Tuple
import re

# Configuration for included/excluded paths and extensions
DEFAULT_INCLUDE_DIRS = ["."]
DEFAULT_INCLUDE_EXTENSIONS = [
    ".toml",
    ".py",
    ".yaml",
    ".yml",
    ".json",
    ".md",
    ".txt",
    "html",
    ".bat",
    ".sh",
    ".jsx",
    ".js",
    ".json",
    ".css"    
]
DEFAULT_EXCLUDE_PATTERNS = [
    "__pycache__",
    ".git",
    ".venv",
    ".vscode",
    ".idea",
    "build",
    "dist",
    "*.egg-info",
    "*.pyc",
    "*.so",
    "*.pyd",
    ".pytest_cache",
    ".mypy_cache",
    ".dataset",
    "dataset",
    ".logs",
    "logs",
    ".output",
    "output",
    "inputs",
    "outputs",
    ".tmp",
    "checkpoints",
    "reports",
    "docs/_build",
    "site",
    "node_modules",
    ".DS_Store",
    "Thumbs.db", # Windows thumbnail cache
    "*.lock", # npm lock dosyaları gibi
    "package-lock.json"
]

FILE_HEADER_TEMPLATE = "========== FILE: {file_path} =========="
SNAPSHOT_INFO_TEMPLATE = """PROJE KOD SNAPSHOT (TAM)
Toplam {total_files_placeholder} dosya bulundu ve eklendi.
Dahil Edilen Dizinler: {included_dirs_placeholder}
Dahil Edilen Uzantılar: {included_extensions_placeholder}
Hariç Tutulan Desenler/Yollar: {excluded_patterns_placeholder}
================================================================================
"""

def clean_code_comments(content: str, file_extension: str) -> str:
    """Removes most comments from code, attempting to preserve shebangs and type hints."""
    if file_extension not in [".py", ".sh", ".bat"]: return content
    lines = content.splitlines()
    cleaned_lines = []
    for line in lines:
        stripped_line = line.strip()
        if file_extension == ".py":
            # Preserve special comments like '# type:' and shebangs
            if stripped_line.startswith("# type:") or stripped_line.startswith("# noqa"): 
                cleaned_lines.append(line)
            elif stripped_line.startswith("#!/"): 
                cleaned_lines.append(line)
            # Remove inline comments
            elif "#" in line and not stripped_line.startswith("#"): 
                cleaned_lines.append(line.split("#", 1)[0].rstrip())
            # Remove full-line comments
            elif stripped_line.startswith("#"):
                continue # Skip full line comments
            else: 
                cleaned_lines.append(line)
        elif file_extension == ".sh":
            if stripped_line.startswith("#!/"): 
                cleaned_lines.append(line)
            elif not stripped_line.startswith("#"): 
                cleaned_lines.append(line)
        elif file_extension == ".bat":
            if not stripped_line.lower().startswith("rem "): 
                cleaned_lines.append(line)
        else: 
            cleaned_lines.append(line)
    return "\n".join(cleaned_lines)


def should_exclude(item_path: str, root_path: str, exclude_patterns: List[str]) -> bool:
    """Checks if a file or directory should be excluded based on the patterns."""
    normalized_item_path = os.path.normpath(item_path)
    normalized_root_path = os.path.normpath(os.path.abspath(root_path))
    
    try:
        relative_item_path = os.path.relpath(normalized_item_path, normalized_root_path)
    except ValueError:
        # If item_path is not relative to root_path (e.g., different drive on Windows)
        # or other path normalization issues, treat it as its own path.
        relative_item_path = normalized_item_path
    
    relative_item_path_slashes = relative_item_path.replace(os.sep, "/")

    for pattern in exclude_patterns:
        normalized_pattern = os.path.normpath(pattern)
        normalized_pattern_slashes = normalized_pattern.replace(os.sep, "/")

        # Wildcard extensions like "*.pyc"
        if pattern.startswith("*."):
            if relative_item_path_slashes.endswith(pattern[1:]): return True
        # Directory names or file names without path
        elif "/" not in pattern and "." not in pattern and not pattern.startswith("*"):
            path_segments = relative_item_path_slashes.split("/")
            if pattern in path_segments: return True
        # Exact file name match
        elif pattern == os.path.basename(normalized_item_path): return True
        # Full path prefix match or relative path match
        elif normalized_item_path.startswith(os.path.join(normalized_root_path, normalized_pattern)) or \
             relative_item_path_slashes.startswith(normalized_pattern_slashes): return True
        # Absolute path match
        elif os.path.isabs(normalized_pattern) and normalized_pattern == normalized_item_path: return True
    return False


def collect_project_files_full(
    output_file: str,
    include_dirs: Optional[List[str]] = None,
    include_extensions: Optional[List[str]] = None,
    exclude_patterns: Optional[List[str]] = None,
    base_dir: str = ".",
    clean_comments: bool = False,
) -> None:
    if include_dirs is None: include_dirs = DEFAULT_INCLUDE_DIRS
    if include_extensions is None: include_extensions = DEFAULT_INCLUDE_EXTENSIONS
    if exclude_patterns is None: exclude_patterns = DEFAULT_EXCLUDE_PATTERNS

    abs_base_dir = os.path.abspath(base_dir)
    
    snapshot_content_header = SNAPSHOT_INFO_TEMPLATE.format(
        total_files_placeholder="{total_files_counter}",
        included_dirs_placeholder=", ".join(include_dirs),
        included_extensions_placeholder=", ".join(include_extensions),
        excluded_patterns_placeholder=", ".join(exclude_patterns),
    )

    all_found_relative_paths: Set[str] = set() # This set stores relative paths to prevent duplicates
    content_parts: List[str] = [snapshot_content_header]
    processed_files_count = 0

    for inc_dir_pattern in include_dirs:
        current_scan_dir = os.path.abspath(os.path.join(abs_base_dir, inc_dir_pattern))
        if not os.path.exists(current_scan_dir):
            print(f"Warning: Include directory '{inc_dir_pattern}' (resolved to '{current_scan_dir}') does not exist. Skipping.")
            continue

        for root, dirs, files in os.walk(current_scan_dir, topdown=True):
            # Filter directories in-place to prevent os.walk from entering excluded ones
            dirs[:] = [
                d for d in dirs
                if not should_exclude(os.path.join(root, d), abs_base_dir, exclude_patterns)
            ]
            for file_name in files:
                file_path = os.path.join(root, file_name)

                relative_file_path = os.path.relpath(file_path, abs_base_dir)
                display_path = relative_file_path.replace(os.sep, "/")

                # Skip if already processed (e.g., if included by multiple patterns)
                if display_path in all_found_relative_paths:
                    continue 

                # Apply exclusion patterns to files
                if should_exclude(file_path, abs_base_dir, exclude_patterns):
                    continue

                _, file_extension = os.path.splitext(file_name)
                # For extension check, handle files without an explicit extension (like Dockerfile)
                name_part_for_ext_check = file_extension.lower() if file_extension else file_name.lower()

                # Check if file extension (or full name for extensionless files) is in include list
                if any(name_part_for_ext_check.endswith(ext.lower()) for ext in include_extensions) or \
                   (not file_extension and file_name.lower() in [ext.lower() for ext in include_extensions if not ext.startswith('.')]):
                    
                    all_found_relative_paths.add(display_path) # Add to set of found paths
                    try:
                        with open(file_path, "r", encoding="utf-8", errors="ignore") as f:
                            file_content = f.read()
                        
                        if clean_comments:
                            file_content = clean_code_comments(file_content, file_extension)
                        
                        # Add a leading newline for separator, then the header, then content.
                        # This creates the format: \n========== FILE:PATH==========\nCONTENT
                        content_parts.append(f"\n{FILE_HEADER_TEMPLATE.format(file_path=display_path)}\n")
                        content_parts.append(file_content)
                        processed_files_count += 1
                    except Exception as e:
                        print(f"Error reading file {relative_file_path}: {e}")
                        content_parts.append(f"\nError reading file {relative_file_path}: {e}\n")

    final_header_with_count = content_parts[0].replace("{total_files_counter}", str(processed_files_count))
    content_parts[0] = final_header_with_count

    with open(output_file, "w", encoding="utf-8") as f:
        f.write("".join(content_parts))

    print(f"Project snapshot (full) generated: {output_file}")
    print(f"Total {processed_files_count} files included.")


def restore_from_full_snapshot(
    snapshot_file: str,
    target_dir: str = ".",
    dry_run: bool = False,
    overwrite_existing: bool = False,
) -> None:
    print(f"Restoring project from snapshot: {snapshot_file}")
    if dry_run: print("DRY RUN: No files will be written.")

    try:
        with open(snapshot_file, "r", encoding="utf-8") as f:
            full_content = f.read()
    except FileNotFoundError:
        print(f"Error: Snapshot file '{snapshot_file}' not found.")
        return
    except Exception as e:
        print(f"Error reading snapshot file: {e}")
        return

    # Regex to find file blocks. It captures the file path (group 1) and its content (group 2).
    # The crucial point is that group(2) captures ALL characters (including newlines due to re.DOTALL)
    # after the header line's trailing newline, until the START of the next file header or end of string.
    # The lookahead `(?=...)` is non-consuming, so the content is captured completely.
    file_block_pattern = re.compile(
        r"^========== FILE: (.*?) ==========\n"  # Match header line and its trailing newline
        r"(.*?)"                                 # Capture content (non-greedy)
        r"(?=\n========== FILE: |\Z)",           # Lookahead: followed by newline then next header, OR end of string.
                                                # \Z matches only at the end of the string.
        re.MULTILINE | re.DOTALL
    )
    
    # Find the end of the initial info header to start parsing file blocks
    info_header_last_line = SNAPSHOT_INFO_TEMPLATE.splitlines()[-1]
    content_start_index = full_content.find(info_header_last_line)
    if content_start_index == -1:
        print("Error: Could not find the end of the snapshot info header.")
        return
    
    # Slice the content to start exactly after the info header,
    # and then lstrip any *leading* newlines that might be left before the first file block.
    # This ensures the regex for the first file block can match correctly.
    content_to_parse = full_content[content_start_index + len(info_header_last_line):].lstrip('\n')

    files_restored = 0
    files_skipped = 0
    files_overwritten = 0
    
    matches = file_block_pattern.finditer(content_to_parse)

    for match in matches:
        relative_file_path = match.group(1).strip()
        # KRİTİK DÜZELTME: match.group(2) üzerinde .strip() metodunu kaldırdık.
        # Bu, tüm boşluk karakterlerinin (yeni satırlar dahil) korunmasını sağlar.
        content_part = match.group(2) 

        os_specific_relative_path = relative_file_path.replace("/", os.sep)
        target_file_path = os.path.join(target_dir, os_specific_relative_path)
        
        # DEBUG YARDIMI: Yazılacak içeriğin uzunluğunu göster
        print(f"Processing file: {relative_file_path} (Content length: {len(content_part)}) -> {target_file_path}")

        if os.path.exists(target_file_path) and not overwrite_existing:
            print(f"  SKIPPED: File '{target_file_path}' already exists (overwrite_existing is False).")
            files_skipped += 1
            continue

        if os.path.exists(target_file_path) and overwrite_existing:
            print(f"  OVERWRITING: File '{target_file_path}'.")
            files_overwritten += 1

        if not dry_run:
            try:
                os.makedirs(os.path.dirname(target_file_path), exist_ok=True)
                with open(target_file_path, "w", encoding="utf-8") as f:
                    f.write(content_part)
                files_restored += 1
            except Exception as e:
                print(f"  ERROR: Could not write file '{target_file_path}': {e}")
        else:
            if not os.path.exists(os.path.dirname(target_file_path)):
                print(f"  DRY RUN: Would create directory {os.path.dirname(target_file_path)}")
            print(f"  DRY RUN: Would write {len(content_part)} bytes to {target_file_path}")
            files_restored += 1

    print("\n--- Restoration Summary ---")
    print(f"Files processed for restoration: {files_restored}")
    if not dry_run:
        print(f"Files actually written/overwritten: {files_restored - files_skipped}")
        print(f"Files overwritten: {files_overwritten}")
    print(f"Files skipped (already exist and overwrite=False): {files_skipped}")


def main():
    parser = argparse.ArgumentParser(description="Project Snapshot Tool (Full Version)")
    subparsers = parser.add_subparsers(dest="command", required=True)

    parser_collect = subparsers.add_parser(
        "collect", help="Collect project files into a single snapshot file."
    )
    parser_collect.add_argument(
        "output_file",
        type=str,
        default="project_snapshot_full.txt",
        nargs="?",
        help="Path to the output snapshot file (default: project_snapshot_full.txt)",
    )
    parser_collect.add_argument(
        "--include-dir",
        action="append",
        dest="include_dirs",
        help="Directory to include (relative to base_dir or absolute). Can be used multiple times. Defaults to ['.']",
    )
    parser_collect.add_argument(
        "--include-ext",
        action="append",
        dest="include_extensions",
        help="File extension to include (e.g., .py, .md). Can be used multiple times. Defaults to common code/config extensions.",
    )
    parser_collect.add_argument(
        "--exclude-pattern",
        action="append",
        dest="exclude_patterns",
        help="Pattern/path to exclude. Can be used multiple times. Defaults to common ignores.",
    )
    parser_collect.add_argument(
        "--base-dir",
        type=str,
        default=".",
        help="Base directory for the project (default: current directory). Relative paths are resolved against this.",
    )
    parser_collect.add_argument(
        "--clean-comments",
        action="store_true",
        help="Attempt to remove comments from collected code files (.py, .sh, .bat).",
    )

    parser_restore = subparsers.add_parser(
        "restore", help="Restore project files from a snapshot."
    )
    parser_restore.add_argument(
        "snapshot_file", type=str, help="Path to the snapshot file to restore from."
    )
    parser_restore.add_argument(
        "--target-dir",
        type=str,
        default=".",
        help="Directory where files will be restored (default: current directory).",
    )
    parser_restore.add_argument(
        "--dry-run",
        action="store_true",
        help="Simulate restoration without writing any files.",
    )
    parser_restore.add_argument(
        "--overwrite",
        action="store_true",
        dest="overwrite_existing",
        help="Overwrite files if they already exist in the target directory.",
    )

    args = parser.parse_args()

    if args.command == "collect":
        final_include_dirs = (
            args.include_dirs if args.include_dirs is not None else DEFAULT_INCLUDE_DIRS
        )
        final_include_extensions = (
            args.include_extensions
            if args.include_extensions is not None
            else DEFAULT_INCLUDE_EXTENSIONS
        )
        final_exclude_patterns = (
            args.exclude_patterns
            if args.exclude_patterns is not None
            else DEFAULT_EXCLUDE_PATTERNS
        )
        collect_project_files_full(
            output_file=args.output_file,
            include_dirs=final_include_dirs,
            include_extensions=final_include_extensions,
            exclude_patterns=final_exclude_patterns,
            base_dir=args.base_dir,
            clean_comments=args.clean_comments,
        )
    elif args.command == "restore":
        restore_from_full_snapshot(
            snapshot_file=args.snapshot_file,
            target_dir=args.target_dir,
            dry_run=args.dry_run,
            overwrite_existing=args.overwrite_existing,
        )


if __name__ == "__main__":
    # Example usage:
    # python tools/snapshot_generator.py collect project_full_snapshot.txt
    # python tools/snapshot_generator.py restore project_full_snapshot.txt --dry-run   
    # python tools/snapshot_generator.py restore project_full_snapshot.txt --overwrite
    print("Project Snapshot Tool (Full Version)")
    print("Collects project files into a single snapshot file or restores from a snapshot.")
    print("Use 'collect' to create a snapshot and 'restore' to restore files from it.")    
    main()
========== FILE: worker/pyproject.toml ==========
# ========== DOSYA: worker/pyproject.toml ==========
[build-system]
requires = ["setuptools>=61.0"]
build-backend = "setuptools.build_meta"

[project]
name = "azuraforge-worker"
version = "0.1.0"
description = "The Celery worker for the AzuraForge Platform. Discovers and runs pipeline plugins."
requires-python = ">=3.8"
dependencies = [
    # Worker'ın kendisi doğrudan Learner'a değil, eklentilere ihtiyaç duyar.
    # Eklentiler zaten Learner'a bağımlı olduğu için, pip bunu çözecektir.
    
    # Geliştirme ve test sırasında bu eklentinin kurulu olmasını sağlıyoruz.
    # Canlı bir ortamda, hangi eklentilerin kurulacağı bir konfigürasyon dosyası ile yönetilir.
    "azuraforge-app-stock-predictor @ git+https://github.com/AzuraForge/app-stock-predictor.git@main",
    
    "celery[redis]",
    "pyyaml",
]

[project.scripts]
start-worker = "azuraforge_worker.main:run_celery_worker"
========== FILE: worker/README.md ==========
# worker
========== FILE: worker/setup.py ==========
# ========== DOSYA: worker/setup.py ==========
from setuptools import setup, find_packages

setup(
    package_dir={"": "src"},
    packages=find_packages(where="src"),
)
========== FILE: worker/src/azuraforge_worker/celery_app.py ==========
# ========== DOSYA: src/azuraforge_worker/celery_app.py ==========
from celery import Celery
import os

REDIS_URL = os.getenv("REDIS_URL", "redis://localhost:6379/0")

celery_app = Celery(
    "azuraforge_worker",
    broker=REDIS_URL,
    backend=REDIS_URL,
    # Worker başladığında görevlerin nerede olduğunu belirtir.
    include=["azuraforge_worker.tasks.training_tasks"]
)
========== FILE: worker/src/azuraforge_worker/main.py ==========
# ========== DOSYA: src/azuraforge_worker/main.py ==========
import subprocess
import sys

def run_celery_worker():
    """'start-worker' komutu için giriş noktası."""
    print("👷‍♂️ Starting AzuraForge Worker...")
    command = [
        sys.executable, "-m", "celery",
        "-A", "azuraforge_worker.celery_app:celery_app", # Celery app nesnesinin tam yolu
        "worker",
        "--pool=solo", # Windows uyumluluğu üretim için prefork kullanın
        "--loglevel=INFO"
    ]
    subprocess.run(command)
========== FILE: worker/src/azuraforge_worker/__init__.py ==========
# ========== DOSYA: worker/src/azuraforge_worker/__init__.py ==========
from .celery_app import celery_app

# Bu, diğer projelerin 'from azuraforge_worker import celery_app' yapabilmesini sağlar.
__all__ = ("celery_app",)
========== FILE: worker/src/azuraforge_worker/tasks/training_tasks.py ==========
# ========== DOSYA: worker/src/azuraforge_worker/tasks/training_tasks.py ==========
import logging
import os
import json
from datetime import datetime
from importlib.metadata import entry_points
from celery import current_task # Görevin durumunu güncellemek için
import time # Simülasyon için
import traceback # Hata detaylarını yakalamak için

from ..celery_app import celery_app
# applications reposundan pipeline'ı import etmek için bu kodun olduğu yerde değil,
# pip tarafından paket olarak kurulmuş azuraforge_stockapp'tan import edilecek.

# --- Eklenti Keşfi ---
def discover_pipelines():
    """Sisteme kurulmuş tüm AzuraForge pipeline'larını keşfeder."""
    logging.info("Worker: Discovering installed AzuraForge pipeline plugins...")
    discovered = {}
    try:
        eps = entry_points(group='azuraforge.pipelines')
        for ep in eps:
            logging.info(f"Worker: Found plugin: '{ep.name}' -> points to '{ep.value}'")
            discovered[ep.name] = ep.load() 
    except Exception as e:
        logging.error(f"Worker: Error discovering pipelines: {e}", exc_info=True)
    return discovered

AVAILABLE_PIPELINES = discover_pipelines()
if not AVAILABLE_PIPELINES:
    logging.warning("Worker: No AzuraForge pipelines found! Please install a pipeline plugin, e.g., 'azuraforge-app-stock-predictor'.")

REPORTS_BASE_DIR = os.path.abspath(os.getenv("REPORTS_DIR", "/app/reports"))
os.makedirs(REPORTS_BASE_DIR, exist_ok=True) # Dizinin var olduğundan emin ol

@celery_app.task(bind=True, name="start_training_pipeline")
def start_training_pipeline(self, config: dict):
    pipeline_name = config.get("pipeline_name")
    if not pipeline_name or pipeline_name not in AVAILABLE_PIPELINES:
        raise ValueError(f"Pipeline '{pipeline_name}' not found or installed.")

    # --- Deney için benzersiz bir klasör ve ID oluştur ---
    run_timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    experiment_id = f"{pipeline_name}_{run_timestamp}_{self.request.id}" 
    
    pipeline_specific_report_dir = os.path.join(REPORTS_BASE_DIR, pipeline_name)
    os.makedirs(pipeline_specific_report_dir, exist_ok=True)
    experiment_dir = os.path.join(pipeline_specific_report_dir, experiment_id)
    os.makedirs(experiment_dir, exist_ok=True)
    
    config['experiment_id'] = experiment_id
    config['task_id'] = self.request.id
    config['experiment_dir'] = experiment_dir

    PipelineClass = AVAILABLE_PIPELINES[pipeline_name]
    logging.info(f"Worker: Instantiating pipeline '{PipelineClass.__name__}' for experiment {experiment_id}")
    
    initial_report_data = {
        "task_id": self.request.id, "experiment_id": experiment_id, "status": "STARTED", "config": config, "results": {}
    }
    with open(os.path.join(experiment_dir, "results.json"), 'w') as f:
        json.dump(initial_report_data, f, indent=4, default=str)

    try:
        # --- KRİTİK DÜZELTME: Pipeline'a Celery Task objesini iletiyoruz ---
        # Bu, pipeline'ın içindeki Learner'ın Celery state'i güncelleyebilmesini sağlar.
        pipeline_instance = PipelineClass(config, celery_task=self) # <- Yeni parametre
        results = pipeline_instance.run() 

        final_report_data = {
            "task_id": self.request.id, "experiment_id": experiment_id, "status": "SUCCESS", "config": config, "results": results, "completed_at": datetime.now().isoformat()
        }
        with open(os.path.join(experiment_dir, "results.json"), 'w') as f:
            json.dump(final_report_data, f, indent=4, default=str)
            
        logging.info(f"Worker: Task {self.request.id} for pipeline '{pipeline_name}' completed successfully. Results in {experiment_dir}")
        return final_report_data

    except Exception as e:
        error_traceback = traceback.format_exc()
        error_message = f"Pipeline execution failed for {pipeline_name}: {e}\n{error_traceback}"
        logging.error(error_message)
        
        self.update_state(state='FAILURE', meta={'error_message': str(e), 'traceback': error_traceback})
        
        error_report_data = {
            "task_id": self.request.id, "experiment_id": experiment_id, "status": "FAILURE", "config": config, "error": error_message, "failed_at": datetime.now().isoformat()
        }
        with open(os.path.join(experiment_dir, "results.json"), 'w') as f:
            json.dump(error_report_data, f, indent=4)
            
        raise e
========== FILE: worker/src/azuraforge_worker/tasks/__init__.py ==========
